{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e08b866-f6c3-4b4c-8185-0e847a2568e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rasa/PycharmProjects/reversiProject/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19fdeba6-0cdc-4fa8-8ebb-b6d5634034d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, sync_envs_normalization\n",
    "\n",
    "import stable_baselines3.common.callbacks as callbacks_module\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy as masked_evaluate_policy\n",
    "\n",
    "# Modify the namespace of EvalCallback directly\n",
    "callbacks_module.evaluate_policy = masked_evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "# from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "# from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "from shutil import copyfile # keep track of generations\n",
    "from collections import OrderedDict\n",
    "\n",
    "from gymnasium.spaces import Discrete, Box, Dict, MultiDiscrete\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "import gymnasium.spaces as spaces\n",
    "from game_logic import Othello\n",
    "import numpy as np\n",
    "import os, math\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23086ab8-3197-4112-9877-fcdb52f351ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "SEED = 19\n",
    "NUM_TIMESTEPS = int(30_000_000)\n",
    "EVAL_FREQ = int(10_000)\n",
    "EVAL_EPISODES = int(100)\n",
    "BEST_THRESHOLD = 0.20 # must achieve a mean score above this to replace prev best self\n",
    "\n",
    "RENDER_MODE = False # set this to false if you plan on running for full 1000 trials.\n",
    "\n",
    "LOGDIR = \"ppo_masked_selfplay_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015cd09b-673e-4145-b7b9-2c22763c0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OthelloEnv(gym.Env):   \n",
    "    def __init__(self):\n",
    "        self.game = Othello()\n",
    "        self.agent_turn = 1\n",
    "        shape = self.game.board.shape  \n",
    "        self.action_mapping = self.am(shape)\n",
    "        self.action_space = Discrete(shape[0] * shape[1])  # sample - [x, y]\n",
    "        self.observation_space = Dict({\n",
    "                                        'board' : Box(0, 2, shape=shape, dtype=int), \n",
    "                                        'player': Discrete(2, start=1)\n",
    "                                      })        \n",
    "        self.other_agent = None\n",
    "        self.reset_othello_gen = self.reset_othello()    \n",
    "        self.episodes = 0    \n",
    "    \n",
    "\n",
    "    def am(self, shape):\n",
    "        x, y = shape\n",
    "        return [(n//x, n%x) for n in range(x * y)]\n",
    "        \n",
    "\n",
    "    def reset_othello(self):\n",
    "        '''resets game to starting position \n",
    "           and also changes starting player alternatively'''\n",
    "        infinite_player_turn = cycle([1, 2])\n",
    "        while True:\n",
    "            game = Othello()\n",
    "            model_turn = next(infinite_player_turn)\n",
    "            yield game, model_turn\n",
    "    \n",
    "    def change_to_latest_agent(self, agent):\n",
    "        self.other_agent = agent\n",
    "\n",
    "    def get_obs(self):\n",
    "        return OrderedDict({\n",
    "            'board' : self.game.board,\n",
    "            'player': self.game.player_turn\n",
    "        })\n",
    "        \n",
    "    def check_game_ended(self):\n",
    "        reward = 0\n",
    "        done = False\n",
    "        winner = self.game.get_winner()\n",
    "        if winner is not None:\n",
    "            self.episodes += 1\n",
    "            # if self.episodes % 10000 == 0:\n",
    "            #     print(f'Ep done - {self.episodes}.')\n",
    "            \n",
    "            done = True\n",
    "            if winner == self.agent_turn:\n",
    "                reward = 1\n",
    "            elif winner == 3 - self.agent_turn: #  other agent turn/figure\n",
    "                reward = -1\n",
    "        return reward, done\n",
    "    \n",
    "    def render(self):  # todo \n",
    "        pass\n",
    "\n",
    "    def close(self):  # todo\n",
    "        pass\n",
    "\n",
    "    def other_agent_play_move(self): \n",
    "        obs = spaces.flatten(self.observation_space, self.get_obs())#  need to flatten observation         \n",
    "        action, _ = self.other_agent.predict(obs, action_masks=self.action_masks()) \n",
    "        game_action = self.action_mapping[action]\n",
    "        self.game.play_move(game_action)\n",
    "\n",
    "    def step(self, action):\n",
    "        game_action = self.action_mapping[action]\n",
    "        self.game.play_move(game_action)\n",
    "\n",
    "        # do self play\n",
    "        while self.game.get_winner() is None and self.game.player_turn != self.agent_turn: #  if game hasnt ended do moves if opponent doesnt have one \n",
    "            self.other_agent_play_move()\n",
    "\n",
    "        reward, done = self.check_game_ended()\n",
    "        info = {}\n",
    "        truncated = False\n",
    "\n",
    "                \n",
    "        # Return step information\n",
    "        return self.get_obs(), reward, done, truncated, info\n",
    "    \n",
    "    def reset(self, *args, **kwargs):\n",
    "        self.game, self.agent_turn = next(self.reset_othello_gen)\n",
    "        if self.agent_turn == 2:\n",
    "            self.other_agent_play_move()\n",
    "        return self.get_obs(), None\n",
    "\n",
    "    def action_masks(self):        \n",
    "        valid_moves = self.game.valid_moves()\n",
    "    \n",
    "        mask = np.zeros(self.game.board.shape, dtype=bool)\n",
    "        \n",
    "        # Set True for each index in the set\n",
    "        for index in valid_moves:\n",
    "            mask[index] = True\n",
    "        mask.flatten()\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdecf41-ef1c-4f12-bbc7-02d06ce2a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfPlayCallback(EvalCallback):\n",
    "    # hacked it to only save new version offrom gymnasium.wrappers import FlattenObservation best model if beats prev self by BEST_THRESHOLD score\n",
    "    # after saving model, resets the best score to be BEST_THRESHOLD\n",
    "    def __init__(self, train_env, eval_env, *args, **kwargs):\n",
    "        super().__init__(eval_env, *args, **kwargs)\n",
    "        self.best_mean_reward = BEST_THRESHOLD\n",
    "        self.generation = 0\n",
    "        self.train_env = train_env\n",
    "        self.eval_env = eval_env\n",
    "    def _on_step(self) -> bool:\n",
    "        # result = super()._on_step() #  eval needs to be masked, its less efficient \n",
    "        result = super()._on_step()\n",
    "        \n",
    "        if result and self.best_mean_reward > BEST_THRESHOLD:\n",
    "            self.generation += 1\n",
    "            print(\"SELFPLAY: mean_reward achieved:\", self.best_mean_reward)\n",
    "            print(\"SELFPLAY: new best model, bumping up generation to\", self.generation)            \n",
    "            source_file = os.path.join(LOGDIR, \"best_model.zip\")\n",
    "            backup_file = os.path.join(LOGDIR, \"history_\"+str(self.generation).zfill(8)+\".zip\")\n",
    "            copyfile(source_file, backup_file)\n",
    "            self.best_mean_reward = BEST_THRESHOLD\n",
    "            agent = self.model.load(source_file)\n",
    "            self.train_env.unwrapped.change_to_latest_agent(agent)            \n",
    "            self.eval_env.envs[0].unwrapped.change_to_latest_agent(agent)      \n",
    "        return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200cff4-ce58-4527-a24c-5db541c62ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rasa/Desktop/jupyter/rl demo/ml-venv/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.0588  |\n",
      "| time/              |          |\n",
      "|    fps             | 461      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030008513 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 45070       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.3       |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 365        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03048275 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.357     |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0781     |\n",
      "|    n_updates            | 45080      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 354         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031719245 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.352      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0519      |\n",
      "|    n_updates            | 45090       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.20 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026929956 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 45100       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.5     |\n",
      "|    ep_rew_mean     | 0.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031123046 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 45110       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032894667 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0573      |\n",
      "|    n_updates            | 45120       |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028290719 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 45130       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029343698 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0627      |\n",
      "|    n_updates            | 45140       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-0.11 +/- 0.99\n",
      "Episode length: 29.68 +/- 2.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027118914 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0483      |\n",
      "|    n_updates            | 45150       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 80         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02634383 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.327     |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0495     |\n",
      "|    n_updates            | 45160      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 86         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03110349 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.336     |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0133     |\n",
      "|    n_updates            | 45170      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026918782 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0468      |\n",
      "|    n_updates            | 45180       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028900994 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0612      |\n",
      "|    n_updates            | 45190       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.11 +/- 0.98\n",
      "Episode length: 30.00 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 30000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02418431 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.336     |\n",
      "|    explained_variance   | 0.317      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0106     |\n",
      "|    n_updates            | 45200      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027688064 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 45210       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027120532 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 45220       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026052607 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0336      |\n",
      "|    n_updates            | 45230       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026557835 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 45240       |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.04 +/- 1.00\n",
      "Episode length: 30.02 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027778784 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00944    |\n",
      "|    n_updates            | 45250       |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030080877 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 45260       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032541342 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0556      |\n",
      "|    n_updates            | 45270       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030786932 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0156      |\n",
      "|    n_updates            | 45280       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024502842 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 45290       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-0.01 +/- 0.99\n",
      "Episode length: 30.03 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027924633 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0155      |\n",
      "|    n_updates            | 45300       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 185      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031019948 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00719     |\n",
      "|    n_updates            | 45310       |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025696646 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 45320       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 203        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02895089 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.287     |\n",
      "|    explained_variance   | 0.288      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0227     |\n",
      "|    n_updates            | 45330      |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031495098 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0281      |\n",
      "|    n_updates            | 45340       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.25 +/- 0.96\n",
      "Episode length: 29.96 +/- 0.40\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 60000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02688405 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.291     |\n",
      "|    explained_variance   | 0.124      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0274     |\n",
      "|    n_updates            | 45350      |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024097402 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 45360       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034550402 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 45370       |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 240        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02948853 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.306     |\n",
      "|    explained_variance   | 0.29       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0192     |\n",
      "|    n_updates            | 45380      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.4       |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 245        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02425195 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.312     |\n",
      "|    explained_variance   | 0.324      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0408     |\n",
      "|    n_updates            | 45390      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.221      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.84 +/- 2.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028694931 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0616      |\n",
      "|    n_updates            | 45400       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 279      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 256      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028779624 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 45410       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033554457 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0664      |\n",
      "|    n_updates            | 45420       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.1       |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 272        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03106945 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.264      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0651     |\n",
      "|    n_updates            | 45430      |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030764759 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 45440       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.09 +/- 0.98\n",
      "Episode length: 29.20 +/- 3.90\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.2       |\n",
      "|    mean_reward          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 80000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03276044 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.331      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0665     |\n",
      "|    n_updates            | 45450      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 283      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029527972 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0525      |\n",
      "|    n_updates            | 45460       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.4       |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02646843 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.297     |\n",
      "|    explained_variance   | 0.242      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0579     |\n",
      "|    n_updates            | 45470      |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031812575 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00287    |\n",
      "|    n_updates            | 45480       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 28.97 +/- 4.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023744669 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 45490       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 285      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028569873 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00353    |\n",
      "|    n_updates            | 45500       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037586533 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0535      |\n",
      "|    n_updates            | 45510       |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.1       |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 331        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02872134 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0.321      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0493     |\n",
      "|    n_updates            | 45520      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.5       |\n",
      "|    ep_rew_mean          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 337        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03441725 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0477     |\n",
      "|    n_updates            | 45530      |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 29.60 +/- 2.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.6        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027613152 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00714     |\n",
      "|    n_updates            | 45540       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030095214 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0488      |\n",
      "|    n_updates            | 45550       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028455084 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 45560       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028183723 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0378      |\n",
      "|    n_updates            | 45570       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029795628 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0331      |\n",
      "|    n_updates            | 45580       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=0.09 +/- 0.97\n",
      "Episode length: 29.91 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030840468 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0376      |\n",
      "|    n_updates            | 45590       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 290      |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 380      |\n",
      "|    total_timesteps | 110592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032211088 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0269      |\n",
      "|    n_updates            | 45600       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028460743 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0338      |\n",
      "|    n_updates            | 45610       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026535511 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0136      |\n",
      "|    n_updates            | 45620       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022330025 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0203      |\n",
      "|    n_updates            | 45630       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=0.06 +/- 0.98\n",
      "Episode length: 29.56 +/- 2.96\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.6       |\n",
      "|    mean_reward          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 120000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03416285 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.325     |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0268     |\n",
      "|    n_updates            | 45640      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 292      |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 412      |\n",
      "|    total_timesteps | 120832   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024185184 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 45650       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027205626 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.045       |\n",
      "|    n_updates            | 45660       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026742026 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0688      |\n",
      "|    n_updates            | 45670       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020116009 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 45680       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=0.20 +/- 0.97\n",
      "Episode length: 29.82 +/- 2.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028629992 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0806      |\n",
      "|    n_updates            | 45690       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.42     |\n",
      "| time/              |          |\n",
      "|    fps             | 294      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 445      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025913376 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00874     |\n",
      "|    n_updates            | 45700       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 456        |\n",
      "|    total_timesteps      | 135168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02181954 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.27      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0443     |\n",
      "|    n_updates            | 45710      |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 297        |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 461        |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03144283 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.28      |\n",
      "|    explained_variance   | 0.389      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0422     |\n",
      "|    n_updates            | 45720      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.03      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 298       |\n",
      "|    iterations           | 68        |\n",
      "|    time_elapsed         | 466       |\n",
      "|    total_timesteps      | 139264    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0260182 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.283    |\n",
      "|    explained_variance   | 0.36      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0517    |\n",
      "|    n_updates            | 45730     |\n",
      "|    policy_gradient_loss | -0.0281   |\n",
      "|    value_loss           | 0.206     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.99 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024000563 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 45740       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 295      |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 477      |\n",
      "|    total_timesteps | 141312   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026114246 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 45750       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028944656 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00779     |\n",
      "|    n_updates            | 45760       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 493        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02539793 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.265     |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0214     |\n",
      "|    n_updates            | 45770      |\n",
      "|    policy_gradient_loss | -0.0273    |\n",
      "|    value_loss           | 0.166      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031591155 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0397      |\n",
      "|    n_updates            | 45780       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 30.04 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027460128 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 45790       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.34     |\n",
      "| time/              |          |\n",
      "|    fps             | 296      |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 510      |\n",
      "|    total_timesteps | 151552   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030736336 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0431      |\n",
      "|    n_updates            | 45800       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023686685 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0332      |\n",
      "|    n_updates            | 45810       |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 526        |\n",
      "|    total_timesteps      | 157696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02826104 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.242     |\n",
      "|    explained_variance   | 0.382      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0603     |\n",
      "|    n_updates            | 45820      |\n",
      "|    policy_gradient_loss | -0.0264    |\n",
      "|    value_loss           | 0.15       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023754619 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.242      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0708      |\n",
      "|    n_updates            | 45830       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.28 +/- 0.94\n",
      "Episode length: 29.96 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027320769 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.246      |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 45840       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.28\n",
      "SELFPLAY: new best model, bumping up generation to 3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.3      |\n",
      "| time/              |          |\n",
      "|    fps             | 298      |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 542      |\n",
      "|    total_timesteps | 161792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029113792 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0699      |\n",
      "|    n_updates            | 45850       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 553         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028238136 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 45860       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033435345 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.213      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0583      |\n",
      "|    n_updates            | 45870       |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023944788 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0236      |\n",
      "|    n_updates            | 45880       |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=0.27 +/- 0.96\n",
      "Episode length: 30.01 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 170000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022410944 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0224      |\n",
      "|    n_updates            | 45890       |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.27\n",
      "SELFPLAY: new best model, bumping up generation to 4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 298      |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 575      |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 580         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029821139 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0461      |\n",
      "|    n_updates            | 45900       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027986448 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0841      |\n",
      "|    n_updates            | 45910       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030381992 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0194      |\n",
      "|    n_updates            | 45920       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=0.22 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027772533 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 45930       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 298      |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 602      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 608         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032724306 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0219      |\n",
      "|    n_updates            | 45940       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 613         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026688047 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00529     |\n",
      "|    n_updates            | 45950       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030633083 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.068       |\n",
      "|    n_updates            | 45960       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.05      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 301        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 624        |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03153345 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.334     |\n",
      "|    explained_variance   | 0.348      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00311   |\n",
      "|    n_updates            | 45970      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=0.07 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031177115 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0679      |\n",
      "|    n_updates            | 45980       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 299      |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 635      |\n",
      "|    total_timesteps | 190464   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 300        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 640        |\n",
      "|    total_timesteps      | 192512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02707396 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0428     |\n",
      "|    n_updates            | 45990      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.09      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 301        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 645        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02772321 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.316      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0273     |\n",
      "|    n_updates            | 46000      |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 651         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034182504 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 46010       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 656        |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02937428 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.316     |\n",
      "|    explained_variance   | 0.305      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.045      |\n",
      "|    n_updates            | 46020      |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-0.02 +/- 0.99\n",
      "Episode length: 30.02 +/- 0.45\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30        |\n",
      "|    mean_reward          | -0.02     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 200000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0330337 |\n",
      "|    clip_fraction        | 0.171     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.345    |\n",
      "|    explained_variance   | 0.297     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0258    |\n",
      "|    n_updates            | 46030     |\n",
      "|    policy_gradient_loss | -0.0364   |\n",
      "|    value_loss           | 0.208     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 300      |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 667      |\n",
      "|    total_timesteps | 200704   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031277448 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0724      |\n",
      "|    n_updates            | 46040       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 678         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025502022 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0477      |\n",
      "|    n_updates            | 46050       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 683         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025953889 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0743      |\n",
      "|    n_updates            | 46060       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 689         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026569862 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00534    |\n",
      "|    n_updates            | 46070       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=0.14 +/- 0.97\n",
      "Episode length: 29.94 +/- 0.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029908529 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 46080       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 301      |\n",
      "|    iterations      | 103      |\n",
      "|    time_elapsed    | 700      |\n",
      "|    total_timesteps | 210944   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 705         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030763632 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00754     |\n",
      "|    n_updates            | 46090       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026468363 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.043       |\n",
      "|    n_updates            | 46100       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 716         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028708603 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0341      |\n",
      "|    n_updates            | 46110       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022143781 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 46120       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-0.01 +/- 0.99\n",
      "Episode length: 29.94 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030611789 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.046       |\n",
      "|    n_updates            | 46130       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 301      |\n",
      "|    iterations      | 108      |\n",
      "|    time_elapsed    | 732      |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.7       |\n",
      "|    ep_rew_mean          | 0.28       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 738        |\n",
      "|    total_timesteps      | 223232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03534921 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.291     |\n",
      "|    explained_variance   | 0.18       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0478     |\n",
      "|    n_updates            | 46140      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.226      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 743         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023422938 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 46150       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 748         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024814282 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0733      |\n",
      "|    n_updates            | 46160       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 754         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023586156 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0416      |\n",
      "|    n_updates            | 46170       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=0.20 +/- 0.96\n",
      "Episode length: 30.00 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026799314 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 46180       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 302      |\n",
      "|    iterations      | 113      |\n",
      "|    time_elapsed    | 765      |\n",
      "|    total_timesteps | 231424   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 770         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025891222 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0393      |\n",
      "|    n_updates            | 46190       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 776         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023661936 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0454      |\n",
      "|    n_updates            | 46200       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 781         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028282959 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0312      |\n",
      "|    n_updates            | 46210       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 786         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024601713 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0456      |\n",
      "|    n_updates            | 46220       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.23 +/- 0.95\n",
      "Episode length: 30.03 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025438596 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 46230       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 6\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 302      |\n",
      "|    iterations      | 118      |\n",
      "|    time_elapsed    | 797      |\n",
      "|    total_timesteps | 241664   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 803         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025477694 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0478      |\n",
      "|    n_updates            | 46240       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 808         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031585895 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0134      |\n",
      "|    n_updates            | 46250       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | -0.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 121       |\n",
      "|    time_elapsed         | 813       |\n",
      "|    total_timesteps      | 247808    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0275433 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.341    |\n",
      "|    explained_variance   | 0.223     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0369    |\n",
      "|    n_updates            | 46260     |\n",
      "|    policy_gradient_loss | -0.0324   |\n",
      "|    value_loss           | 0.229     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 819        |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02770866 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.352     |\n",
      "|    explained_variance   | 0.194      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00487    |\n",
      "|    n_updates            | 46270      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028050233 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.362      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 46280       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 303      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 830      |\n",
      "|    total_timesteps | 251904   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 835         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026923273 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0228      |\n",
      "|    n_updates            | 46290       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 841         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029282358 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0751      |\n",
      "|    n_updates            | 46300       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.07      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 846        |\n",
      "|    total_timesteps      | 258048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03247322 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.291      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0344     |\n",
      "|    n_updates            | 46310      |\n",
      "|    policy_gradient_loss | -0.0346    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=0.04 +/- 0.98\n",
      "Episode length: 30.05 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028769743 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0573      |\n",
      "|    n_updates            | 46320       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 303      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 857      |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.23      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 303       |\n",
      "|    iterations           | 128       |\n",
      "|    time_elapsed         | 862       |\n",
      "|    total_timesteps      | 262144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0267953 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.324    |\n",
      "|    explained_variance   | 0.337     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0414    |\n",
      "|    n_updates            | 46330     |\n",
      "|    policy_gradient_loss | -0.0329   |\n",
      "|    value_loss           | 0.163     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 868        |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02734696 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00942    |\n",
      "|    n_updates            | 46340      |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 873         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023396585 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00464     |\n",
      "|    n_updates            | 46350       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 879        |\n",
      "|    total_timesteps      | 268288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02720929 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.337     |\n",
      "|    explained_variance   | 0.144      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0145     |\n",
      "|    n_updates            | 46360      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 270000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02469056 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0338     |\n",
      "|    n_updates            | 46370      |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 303      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 890      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 895        |\n",
      "|    total_timesteps      | 272384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02650658 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.344     |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0709     |\n",
      "|    n_updates            | 46380      |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 0.222      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028388094 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 46390       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 906         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027001986 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0193      |\n",
      "|    n_updates            | 46400       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 911         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023068905 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.053       |\n",
      "|    n_updates            | 46410       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 30.03 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026803415 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 46420       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 922      |\n",
      "|    total_timesteps | 280576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 927        |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03191147 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.317     |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0535     |\n",
      "|    n_updates            | 46430      |\n",
      "|    policy_gradient_loss | -0.0332    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028290417 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0382      |\n",
      "|    n_updates            | 46440       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 938         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030597417 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0394      |\n",
      "|    n_updates            | 46450       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 943         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027172089 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000473    |\n",
      "|    n_updates            | 46460       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 29.91 +/- 0.38\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 290000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02379321 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.355      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0626     |\n",
      "|    n_updates            | 46470      |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 954      |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 960         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024037246 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 46480       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 965         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027995411 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00171     |\n",
      "|    n_updates            | 46490       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 971         |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024712695 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0344      |\n",
      "|    n_updates            | 46500       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 976         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024761807 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 46510       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=0.11 +/- 0.97\n",
      "Episode length: 29.96 +/- 0.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 300000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02489454 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.024      |\n",
      "|    n_updates            | 46520      |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    value_loss           | 0.161      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 987      |\n",
      "|    total_timesteps | 301056   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 992         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024852596 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0322      |\n",
      "|    n_updates            | 46530       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 998         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028962448 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.061       |\n",
      "|    n_updates            | 46540       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028734569 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0524      |\n",
      "|    n_updates            | 46550       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 1009        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024278592 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0268      |\n",
      "|    n_updates            | 46560       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=0.23 +/- 0.96\n",
      "Episode length: 30.01 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029212914 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00944     |\n",
      "|    n_updates            | 46570       |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 7\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 152      |\n",
      "|    time_elapsed    | 1020     |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 1025        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030233953 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0124      |\n",
      "|    n_updates            | 46580       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 1031        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025825482 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0295      |\n",
      "|    n_updates            | 46590       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 1036        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027514383 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 46600       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 1041        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031555183 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0465      |\n",
      "|    n_updates            | 46610       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-0.05 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026692124 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 46620       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 1053     |\n",
      "|    total_timesteps | 321536   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 1058       |\n",
      "|    total_timesteps      | 323584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02274064 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.293      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0302     |\n",
      "|    n_updates            | 46630      |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 1063        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025618996 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 46640       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 1069        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031565156 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0543      |\n",
      "|    n_updates            | 46650       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 1074        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029483052 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0367      |\n",
      "|    n_updates            | 46660       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 29.92 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026347967 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0545      |\n",
      "|    n_updates            | 46670       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 162      |\n",
      "|    time_elapsed    | 1085     |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 1091        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025967883 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00819     |\n",
      "|    n_updates            | 46680       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 1096        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028486326 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0146      |\n",
      "|    n_updates            | 46690       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.29       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 165        |\n",
      "|    time_elapsed         | 1102       |\n",
      "|    total_timesteps      | 337920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02529613 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.243     |\n",
      "|    explained_variance   | 0.367      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0261     |\n",
      "|    n_updates            | 46700      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.143      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 1107        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024938043 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0743      |\n",
      "|    n_updates            | 46710       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=0.29 +/- 0.95\n",
      "Episode length: 29.97 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031415015 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0354      |\n",
      "|    n_updates            | 46720       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.29\n",
      "SELFPLAY: new best model, bumping up generation to 8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 167      |\n",
      "|    time_elapsed    | 1118     |\n",
      "|    total_timesteps | 342016   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 1124        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021543875 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0535      |\n",
      "|    n_updates            | 46730       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 1129        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022907242 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 46740       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 1135        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026229892 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 46750       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-0.06 +/- 0.99\n",
      "Episode length: 29.88 +/- 1.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023508891 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0441      |\n",
      "|    n_updates            | 46760       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 1146     |\n",
      "|    total_timesteps | 350208   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 1151        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023575585 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0575      |\n",
      "|    n_updates            | 46770       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 1156        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027093286 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0295      |\n",
      "|    n_updates            | 46780       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 1162        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027049297 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00708    |\n",
      "|    n_updates            | 46790       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 1167        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028484365 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0628      |\n",
      "|    n_updates            | 46800       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=0.20 +/- 0.96\n",
      "Episode length: 30.03 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 360000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035416935 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 46810       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 1178     |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 1184        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030996557 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0137      |\n",
      "|    n_updates            | 46820       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 1189        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027581431 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0707      |\n",
      "|    n_updates            | 46830       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 1195       |\n",
      "|    total_timesteps      | 366592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03305742 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.284     |\n",
      "|    explained_variance   | 0.249      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0598     |\n",
      "|    n_updates            | 46840      |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 1200        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029078905 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0414      |\n",
      "|    n_updates            | 46850       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=0.16 +/- 0.99\n",
      "Episode length: 29.93 +/- 0.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 370000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02698889 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.298     |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0528     |\n",
      "|    n_updates            | 46860      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 1211     |\n",
      "|    total_timesteps | 370688   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.39       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 182        |\n",
      "|    time_elapsed         | 1216       |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02602939 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.28      |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0189     |\n",
      "|    n_updates            | 46870      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.156      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 183        |\n",
      "|    time_elapsed         | 1222       |\n",
      "|    total_timesteps      | 374784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02491099 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.458      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0395     |\n",
      "|    n_updates            | 46880      |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    value_loss           | 0.159      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1227        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029920645 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0104     |\n",
      "|    n_updates            | 46890       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 1233        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028037753 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0773      |\n",
      "|    n_updates            | 46900       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=0.15 +/- 0.98\n",
      "Episode length: 29.95 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023370538 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0437      |\n",
      "|    n_updates            | 46910       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 186      |\n",
      "|    time_elapsed    | 1244     |\n",
      "|    total_timesteps | 380928   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1249        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027344111 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 46920       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 1255        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021438826 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0233      |\n",
      "|    n_updates            | 46930       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 1260        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028860621 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00713     |\n",
      "|    n_updates            | 46940       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 1265        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025683068 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0132     |\n",
      "|    n_updates            | 46950       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=0.11 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029383276 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0235      |\n",
      "|    n_updates            | 46960       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 191      |\n",
      "|    time_elapsed    | 1276     |\n",
      "|    total_timesteps | 391168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 1282        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031683885 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0104      |\n",
      "|    n_updates            | 46970       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 1287        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031033972 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 46980       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 1293        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033031464 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0424      |\n",
      "|    n_updates            | 46990       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028652677 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0422      |\n",
      "|    n_updates            | 47000       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 30.02 +/- 0.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028157314 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 47010       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 1309     |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 1315        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028401375 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 47020       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 1320        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026701167 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 47030       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 1325        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028896503 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0153      |\n",
      "|    n_updates            | 47040       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 1331        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039892767 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0483      |\n",
      "|    n_updates            | 47050       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=0.11 +/- 0.97\n",
      "Episode length: 29.95 +/- 0.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 410000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024780845 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 47060       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 201      |\n",
      "|    time_elapsed    | 1342     |\n",
      "|    total_timesteps | 411648   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 1347        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028003013 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0671      |\n",
      "|    n_updates            | 47070       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 1353        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029106203 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0237      |\n",
      "|    n_updates            | 47080       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 1358        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025099494 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0309      |\n",
      "|    n_updates            | 47090       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 1363        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030712638 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0544      |\n",
      "|    n_updates            | 47100       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=0.24 +/- 0.96\n",
      "Episode length: 30.03 +/- 0.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 420000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027864812 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0464      |\n",
      "|    n_updates            | 47110       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 9\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 206      |\n",
      "|    time_elapsed    | 1374     |\n",
      "|    total_timesteps | 421888   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 1380        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031024667 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00895     |\n",
      "|    n_updates            | 47120       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 1385        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024831241 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0541      |\n",
      "|    n_updates            | 47130       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 1391        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025792263 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0466      |\n",
      "|    n_updates            | 47140       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=0.01 +/- 0.96\n",
      "Episode length: 29.99 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028734215 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0754      |\n",
      "|    n_updates            | 47150       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 210      |\n",
      "|    time_elapsed    | 1402     |\n",
      "|    total_timesteps | 430080   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 1407        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028319266 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0555      |\n",
      "|    n_updates            | 47160       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | 0.14      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 212       |\n",
      "|    time_elapsed         | 1413      |\n",
      "|    total_timesteps      | 434176    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0247068 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.306    |\n",
      "|    explained_variance   | 0.314     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0166    |\n",
      "|    n_updates            | 47170     |\n",
      "|    policy_gradient_loss | -0.0322   |\n",
      "|    value_loss           | 0.2       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 1418        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029733103 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0241      |\n",
      "|    n_updates            | 47180       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 1424       |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03594287 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.346      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0489     |\n",
      "|    n_updates            | 47190      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=0.22 +/- 0.95\n",
      "Episode length: 29.93 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026493419 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 47200       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 1435     |\n",
      "|    total_timesteps | 440320   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 1440        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029676095 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 47210       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 1446        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028511364 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 47220       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 1451        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026255025 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.018       |\n",
      "|    n_updates            | 47230       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 1456        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027043246 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 47240       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=0.10 +/- 0.96\n",
      "Episode length: 30.02 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 450000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027035516 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00232     |\n",
      "|    n_updates            | 47250       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 1467     |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 1473        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027038805 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0212      |\n",
      "|    n_updates            | 47260       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 1479        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020851022 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 47270       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 1485        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026578713 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 47280       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 224        |\n",
      "|    time_elapsed         | 1490       |\n",
      "|    total_timesteps      | 458752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03337323 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.265      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0742     |\n",
      "|    n_updates            | 47290      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=0.14 +/- 0.98\n",
      "Episode length: 30.09 +/- 0.43\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 460000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02874383 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.303     |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00587    |\n",
      "|    n_updates            | 47300      |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 1502     |\n",
      "|    total_timesteps | 460800   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 1507        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024703769 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0592      |\n",
      "|    n_updates            | 47310       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 227        |\n",
      "|    time_elapsed         | 1512       |\n",
      "|    total_timesteps      | 464896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03197009 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.28      |\n",
      "|    explained_variance   | 0.291      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0277     |\n",
      "|    n_updates            | 47320      |\n",
      "|    policy_gradient_loss | -0.0337    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 1518        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027380396 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0323      |\n",
      "|    n_updates            | 47330       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 1524        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025470534 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00924    |\n",
      "|    n_updates            | 47340       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=0.26 +/- 0.96\n",
      "Episode length: 30.01 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 470000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027271837 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0423      |\n",
      "|    n_updates            | 47350       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 230      |\n",
      "|    time_elapsed    | 1535     |\n",
      "|    total_timesteps | 471040   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 1540        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028353442 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 47360       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 1546        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028491903 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0449      |\n",
      "|    n_updates            | 47370       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 1551        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033254363 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.364      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 47380       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 1557        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028889067 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0444      |\n",
      "|    n_updates            | 47390       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 30.02 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027485827 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0236      |\n",
      "|    n_updates            | 47400       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 235      |\n",
      "|    time_elapsed    | 1567     |\n",
      "|    total_timesteps | 481280   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 1573        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032511033 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0376      |\n",
      "|    n_updates            | 47410       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 1578        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028145306 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00735    |\n",
      "|    n_updates            | 47420       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 1584        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031804517 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0272      |\n",
      "|    n_updates            | 47430       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 1589        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028279603 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0371      |\n",
      "|    n_updates            | 47440       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=0.17 +/- 0.98\n",
      "Episode length: 29.93 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 490000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028322725 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 47450       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 240      |\n",
      "|    time_elapsed    | 1600     |\n",
      "|    total_timesteps | 491520   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 241        |\n",
      "|    time_elapsed         | 1606       |\n",
      "|    total_timesteps      | 493568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02865715 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00744    |\n",
      "|    n_updates            | 47460      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 1611        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030633919 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0139      |\n",
      "|    n_updates            | 47470       |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 243        |\n",
      "|    time_elapsed         | 1617       |\n",
      "|    total_timesteps      | 497664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02973494 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.314     |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0568     |\n",
      "|    n_updates            | 47480      |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 1622        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031346697 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0682      |\n",
      "|    n_updates            | 47490       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=0.00 +/- 0.98\n",
      "Episode length: 30.04 +/- 0.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 500000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02399427 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.291     |\n",
      "|    explained_variance   | 0.248      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0118     |\n",
      "|    n_updates            | 47500      |\n",
      "|    policy_gradient_loss | -0.0294    |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 245      |\n",
      "|    time_elapsed    | 1633     |\n",
      "|    total_timesteps | 501760   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 1639        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028416762 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00513     |\n",
      "|    n_updates            | 47510       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.21      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 247       |\n",
      "|    time_elapsed         | 1644      |\n",
      "|    total_timesteps      | 505856    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0300849 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.302    |\n",
      "|    explained_variance   | 0.454     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00696  |\n",
      "|    n_updates            | 47520     |\n",
      "|    policy_gradient_loss | -0.0329   |\n",
      "|    value_loss           | 0.167     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 1649        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030582927 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 47530       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 1655        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036573295 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0239      |\n",
      "|    n_updates            | 47540       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=0.14 +/- 0.96\n",
      "Episode length: 30.04 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026241317 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0428      |\n",
      "|    n_updates            | 47550       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 250      |\n",
      "|    time_elapsed    | 1666     |\n",
      "|    total_timesteps | 512000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 1671        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029381553 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0264      |\n",
      "|    n_updates            | 47560       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 1677        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024743974 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0186      |\n",
      "|    n_updates            | 47570       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 253        |\n",
      "|    time_elapsed         | 1682       |\n",
      "|    total_timesteps      | 518144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03168638 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.317     |\n",
      "|    explained_variance   | 0.2        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0318     |\n",
      "|    n_updates            | 47580      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=0.22 +/- 0.95\n",
      "Episode length: 29.61 +/- 2.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.6        |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026504371 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00496     |\n",
      "|    n_updates            | 47590       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 12\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 254      |\n",
      "|    time_elapsed    | 1693     |\n",
      "|    total_timesteps | 520192   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 1698        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027253771 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.05        |\n",
      "|    n_updates            | 47600       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 256        |\n",
      "|    time_elapsed         | 1704       |\n",
      "|    total_timesteps      | 524288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03597828 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.327     |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00232    |\n",
      "|    n_updates            | 47610      |\n",
      "|    policy_gradient_loss | -0.0365    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 1709        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026901733 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 47620       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 1715        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026896205 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 47630       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.52 +/- 2.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.5        |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028500019 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0657      |\n",
      "|    n_updates            | 47640       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 259      |\n",
      "|    time_elapsed    | 1726     |\n",
      "|    total_timesteps | 530432   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 1731        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031865574 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0214      |\n",
      "|    n_updates            | 47650       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 261        |\n",
      "|    time_elapsed         | 1737       |\n",
      "|    total_timesteps      | 534528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03071196 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.324     |\n",
      "|    explained_variance   | 0.24       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0661     |\n",
      "|    n_updates            | 47660      |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 1742       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03667476 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.409      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0328     |\n",
      "|    n_updates            | 47670      |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 1748        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031102028 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 47680       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=0.20 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 540000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034131277 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0393      |\n",
      "|    n_updates            | 47690       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 264      |\n",
      "|    time_elapsed    | 1759     |\n",
      "|    total_timesteps | 540672   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.5       |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 265        |\n",
      "|    time_elapsed         | 1765       |\n",
      "|    total_timesteps      | 542720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03428065 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.288     |\n",
      "|    explained_variance   | 0.22       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0243     |\n",
      "|    n_updates            | 47700      |\n",
      "|    policy_gradient_loss | -0.0315    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 1770        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027049733 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 47710       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 267        |\n",
      "|    time_elapsed         | 1775       |\n",
      "|    total_timesteps      | 546816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02928368 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.3       |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0231     |\n",
      "|    n_updates            | 47720      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 1781        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029316675 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0251      |\n",
      "|    n_updates            | 47730       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=0.30 +/- 0.92\n",
      "Episode length: 29.69 +/- 2.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029341035 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0217      |\n",
      "|    n_updates            | 47740       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.3\n",
      "SELFPLAY: new best model, bumping up generation to 13\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 269      |\n",
      "|    time_elapsed    | 1792     |\n",
      "|    total_timesteps | 550912   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 1798        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027274642 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0578      |\n",
      "|    n_updates            | 47750       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.1       |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 271        |\n",
      "|    time_elapsed         | 1803       |\n",
      "|    total_timesteps      | 555008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02510314 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.303      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0377     |\n",
      "|    n_updates            | 47760      |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.221      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.4       |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 272        |\n",
      "|    time_elapsed         | 1809       |\n",
      "|    total_timesteps      | 557056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04092504 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.327     |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0388     |\n",
      "|    n_updates            | 47770      |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 1814        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031745166 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.017       |\n",
      "|    n_updates            | 47780       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=0.09 +/- 0.98\n",
      "Episode length: 29.35 +/- 3.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033794362 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0303      |\n",
      "|    n_updates            | 47790       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 274      |\n",
      "|    time_elapsed    | 1825     |\n",
      "|    total_timesteps | 561152   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 275        |\n",
      "|    time_elapsed         | 1830       |\n",
      "|    total_timesteps      | 563200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03186895 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.332     |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0462     |\n",
      "|    n_updates            | 47800      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 1836        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029169332 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 47810       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 1841        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028252352 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0209      |\n",
      "|    n_updates            | 47820       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 1847        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028361838 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 47830       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=0.34 +/- 0.91\n",
      "Episode length: 29.63 +/- 2.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.6        |\n",
      "|    mean_reward          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 570000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029349051 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 47840       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.34\n",
      "SELFPLAY: new best model, bumping up generation to 14\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.2     |\n",
      "|    ep_rew_mean     | -0.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 279      |\n",
      "|    time_elapsed    | 1858     |\n",
      "|    total_timesteps | 571392   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.5        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 1864        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030407272 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00718    |\n",
      "|    n_updates            | 47850       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.4       |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 281        |\n",
      "|    time_elapsed         | 1869       |\n",
      "|    total_timesteps      | 575488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03322482 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.302     |\n",
      "|    explained_variance   | 0.275      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0696     |\n",
      "|    n_updates            | 47860      |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 1875        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026593493 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 47870       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 1880        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027579568 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0494      |\n",
      "|    n_updates            | 47880       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 29.81 +/- 2.14\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.8       |\n",
      "|    mean_reward          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 580000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02612042 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.375      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0237     |\n",
      "|    n_updates            | 47890      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 284      |\n",
      "|    time_elapsed    | 1891     |\n",
      "|    total_timesteps | 581632   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 1897        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027115218 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00231     |\n",
      "|    n_updates            | 47900       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.3       |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 286        |\n",
      "|    time_elapsed         | 1903       |\n",
      "|    total_timesteps      | 585728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03287799 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0.449      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0202     |\n",
      "|    n_updates            | 47910      |\n",
      "|    policy_gradient_loss | -0.0336    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 1908        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021523371 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0475      |\n",
      "|    n_updates            | 47920       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 1914        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026569743 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0407      |\n",
      "|    n_updates            | 47930       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 29.73 +/- 2.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.7       |\n",
      "|    mean_reward          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 590000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02532997 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.3       |\n",
      "|    explained_variance   | 0.285      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0358     |\n",
      "|    n_updates            | 47940      |\n",
      "|    policy_gradient_loss | -0.0294    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 289      |\n",
      "|    time_elapsed    | 1925     |\n",
      "|    total_timesteps | 591872   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 1930        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033030573 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0089      |\n",
      "|    n_updates            | 47950       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 1936        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031471197 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0295      |\n",
      "|    n_updates            | 47960       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 1941        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036110714 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0722      |\n",
      "|    n_updates            | 47970       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=0.24 +/- 0.95\n",
      "Episode length: 29.39 +/- 3.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029199323 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0592      |\n",
      "|    n_updates            | 47980       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 15\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 293      |\n",
      "|    time_elapsed    | 1952     |\n",
      "|    total_timesteps | 600064   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 1958        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031080913 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 47990       |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 1963        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034238815 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0758      |\n",
      "|    n_updates            | 48000       |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 1969        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027362142 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0511      |\n",
      "|    n_updates            | 48010       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 1974        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029620674 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0301      |\n",
      "|    n_updates            | 48020       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-0.01 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 610000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02866582 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.337     |\n",
      "|    explained_variance   | 0.31       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00979    |\n",
      "|    n_updates            | 48030      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.07    |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 298      |\n",
      "|    time_elapsed    | 1986     |\n",
      "|    total_timesteps | 610304   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 1991        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032334637 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0044      |\n",
      "|    n_updates            | 48040       |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 1997        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027804822 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0186      |\n",
      "|    n_updates            | 48050       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 301        |\n",
      "|    time_elapsed         | 2002       |\n",
      "|    total_timesteps      | 616448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03358358 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.334     |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0445     |\n",
      "|    n_updates            | 48060      |\n",
      "|    policy_gradient_loss | -0.0339    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 2008        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030950453 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0249      |\n",
      "|    n_updates            | 48070       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-0.02 +/- 0.98\n",
      "Episode length: 30.02 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 620000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027432444 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0574      |\n",
      "|    n_updates            | 48080       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 303      |\n",
      "|    time_elapsed    | 2019     |\n",
      "|    total_timesteps | 620544   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 304        |\n",
      "|    time_elapsed         | 2024       |\n",
      "|    total_timesteps      | 622592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03142205 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.313      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0438     |\n",
      "|    n_updates            | 48090      |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 2029        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026355524 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00165     |\n",
      "|    n_updates            | 48100       |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 2035        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031936444 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0601      |\n",
      "|    n_updates            | 48110       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 2040        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030796519 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0602      |\n",
      "|    n_updates            | 48120       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=-0.02 +/- 1.00\n",
      "Episode length: 29.94 +/- 0.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 630000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03798797 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.303     |\n",
      "|    explained_variance   | 0.276      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0417     |\n",
      "|    n_updates            | 48130      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 308      |\n",
      "|    time_elapsed    | 2051     |\n",
      "|    total_timesteps | 630784   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 2056        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029822383 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0667      |\n",
      "|    n_updates            | 48140       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 2061        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028480956 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 48150       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 2066        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028551903 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0544      |\n",
      "|    n_updates            | 48160       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 2072        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030443057 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0379      |\n",
      "|    n_updates            | 48170       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 30.00 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025605332 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0682      |\n",
      "|    n_updates            | 48180       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 313      |\n",
      "|    time_elapsed    | 2082     |\n",
      "|    total_timesteps | 641024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 2088        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035412386 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0218      |\n",
      "|    n_updates            | 48190       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 2093        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029412393 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0492      |\n",
      "|    n_updates            | 48200       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 316        |\n",
      "|    time_elapsed         | 2098       |\n",
      "|    total_timesteps      | 647168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03337961 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.297     |\n",
      "|    explained_variance   | 0.338      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0507     |\n",
      "|    n_updates            | 48210      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 2104        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034212165 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 48220       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026727084 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0461      |\n",
      "|    n_updates            | 48230       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 307      |\n",
      "|    iterations      | 318      |\n",
      "|    time_elapsed    | 2114     |\n",
      "|    total_timesteps | 651264   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 2119        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027697753 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0223      |\n",
      "|    n_updates            | 48240       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 320        |\n",
      "|    time_elapsed         | 2125       |\n",
      "|    total_timesteps      | 655360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03137234 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.277     |\n",
      "|    explained_variance   | 0.295      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0456     |\n",
      "|    n_updates            | 48250      |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 321        |\n",
      "|    time_elapsed         | 2130       |\n",
      "|    total_timesteps      | 657408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03205398 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0411     |\n",
      "|    n_updates            | 48260      |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 2135        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028653614 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 48270       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=0.11 +/- 0.98\n",
      "Episode length: 29.89 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 660000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028201235 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.068       |\n",
      "|    n_updates            | 48280       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 323      |\n",
      "|    time_elapsed    | 2146     |\n",
      "|    total_timesteps | 661504   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 2151        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029771155 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 48290       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 2157        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026019279 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0756      |\n",
      "|    n_updates            | 48300       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 2162        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026349569 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0382      |\n",
      "|    n_updates            | 48310       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 2167        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032183528 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0301      |\n",
      "|    n_updates            | 48320       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 29.93 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 670000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029525202 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0326      |\n",
      "|    n_updates            | 48330       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 328      |\n",
      "|    time_elapsed    | 2178     |\n",
      "|    total_timesteps | 671744   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 2183        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026444182 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0362      |\n",
      "|    n_updates            | 48340       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.36       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 330        |\n",
      "|    time_elapsed         | 2189       |\n",
      "|    total_timesteps      | 675840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03038154 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.285     |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0209     |\n",
      "|    n_updates            | 48350      |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    value_loss           | 0.174      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 2194        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027090374 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 48360       |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 332        |\n",
      "|    time_elapsed         | 2199       |\n",
      "|    total_timesteps      | 679936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02951108 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.256     |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0644     |\n",
      "|    n_updates            | 48370      |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    value_loss           | 0.173      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=0.22 +/- 0.98\n",
      "Episode length: 30.02 +/- 0.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 680000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02421276 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.244     |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0511     |\n",
      "|    n_updates            | 48380      |\n",
      "|    policy_gradient_loss | -0.026     |\n",
      "|    value_loss           | 0.168      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 16\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 333      |\n",
      "|    time_elapsed    | 2210     |\n",
      "|    total_timesteps | 681984   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 2216        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036370482 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 48390       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 2221        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027396288 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0183      |\n",
      "|    n_updates            | 48400       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 2226        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028005231 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 48410       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=0.01 +/- 0.99\n",
      "Episode length: 29.84 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029484004 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0242      |\n",
      "|    n_updates            | 48420       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 337      |\n",
      "|    time_elapsed    | 2237     |\n",
      "|    total_timesteps | 690176   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 338        |\n",
      "|    time_elapsed         | 2242       |\n",
      "|    total_timesteps      | 692224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03338619 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.278     |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0602     |\n",
      "|    n_updates            | 48430      |\n",
      "|    policy_gradient_loss | -0.0283    |\n",
      "|    value_loss           | 0.235      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 2248        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028247591 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.059       |\n",
      "|    n_updates            | 48440       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 2253       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02341761 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.27      |\n",
      "|    explained_variance   | 0.285      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0495     |\n",
      "|    n_updates            | 48450      |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 2258        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030529598 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0396      |\n",
      "|    n_updates            | 48460       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=0.32 +/- 0.92\n",
      "Episode length: 29.99 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028664937 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0423      |\n",
      "|    n_updates            | 48470       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.32\n",
      "SELFPLAY: new best model, bumping up generation to 17\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 342      |\n",
      "|    time_elapsed    | 2269     |\n",
      "|    total_timesteps | 700416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 2274        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027084231 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0525      |\n",
      "|    n_updates            | 48480       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 308        |\n",
      "|    iterations           | 344        |\n",
      "|    time_elapsed         | 2280       |\n",
      "|    total_timesteps      | 704512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04251286 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.334     |\n",
      "|    explained_variance   | 0.341      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0403     |\n",
      "|    n_updates            | 48490      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.174      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 2285        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032226022 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00289     |\n",
      "|    n_updates            | 48500       |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 2290        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029628824 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 48510       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=0.15 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 710000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03317939 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.342     |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0314     |\n",
      "|    n_updates            | 48520      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 347      |\n",
      "|    time_elapsed    | 2301     |\n",
      "|    total_timesteps | 710656   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 2306        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032562815 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.355      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0395      |\n",
      "|    n_updates            | 48530       |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 2311        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030508608 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.356      |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 48540       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 2316        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029887391 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0117      |\n",
      "|    n_updates            | 48550       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.05      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 351        |\n",
      "|    time_elapsed         | 2322       |\n",
      "|    total_timesteps      | 718848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02833566 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.327     |\n",
      "|    explained_variance   | 0.414      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0367     |\n",
      "|    n_updates            | 48560      |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.176      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=0.02 +/- 0.99\n",
      "Episode length: 30.03 +/- 0.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 720000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02666954 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.361     |\n",
      "|    explained_variance   | 0.417      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0573     |\n",
      "|    n_updates            | 48570      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.171      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 352      |\n",
      "|    time_elapsed    | 2332     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 2338        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029209599 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0263      |\n",
      "|    n_updates            | 48580       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 2343        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027141213 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0706      |\n",
      "|    n_updates            | 48590       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 2348        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035676207 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 48600       |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 2354        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031149514 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 48610       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=-0.08 +/- 0.99\n",
      "Episode length: 29.92 +/- 0.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | -0.08      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 730000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02542191 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.293     |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0349     |\n",
      "|    n_updates            | 48620      |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.31     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 357      |\n",
      "|    time_elapsed    | 2364     |\n",
      "|    total_timesteps | 731136   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 2370        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030576108 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0442      |\n",
      "|    n_updates            | 48630       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 2375        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025981676 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0676      |\n",
      "|    n_updates            | 48640       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 360        |\n",
      "|    time_elapsed         | 2380       |\n",
      "|    total_timesteps      | 737280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02733695 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.278     |\n",
      "|    explained_variance   | 0.281      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0583     |\n",
      "|    n_updates            | 48650      |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 2386        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027915906 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0166      |\n",
      "|    n_updates            | 48660       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=0.29 +/- 0.94\n",
      "Episode length: 29.96 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030041847 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 48670       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.29\n",
      "SELFPLAY: new best model, bumping up generation to 18\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 362      |\n",
      "|    time_elapsed    | 2396     |\n",
      "|    total_timesteps | 741376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 2402        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032680914 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0304      |\n",
      "|    n_updates            | 48680       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 364        |\n",
      "|    time_elapsed         | 2407       |\n",
      "|    total_timesteps      | 745472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03152721 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0299     |\n",
      "|    n_updates            | 48690      |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 2412        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033073537 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0262      |\n",
      "|    n_updates            | 48700       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 2418        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032859936 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 48710       |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027963612 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 48720       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 367      |\n",
      "|    time_elapsed    | 2428     |\n",
      "|    total_timesteps | 751616   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 2433        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030869037 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0549      |\n",
      "|    n_updates            | 48730       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 309       |\n",
      "|    iterations           | 369       |\n",
      "|    time_elapsed         | 2439      |\n",
      "|    total_timesteps      | 755712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0344208 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.332    |\n",
      "|    explained_variance   | 0.322     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0504    |\n",
      "|    n_updates            | 48740     |\n",
      "|    policy_gradient_loss | -0.0356   |\n",
      "|    value_loss           | 0.215     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 2444        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029293846 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 48750       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 2450        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032767747 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 48760       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=0.06 +/- 0.96\n",
      "Episode length: 29.99 +/- 0.52\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 760000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02926327 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.352     |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0284     |\n",
      "|    n_updates            | 48770      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 372      |\n",
      "|    time_elapsed    | 2460     |\n",
      "|    total_timesteps | 761856   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 2466        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026106171 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 48780       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 2471        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031337596 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0365      |\n",
      "|    n_updates            | 48790       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 2476        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031221144 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 48800       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=0.29 +/- 0.95\n",
      "Episode length: 30.03 +/- 0.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.29       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 770000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03352736 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.36      |\n",
      "|    explained_variance   | 0.442      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0377     |\n",
      "|    n_updates            | 48810      |\n",
      "|    policy_gradient_loss | -0.0336    |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.29\n",
      "SELFPLAY: new best model, bumping up generation to 19\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 376      |\n",
      "|    time_elapsed    | 2487     |\n",
      "|    total_timesteps | 770048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 2492        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025970744 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0164      |\n",
      "|    n_updates            | 48820       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 2498        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031402126 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 48830       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 379        |\n",
      "|    time_elapsed         | 2503       |\n",
      "|    total_timesteps      | 776192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03940937 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.359     |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0109     |\n",
      "|    n_updates            | 48840      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 380        |\n",
      "|    time_elapsed         | 2508       |\n",
      "|    total_timesteps      | 778240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07283752 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.34      |\n",
      "|    explained_variance   | 0.299      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0353     |\n",
      "|    n_updates            | 48850      |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=0.02 +/- 0.99\n",
      "Episode length: 29.90 +/- 0.44\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 780000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03321986 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0352     |\n",
      "|    n_updates            | 48860      |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 381      |\n",
      "|    time_elapsed    | 2519     |\n",
      "|    total_timesteps | 780288   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 2524        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025596414 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.052       |\n",
      "|    n_updates            | 48870       |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 2529        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030239476 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.352      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0593      |\n",
      "|    n_updates            | 48880       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 384        |\n",
      "|    time_elapsed         | 2535       |\n",
      "|    total_timesteps      | 786432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03318762 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.342     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0364     |\n",
      "|    n_updates            | 48890      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 2540        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031563357 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00943     |\n",
      "|    n_updates            | 48900       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=0.26 +/- 0.96\n",
      "Episode length: 29.96 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 790000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03410667 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.32      |\n",
      "|    explained_variance   | 0.177      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0566     |\n",
      "|    n_updates            | 48910      |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.17       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 20\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 309      |\n",
      "|    iterations      | 386      |\n",
      "|    time_elapsed    | 2550     |\n",
      "|    total_timesteps | 790528   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.19      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 310       |\n",
      "|    iterations           | 387       |\n",
      "|    time_elapsed         | 2555      |\n",
      "|    total_timesteps      | 792576    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0375147 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.33     |\n",
      "|    explained_variance   | 0.331     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0109    |\n",
      "|    n_updates            | 48920     |\n",
      "|    policy_gradient_loss | -0.0345   |\n",
      "|    value_loss           | 0.164     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 2561        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035290025 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0209      |\n",
      "|    n_updates            | 48930       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 2566        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027257169 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0847      |\n",
      "|    n_updates            | 48940       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 390        |\n",
      "|    time_elapsed         | 2571       |\n",
      "|    total_timesteps      | 798720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03297936 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | 0.408      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0525     |\n",
      "|    n_updates            | 48950      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=0.25 +/- 0.94\n",
      "Episode length: 29.76 +/- 2.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026715662 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 48960       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 21\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 310      |\n",
      "|    iterations      | 391      |\n",
      "|    time_elapsed    | 2582     |\n",
      "|    total_timesteps | 800768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 2587        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031614516 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0441      |\n",
      "|    n_updates            | 48970       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 2592        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033276763 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0483      |\n",
      "|    n_updates            | 48980       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 2598        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033942707 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0612      |\n",
      "|    n_updates            | 48990       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 2603        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037718665 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0185      |\n",
      "|    n_updates            | 49000       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=0.07 +/- 0.98\n",
      "Episode length: 29.87 +/- 0.44\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 810000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04841655 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.35      |\n",
      "|    explained_variance   | 0.348      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0478     |\n",
      "|    n_updates            | 49010      |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 310      |\n",
      "|    iterations      | 396      |\n",
      "|    time_elapsed    | 2613     |\n",
      "|    total_timesteps | 811008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 2618        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032299913 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0586      |\n",
      "|    n_updates            | 49020       |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 2624        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028198786 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 49030       |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 2629        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031611226 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 49040       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 2634        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028428858 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 49050       |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=0.20 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025913384 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0448      |\n",
      "|    n_updates            | 49060       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.09    |\n",
      "| time/              |          |\n",
      "|    fps             | 310      |\n",
      "|    iterations      | 401      |\n",
      "|    time_elapsed    | 2645     |\n",
      "|    total_timesteps | 821248   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 2650        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035683792 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0172      |\n",
      "|    n_updates            | 49070       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 2655        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029838247 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0113      |\n",
      "|    n_updates            | 49080       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 2661        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025951251 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0595      |\n",
      "|    n_updates            | 49090       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 405        |\n",
      "|    time_elapsed         | 2666       |\n",
      "|    total_timesteps      | 829440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03247517 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.315      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0585     |\n",
      "|    n_updates            | 49100      |\n",
      "|    policy_gradient_loss | -0.0359    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=0.19 +/- 0.97\n",
      "Episode length: 29.94 +/- 1.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 830000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028761376 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00414     |\n",
      "|    n_updates            | 49110       |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 310      |\n",
      "|    iterations      | 406      |\n",
      "|    time_elapsed    | 2676     |\n",
      "|    total_timesteps | 831488   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 2681        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030896492 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0452      |\n",
      "|    n_updates            | 49120       |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 2686        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024703821 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0706      |\n",
      "|    n_updates            | 49130       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.3        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 2692       |\n",
      "|    total_timesteps      | 837632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03223617 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.341     |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0197     |\n",
      "|    n_updates            | 49140      |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 2697        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027380792 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00982     |\n",
      "|    n_updates            | 49150       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=0.06 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 840000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03456386 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.316     |\n",
      "|    explained_variance   | 0.344      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0183     |\n",
      "|    n_updates            | 49160      |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 310      |\n",
      "|    iterations      | 411      |\n",
      "|    time_elapsed    | 2708     |\n",
      "|    total_timesteps | 841728   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 2713        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030272111 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0324      |\n",
      "|    n_updates            | 49170       |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 2718        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032194756 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.037       |\n",
      "|    n_updates            | 49180       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 2724        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026089473 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 49190       |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 415        |\n",
      "|    time_elapsed         | 2729       |\n",
      "|    total_timesteps      | 849920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02556079 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.299     |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0691     |\n",
      "|    n_updates            | 49200      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.48\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 29.9      |\n",
      "|    mean_reward          | 0.06      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 850000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0308274 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.313    |\n",
      "|    explained_variance   | 0.312     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0372    |\n",
      "|    n_updates            | 49210     |\n",
      "|    policy_gradient_loss | -0.032    |\n",
      "|    value_loss           | 0.195     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 310      |\n",
      "|    iterations      | 416      |\n",
      "|    time_elapsed    | 2739     |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 2744        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034542724 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 49220       |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 2750        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033638988 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0502      |\n",
      "|    n_updates            | 49230       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 2755        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024269156 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.018       |\n",
      "|    n_updates            | 49240       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 30.03 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 860000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032954384 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 49250       |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 22\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 311      |\n",
      "|    iterations      | 420      |\n",
      "|    time_elapsed    | 2765     |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 2770        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027681626 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0368      |\n",
      "|    n_updates            | 49260       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 422        |\n",
      "|    time_elapsed         | 2775       |\n",
      "|    total_timesteps      | 864256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03192555 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.379     |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0387     |\n",
      "|    n_updates            | 49270      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 2780        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030280842 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.371      |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0693      |\n",
      "|    n_updates            | 49280       |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 2785        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032421157 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.363      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0303      |\n",
      "|    n_updates            | 49290       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=0.03 +/- 0.98\n",
      "Episode length: 30.04 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027362749 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.373      |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0306      |\n",
      "|    n_updates            | 49300       |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | -0.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 311      |\n",
      "|    iterations      | 425      |\n",
      "|    time_elapsed    | 2796     |\n",
      "|    total_timesteps | 870400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 2801        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030752208 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.354      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00772     |\n",
      "|    n_updates            | 49310       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 2806        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029105574 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0422      |\n",
      "|    n_updates            | 49320       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 2812        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033885006 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0849      |\n",
      "|    n_updates            | 49330       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 2817        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031933665 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 49340       |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-0.11 +/- 0.98\n",
      "Episode length: 29.93 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030489208 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0687      |\n",
      "|    n_updates            | 49350       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 311      |\n",
      "|    iterations      | 430      |\n",
      "|    time_elapsed    | 2827     |\n",
      "|    total_timesteps | 880640   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 431        |\n",
      "|    time_elapsed         | 2833       |\n",
      "|    total_timesteps      | 882688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03186255 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.324     |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.021      |\n",
      "|    n_updates            | 49360      |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 2838        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034333974 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0184      |\n",
      "|    n_updates            | 49370       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 2843        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032726906 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0362      |\n",
      "|    n_updates            | 49380       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 2848        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027916392 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 49390       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 30.02 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030943029 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000348   |\n",
      "|    n_updates            | 49400       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 311      |\n",
      "|    iterations      | 435      |\n",
      "|    time_elapsed    | 2858     |\n",
      "|    total_timesteps | 890880   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 2863        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032314792 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0304      |\n",
      "|    n_updates            | 49410       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 2869        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027569607 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0207      |\n",
      "|    n_updates            | 49420       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 2874        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032282777 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00228    |\n",
      "|    n_updates            | 49430       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 2879        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028798398 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0462      |\n",
      "|    n_updates            | 49440       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=0.25 +/- 0.95\n",
      "Episode length: 29.95 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028762132 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0137      |\n",
      "|    n_updates            | 49450       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 23\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.17    |\n",
      "| time/              |          |\n",
      "|    fps             | 311      |\n",
      "|    iterations      | 440      |\n",
      "|    time_elapsed    | 2889     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | -0.03     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 311       |\n",
      "|    iterations           | 441       |\n",
      "|    time_elapsed         | 2894      |\n",
      "|    total_timesteps      | 903168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0382099 |\n",
      "|    clip_fraction        | 0.172     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.336    |\n",
      "|    explained_variance   | 0.375     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0342    |\n",
      "|    n_updates            | 49460     |\n",
      "|    policy_gradient_loss | -0.0368   |\n",
      "|    value_loss           | 0.184     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 2900        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027385257 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0773      |\n",
      "|    n_updates            | 49470       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 2905        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035052825 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0329      |\n",
      "|    n_updates            | 49480       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 2910        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023255102 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0347      |\n",
      "|    n_updates            | 49490       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=0.24 +/- 0.95\n",
      "Episode length: 30.02 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 910000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028441666 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 49500       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 24\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 445      |\n",
      "|    time_elapsed    | 2920     |\n",
      "|    total_timesteps | 911360   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 2925        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032754198 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00891     |\n",
      "|    n_updates            | 49510       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 2930        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026191687 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0179      |\n",
      "|    n_updates            | 49520       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 2936        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033413086 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0302      |\n",
      "|    n_updates            | 49530       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 2941        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026157554 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0473      |\n",
      "|    n_updates            | 49540       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=0.02 +/- 0.99\n",
      "Episode length: 29.98 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025834884 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0557      |\n",
      "|    n_updates            | 49550       |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.3      |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 450      |\n",
      "|    time_elapsed    | 2951     |\n",
      "|    total_timesteps | 921600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 2957        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023825098 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0695      |\n",
      "|    n_updates            | 49560       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 312        |\n",
      "|    iterations           | 452        |\n",
      "|    time_elapsed         | 2962       |\n",
      "|    total_timesteps      | 925696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02544616 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.269     |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0325     |\n",
      "|    n_updates            | 49570      |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 2967        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024119716 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0119      |\n",
      "|    n_updates            | 49580       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 2972        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027748156 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 49590       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=0.13 +/- 0.99\n",
      "Episode length: 30.01 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 930000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023651138 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0587      |\n",
      "|    n_updates            | 49600       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.37     |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 455      |\n",
      "|    time_elapsed    | 2983     |\n",
      "|    total_timesteps | 931840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 2988        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031454418 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 49610       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.29      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 312       |\n",
      "|    iterations           | 457       |\n",
      "|    time_elapsed         | 2993      |\n",
      "|    total_timesteps      | 935936    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0314558 |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.264    |\n",
      "|    explained_variance   | 0.538     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0377    |\n",
      "|    n_updates            | 49620     |\n",
      "|    policy_gradient_loss | -0.0262   |\n",
      "|    value_loss           | 0.139     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.43        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 2998        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034244336 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0245      |\n",
      "|    n_updates            | 49630       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=0.25 +/- 0.95\n",
      "Episode length: 29.93 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 940000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023336751 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 49640       |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 25\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.33     |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 459      |\n",
      "|    time_elapsed    | 3009     |\n",
      "|    total_timesteps | 940032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 3014        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026628869 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 49650       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 3019        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023849916 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.257      |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 49660       |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 3024        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036233906 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 49670       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 3029        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037247673 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0414      |\n",
      "|    n_updates            | 49680       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021080948 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00574    |\n",
      "|    n_updates            | 49690       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 464      |\n",
      "|    time_elapsed    | 3039     |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 312        |\n",
      "|    iterations           | 465        |\n",
      "|    time_elapsed         | 3045       |\n",
      "|    total_timesteps      | 952320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02708656 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.261     |\n",
      "|    explained_variance   | 0.583      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0267     |\n",
      "|    n_updates            | 49700      |\n",
      "|    policy_gradient_loss | -0.0265    |\n",
      "|    value_loss           | 0.13       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 3050        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028121574 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.033       |\n",
      "|    n_updates            | 49710       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 3056        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023351958 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00257    |\n",
      "|    n_updates            | 49720       |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.29       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 468        |\n",
      "|    time_elapsed         | 3061       |\n",
      "|    total_timesteps      | 958464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02957645 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.244     |\n",
      "|    explained_variance   | 0.474      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0426     |\n",
      "|    n_updates            | 49730      |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    value_loss           | 0.161      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=0.33 +/- 0.93\n",
      "Episode length: 30.05 +/- 0.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025133781 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.214      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0322      |\n",
      "|    n_updates            | 49740       |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.33\n",
      "SELFPLAY: new best model, bumping up generation to 26\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 469      |\n",
      "|    time_elapsed    | 3072     |\n",
      "|    total_timesteps | 960512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 3077        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024631325 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0477      |\n",
      "|    n_updates            | 49750       |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 3082        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028151864 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0528      |\n",
      "|    n_updates            | 49760       |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | -0.08     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 313       |\n",
      "|    iterations           | 472       |\n",
      "|    time_elapsed         | 3087      |\n",
      "|    total_timesteps      | 966656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0298803 |\n",
      "|    clip_fraction        | 0.11      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.24     |\n",
      "|    explained_variance   | 0.525     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0591    |\n",
      "|    n_updates            | 49770     |\n",
      "|    policy_gradient_loss | -0.0251   |\n",
      "|    value_loss           | 0.167     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 473        |\n",
      "|    time_elapsed         | 3093       |\n",
      "|    total_timesteps      | 968704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02784158 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.247     |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0113     |\n",
      "|    n_updates            | 49780      |\n",
      "|    policy_gradient_loss | -0.0219    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-0.01 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 970000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02985189 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.263     |\n",
      "|    explained_variance   | 0.443      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0339     |\n",
      "|    n_updates            | 49790      |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 474      |\n",
      "|    time_elapsed    | 3103     |\n",
      "|    total_timesteps | 970752   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 3109        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028048923 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.039       |\n",
      "|    n_updates            | 49800       |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 3114        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019321922 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.232      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 49810       |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 477        |\n",
      "|    time_elapsed         | 3119       |\n",
      "|    total_timesteps      | 976896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02550964 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.237     |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0318     |\n",
      "|    n_updates            | 49820      |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 3124        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023904216 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0625      |\n",
      "|    n_updates            | 49830       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=0.11 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 980000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032202262 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00545     |\n",
      "|    n_updates            | 49840       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 479      |\n",
      "|    time_elapsed    | 3135     |\n",
      "|    total_timesteps | 980992   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 3140        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024200987 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0641      |\n",
      "|    n_updates            | 49850       |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 3145        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027193412 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0335      |\n",
      "|    n_updates            | 49860       |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 3150        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027657373 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.045       |\n",
      "|    n_updates            | 49870       |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 3155        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029517462 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0597      |\n",
      "|    n_updates            | 49880       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=0.40 +/- 0.91\n",
      "Episode length: 30.05 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 990000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034632728 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 49890       |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.4\n",
      "SELFPLAY: new best model, bumping up generation to 27\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.09    |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 484      |\n",
      "|    time_elapsed    | 3165     |\n",
      "|    total_timesteps | 991232   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 3171        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025979383 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 49900       |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 3176        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060503043 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.086       |\n",
      "|    n_updates            | 49910       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 3181        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034170814 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0638      |\n",
      "|    n_updates            | 49920       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 3186        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025432412 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0466      |\n",
      "|    n_updates            | 49930       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=0.09 +/- 0.98\n",
      "Episode length: 29.92 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026328795 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 49940       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 489      |\n",
      "|    time_elapsed    | 3197     |\n",
      "|    total_timesteps | 1001472  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 3202        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036642883 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 49950       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 3207        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030249212 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0424      |\n",
      "|    n_updates            | 49960       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 3212        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026346136 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0641      |\n",
      "|    n_updates            | 49970       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 3217        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029334862 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 49980       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=0.30 +/- 0.95\n",
      "Episode length: 29.83 +/- 1.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027879091 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 49990       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.3\n",
      "SELFPLAY: new best model, bumping up generation to 28\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 494      |\n",
      "|    time_elapsed    | 3228     |\n",
      "|    total_timesteps | 1011712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 3233        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030203419 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0306      |\n",
      "|    n_updates            | 50000       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 3239        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027981646 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0535      |\n",
      "|    n_updates            | 50010       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 497        |\n",
      "|    time_elapsed         | 3244       |\n",
      "|    total_timesteps      | 1017856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03291717 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.325     |\n",
      "|    explained_variance   | 0.265      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0245     |\n",
      "|    n_updates            | 50020      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.224      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 3249        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031259988 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.062       |\n",
      "|    n_updates            | 50030       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=0.25 +/- 0.96\n",
      "Episode length: 30.02 +/- 0.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1020000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03312055 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.333     |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0779     |\n",
      "|    n_updates            | 50040      |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 29\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 499      |\n",
      "|    time_elapsed    | 3259     |\n",
      "|    total_timesteps | 1021952  |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 30       |\n",
      "|    ep_rew_mean          | -0.09    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 313      |\n",
      "|    iterations           | 500      |\n",
      "|    time_elapsed         | 3264     |\n",
      "|    total_timesteps      | 1024000  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.031677 |\n",
      "|    clip_fraction        | 0.146    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.327   |\n",
      "|    explained_variance   | 0.335    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0277   |\n",
      "|    n_updates            | 50050    |\n",
      "|    policy_gradient_loss | -0.0305  |\n",
      "|    value_loss           | 0.19     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 3269        |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034604132 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0189      |\n",
      "|    n_updates            | 50060       |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 3275        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033722818 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0399      |\n",
      "|    n_updates            | 50070       |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=0.19 +/- 0.98\n",
      "Episode length: 29.95 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030576743 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0134      |\n",
      "|    n_updates            | 50080       |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 503      |\n",
      "|    time_elapsed    | 3286     |\n",
      "|    total_timesteps | 1030144  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 3291        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030995626 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 50090       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 3297        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034227226 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.362      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0216      |\n",
      "|    n_updates            | 50100       |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 3302        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027883302 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0333      |\n",
      "|    n_updates            | 50110       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 507        |\n",
      "|    time_elapsed         | 3307       |\n",
      "|    total_timesteps      | 1038336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03238423 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.358     |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0343     |\n",
      "|    n_updates            | 50120      |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.89 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1040000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03417121 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.346     |\n",
      "|    explained_variance   | 0.234      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0327     |\n",
      "|    n_updates            | 50130      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.229      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 508      |\n",
      "|    time_elapsed    | 3317     |\n",
      "|    total_timesteps | 1040384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 3322        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031644084 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0448      |\n",
      "|    n_updates            | 50140       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 3328        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025696306 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0193      |\n",
      "|    n_updates            | 50150       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 511        |\n",
      "|    time_elapsed         | 3333       |\n",
      "|    total_timesteps      | 1046528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03339007 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.335     |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0217     |\n",
      "|    n_updates            | 50160      |\n",
      "|    policy_gradient_loss | -0.0357    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 3338        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031092206 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0479      |\n",
      "|    n_updates            | 50170       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=0.26 +/- 0.94\n",
      "Episode length: 29.94 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1050000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02946878 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0304     |\n",
      "|    n_updates            | 50180      |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    value_loss           | 0.223      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 30\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 513      |\n",
      "|    time_elapsed    | 3349     |\n",
      "|    total_timesteps | 1050624  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 3354        |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027824815 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0113      |\n",
      "|    n_updates            | 50190       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 3359        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024124049 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0399      |\n",
      "|    n_updates            | 50200       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 3364        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028464973 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 50210       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.08      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 517        |\n",
      "|    time_elapsed         | 3369       |\n",
      "|    total_timesteps      | 1058816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02910541 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.352     |\n",
      "|    explained_variance   | 0.237      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0401     |\n",
      "|    n_updates            | 50220      |\n",
      "|    policy_gradient_loss | -0.0345    |\n",
      "|    value_loss           | 0.236      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=-0.06 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025825411 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0433      |\n",
      "|    n_updates            | 50230       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 518      |\n",
      "|    time_elapsed    | 3380     |\n",
      "|    total_timesteps | 1060864  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.6       |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 519        |\n",
      "|    time_elapsed         | 3385       |\n",
      "|    total_timesteps      | 1062912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02990454 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.329     |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.044      |\n",
      "|    n_updates            | 50240      |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 520        |\n",
      "|    time_elapsed         | 3390       |\n",
      "|    total_timesteps      | 1064960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03238844 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.334     |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.018      |\n",
      "|    n_updates            | 50250      |\n",
      "|    policy_gradient_loss | -0.0353    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 3395        |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026267499 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0803      |\n",
      "|    n_updates            | 50260       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 3400        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035560995 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0219      |\n",
      "|    n_updates            | 50270       |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=-0.12 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026069455 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0571      |\n",
      "|    n_updates            | 50280       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 523      |\n",
      "|    time_elapsed    | 3411     |\n",
      "|    total_timesteps | 1071104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 3416        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026400985 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 50290       |\n",
      "|    policy_gradient_loss | -0.0366     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 3421        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030616108 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0691      |\n",
      "|    n_updates            | 50300       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 3427        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030605432 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 50310       |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 3432        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029170856 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0204      |\n",
      "|    n_updates            | 50320       |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=-0.02 +/- 0.99\n",
      "Episode length: 29.90 +/- 0.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032989025 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0634      |\n",
      "|    n_updates            | 50330       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 528      |\n",
      "|    time_elapsed    | 3442     |\n",
      "|    total_timesteps | 1081344  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 529        |\n",
      "|    time_elapsed         | 3447       |\n",
      "|    total_timesteps      | 1083392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02657407 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.327     |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0157     |\n",
      "|    n_updates            | 50340      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 530        |\n",
      "|    time_elapsed         | 3453       |\n",
      "|    total_timesteps      | 1085440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03121337 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.316     |\n",
      "|    explained_variance   | 0.406      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0586     |\n",
      "|    n_updates            | 50350      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 3458        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031044342 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 50360       |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 532        |\n",
      "|    time_elapsed         | 3463       |\n",
      "|    total_timesteps      | 1089536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03145279 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.44       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0648     |\n",
      "|    n_updates            | 50370      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1090000, episode_reward=-0.08 +/- 1.00\n",
      "Episode length: 30.04 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031374242 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00763     |\n",
      "|    n_updates            | 50380       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 533      |\n",
      "|    time_elapsed    | 3474     |\n",
      "|    total_timesteps | 1091584  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.11      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 534        |\n",
      "|    time_elapsed         | 3479       |\n",
      "|    total_timesteps      | 1093632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03449322 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00251    |\n",
      "|    n_updates            | 50390      |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 3484        |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028280068 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0141      |\n",
      "|    n_updates            | 50400       |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 536        |\n",
      "|    time_elapsed         | 3489       |\n",
      "|    total_timesteps      | 1097728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02551224 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.319     |\n",
      "|    explained_variance   | 0.33       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0378     |\n",
      "|    n_updates            | 50410      |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 537        |\n",
      "|    time_elapsed         | 3494       |\n",
      "|    total_timesteps      | 1099776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02874261 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.315     |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0184     |\n",
      "|    n_updates            | 50420      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035822175 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 50430       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 538      |\n",
      "|    time_elapsed    | 3504     |\n",
      "|    total_timesteps | 1101824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 3509        |\n",
      "|    total_timesteps      | 1103872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027397301 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0233      |\n",
      "|    n_updates            | 50440       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.6       |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 540        |\n",
      "|    time_elapsed         | 3515       |\n",
      "|    total_timesteps      | 1105920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02993396 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0389     |\n",
      "|    n_updates            | 50450      |\n",
      "|    policy_gradient_loss | -0.0339    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 3520        |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030698039 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0148      |\n",
      "|    n_updates            | 50460       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=0.20 +/- 0.96\n",
      "Episode length: 29.98 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030531805 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0651      |\n",
      "|    n_updates            | 50470       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 542      |\n",
      "|    time_elapsed    | 3530     |\n",
      "|    total_timesteps | 1110016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 3536        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029455654 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0309      |\n",
      "|    n_updates            | 50480       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 3541        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028313365 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 50490       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 545        |\n",
      "|    time_elapsed         | 3546       |\n",
      "|    total_timesteps      | 1116160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03480566 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.318     |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0245     |\n",
      "|    n_updates            | 50500      |\n",
      "|    policy_gradient_loss | -0.0357    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 3551        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032742288 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 50510       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 29.98 +/- 0.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1120000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03589796 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.333     |\n",
      "|    explained_variance   | 0.277      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0504     |\n",
      "|    n_updates            | 50520      |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 0.215      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 547      |\n",
      "|    time_elapsed    | 3562     |\n",
      "|    total_timesteps | 1120256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 3567        |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032334205 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0224      |\n",
      "|    n_updates            | 50530       |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.32      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 314       |\n",
      "|    iterations           | 549       |\n",
      "|    time_elapsed         | 3572      |\n",
      "|    total_timesteps      | 1124352   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0349932 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.316    |\n",
      "|    explained_variance   | 0.188     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0254    |\n",
      "|    n_updates            | 50540     |\n",
      "|    policy_gradient_loss | -0.0343   |\n",
      "|    value_loss           | 0.201     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 3577        |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031074343 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00979    |\n",
      "|    n_updates            | 50550       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 3582        |\n",
      "|    total_timesteps      | 1128448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027700488 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0606      |\n",
      "|    n_updates            | 50560       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=0.28 +/- 0.95\n",
      "Episode length: 29.93 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023766203 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0292      |\n",
      "|    n_updates            | 50570       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.28\n",
      "SELFPLAY: new best model, bumping up generation to 31\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 552      |\n",
      "|    time_elapsed    | 3593     |\n",
      "|    total_timesteps | 1130496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 3598        |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030664895 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0405      |\n",
      "|    n_updates            | 50580       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 3603        |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031308845 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.356      |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 50590       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 3609        |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034356117 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.368      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0212      |\n",
      "|    n_updates            | 50600       |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 556        |\n",
      "|    time_elapsed         | 3614       |\n",
      "|    total_timesteps      | 1138688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03138835 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.348     |\n",
      "|    explained_variance   | 0.393      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00242    |\n",
      "|    n_updates            | 50610      |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1140000, episode_reward=0.14 +/- 0.96\n",
      "Episode length: 29.93 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033064246 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.364      |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 50620       |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 557      |\n",
      "|    time_elapsed    | 3624     |\n",
      "|    total_timesteps | 1140736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 3629        |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035453755 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.378      |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 50630       |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 559        |\n",
      "|    time_elapsed         | 3634       |\n",
      "|    total_timesteps      | 1144832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02886132 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.367     |\n",
      "|    explained_variance   | 0.331      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0425     |\n",
      "|    n_updates            | 50640      |\n",
      "|    policy_gradient_loss | -0.037     |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 3639        |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030233353 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 50650       |\n",
      "|    policy_gradient_loss | -0.0361     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 561        |\n",
      "|    time_elapsed         | 3645       |\n",
      "|    total_timesteps      | 1148928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03302055 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0379     |\n",
      "|    n_updates            | 50660      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=0.14 +/- 0.97\n",
      "Episode length: 30.02 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035265185 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 50670       |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 562      |\n",
      "|    time_elapsed    | 3655     |\n",
      "|    total_timesteps | 1150976  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 563        |\n",
      "|    time_elapsed         | 3660       |\n",
      "|    total_timesteps      | 1153024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03836298 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.391      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.024      |\n",
      "|    n_updates            | 50680      |\n",
      "|    policy_gradient_loss | -0.0348    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 564        |\n",
      "|    time_elapsed         | 3665       |\n",
      "|    total_timesteps      | 1155072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03513384 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.363     |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0476     |\n",
      "|    n_updates            | 50690      |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 3670        |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026567005 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.354      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.057       |\n",
      "|    n_updates            | 50700       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 3675        |\n",
      "|    total_timesteps      | 1159168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027973775 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.352      |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 50710       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=0.40 +/- 0.91\n",
      "Episode length: 30.08 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028833961 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.064       |\n",
      "|    n_updates            | 50720       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.4\n",
      "SELFPLAY: new best model, bumping up generation to 32\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 567      |\n",
      "|    time_elapsed    | 3686     |\n",
      "|    total_timesteps | 1161216  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 568        |\n",
      "|    time_elapsed         | 3691       |\n",
      "|    total_timesteps      | 1163264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03267783 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.365     |\n",
      "|    explained_variance   | 0.259      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0189     |\n",
      "|    n_updates            | 50730      |\n",
      "|    policy_gradient_loss | -0.0367    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 3696        |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030599862 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.363      |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.019       |\n",
      "|    n_updates            | 50740       |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 3701        |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036777142 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.369      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0163      |\n",
      "|    n_updates            | 50750       |\n",
      "|    policy_gradient_loss | -0.0357     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 3707        |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031135555 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 50760       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=0.05 +/- 0.98\n",
      "Episode length: 29.98 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031039935 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.354      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0298      |\n",
      "|    n_updates            | 50770       |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 572      |\n",
      "|    time_elapsed    | 3717     |\n",
      "|    total_timesteps | 1171456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 3722        |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029971417 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00771     |\n",
      "|    n_updates            | 50780       |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 3727        |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029465672 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0479      |\n",
      "|    n_updates            | 50790       |\n",
      "|    policy_gradient_loss | -0.0351     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 3733        |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033908032 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 50800       |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 3738        |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031394843 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 50810       |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=-0.04 +/- 0.99\n",
      "Episode length: 30.01 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028948503 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.362      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.078       |\n",
      "|    n_updates            | 50820       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 577      |\n",
      "|    time_elapsed    | 3748     |\n",
      "|    total_timesteps | 1181696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 3754        |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036066666 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00566    |\n",
      "|    n_updates            | 50830       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 3759        |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031943712 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0463      |\n",
      "|    n_updates            | 50840       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 3764        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030257158 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0641      |\n",
      "|    n_updates            | 50850       |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 3769        |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026241483 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0323      |\n",
      "|    n_updates            | 50860       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=0.20 +/- 0.95\n",
      "Episode length: 30.00 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028059324 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 50870       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 582      |\n",
      "|    time_elapsed    | 3779     |\n",
      "|    total_timesteps | 1191936  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 583        |\n",
      "|    time_elapsed         | 3785       |\n",
      "|    total_timesteps      | 1193984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02749874 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.345     |\n",
      "|    explained_variance   | 0.352      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0302     |\n",
      "|    n_updates            | 50880      |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 3790        |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027122393 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 50890       |\n",
      "|    policy_gradient_loss | -0.036      |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 3795        |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031198673 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.364      |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00443     |\n",
      "|    n_updates            | 50900       |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=0.10 +/- 0.98\n",
      "Episode length: 29.95 +/- 0.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028961908 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 50910       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 586      |\n",
      "|    time_elapsed    | 3805     |\n",
      "|    total_timesteps | 1200128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 3810        |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032605287 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0298      |\n",
      "|    n_updates            | 50920       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 588        |\n",
      "|    time_elapsed         | 3815       |\n",
      "|    total_timesteps      | 1204224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03162636 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.358     |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00939    |\n",
      "|    n_updates            | 50930      |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 3820        |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027671631 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 50940       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 3826        |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030394075 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 50950       |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=0.01 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028843364 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.37       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.011       |\n",
      "|    n_updates            | 50960       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 591      |\n",
      "|    time_elapsed    | 3836     |\n",
      "|    total_timesteps | 1210368  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 3841        |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038463492 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00468    |\n",
      "|    n_updates            | 50970       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 3846        |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028200433 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.379      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 50980       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 3851        |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027087338 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.358      |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 50990       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 3857        |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032903016 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 51000       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=0.11 +/- 0.97\n",
      "Episode length: 29.99 +/- 0.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028369486 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00344    |\n",
      "|    n_updates            | 51010       |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 596      |\n",
      "|    time_elapsed    | 3867     |\n",
      "|    total_timesteps | 1220608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 3872        |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032487568 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 51020       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 3877        |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034334756 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.356      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0595      |\n",
      "|    n_updates            | 51030       |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.03      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 315       |\n",
      "|    iterations           | 599       |\n",
      "|    time_elapsed         | 3882      |\n",
      "|    total_timesteps      | 1226752   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0282027 |\n",
      "|    clip_fraction        | 0.151     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.359    |\n",
      "|    explained_variance   | 0.235     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0629    |\n",
      "|    n_updates            | 51040     |\n",
      "|    policy_gradient_loss | -0.0339   |\n",
      "|    value_loss           | 0.225     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 3887        |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036570612 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0146      |\n",
      "|    n_updates            | 51050       |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.52\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1230000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03109254 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.341     |\n",
      "|    explained_variance   | 0.33       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0315     |\n",
      "|    n_updates            | 51060      |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 601      |\n",
      "|    time_elapsed    | 3898     |\n",
      "|    total_timesteps | 1230848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 3903        |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030785479 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0083      |\n",
      "|    n_updates            | 51070       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 3908        |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029430242 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 51080       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | -0.09     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 316       |\n",
      "|    iterations           | 604       |\n",
      "|    time_elapsed         | 3914      |\n",
      "|    total_timesteps      | 1236992   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0315186 |\n",
      "|    clip_fraction        | 0.154     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.327    |\n",
      "|    explained_variance   | 0.351     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0319    |\n",
      "|    n_updates            | 51090     |\n",
      "|    policy_gradient_loss | -0.0337   |\n",
      "|    value_loss           | 0.193     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 605        |\n",
      "|    time_elapsed         | 3919       |\n",
      "|    total_timesteps      | 1239040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02943834 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0474     |\n",
      "|    n_updates            | 51100      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=0.04 +/- 0.99\n",
      "Episode length: 29.93 +/- 0.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1240000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03092328 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.343     |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0407     |\n",
      "|    n_updates            | 51110      |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 606      |\n",
      "|    time_elapsed    | 3929     |\n",
      "|    total_timesteps | 1241088  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 607        |\n",
      "|    time_elapsed         | 3935       |\n",
      "|    total_timesteps      | 1243136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03801231 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.341     |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0353     |\n",
      "|    n_updates            | 51120      |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.31       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 608        |\n",
      "|    time_elapsed         | 3940       |\n",
      "|    total_timesteps      | 1245184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02835276 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.32      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0712     |\n",
      "|    n_updates            | 51130      |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 609        |\n",
      "|    time_elapsed         | 3945       |\n",
      "|    total_timesteps      | 1247232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03267049 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0193     |\n",
      "|    n_updates            | 51140      |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 610         |\n",
      "|    time_elapsed         | 3951        |\n",
      "|    total_timesteps      | 1249280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029045466 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0306      |\n",
      "|    n_updates            | 51150       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=0.03 +/- 0.97\n",
      "Episode length: 30.04 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023866434 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0181      |\n",
      "|    n_updates            | 51160       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 611      |\n",
      "|    time_elapsed    | 3961     |\n",
      "|    total_timesteps | 1251328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 3966        |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029185453 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0303      |\n",
      "|    n_updates            | 51170       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 3972        |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027331688 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0376      |\n",
      "|    n_updates            | 51180       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 3977        |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027513977 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 51190       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 3982        |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028668381 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0385      |\n",
      "|    n_updates            | 51200       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=0.29 +/- 0.94\n",
      "Episode length: 29.98 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025949692 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0482      |\n",
      "|    n_updates            | 51210       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.29\n",
      "SELFPLAY: new best model, bumping up generation to 33\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 616      |\n",
      "|    time_elapsed    | 3993     |\n",
      "|    total_timesteps | 1261568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 3998        |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030059446 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0156      |\n",
      "|    n_updates            | 51220       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 4003        |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030534942 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 51230       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.04      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 316       |\n",
      "|    iterations           | 619       |\n",
      "|    time_elapsed         | 4008      |\n",
      "|    total_timesteps      | 1267712   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0337088 |\n",
      "|    clip_fraction        | 0.13      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.286    |\n",
      "|    explained_variance   | 0.32      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0526    |\n",
      "|    n_updates            | 51240     |\n",
      "|    policy_gradient_loss | -0.0289   |\n",
      "|    value_loss           | 0.204     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 4014        |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027132103 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 51250       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1270000, episode_reward=0.01 +/- 0.98\n",
      "Episode length: 29.98 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029163036 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 51260       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 621      |\n",
      "|    time_elapsed    | 4025     |\n",
      "|    total_timesteps | 1271808  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 4030        |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028891731 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 51270       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 4035        |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027264936 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0641      |\n",
      "|    n_updates            | 51280       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 4040        |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029182639 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 51290       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=0.15 +/- 0.98\n",
      "Episode length: 29.93 +/- 0.57\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1280000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03291259 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0307     |\n",
      "|    n_updates            | 51300      |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 625      |\n",
      "|    time_elapsed    | 4051     |\n",
      "|    total_timesteps | 1280000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 4056        |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022453386 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00165    |\n",
      "|    n_updates            | 51310       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 4061        |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026411783 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0311      |\n",
      "|    n_updates            | 51320       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 628        |\n",
      "|    time_elapsed         | 4067       |\n",
      "|    total_timesteps      | 1286144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02500765 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.275     |\n",
      "|    explained_variance   | 0.341      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0163     |\n",
      "|    n_updates            | 51330      |\n",
      "|    policy_gradient_loss | -0.0267    |\n",
      "|    value_loss           | 0.172      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 4072        |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030173011 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00495     |\n",
      "|    n_updates            | 51340       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=0.04 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.43\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1290000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02139369 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.245     |\n",
      "|    explained_variance   | 0.437      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0278     |\n",
      "|    n_updates            | 51350      |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 630      |\n",
      "|    time_elapsed    | 4082     |\n",
      "|    total_timesteps | 1290240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 4087        |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027682135 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.044       |\n",
      "|    n_updates            | 51360       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 4092        |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022521209 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0527      |\n",
      "|    n_updates            | 51370       |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 4098        |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032223575 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0345      |\n",
      "|    n_updates            | 51380       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 4103        |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026097588 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0608      |\n",
      "|    n_updates            | 51390       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=0.19 +/- 0.97\n",
      "Episode length: 29.92 +/- 0.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1300000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02617854 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.256     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0811     |\n",
      "|    n_updates            | 51400      |\n",
      "|    policy_gradient_loss | -0.028     |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 635      |\n",
      "|    time_elapsed    | 4113     |\n",
      "|    total_timesteps | 1300480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 4118        |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035031248 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0304      |\n",
      "|    n_updates            | 51410       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 4123        |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029796612 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 51420       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 4129        |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029562052 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0383      |\n",
      "|    n_updates            | 51430       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 4134        |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026031261 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 51440       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=0.19 +/- 0.98\n",
      "Episode length: 29.98 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032942757 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00752     |\n",
      "|    n_updates            | 51450       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 640      |\n",
      "|    time_elapsed    | 4145     |\n",
      "|    total_timesteps | 1310720  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 4150        |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024489831 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0581      |\n",
      "|    n_updates            | 51460       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 4155        |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027380442 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0214      |\n",
      "|    n_updates            | 51470       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 4160        |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029480584 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0204      |\n",
      "|    n_updates            | 51480       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 4166        |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024889948 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0385      |\n",
      "|    n_updates            | 51490       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=0.05 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025136467 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 51500       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 645      |\n",
      "|    time_elapsed    | 4176     |\n",
      "|    total_timesteps | 1320960  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 4181        |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024985634 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0496      |\n",
      "|    n_updates            | 51510       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 647        |\n",
      "|    time_elapsed         | 4187       |\n",
      "|    total_timesteps      | 1325056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03444679 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.277     |\n",
      "|    explained_variance   | 0.289      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0464     |\n",
      "|    n_updates            | 51520      |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 4192        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030835275 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 51530       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 649        |\n",
      "|    time_elapsed         | 4197       |\n",
      "|    total_timesteps      | 1329152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03045291 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.276     |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0212     |\n",
      "|    n_updates            | 51540      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027830925 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0502      |\n",
      "|    n_updates            | 51550       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 650      |\n",
      "|    time_elapsed    | 4208     |\n",
      "|    total_timesteps | 1331200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 4213        |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035171464 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000947    |\n",
      "|    n_updates            | 51560       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 652        |\n",
      "|    time_elapsed         | 4218       |\n",
      "|    total_timesteps      | 1335296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02396132 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.272     |\n",
      "|    explained_variance   | 0.476      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0156     |\n",
      "|    n_updates            | 51570      |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    value_loss           | 0.17       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 4223        |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033370487 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 51580       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 4228        |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023780324 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 51590       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=0.17 +/- 0.98\n",
      "Episode length: 29.79 +/- 1.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022299344 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0464      |\n",
      "|    n_updates            | 51600       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 655      |\n",
      "|    time_elapsed    | 4239     |\n",
      "|    total_timesteps | 1341440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 4244        |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023175314 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 51610       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 4250        |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027209766 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0303      |\n",
      "|    n_updates            | 51620       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 4255        |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024781832 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0302      |\n",
      "|    n_updates            | 51630       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 4260        |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029384062 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0531      |\n",
      "|    n_updates            | 51640       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=0.26 +/- 0.94\n",
      "Episode length: 30.02 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024915198 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0277      |\n",
      "|    n_updates            | 51650       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 34\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 660      |\n",
      "|    time_elapsed    | 4271     |\n",
      "|    total_timesteps | 1351680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 4276        |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038954534 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0377      |\n",
      "|    n_updates            | 51660       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 4282        |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032004096 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00762     |\n",
      "|    n_updates            | 51670       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 4287        |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030690972 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0281      |\n",
      "|    n_updates            | 51680       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 4292        |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026984934 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0194      |\n",
      "|    n_updates            | 51690       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=0.10 +/- 0.97\n",
      "Episode length: 29.93 +/- 0.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021895103 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0209      |\n",
      "|    n_updates            | 51700       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 665      |\n",
      "|    time_elapsed    | 4303     |\n",
      "|    total_timesteps | 1361920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 4308        |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025067972 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 51710       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 4313        |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029912928 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0495      |\n",
      "|    n_updates            | 51720       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 4319        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023941306 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 51730       |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1370000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 29.97 +/- 0.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025016794 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 51740       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 669      |\n",
      "|    time_elapsed    | 4329     |\n",
      "|    total_timesteps | 1370112  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 670        |\n",
      "|    time_elapsed         | 4334       |\n",
      "|    total_timesteps      | 1372160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02468365 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.483      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0307     |\n",
      "|    n_updates            | 51750      |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    value_loss           | 0.168      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 4339        |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025771352 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0792      |\n",
      "|    n_updates            | 51760       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 4345        |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028257132 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0285      |\n",
      "|    n_updates            | 51770       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 4350        |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031955417 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00568     |\n",
      "|    n_updates            | 51780       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=0.03 +/- 0.99\n",
      "Episode length: 29.92 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029243577 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0187      |\n",
      "|    n_updates            | 51790       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 674      |\n",
      "|    time_elapsed    | 4360     |\n",
      "|    total_timesteps | 1380352  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 4365        |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030011248 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0103      |\n",
      "|    n_updates            | 51800       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 4370        |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025310624 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0261      |\n",
      "|    n_updates            | 51810       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 4376        |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021854047 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.242      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 51820       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 4381        |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020771261 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 51830       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=0.19 +/- 0.96\n",
      "Episode length: 29.92 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028751235 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0565      |\n",
      "|    n_updates            | 51840       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 679      |\n",
      "|    time_elapsed    | 4391     |\n",
      "|    total_timesteps | 1390592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 4397        |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024816785 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 51850       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 4402        |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021352166 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.238      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.067       |\n",
      "|    n_updates            | 51860       |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 682        |\n",
      "|    time_elapsed         | 4407       |\n",
      "|    total_timesteps      | 1396736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02579587 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.261     |\n",
      "|    explained_variance   | 0.357      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0554     |\n",
      "|    n_updates            | 51870      |\n",
      "|    policy_gradient_loss | -0.0284    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 4413        |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027909327 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0437      |\n",
      "|    n_updates            | 51880       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=0.25 +/- 0.96\n",
      "Episode length: 30.05 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032740097 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0732      |\n",
      "|    n_updates            | 51890       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 35\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 684      |\n",
      "|    time_elapsed    | 4423     |\n",
      "|    total_timesteps | 1400832  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 685        |\n",
      "|    time_elapsed         | 4429       |\n",
      "|    total_timesteps      | 1402880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03960369 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.255     |\n",
      "|    explained_variance   | 0.359      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0378     |\n",
      "|    n_updates            | 51900      |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.167      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 686        |\n",
      "|    time_elapsed         | 4434       |\n",
      "|    total_timesteps      | 1404928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04509625 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.268     |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0117     |\n",
      "|    n_updates            | 51910      |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    value_loss           | 0.22       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 316        |\n",
      "|    iterations           | 687        |\n",
      "|    time_elapsed         | 4439       |\n",
      "|    total_timesteps      | 1406976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03306205 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.262     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0342     |\n",
      "|    n_updates            | 51920      |\n",
      "|    policy_gradient_loss | -0.0255    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 4444        |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026219469 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 51930       |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=0.02 +/- 0.97\n",
      "Episode length: 30.00 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033016615 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0627      |\n",
      "|    n_updates            | 51940       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 689      |\n",
      "|    time_elapsed    | 4455     |\n",
      "|    total_timesteps | 1411072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 4460        |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040603697 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 51950       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 4465        |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029132048 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0468      |\n",
      "|    n_updates            | 51960       |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 4470        |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026051778 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 51970       |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 4476        |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029173648 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0251      |\n",
      "|    n_updates            | 51980       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=0.15 +/- 0.97\n",
      "Episode length: 30.00 +/- 0.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030286402 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 51990       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.36     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 694      |\n",
      "|    time_elapsed    | 4486     |\n",
      "|    total_timesteps | 1421312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 4491        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025795408 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0267      |\n",
      "|    n_updates            | 52000       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 4497        |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022641584 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0433      |\n",
      "|    n_updates            | 52010       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 4502        |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024830393 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0297      |\n",
      "|    n_updates            | 52020       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 4507        |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027052695 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0567      |\n",
      "|    n_updates            | 52030       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=0.20 +/- 0.97\n",
      "Episode length: 29.99 +/- 0.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025208754 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 52040       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 699      |\n",
      "|    time_elapsed    | 4518     |\n",
      "|    total_timesteps | 1431552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 4523        |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023165632 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 52050       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 4528        |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030148368 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 52060       |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 4533        |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023645373 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0297      |\n",
      "|    n_updates            | 52070       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 4539        |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030592559 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.238      |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0718      |\n",
      "|    n_updates            | 52080       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=0.32 +/- 0.94\n",
      "Episode length: 30.03 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029617298 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0589      |\n",
      "|    n_updates            | 52090       |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.32\n",
      "SELFPLAY: new best model, bumping up generation to 36\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 704      |\n",
      "|    time_elapsed    | 4549     |\n",
      "|    total_timesteps | 1441792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 4554        |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027805258 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 52100       |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 4560        |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033223316 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0552      |\n",
      "|    n_updates            | 52110       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 4565        |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027610045 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0531      |\n",
      "|    n_updates            | 52120       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 4570        |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032018274 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00887     |\n",
      "|    n_updates            | 52130       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1450000, episode_reward=0.31 +/- 0.93\n",
      "Episode length: 30.03 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026987623 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0528      |\n",
      "|    n_updates            | 52140       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.31\n",
      "SELFPLAY: new best model, bumping up generation to 37\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 709      |\n",
      "|    time_elapsed    | 4580     |\n",
      "|    total_timesteps | 1452032  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 710        |\n",
      "|    time_elapsed         | 4586       |\n",
      "|    total_timesteps      | 1454080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03318248 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.123      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0519     |\n",
      "|    n_updates            | 52150      |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 0.227      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.12      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 317       |\n",
      "|    iterations           | 711       |\n",
      "|    time_elapsed         | 4591      |\n",
      "|    total_timesteps      | 1456128   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0266973 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.339    |\n",
      "|    explained_variance   | 0.187     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0682    |\n",
      "|    n_updates            | 52160     |\n",
      "|    policy_gradient_loss | -0.0303   |\n",
      "|    value_loss           | 0.214     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 4596        |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030298455 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0377      |\n",
      "|    n_updates            | 52170       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=-0.07 +/- 0.99\n",
      "Episode length: 29.98 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | -0.07      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1460000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02831002 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.332     |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0664     |\n",
      "|    n_updates            | 52180      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 713      |\n",
      "|    time_elapsed    | 4607     |\n",
      "|    total_timesteps | 1460224  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 4612        |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026984397 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 52190       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 4617        |\n",
      "|    total_timesteps      | 1464320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030583875 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.014       |\n",
      "|    n_updates            | 52200       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 4622        |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029392226 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00831     |\n",
      "|    n_updates            | 52210       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 717        |\n",
      "|    time_elapsed         | 4628       |\n",
      "|    total_timesteps      | 1468416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02762353 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.331     |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0278     |\n",
      "|    n_updates            | 52220      |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=0.00 +/- 0.99\n",
      "Episode length: 29.99 +/- 0.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1470000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02860206 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.319     |\n",
      "|    explained_variance   | 0.29       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0344     |\n",
      "|    n_updates            | 52230      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.176      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 316      |\n",
      "|    iterations      | 718      |\n",
      "|    time_elapsed    | 4638     |\n",
      "|    total_timesteps | 1470464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 4643        |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022470571 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00175     |\n",
      "|    n_updates            | 52240       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 4649        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026561644 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 52250       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 721        |\n",
      "|    time_elapsed         | 4654       |\n",
      "|    total_timesteps      | 1476608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03258086 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0349     |\n",
      "|    n_updates            | 52260      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 722        |\n",
      "|    time_elapsed         | 4659       |\n",
      "|    total_timesteps      | 1478656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02742589 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.302     |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0275     |\n",
      "|    n_updates            | 52270      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=0.22 +/- 0.95\n",
      "Episode length: 30.01 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025355315 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.061       |\n",
      "|    n_updates            | 52280       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 38\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 723      |\n",
      "|    time_elapsed    | 4670     |\n",
      "|    total_timesteps | 1480704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 4675        |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030658294 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0355      |\n",
      "|    n_updates            | 52290       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 4680        |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028162917 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 52300       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 4685        |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032153465 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0345      |\n",
      "|    n_updates            | 52310       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 4691        |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028424956 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0483      |\n",
      "|    n_updates            | 52320       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=0.06 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025845483 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0311      |\n",
      "|    n_updates            | 52330       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 728      |\n",
      "|    time_elapsed    | 4701     |\n",
      "|    total_timesteps | 1490944  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 4706        |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027797155 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 52340       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.09      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 317       |\n",
      "|    iterations           | 730       |\n",
      "|    time_elapsed         | 4711      |\n",
      "|    total_timesteps      | 1495040   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0295218 |\n",
      "|    clip_fraction        | 0.149     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.347    |\n",
      "|    explained_variance   | 0.426     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0189    |\n",
      "|    n_updates            | 52350     |\n",
      "|    policy_gradient_loss | -0.0324   |\n",
      "|    value_loss           | 0.191     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 4716        |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029762078 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0203      |\n",
      "|    n_updates            | 52360       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 732        |\n",
      "|    time_elapsed         | 4722       |\n",
      "|    total_timesteps      | 1499136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02765163 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.336     |\n",
      "|    explained_variance   | 0.432      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0247     |\n",
      "|    n_updates            | 52370      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=-0.02 +/- 0.97\n",
      "Episode length: 29.61 +/- 2.39\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.6       |\n",
      "|    mean_reward          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1500000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03154477 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.353     |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0448     |\n",
      "|    n_updates            | 52380      |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 733      |\n",
      "|    time_elapsed    | 4732     |\n",
      "|    total_timesteps | 1501184  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.03      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 317       |\n",
      "|    iterations           | 734       |\n",
      "|    time_elapsed         | 4737      |\n",
      "|    total_timesteps      | 1503232   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0366851 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.352    |\n",
      "|    explained_variance   | 0.461     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0505    |\n",
      "|    n_updates            | 52390     |\n",
      "|    policy_gradient_loss | -0.0354   |\n",
      "|    value_loss           | 0.173     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 4743        |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027948968 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 52400       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 4748        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031059382 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 52410       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 4753        |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027050205 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0196      |\n",
      "|    n_updates            | 52420       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=0.04 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1510000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03005983 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.329     |\n",
      "|    explained_variance   | 0.4        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0783     |\n",
      "|    n_updates            | 52430      |\n",
      "|    policy_gradient_loss | -0.03      |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 738      |\n",
      "|    time_elapsed    | 4764     |\n",
      "|    total_timesteps | 1511424  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 4769        |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025225654 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0466      |\n",
      "|    n_updates            | 52440       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 740         |\n",
      "|    time_elapsed         | 4774        |\n",
      "|    total_timesteps      | 1515520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031361002 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0263      |\n",
      "|    n_updates            | 52450       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.05      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 741        |\n",
      "|    time_elapsed         | 4780       |\n",
      "|    total_timesteps      | 1517568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02617008 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.389      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0104     |\n",
      "|    n_updates            | 52460      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 4785        |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027795976 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 52470       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 30.04 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026917955 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00913     |\n",
      "|    n_updates            | 52480       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 39\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 743      |\n",
      "|    time_elapsed    | 4795     |\n",
      "|    total_timesteps | 1521664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 4801        |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029194124 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.354      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0624      |\n",
      "|    n_updates            | 52490       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 745        |\n",
      "|    time_elapsed         | 4806       |\n",
      "|    total_timesteps      | 1525760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03125929 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.355     |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0275     |\n",
      "|    n_updates            | 52500      |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 4811        |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026964232 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0461      |\n",
      "|    n_updates            | 52510       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 4816        |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027773846 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000375    |\n",
      "|    n_updates            | 52520       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=0.24 +/- 0.96\n",
      "Episode length: 29.99 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033808395 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0591      |\n",
      "|    n_updates            | 52530       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 40\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.17    |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 748      |\n",
      "|    time_elapsed    | 4827     |\n",
      "|    total_timesteps | 1531904  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 4832        |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032756347 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.368      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 52540       |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 4837        |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042761493 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0671      |\n",
      "|    n_updates            | 52550       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.11      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 751        |\n",
      "|    time_elapsed         | 4843       |\n",
      "|    total_timesteps      | 1538048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02916858 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.362     |\n",
      "|    explained_variance   | 0.4        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0462     |\n",
      "|    n_updates            | 52560      |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=-0.03 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028708916 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.052       |\n",
      "|    n_updates            | 52570       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 752      |\n",
      "|    time_elapsed    | 4853     |\n",
      "|    total_timesteps | 1540096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 4859        |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027706046 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.355      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 52580       |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 4864        |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030291818 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0137      |\n",
      "|    n_updates            | 52590       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 755        |\n",
      "|    time_elapsed         | 4869       |\n",
      "|    total_timesteps      | 1546240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03058334 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.353     |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0502     |\n",
      "|    n_updates            | 52600      |\n",
      "|    policy_gradient_loss | -0.0339    |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 4875        |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027577806 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 52610       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1550000, episode_reward=-0.07 +/- 0.97\n",
      "Episode length: 29.95 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027561031 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 52620       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 757      |\n",
      "|    time_elapsed    | 4885     |\n",
      "|    total_timesteps | 1550336  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 4890        |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024610829 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 52630       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 4896        |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033506818 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 52640       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 4901        |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036607746 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 52650       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 4906        |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029009443 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.358      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.024       |\n",
      "|    n_updates            | 52660       |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=-0.12 +/- 0.97\n",
      "Episode length: 29.73 +/- 2.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035241462 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0263      |\n",
      "|    n_updates            | 52670       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 762      |\n",
      "|    time_elapsed    | 4917     |\n",
      "|    total_timesteps | 1560576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 4922        |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029469945 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 52680       |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 4927        |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033869192 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0231      |\n",
      "|    n_updates            | 52690       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 765        |\n",
      "|    time_elapsed         | 4933       |\n",
      "|    total_timesteps      | 1566720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03797941 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.037      |\n",
      "|    n_updates            | 52700      |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 766        |\n",
      "|    time_elapsed         | 4938       |\n",
      "|    total_timesteps      | 1568768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02904025 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.347     |\n",
      "|    explained_variance   | 0.405      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0119     |\n",
      "|    n_updates            | 52710      |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=0.22 +/- 0.97\n",
      "Episode length: 30.06 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033268765 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0505      |\n",
      "|    n_updates            | 52720       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 41\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 767      |\n",
      "|    time_elapsed    | 4949     |\n",
      "|    total_timesteps | 1570816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 4954        |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025328327 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00108     |\n",
      "|    n_updates            | 52730       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 769        |\n",
      "|    time_elapsed         | 4959       |\n",
      "|    total_timesteps      | 1574912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03312619 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.324     |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0461     |\n",
      "|    n_updates            | 52740      |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 770        |\n",
      "|    time_elapsed         | 4964       |\n",
      "|    total_timesteps      | 1576960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03113107 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.335     |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0192     |\n",
      "|    n_updates            | 52750      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 4970        |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034701806 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0257      |\n",
      "|    n_updates            | 52760       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028191589 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.358      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00107    |\n",
      "|    n_updates            | 52770       |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.17    |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 772      |\n",
      "|    time_elapsed    | 4980     |\n",
      "|    total_timesteps | 1581056  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 4985        |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029214907 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.361      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 52780       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 774        |\n",
      "|    time_elapsed         | 4991       |\n",
      "|    total_timesteps      | 1585152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02683869 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.362     |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0455     |\n",
      "|    n_updates            | 52790      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 4996        |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033330098 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.357      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0294      |\n",
      "|    n_updates            | 52800       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.17      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 317       |\n",
      "|    iterations           | 776       |\n",
      "|    time_elapsed         | 5001      |\n",
      "|    total_timesteps      | 1589248   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0456705 |\n",
      "|    clip_fraction        | 0.161     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.36     |\n",
      "|    explained_variance   | 0.448     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.02      |\n",
      "|    n_updates            | 52810     |\n",
      "|    policy_gradient_loss | -0.0354   |\n",
      "|    value_loss           | 0.169     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=0.05 +/- 0.99\n",
      "Episode length: 29.89 +/- 1.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039288096 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0676      |\n",
      "|    n_updates            | 52820       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 777      |\n",
      "|    time_elapsed    | 5012     |\n",
      "|    total_timesteps | 1591296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 5017        |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030820455 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0254      |\n",
      "|    n_updates            | 52830       |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 5022        |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031233495 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 52840       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 5028        |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035435997 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0525      |\n",
      "|    n_updates            | 52850       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 5033        |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031471223 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0178      |\n",
      "|    n_updates            | 52860       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.93 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032930057 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00702     |\n",
      "|    n_updates            | 52870       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 782      |\n",
      "|    time_elapsed    | 5043     |\n",
      "|    total_timesteps | 1601536  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 783        |\n",
      "|    time_elapsed         | 5049       |\n",
      "|    total_timesteps      | 1603584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03503152 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.356     |\n",
      "|    explained_variance   | 0.349      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00596    |\n",
      "|    n_updates            | 52880      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 5054        |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042618643 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.352      |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0266      |\n",
      "|    n_updates            | 52890       |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 5059        |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030738227 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0519      |\n",
      "|    n_updates            | 52900       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 5064        |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035271864 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.072       |\n",
      "|    n_updates            | 52910       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=-0.09 +/- 0.99\n",
      "Episode length: 29.94 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030949758 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0567      |\n",
      "|    n_updates            | 52920       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 787      |\n",
      "|    time_elapsed    | 5074     |\n",
      "|    total_timesteps | 1611776  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 788        |\n",
      "|    time_elapsed         | 5080       |\n",
      "|    total_timesteps      | 1613824    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03091146 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.355     |\n",
      "|    explained_variance   | 0.316      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0397     |\n",
      "|    n_updates            | 52930      |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    value_loss           | 0.176      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 5085        |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027343601 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00843     |\n",
      "|    n_updates            | 52940       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 5090        |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031133426 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00646     |\n",
      "|    n_updates            | 52950       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 5095        |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028058628 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0664      |\n",
      "|    n_updates            | 52960       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=0.09 +/- 0.97\n",
      "Episode length: 29.95 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034700796 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0401      |\n",
      "|    n_updates            | 52970       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 792      |\n",
      "|    time_elapsed    | 5106     |\n",
      "|    total_timesteps | 1622016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 5111        |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030410953 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 52980       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 5116        |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029001229 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 52990       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 5121        |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026931083 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0583      |\n",
      "|    n_updates            | 53000       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 29.98 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031163376 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0107      |\n",
      "|    n_updates            | 53010       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 42\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 796      |\n",
      "|    time_elapsed    | 5132     |\n",
      "|    total_timesteps | 1630208  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 5137        |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027071815 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00667     |\n",
      "|    n_updates            | 53020       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 5143        |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039976172 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.356      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00971    |\n",
      "|    n_updates            | 53030       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 5148        |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033683233 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 53040       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 5154        |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030902356 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0317      |\n",
      "|    n_updates            | 53050       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=0.22 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.41\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1640000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02726167 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.337     |\n",
      "|    explained_variance   | 0.167      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0193     |\n",
      "|    n_updates            | 53060      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 43\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 801      |\n",
      "|    time_elapsed    | 5164     |\n",
      "|    total_timesteps | 1640448  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 802        |\n",
      "|    time_elapsed         | 5169       |\n",
      "|    total_timesteps      | 1642496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02734543 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.257      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0289     |\n",
      "|    n_updates            | 53070      |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    value_loss           | 0.223      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 5175        |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030132707 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0554      |\n",
      "|    n_updates            | 53080       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 5180        |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031810325 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.024       |\n",
      "|    n_updates            | 53090       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 805        |\n",
      "|    time_elapsed         | 5185       |\n",
      "|    total_timesteps      | 1648640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03400385 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.344     |\n",
      "|    explained_variance   | 0.44       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0272     |\n",
      "|    n_updates            | 53100      |\n",
      "|    policy_gradient_loss | -0.0332    |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=0.07 +/- 0.99\n",
      "Episode length: 29.99 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025971223 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0568      |\n",
      "|    n_updates            | 53110       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 806      |\n",
      "|    time_elapsed    | 5196     |\n",
      "|    total_timesteps | 1650688  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 807        |\n",
      "|    time_elapsed         | 5201       |\n",
      "|    total_timesteps      | 1652736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02919453 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.346     |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0153     |\n",
      "|    n_updates            | 53120      |\n",
      "|    policy_gradient_loss | -0.0339    |\n",
      "|    value_loss           | 0.173      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 5206        |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031213399 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0399      |\n",
      "|    n_updates            | 53130       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 809         |\n",
      "|    time_elapsed         | 5211        |\n",
      "|    total_timesteps      | 1656832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028260829 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0498      |\n",
      "|    n_updates            | 53140       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | -0.09     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 317       |\n",
      "|    iterations           | 810       |\n",
      "|    time_elapsed         | 5216      |\n",
      "|    total_timesteps      | 1658880   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0292052 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.367    |\n",
      "|    explained_variance   | 0.288     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.038     |\n",
      "|    n_updates            | 53150     |\n",
      "|    policy_gradient_loss | -0.033    |\n",
      "|    value_loss           | 0.205     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=0.02 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029604515 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0183      |\n",
      "|    n_updates            | 53160       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 811      |\n",
      "|    time_elapsed    | 5227     |\n",
      "|    total_timesteps | 1660928  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 812        |\n",
      "|    time_elapsed         | 5232       |\n",
      "|    total_timesteps      | 1662976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02871942 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.365     |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0421     |\n",
      "|    n_updates            | 53170      |\n",
      "|    policy_gradient_loss | -0.0332    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 5237        |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037455417 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 53180       |\n",
      "|    policy_gradient_loss | -0.0365     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 5242        |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029957738 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 53190       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 5248        |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033688758 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 53200       |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=0.07 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030246211 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 53210       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 816      |\n",
      "|    time_elapsed    | 5258     |\n",
      "|    total_timesteps | 1671168  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 5263        |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032796305 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0234      |\n",
      "|    n_updates            | 53220       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 5268        |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030467402 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 53230       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 5274        |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027147993 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 53240       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 820        |\n",
      "|    time_elapsed         | 5279       |\n",
      "|    total_timesteps      | 1679360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02830723 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.023      |\n",
      "|    n_updates            | 53250      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1680000, episode_reward=0.15 +/- 0.97\n",
      "Episode length: 30.06 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023958739 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00432    |\n",
      "|    n_updates            | 53260       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.154       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 821      |\n",
      "|    time_elapsed    | 5290     |\n",
      "|    total_timesteps | 1681408  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 317        |\n",
      "|    iterations           | 822        |\n",
      "|    time_elapsed         | 5295       |\n",
      "|    total_timesteps      | 1683456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02736368 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.298     |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0388     |\n",
      "|    n_updates            | 53270      |\n",
      "|    policy_gradient_loss | -0.0269    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 5300        |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040428698 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 53280       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 5305        |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036473826 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0132      |\n",
      "|    n_updates            | 53290       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 5310        |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032390248 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00821     |\n",
      "|    n_updates            | 53300       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=0.18 +/- 0.98\n",
      "Episode length: 30.05 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1690000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029811788 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0271      |\n",
      "|    n_updates            | 53310       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 826      |\n",
      "|    time_elapsed    | 5321     |\n",
      "|    total_timesteps | 1691648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 5326        |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034171052 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00812     |\n",
      "|    n_updates            | 53320       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 5331        |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030143222 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.024       |\n",
      "|    n_updates            | 53330       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 5337        |\n",
      "|    total_timesteps      | 1697792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029675681 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0253      |\n",
      "|    n_updates            | 53340       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 5342        |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025785357 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0731      |\n",
      "|    n_updates            | 53350       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=0.18 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032417007 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0411      |\n",
      "|    n_updates            | 53360       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 831      |\n",
      "|    time_elapsed    | 5352     |\n",
      "|    total_timesteps | 1701888  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 832        |\n",
      "|    time_elapsed         | 5358       |\n",
      "|    total_timesteps      | 1703936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02626496 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.435      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0135     |\n",
      "|    n_updates            | 53370      |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 0.17       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | 0.21      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 318       |\n",
      "|    iterations           | 833       |\n",
      "|    time_elapsed         | 5363      |\n",
      "|    total_timesteps      | 1705984   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0250748 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.291    |\n",
      "|    explained_variance   | 0.426     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0299    |\n",
      "|    n_updates            | 53380     |\n",
      "|    policy_gradient_loss | -0.0309   |\n",
      "|    value_loss           | 0.161     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 5369        |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029984092 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0606      |\n",
      "|    n_updates            | 53390       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1710000, episode_reward=0.14 +/- 0.97\n",
      "Episode length: 29.97 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026783863 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0138      |\n",
      "|    n_updates            | 53400       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 835      |\n",
      "|    time_elapsed    | 5379     |\n",
      "|    total_timesteps | 1710080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 5384        |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029418282 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0311      |\n",
      "|    n_updates            | 53410       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 837        |\n",
      "|    time_elapsed         | 5390       |\n",
      "|    total_timesteps      | 1714176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02947237 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0146     |\n",
      "|    n_updates            | 53420      |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 5395        |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026911011 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0163      |\n",
      "|    n_updates            | 53430       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 5400        |\n",
      "|    total_timesteps      | 1718272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025907464 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00206     |\n",
      "|    n_updates            | 53440       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=0.29 +/- 0.94\n",
      "Episode length: 29.85 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024688352 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 53450       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.29\n",
      "SELFPLAY: new best model, bumping up generation to 44\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 840      |\n",
      "|    time_elapsed    | 5411     |\n",
      "|    total_timesteps | 1720320  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 5416        |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031895313 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0172      |\n",
      "|    n_updates            | 53460       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.154       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 5421        |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031770162 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0139      |\n",
      "|    n_updates            | 53470       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 5426        |\n",
      "|    total_timesteps      | 1726464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032965586 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 53480       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 5432        |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026916966 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0528      |\n",
      "|    n_updates            | 53490       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1730000, episode_reward=0.11 +/- 0.99\n",
      "Episode length: 29.92 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034897394 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00226     |\n",
      "|    n_updates            | 53500       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 845      |\n",
      "|    time_elapsed    | 5442     |\n",
      "|    total_timesteps | 1730560  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.04      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 846        |\n",
      "|    time_elapsed         | 5447       |\n",
      "|    total_timesteps      | 1732608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03463725 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.314     |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00478    |\n",
      "|    n_updates            | 53510      |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 5453        |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033486582 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0373      |\n",
      "|    n_updates            | 53520       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 5459        |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031272538 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 53530       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 849        |\n",
      "|    time_elapsed         | 5464       |\n",
      "|    total_timesteps      | 1738752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03238589 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00631    |\n",
      "|    n_updates            | 53540      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=0.11 +/- 0.99\n",
      "Episode length: 30.00 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030295324 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 53550       |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 850      |\n",
      "|    time_elapsed    | 5474     |\n",
      "|    total_timesteps | 1740800  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 851        |\n",
      "|    time_elapsed         | 5480       |\n",
      "|    total_timesteps      | 1742848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03912659 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.312     |\n",
      "|    explained_variance   | 0.493      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0388     |\n",
      "|    n_updates            | 53560      |\n",
      "|    policy_gradient_loss | -0.0337    |\n",
      "|    value_loss           | 0.139      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 852        |\n",
      "|    time_elapsed         | 5485       |\n",
      "|    total_timesteps      | 1744896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03275285 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.318     |\n",
      "|    explained_variance   | 0.299      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0366     |\n",
      "|    n_updates            | 53570      |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.22       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 5490        |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034900688 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 53580       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 5495        |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028518725 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 53590       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=0.15 +/- 0.98\n",
      "Episode length: 29.76 +/- 1.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030172847 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00734     |\n",
      "|    n_updates            | 53600       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 855      |\n",
      "|    time_elapsed    | 5506     |\n",
      "|    total_timesteps | 1751040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 5512        |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038006417 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0772      |\n",
      "|    n_updates            | 53610       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 5517        |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033179708 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0325      |\n",
      "|    n_updates            | 53620       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 858        |\n",
      "|    time_elapsed         | 5522       |\n",
      "|    total_timesteps      | 1757184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02740114 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.32      |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0634     |\n",
      "|    n_updates            | 53630      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 859        |\n",
      "|    time_elapsed         | 5527       |\n",
      "|    total_timesteps      | 1759232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02845565 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.291     |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00818    |\n",
      "|    n_updates            | 53640      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=0.15 +/- 0.97\n",
      "Episode length: 29.94 +/- 0.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1760000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03231826 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.364      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0163     |\n",
      "|    n_updates            | 53650      |\n",
      "|    policy_gradient_loss | -0.0353    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 860      |\n",
      "|    time_elapsed    | 5538     |\n",
      "|    total_timesteps | 1761280  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 5543        |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030143073 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0304      |\n",
      "|    n_updates            | 53660       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 5548        |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029616328 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0384      |\n",
      "|    n_updates            | 53670       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 5554        |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030620899 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00271     |\n",
      "|    n_updates            | 53680       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 864         |\n",
      "|    time_elapsed         | 5559        |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035947025 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0391      |\n",
      "|    n_updates            | 53690       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=0.26 +/- 0.96\n",
      "Episode length: 29.94 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032145094 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0518      |\n",
      "|    n_updates            | 53700       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 45\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 865      |\n",
      "|    time_elapsed    | 5569     |\n",
      "|    total_timesteps | 1771520  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 5575        |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029632453 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0421      |\n",
      "|    n_updates            | 53710       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 867        |\n",
      "|    time_elapsed         | 5580       |\n",
      "|    total_timesteps      | 1775616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02867293 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.344     |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0422     |\n",
      "|    n_updates            | 53720      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 5585        |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030111738 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 53730       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 5590        |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031468354 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000495    |\n",
      "|    n_updates            | 53740       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=-0.03 +/- 0.98\n",
      "Episode length: 29.91 +/- 0.55\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | -0.03      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1780000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03762667 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.343     |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0407     |\n",
      "|    n_updates            | 53750      |\n",
      "|    policy_gradient_loss | -0.0357    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.09    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 870      |\n",
      "|    time_elapsed    | 5601     |\n",
      "|    total_timesteps | 1781760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 5606        |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030507112 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0403      |\n",
      "|    n_updates            | 53760       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 5611        |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034993146 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 53770       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 5617        |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030962132 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00316    |\n",
      "|    n_updates            | 53780       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 874        |\n",
      "|    time_elapsed         | 5622       |\n",
      "|    total_timesteps      | 1789952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03277445 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0379     |\n",
      "|    n_updates            | 53790      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=0.24 +/- 0.96\n",
      "Episode length: 30.06 +/- 0.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1790000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03657322 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.302     |\n",
      "|    explained_variance   | 0.317      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00327   |\n",
      "|    n_updates            | 53800      |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 46\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 875      |\n",
      "|    time_elapsed    | 5632     |\n",
      "|    total_timesteps | 1792000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 5638        |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029366909 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0734      |\n",
      "|    n_updates            | 53810       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.14      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 318       |\n",
      "|    iterations           | 877       |\n",
      "|    time_elapsed         | 5643      |\n",
      "|    total_timesteps      | 1796096   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0332931 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.338    |\n",
      "|    explained_variance   | 0.356     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0279    |\n",
      "|    n_updates            | 53820     |\n",
      "|    policy_gradient_loss | -0.0296   |\n",
      "|    value_loss           | 0.185     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 5648        |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029567845 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0233      |\n",
      "|    n_updates            | 53830       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=0.00 +/- 0.98\n",
      "Episode length: 29.91 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023517326 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0526      |\n",
      "|    n_updates            | 53840       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 879      |\n",
      "|    time_elapsed    | 5659     |\n",
      "|    total_timesteps | 1800192  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 5664        |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026774287 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0339      |\n",
      "|    n_updates            | 53850       |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 5669        |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036338896 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0756      |\n",
      "|    n_updates            | 53860       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 5674        |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030528981 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0632      |\n",
      "|    n_updates            | 53870       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 883        |\n",
      "|    time_elapsed         | 5679       |\n",
      "|    total_timesteps      | 1808384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02745182 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0486     |\n",
      "|    n_updates            | 53880      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=0.18 +/- 0.97\n",
      "Episode length: 29.97 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029097117 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 53890       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 884      |\n",
      "|    time_elapsed    | 5690     |\n",
      "|    total_timesteps | 1810432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 5695        |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028907778 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0108      |\n",
      "|    n_updates            | 53900       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 5701        |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028322034 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0485      |\n",
      "|    n_updates            | 53910       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 5706        |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029366115 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.038       |\n",
      "|    n_updates            | 53920       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 888        |\n",
      "|    time_elapsed         | 5711       |\n",
      "|    total_timesteps      | 1818624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02957929 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.312     |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0362     |\n",
      "|    n_updates            | 53930      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=0.17 +/- 0.96\n",
      "Episode length: 30.01 +/- 0.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1820000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04546075 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0462     |\n",
      "|    n_updates            | 53940      |\n",
      "|    policy_gradient_loss | -0.0352    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 889      |\n",
      "|    time_elapsed    | 5722     |\n",
      "|    total_timesteps | 1820672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 5727        |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030766247 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0263      |\n",
      "|    n_updates            | 53950       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 5732        |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028328963 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0269      |\n",
      "|    n_updates            | 53960       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 5738        |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025893997 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0058      |\n",
      "|    n_updates            | 53970       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.11      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 318       |\n",
      "|    iterations           | 893       |\n",
      "|    time_elapsed         | 5743      |\n",
      "|    total_timesteps      | 1828864   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0336024 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.318    |\n",
      "|    explained_variance   | 0.296     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.04      |\n",
      "|    n_updates            | 53980     |\n",
      "|    policy_gradient_loss | -0.0335   |\n",
      "|    value_loss           | 0.198     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1830000, episode_reward=0.14 +/- 0.97\n",
      "Episode length: 30.02 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1830000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02685924 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.299     |\n",
      "|    explained_variance   | 0.281      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0843     |\n",
      "|    n_updates            | 53990      |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.3      |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 894      |\n",
      "|    time_elapsed    | 5753     |\n",
      "|    total_timesteps | 1830912  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.36       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 895        |\n",
      "|    time_elapsed         | 5759       |\n",
      "|    total_timesteps      | 1832960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02676041 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.286     |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0267     |\n",
      "|    n_updates            | 54000      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 896         |\n",
      "|    time_elapsed         | 5764        |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030285422 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0235      |\n",
      "|    n_updates            | 54010       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 5769        |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030850796 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0943      |\n",
      "|    n_updates            | 54020       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 5774        |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021702576 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0485      |\n",
      "|    n_updates            | 54030       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=0.25 +/- 0.95\n",
      "Episode length: 29.64 +/- 3.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.6        |\n",
      "|    mean_reward          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026899075 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0408      |\n",
      "|    n_updates            | 54040       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 47\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 899      |\n",
      "|    time_elapsed    | 5785     |\n",
      "|    total_timesteps | 1841152  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 5790        |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030494014 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.047       |\n",
      "|    n_updates            | 54050       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 901        |\n",
      "|    time_elapsed         | 5795       |\n",
      "|    total_timesteps      | 1845248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03142166 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.346     |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0233     |\n",
      "|    n_updates            | 54060      |\n",
      "|    policy_gradient_loss | -0.0334    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.04      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 902        |\n",
      "|    time_elapsed         | 5800       |\n",
      "|    total_timesteps      | 1847296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03069314 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.337     |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0407     |\n",
      "|    n_updates            | 54070      |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 903        |\n",
      "|    time_elapsed         | 5805       |\n",
      "|    total_timesteps      | 1849344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03837951 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.364      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00423    |\n",
      "|    n_updates            | 54080      |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=0.07 +/- 0.98\n",
      "Episode length: 29.95 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027618736 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.041       |\n",
      "|    n_updates            | 54090       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 904      |\n",
      "|    time_elapsed    | 5816     |\n",
      "|    total_timesteps | 1851392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 5821        |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031057905 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00334     |\n",
      "|    n_updates            | 54100       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 5827        |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031176446 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 54110       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 5832        |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027992096 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 54120       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 908        |\n",
      "|    time_elapsed         | 5837       |\n",
      "|    total_timesteps      | 1859584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02667756 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.298     |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00867    |\n",
      "|    n_updates            | 54130      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1860000, episode_reward=0.12 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034423828 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00702     |\n",
      "|    n_updates            | 54140       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 909      |\n",
      "|    time_elapsed    | 5848     |\n",
      "|    total_timesteps | 1861632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 5853        |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033171624 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0283      |\n",
      "|    n_updates            | 54150       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 5858        |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027072854 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 54160       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 5863        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033692703 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00197     |\n",
      "|    n_updates            | 54170       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 5869        |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029466756 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00946     |\n",
      "|    n_updates            | 54180       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=0.24 +/- 0.97\n",
      "Episode length: 29.95 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040479735 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0232      |\n",
      "|    n_updates            | 54190       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 48\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 914      |\n",
      "|    time_elapsed    | 5879     |\n",
      "|    total_timesteps | 1871872  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 5884        |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024088643 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0501      |\n",
      "|    n_updates            | 54200       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 916        |\n",
      "|    time_elapsed         | 5890       |\n",
      "|    total_timesteps      | 1875968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02475795 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.311     |\n",
      "|    explained_variance   | 0.435      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0121     |\n",
      "|    n_updates            | 54210      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.176      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 917         |\n",
      "|    time_elapsed         | 5895        |\n",
      "|    total_timesteps      | 1878016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027197003 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0262      |\n",
      "|    n_updates            | 54220       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=0.05 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026791189 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00594     |\n",
      "|    n_updates            | 54230       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 918      |\n",
      "|    time_elapsed    | 5905     |\n",
      "|    total_timesteps | 1880064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 5910        |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028218258 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0355      |\n",
      "|    n_updates            | 54240       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 5916        |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029637903 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0427      |\n",
      "|    n_updates            | 54250       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 921         |\n",
      "|    time_elapsed         | 5921        |\n",
      "|    total_timesteps      | 1886208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028063409 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0191      |\n",
      "|    n_updates            | 54260       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 5926        |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034291625 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0982      |\n",
      "|    n_updates            | 54270       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=0.19 +/- 0.96\n",
      "Episode length: 29.93 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023274727 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0281      |\n",
      "|    n_updates            | 54280       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 923      |\n",
      "|    time_elapsed    | 5937     |\n",
      "|    total_timesteps | 1890304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 5942        |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033400282 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0757      |\n",
      "|    n_updates            | 54290       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 5947        |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029306738 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0153      |\n",
      "|    n_updates            | 54300       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 5953        |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029745169 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0264      |\n",
      "|    n_updates            | 54310       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.16      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 318       |\n",
      "|    iterations           | 927       |\n",
      "|    time_elapsed         | 5958      |\n",
      "|    total_timesteps      | 1898496   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0321142 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.286    |\n",
      "|    explained_variance   | 0.368     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0856    |\n",
      "|    n_updates            | 54320     |\n",
      "|    policy_gradient_loss | -0.0299   |\n",
      "|    value_loss           | 0.214     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 29.78 +/- 1.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025023967 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 54330       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 49\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 928      |\n",
      "|    time_elapsed    | 5969     |\n",
      "|    total_timesteps | 1900544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 5974        |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027241291 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0259      |\n",
      "|    n_updates            | 54340       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 5979        |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025739158 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000223    |\n",
      "|    n_updates            | 54350       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 931         |\n",
      "|    time_elapsed         | 5985        |\n",
      "|    total_timesteps      | 1906688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031198902 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 54360       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 932         |\n",
      "|    time_elapsed         | 5990        |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029629257 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0218      |\n",
      "|    n_updates            | 54370       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1910000, episode_reward=0.01 +/- 0.99\n",
      "Episode length: 29.98 +/- 0.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037032753 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 54380       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 933      |\n",
      "|    time_elapsed    | 6000     |\n",
      "|    total_timesteps | 1910784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 6006        |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026399452 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0477      |\n",
      "|    n_updates            | 54390       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 6011        |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033650886 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 54400       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 936        |\n",
      "|    time_elapsed         | 6016       |\n",
      "|    total_timesteps      | 1916928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03054324 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0413     |\n",
      "|    n_updates            | 54410      |\n",
      "|    policy_gradient_loss | -0.0266    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 937        |\n",
      "|    time_elapsed         | 6022       |\n",
      "|    total_timesteps      | 1918976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02792595 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.298     |\n",
      "|    explained_variance   | 0.349      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0209     |\n",
      "|    n_updates            | 54420      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=-0.03 +/- 0.99\n",
      "Episode length: 29.92 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030315617 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 54430       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 938      |\n",
      "|    time_elapsed    | 6032     |\n",
      "|    total_timesteps | 1921024  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 6037        |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023862809 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0493      |\n",
      "|    n_updates            | 54440       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 6043        |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026156604 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0471      |\n",
      "|    n_updates            | 54450       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 941        |\n",
      "|    time_elapsed         | 6048       |\n",
      "|    total_timesteps      | 1927168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02654823 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.27      |\n",
      "|    explained_variance   | 0.523      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0115     |\n",
      "|    n_updates            | 54460      |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 6054        |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020364098 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0483      |\n",
      "|    n_updates            | 54470       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1930000, episode_reward=0.34 +/- 0.93\n",
      "Episode length: 30.00 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027645785 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0183      |\n",
      "|    n_updates            | 54480       |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.34\n",
      "SELFPLAY: new best model, bumping up generation to 50\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 943      |\n",
      "|    time_elapsed    | 6064     |\n",
      "|    total_timesteps | 1931264  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.04      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 944        |\n",
      "|    time_elapsed         | 6070       |\n",
      "|    total_timesteps      | 1933312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02718885 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.284     |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.057      |\n",
      "|    n_updates            | 54490      |\n",
      "|    policy_gradient_loss | -0.0271    |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.11      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 945        |\n",
      "|    time_elapsed         | 6075       |\n",
      "|    total_timesteps      | 1935360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02724264 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.311     |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0461     |\n",
      "|    n_updates            | 54500      |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 6080        |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032019112 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0666      |\n",
      "|    n_updates            | 54510       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 6085        |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030630548 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0407      |\n",
      "|    n_updates            | 54520       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1940000, episode_reward=0.20 +/- 0.96\n",
      "Episode length: 30.04 +/- 0.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028002292 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0219      |\n",
      "|    n_updates            | 54530       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 948      |\n",
      "|    time_elapsed    | 6096     |\n",
      "|    total_timesteps | 1941504  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 6101        |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032712605 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0912      |\n",
      "|    n_updates            | 54540       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 6106        |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025968574 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 54550       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 6112        |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033940036 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0381      |\n",
      "|    n_updates            | 54560       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 6117        |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030660458 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00473    |\n",
      "|    n_updates            | 54570       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=0.23 +/- 0.96\n",
      "Episode length: 29.99 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027294422 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 54580       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 51\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 953      |\n",
      "|    time_elapsed    | 6127     |\n",
      "|    total_timesteps | 1951744  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 6133        |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027432878 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00909     |\n",
      "|    n_updates            | 54590       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 6138        |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027896821 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 54600       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 6143        |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030015599 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0591      |\n",
      "|    n_updates            | 54610       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 6148        |\n",
      "|    total_timesteps      | 1959936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035692893 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 54620       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=-0.02 +/- 1.00\n",
      "Episode length: 29.92 +/- 0.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1960000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02694784 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.032      |\n",
      "|    n_updates            | 54630      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 958      |\n",
      "|    time_elapsed    | 6159     |\n",
      "|    total_timesteps | 1961984  |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 29.9     |\n",
      "|    ep_rew_mean          | 0.08     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 318      |\n",
      "|    iterations           | 959      |\n",
      "|    time_elapsed         | 6164     |\n",
      "|    total_timesteps      | 1964032  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.03768  |\n",
      "|    clip_fraction        | 0.143    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.303   |\n",
      "|    explained_variance   | 0.454    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00396  |\n",
      "|    n_updates            | 54640    |\n",
      "|    policy_gradient_loss | -0.0307  |\n",
      "|    value_loss           | 0.169    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 6169        |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029718418 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00465     |\n",
      "|    n_updates            | 54650       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 6175        |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031603117 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 54660       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1970000, episode_reward=0.07 +/- 0.99\n",
      "Episode length: 30.02 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032370437 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 54670       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 962      |\n",
      "|    time_elapsed    | 6185     |\n",
      "|    total_timesteps | 1970176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 6190        |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028992698 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0743      |\n",
      "|    n_updates            | 54680       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 964        |\n",
      "|    time_elapsed         | 6196       |\n",
      "|    total_timesteps      | 1974272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03150134 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0.359      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0255     |\n",
      "|    n_updates            | 54690      |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 965        |\n",
      "|    time_elapsed         | 6201       |\n",
      "|    total_timesteps      | 1976320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02950561 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.317     |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00415    |\n",
      "|    n_updates            | 54700      |\n",
      "|    policy_gradient_loss | -0.0338    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 6206        |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036243387 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00467     |\n",
      "|    n_updates            | 54710       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1980000, episode_reward=0.14 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1980000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03170906 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00527    |\n",
      "|    n_updates            | 54720      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.31     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 967      |\n",
      "|    time_elapsed    | 6216     |\n",
      "|    total_timesteps | 1980416  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 6222        |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037667356 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 54730       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 6227        |\n",
      "|    total_timesteps      | 1984512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026731856 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 54740       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 970         |\n",
      "|    time_elapsed         | 6232        |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029299382 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0198      |\n",
      "|    n_updates            | 54750       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 6238        |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034015324 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0381      |\n",
      "|    n_updates            | 54760       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1990000, episode_reward=0.35 +/- 0.93\n",
      "Episode length: 29.82 +/- 1.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023036145 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 54770       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.35\n",
      "SELFPLAY: new best model, bumping up generation to 52\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 972      |\n",
      "|    time_elapsed    | 6248     |\n",
      "|    total_timesteps | 1990656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 6253        |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030722152 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0629      |\n",
      "|    n_updates            | 54780       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 6259        |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034104507 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0206      |\n",
      "|    n_updates            | 54790       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 6264        |\n",
      "|    total_timesteps      | 1996800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037437685 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0505      |\n",
      "|    n_updates            | 54800       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 976        |\n",
      "|    time_elapsed         | 6269       |\n",
      "|    total_timesteps      | 1998848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03414782 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.312     |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0429     |\n",
      "|    n_updates            | 54810      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=-0.07 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027773049 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 54820       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 977      |\n",
      "|    time_elapsed    | 6280     |\n",
      "|    total_timesteps | 2000896  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 978        |\n",
      "|    time_elapsed         | 6285       |\n",
      "|    total_timesteps      | 2002944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03132303 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.318     |\n",
      "|    explained_variance   | 0.47       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0337     |\n",
      "|    n_updates            | 54830      |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 979        |\n",
      "|    time_elapsed         | 6290       |\n",
      "|    total_timesteps      | 2004992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03854577 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.479      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00361    |\n",
      "|    n_updates            | 54840      |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.17       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 6295        |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024381358 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00551     |\n",
      "|    n_updates            | 54850       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 6301        |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026247686 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0238      |\n",
      "|    n_updates            | 54860       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2010000, episode_reward=0.13 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2010000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04237952 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.308     |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0371     |\n",
      "|    n_updates            | 54870      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 982      |\n",
      "|    time_elapsed    | 6311     |\n",
      "|    total_timesteps | 2011136  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 6317        |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028779536 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00693     |\n",
      "|    n_updates            | 54880       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 6322        |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024281356 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0278      |\n",
      "|    n_updates            | 54890       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 6327        |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028296832 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0528      |\n",
      "|    n_updates            | 54900       |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 986         |\n",
      "|    time_elapsed         | 6332        |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030478429 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.062       |\n",
      "|    n_updates            | 54910       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2020000, episode_reward=0.03 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.62\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2020000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03421197 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00603    |\n",
      "|    n_updates            | 54920      |\n",
      "|    policy_gradient_loss | -0.0286    |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 987      |\n",
      "|    time_elapsed    | 6343     |\n",
      "|    total_timesteps | 2021376  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 988        |\n",
      "|    time_elapsed         | 6348       |\n",
      "|    total_timesteps      | 2023424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02641674 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.47       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0298     |\n",
      "|    n_updates            | 54930      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.166      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 6354        |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028781537 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 54940       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 6359        |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027715957 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.037       |\n",
      "|    n_updates            | 54950       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 6364        |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033299685 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0304      |\n",
      "|    n_updates            | 54960       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2030000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 29.95 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032357685 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00782    |\n",
      "|    n_updates            | 54970       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 53\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 992      |\n",
      "|    time_elapsed    | 6375     |\n",
      "|    total_timesteps | 2031616  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 6380        |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033887587 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 54980       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 6386        |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033538528 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0339      |\n",
      "|    n_updates            | 54990       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 6391        |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034547187 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0352      |\n",
      "|    n_updates            | 55000       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 996        |\n",
      "|    time_elapsed         | 6396       |\n",
      "|    total_timesteps      | 2039808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03541096 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.338     |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0119     |\n",
      "|    n_updates            | 55010      |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2040000, episode_reward=0.15 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032577306 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 55020       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 997      |\n",
      "|    time_elapsed    | 6407     |\n",
      "|    total_timesteps | 2041856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 6412        |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027296886 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.034       |\n",
      "|    n_updates            | 55030       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 6417        |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033293795 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0468      |\n",
      "|    n_updates            | 55040       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.18      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 318       |\n",
      "|    iterations           | 1000      |\n",
      "|    time_elapsed         | 6423      |\n",
      "|    total_timesteps      | 2048000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0294304 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.332    |\n",
      "|    explained_variance   | 0.255     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0448    |\n",
      "|    n_updates            | 55050     |\n",
      "|    policy_gradient_loss | -0.0317   |\n",
      "|    value_loss           | 0.205     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2050000, episode_reward=-0.13 +/- 0.97\n",
      "Episode length: 29.95 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028301945 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000552    |\n",
      "|    n_updates            | 55060       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1001     |\n",
      "|    time_elapsed    | 6433     |\n",
      "|    total_timesteps | 2050048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 6438        |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028880209 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0234      |\n",
      "|    n_updates            | 55070       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1003        |\n",
      "|    time_elapsed         | 6444        |\n",
      "|    total_timesteps      | 2054144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028279308 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0303      |\n",
      "|    n_updates            | 55080       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1004        |\n",
      "|    time_elapsed         | 6449        |\n",
      "|    total_timesteps      | 2056192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030227412 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 55090       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 6455        |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024821289 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0399      |\n",
      "|    n_updates            | 55100       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2060000, episode_reward=-0.05 +/- 0.99\n",
      "Episode length: 30.02 +/- 0.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | -0.05      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2060000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03547468 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.443      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00399   |\n",
      "|    n_updates            | 55110      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1006     |\n",
      "|    time_elapsed    | 6465     |\n",
      "|    total_timesteps | 2060288  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1007       |\n",
      "|    time_elapsed         | 6470       |\n",
      "|    total_timesteps      | 2062336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03222493 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.299     |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0115     |\n",
      "|    n_updates            | 55120      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 6476        |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023252534 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0678      |\n",
      "|    n_updates            | 55130       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1009        |\n",
      "|    time_elapsed         | 6481        |\n",
      "|    total_timesteps      | 2066432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026487686 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 55140       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 6486        |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031782098 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 55150       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2070000, episode_reward=0.18 +/- 0.98\n",
      "Episode length: 29.95 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032174326 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0266      |\n",
      "|    n_updates            | 55160       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1011     |\n",
      "|    time_elapsed    | 6497     |\n",
      "|    total_timesteps | 2070528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 6502        |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031746395 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0451      |\n",
      "|    n_updates            | 55170       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 6507        |\n",
      "|    total_timesteps      | 2074624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027080959 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 55180       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1014        |\n",
      "|    time_elapsed         | 6513        |\n",
      "|    total_timesteps      | 2076672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028757367 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 55190       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1015       |\n",
      "|    time_elapsed         | 6518       |\n",
      "|    total_timesteps      | 2078720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03230304 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.241      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0357     |\n",
      "|    n_updates            | 55200      |\n",
      "|    policy_gradient_loss | -0.0345    |\n",
      "|    value_loss           | 0.219      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 30.04 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025543407 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 55210       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1016     |\n",
      "|    time_elapsed    | 6528     |\n",
      "|    total_timesteps | 2080768  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1017       |\n",
      "|    time_elapsed         | 6534       |\n",
      "|    total_timesteps      | 2082816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02393639 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.29      |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0108     |\n",
      "|    n_updates            | 55220      |\n",
      "|    policy_gradient_loss | -0.0288    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1018       |\n",
      "|    time_elapsed         | 6539       |\n",
      "|    total_timesteps      | 2084864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03530955 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.28      |\n",
      "|    explained_variance   | 0.414      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0261     |\n",
      "|    n_updates            | 55230      |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.29       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1019       |\n",
      "|    time_elapsed         | 6544       |\n",
      "|    total_timesteps      | 2086912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03682355 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.279     |\n",
      "|    explained_variance   | 0.426      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0116     |\n",
      "|    n_updates            | 55240      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.151      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 6550        |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033500284 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0379      |\n",
      "|    n_updates            | 55250       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2090000, episode_reward=0.20 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028053083 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 55260       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1021     |\n",
      "|    time_elapsed    | 6560     |\n",
      "|    total_timesteps | 2091008  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1022       |\n",
      "|    time_elapsed         | 6565       |\n",
      "|    total_timesteps      | 2093056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02760122 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.268     |\n",
      "|    explained_variance   | 0.398      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0279     |\n",
      "|    n_updates            | 55270      |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 6571        |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025768787 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0262      |\n",
      "|    n_updates            | 55280       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1024       |\n",
      "|    time_elapsed         | 6576       |\n",
      "|    total_timesteps      | 2097152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03349918 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.29      |\n",
      "|    explained_variance   | 0.408      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00717    |\n",
      "|    n_updates            | 55290      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.42        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 6581        |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025464386 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00569    |\n",
      "|    n_updates            | 55300       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2100000, episode_reward=0.15 +/- 0.96\n",
      "Episode length: 29.94 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032205716 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 55310       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.43     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1026     |\n",
      "|    time_elapsed    | 6592     |\n",
      "|    total_timesteps | 2101248  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 6597        |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031289615 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0341      |\n",
      "|    n_updates            | 55320       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1028        |\n",
      "|    time_elapsed         | 6602        |\n",
      "|    total_timesteps      | 2105344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029087385 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00688     |\n",
      "|    n_updates            | 55330       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.37       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1029       |\n",
      "|    time_elapsed         | 6608       |\n",
      "|    total_timesteps      | 2107392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02900037 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.273     |\n",
      "|    explained_variance   | 0.424      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0913     |\n",
      "|    n_updates            | 55340      |\n",
      "|    policy_gradient_loss | -0.0288    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 6613        |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031988475 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 55350       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2110000, episode_reward=0.18 +/- 0.96\n",
      "Episode length: 29.76 +/- 1.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030805029 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0444      |\n",
      "|    n_updates            | 55360       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1031     |\n",
      "|    time_elapsed    | 6623     |\n",
      "|    total_timesteps | 2111488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1032        |\n",
      "|    time_elapsed         | 6628        |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024626296 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0227      |\n",
      "|    n_updates            | 55370       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 6634        |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031182766 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 55380       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 6639        |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030183688 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0344      |\n",
      "|    n_updates            | 55390       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 6644        |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032078937 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 55400       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2120000, episode_reward=0.24 +/- 0.95\n",
      "Episode length: 29.97 +/- 0.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2120000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02734558 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.275     |\n",
      "|    explained_variance   | 0.42       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0234     |\n",
      "|    n_updates            | 55410      |\n",
      "|    policy_gradient_loss | -0.0277    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 54\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1036     |\n",
      "|    time_elapsed    | 6655     |\n",
      "|    total_timesteps | 2121728  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 6660        |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027174212 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0387      |\n",
      "|    n_updates            | 55420       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 6666        |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029122218 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0405      |\n",
      "|    n_updates            | 55430       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1039       |\n",
      "|    time_elapsed         | 6671       |\n",
      "|    total_timesteps      | 2127872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03875848 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.325     |\n",
      "|    explained_variance   | 0.313      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0324     |\n",
      "|    n_updates            | 55440      |\n",
      "|    policy_gradient_loss | -0.035     |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 6676        |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027843952 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0499      |\n",
      "|    n_updates            | 55450       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2130000, episode_reward=0.12 +/- 0.97\n",
      "Episode length: 29.94 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026159607 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 55460       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1041     |\n",
      "|    time_elapsed    | 6687     |\n",
      "|    total_timesteps | 2131968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 6692        |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028791122 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 55470       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 6697        |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026265662 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0437      |\n",
      "|    n_updates            | 55480       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 6703        |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036682986 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0472      |\n",
      "|    n_updates            | 55490       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2140000, episode_reward=0.12 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027339859 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0431      |\n",
      "|    n_updates            | 55500       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1045     |\n",
      "|    time_elapsed    | 6713     |\n",
      "|    total_timesteps | 2140160  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1046       |\n",
      "|    time_elapsed         | 6719       |\n",
      "|    total_timesteps      | 2142208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03146206 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.313      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0166     |\n",
      "|    n_updates            | 55510      |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1047        |\n",
      "|    time_elapsed         | 6724        |\n",
      "|    total_timesteps      | 2144256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033868093 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0527      |\n",
      "|    n_updates            | 55520       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 6729        |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035165533 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.071       |\n",
      "|    n_updates            | 55530       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.06      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 318       |\n",
      "|    iterations           | 1049      |\n",
      "|    time_elapsed         | 6735      |\n",
      "|    total_timesteps      | 2148352   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0321081 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.281    |\n",
      "|    explained_variance   | 0.275     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0171    |\n",
      "|    n_updates            | 55540     |\n",
      "|    policy_gradient_loss | -0.0303   |\n",
      "|    value_loss           | 0.186     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2150000, episode_reward=0.19 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2150000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03007879 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.413      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0323     |\n",
      "|    n_updates            | 55550      |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.08    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1050     |\n",
      "|    time_elapsed    | 6745     |\n",
      "|    total_timesteps | 2150400  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1051       |\n",
      "|    time_elapsed         | 6750       |\n",
      "|    total_timesteps      | 2152448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02869729 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.296     |\n",
      "|    explained_variance   | 0.261      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0618     |\n",
      "|    n_updates            | 55560      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.217      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 6755        |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029092383 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0297      |\n",
      "|    n_updates            | 55570       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 6761        |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025278509 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00482     |\n",
      "|    n_updates            | 55580       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 6766        |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030451328 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0415      |\n",
      "|    n_updates            | 55590       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=0.15 +/- 0.97\n",
      "Episode length: 29.92 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023523428 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 55600       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1055     |\n",
      "|    time_elapsed    | 6776     |\n",
      "|    total_timesteps | 2160640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 6782        |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027472854 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.86e-05    |\n",
      "|    n_updates            | 55610       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1057        |\n",
      "|    time_elapsed         | 6787        |\n",
      "|    total_timesteps      | 2164736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027951304 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0396      |\n",
      "|    n_updates            | 55620       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 6792        |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034388036 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0323      |\n",
      "|    n_updates            | 55630       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 6797        |\n",
      "|    total_timesteps      | 2168832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029552046 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0209      |\n",
      "|    n_updates            | 55640       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2170000, episode_reward=0.19 +/- 0.98\n",
      "Episode length: 29.98 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026812406 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0185      |\n",
      "|    n_updates            | 55650       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1060     |\n",
      "|    time_elapsed    | 6808     |\n",
      "|    total_timesteps | 2170880  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 6813        |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025544852 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0611      |\n",
      "|    n_updates            | 55660       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 6818        |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033188432 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0467      |\n",
      "|    n_updates            | 55670       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 6824        |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030865252 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0296      |\n",
      "|    n_updates            | 55680       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.33      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 319       |\n",
      "|    iterations           | 1064      |\n",
      "|    time_elapsed         | 6829      |\n",
      "|    total_timesteps      | 2179072   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0258516 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.266    |\n",
      "|    explained_variance   | 0.247     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0204    |\n",
      "|    n_updates            | 55690     |\n",
      "|    policy_gradient_loss | -0.0289   |\n",
      "|    value_loss           | 0.204     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2180000, episode_reward=0.19 +/- 0.96\n",
      "Episode length: 29.94 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030152448 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0207      |\n",
      "|    n_updates            | 55700       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1065     |\n",
      "|    time_elapsed    | 6839     |\n",
      "|    total_timesteps | 2181120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1066        |\n",
      "|    time_elapsed         | 6845        |\n",
      "|    total_timesteps      | 2183168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031048674 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0519      |\n",
      "|    n_updates            | 55710       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 6850        |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032195278 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0281      |\n",
      "|    n_updates            | 55720       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1068       |\n",
      "|    time_elapsed         | 6855       |\n",
      "|    total_timesteps      | 2187264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03452255 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.279     |\n",
      "|    explained_variance   | 0.382      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.035      |\n",
      "|    n_updates            | 55730      |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 6860        |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027306937 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.035       |\n",
      "|    n_updates            | 55740       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2190000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 29.90 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031766273 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0564      |\n",
      "|    n_updates            | 55750       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 55\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1070     |\n",
      "|    time_elapsed    | 6871     |\n",
      "|    total_timesteps | 2191360  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1071       |\n",
      "|    time_elapsed         | 6876       |\n",
      "|    total_timesteps      | 2193408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03658805 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0262     |\n",
      "|    n_updates            | 55760      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1072        |\n",
      "|    time_elapsed         | 6882        |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026949737 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 55770       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 6887        |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025703147 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 55780       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 6893        |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027810717 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0687      |\n",
      "|    n_updates            | 55790       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2200000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 30.06 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030048177 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 55800       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1075     |\n",
      "|    time_elapsed    | 6903     |\n",
      "|    total_timesteps | 2201600  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1076       |\n",
      "|    time_elapsed         | 6908       |\n",
      "|    total_timesteps      | 2203648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03150353 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.302     |\n",
      "|    explained_variance   | 0.275      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0417     |\n",
      "|    n_updates            | 55810      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 6914        |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041442443 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 55820       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 6919        |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028936733 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0311      |\n",
      "|    n_updates            | 55830       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1079        |\n",
      "|    time_elapsed         | 6924        |\n",
      "|    total_timesteps      | 2209792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026822764 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0597      |\n",
      "|    n_updates            | 55840       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2210000, episode_reward=0.28 +/- 0.95\n",
      "Episode length: 29.99 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028680107 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 55850       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.28\n",
      "SELFPLAY: new best model, bumping up generation to 56\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1080     |\n",
      "|    time_elapsed    | 6935     |\n",
      "|    total_timesteps | 2211840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 6940        |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027502347 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0533      |\n",
      "|    n_updates            | 55860       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 6946        |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038112693 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0228      |\n",
      "|    n_updates            | 55870       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 6951        |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029883938 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00425     |\n",
      "|    n_updates            | 55880       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2220000, episode_reward=-0.09 +/- 0.99\n",
      "Episode length: 30.00 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030388568 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0385      |\n",
      "|    n_updates            | 55890       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.07    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1084     |\n",
      "|    time_elapsed    | 6961     |\n",
      "|    total_timesteps | 2220032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 6967        |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027393332 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.353      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0376      |\n",
      "|    n_updates            | 55900       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 6972        |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024632487 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0295      |\n",
      "|    n_updates            | 55910       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 6977        |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027826002 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 55920       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 6982        |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033537317 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0459      |\n",
      "|    n_updates            | 55930       |\n",
      "|    policy_gradient_loss | -0.0354     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2230000, episode_reward=0.03 +/- 0.97\n",
      "Episode length: 30.04 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021289706 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0597      |\n",
      "|    n_updates            | 55940       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1089     |\n",
      "|    time_elapsed    | 6993     |\n",
      "|    total_timesteps | 2230272  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.08      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1090       |\n",
      "|    time_elapsed         | 6998       |\n",
      "|    total_timesteps      | 2232320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02651104 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.345     |\n",
      "|    explained_variance   | 0.338      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0519     |\n",
      "|    n_updates            | 55950      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 7003        |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029421806 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0251      |\n",
      "|    n_updates            | 55960       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 7009        |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030365758 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0578      |\n",
      "|    n_updates            | 55970       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 7014        |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024248376 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 55980       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=0.03 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033096008 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 55990       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1094     |\n",
      "|    time_elapsed    | 7025     |\n",
      "|    total_timesteps | 2240512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 7030        |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031547777 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0895      |\n",
      "|    n_updates            | 56000       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1096        |\n",
      "|    time_elapsed         | 7036        |\n",
      "|    total_timesteps      | 2244608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036700945 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0119      |\n",
      "|    n_updates            | 56010       |\n",
      "|    policy_gradient_loss | -0.0375     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1097       |\n",
      "|    time_elapsed         | 7041       |\n",
      "|    total_timesteps      | 2246656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03186208 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0317     |\n",
      "|    n_updates            | 56020      |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 7046        |\n",
      "|    total_timesteps      | 2248704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029648706 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 56030       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2250000, episode_reward=0.17 +/- 0.97\n",
      "Episode length: 30.11 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033220332 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0176      |\n",
      "|    n_updates            | 56040       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1099     |\n",
      "|    time_elapsed    | 7057     |\n",
      "|    total_timesteps | 2250752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 7062        |\n",
      "|    total_timesteps      | 2252800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029937211 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0628      |\n",
      "|    n_updates            | 56050       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 7068        |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029050956 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0658      |\n",
      "|    n_updates            | 56060       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1102       |\n",
      "|    time_elapsed         | 7073       |\n",
      "|    total_timesteps      | 2256896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02691393 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.223      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0337     |\n",
      "|    n_updates            | 56070      |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    value_loss           | 0.221      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 7078        |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029758096 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 56080       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2260000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031179963 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 56090       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1104     |\n",
      "|    time_elapsed    | 7089     |\n",
      "|    total_timesteps | 2260992  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1105       |\n",
      "|    time_elapsed         | 7094       |\n",
      "|    total_timesteps      | 2263040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02971543 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.285     |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0363     |\n",
      "|    n_updates            | 56100      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1106        |\n",
      "|    time_elapsed         | 7099        |\n",
      "|    total_timesteps      | 2265088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027802423 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 56110       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 7105        |\n",
      "|    total_timesteps      | 2267136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029750846 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 56120       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1108       |\n",
      "|    time_elapsed         | 7110       |\n",
      "|    total_timesteps      | 2269184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02712321 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.261      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0667     |\n",
      "|    n_updates            | 56130      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2270000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026494179 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0586      |\n",
      "|    n_updates            | 56140       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1109     |\n",
      "|    time_elapsed    | 7120     |\n",
      "|    total_timesteps | 2271232  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1110        |\n",
      "|    time_elapsed         | 7126        |\n",
      "|    total_timesteps      | 2273280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027212648 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 56150       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 7131        |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031934336 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 56160       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 7136        |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036700662 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 56170       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1113        |\n",
      "|    time_elapsed         | 7141        |\n",
      "|    total_timesteps      | 2279424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034276985 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0315      |\n",
      "|    n_updates            | 56180       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2280000, episode_reward=0.07 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033251002 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0692      |\n",
      "|    n_updates            | 56190       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1114     |\n",
      "|    time_elapsed    | 7152     |\n",
      "|    total_timesteps | 2281472  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 7157        |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024058625 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0721      |\n",
      "|    n_updates            | 56200       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1116       |\n",
      "|    time_elapsed         | 7163       |\n",
      "|    total_timesteps      | 2285568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03253118 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.287     |\n",
      "|    explained_variance   | 0.182      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0339     |\n",
      "|    n_updates            | 56210      |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 7168        |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032707885 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0633      |\n",
      "|    n_updates            | 56220       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1118       |\n",
      "|    time_elapsed         | 7173       |\n",
      "|    total_timesteps      | 2289664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03363617 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.159      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0504     |\n",
      "|    n_updates            | 56230      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2290000, episode_reward=0.26 +/- 0.94\n",
      "Episode length: 30.02 +/- 0.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029502172 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 56240       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 57\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1119     |\n",
      "|    time_elapsed    | 7184     |\n",
      "|    total_timesteps | 2291712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 7189        |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029200234 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0616      |\n",
      "|    n_updates            | 56250       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 7195        |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028978743 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 56260       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 7200        |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028621595 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 56270       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 7205        |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022078179 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0738      |\n",
      "|    n_updates            | 56280       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2300000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 30.07 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028125625 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0768      |\n",
      "|    n_updates            | 56290       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1124     |\n",
      "|    time_elapsed    | 7216     |\n",
      "|    total_timesteps | 2301952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1125        |\n",
      "|    time_elapsed         | 7221        |\n",
      "|    total_timesteps      | 2304000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030056177 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 56300       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 7227        |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027691435 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 56310       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1127       |\n",
      "|    time_elapsed         | 7232       |\n",
      "|    total_timesteps      | 2308096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02474296 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.288     |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0208     |\n",
      "|    n_updates            | 56320      |\n",
      "|    policy_gradient_loss | -0.0288    |\n",
      "|    value_loss           | 0.212      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2310000, episode_reward=0.35 +/- 0.93\n",
      "Episode length: 29.99 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023647081 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0278      |\n",
      "|    n_updates            | 56330       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.35\n",
      "SELFPLAY: new best model, bumping up generation to 58\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1128     |\n",
      "|    time_elapsed    | 7243     |\n",
      "|    total_timesteps | 2310144  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.04      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1129       |\n",
      "|    time_elapsed         | 7248       |\n",
      "|    total_timesteps      | 2312192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03205428 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.279     |\n",
      "|    explained_variance   | 0.35       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0592     |\n",
      "|    n_updates            | 56340      |\n",
      "|    policy_gradient_loss | -0.0294    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1130        |\n",
      "|    time_elapsed         | 7254        |\n",
      "|    total_timesteps      | 2314240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029149275 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 56350       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1131        |\n",
      "|    time_elapsed         | 7259        |\n",
      "|    total_timesteps      | 2316288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026214901 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0627      |\n",
      "|    n_updates            | 56360       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 7265        |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026410015 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0445      |\n",
      "|    n_updates            | 56370       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2320000, episode_reward=0.14 +/- 0.97\n",
      "Episode length: 29.97 +/- 0.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030673865 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0607      |\n",
      "|    n_updates            | 56380       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1133     |\n",
      "|    time_elapsed    | 7275     |\n",
      "|    total_timesteps | 2320384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1134        |\n",
      "|    time_elapsed         | 7280        |\n",
      "|    total_timesteps      | 2322432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025842294 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 56390       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 7286        |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028333768 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0469      |\n",
      "|    n_updates            | 56400       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1136       |\n",
      "|    time_elapsed         | 7291       |\n",
      "|    total_timesteps      | 2326528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02518221 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.286     |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0312     |\n",
      "|    n_updates            | 56410      |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.174      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1137        |\n",
      "|    time_elapsed         | 7296        |\n",
      "|    total_timesteps      | 2328576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026365288 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0702      |\n",
      "|    n_updates            | 56420       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2330000, episode_reward=0.31 +/- 0.93\n",
      "Episode length: 29.95 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025390454 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0744      |\n",
      "|    n_updates            | 56430       |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.31\n",
      "SELFPLAY: new best model, bumping up generation to 59\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1138     |\n",
      "|    time_elapsed    | 7307     |\n",
      "|    total_timesteps | 2330624  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 7313        |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028959433 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 56440       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 7318        |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023679577 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0639      |\n",
      "|    n_updates            | 56450       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1141       |\n",
      "|    time_elapsed         | 7324       |\n",
      "|    total_timesteps      | 2336768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02883258 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.319     |\n",
      "|    explained_variance   | 0.214      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0216     |\n",
      "|    n_updates            | 56460      |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1142       |\n",
      "|    time_elapsed         | 7329       |\n",
      "|    total_timesteps      | 2338816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03118868 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.325     |\n",
      "|    explained_variance   | 0.281      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0136     |\n",
      "|    n_updates            | 56470      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2340000, episode_reward=0.01 +/- 0.99\n",
      "Episode length: 30.00 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027271457 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0524      |\n",
      "|    n_updates            | 56480       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1143     |\n",
      "|    time_elapsed    | 7340     |\n",
      "|    total_timesteps | 2340864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 7345        |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029559087 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.057       |\n",
      "|    n_updates            | 56490       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 7350        |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027827976 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0635      |\n",
      "|    n_updates            | 56500       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1146       |\n",
      "|    time_elapsed         | 7356       |\n",
      "|    total_timesteps      | 2347008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02907805 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.308     |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00921    |\n",
      "|    n_updates            | 56510      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1147        |\n",
      "|    time_elapsed         | 7361        |\n",
      "|    total_timesteps      | 2349056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026219174 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 56520       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2350000, episode_reward=0.11 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.43\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2350000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02987951 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.3       |\n",
      "|    explained_variance   | 0.207      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0385     |\n",
      "|    n_updates            | 56530      |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1148     |\n",
      "|    time_elapsed    | 7372     |\n",
      "|    total_timesteps | 2351104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 7377        |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033884667 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 56540       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 7382        |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027806751 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 56550       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1151        |\n",
      "|    time_elapsed         | 7387        |\n",
      "|    total_timesteps      | 2357248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029445771 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0576      |\n",
      "|    n_updates            | 56560       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.47        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 7393        |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029736003 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00224     |\n",
      "|    n_updates            | 56570       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2360000, episode_reward=0.38 +/- 0.91\n",
      "Episode length: 30.05 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024080941 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 56580       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.38\n",
      "SELFPLAY: new best model, bumping up generation to 60\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1153     |\n",
      "|    time_elapsed    | 7404     |\n",
      "|    total_timesteps | 2361344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 7409        |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022054307 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0233      |\n",
      "|    n_updates            | 56590       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1155        |\n",
      "|    time_elapsed         | 7414        |\n",
      "|    total_timesteps      | 2365440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025589664 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.026       |\n",
      "|    n_updates            | 56600       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 7419        |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037134316 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.023       |\n",
      "|    n_updates            | 56610       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 319        |\n",
      "|    iterations           | 1157       |\n",
      "|    time_elapsed         | 7425       |\n",
      "|    total_timesteps      | 2369536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02460961 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.303     |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0599     |\n",
      "|    n_updates            | 56620      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2370000, episode_reward=-0.09 +/- 0.98\n",
      "Episode length: 29.95 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025865352 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0492      |\n",
      "|    n_updates            | 56630       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1158     |\n",
      "|    time_elapsed    | 7435     |\n",
      "|    total_timesteps | 2371584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 7441        |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029626768 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0786      |\n",
      "|    n_updates            | 56640       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 7446        |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027216282 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0569      |\n",
      "|    n_updates            | 56650       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 7452        |\n",
      "|    total_timesteps      | 2377728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023392543 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0532      |\n",
      "|    n_updates            | 56660       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 7458        |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029471572 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 56670       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2380000, episode_reward=0.15 +/- 0.97\n",
      "Episode length: 29.94 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028622597 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 56680       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1163     |\n",
      "|    time_elapsed    | 7469     |\n",
      "|    total_timesteps | 2381824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1164        |\n",
      "|    time_elapsed         | 7475        |\n",
      "|    total_timesteps      | 2383872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025371354 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.052       |\n",
      "|    n_updates            | 56690       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 7480        |\n",
      "|    total_timesteps      | 2385920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026522398 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0063     |\n",
      "|    n_updates            | 56700       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.37       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1166       |\n",
      "|    time_elapsed         | 7485       |\n",
      "|    total_timesteps      | 2387968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02408696 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.249     |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0105     |\n",
      "|    n_updates            | 56710      |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2390000, episode_reward=0.37 +/- 0.91\n",
      "Episode length: 29.99 +/- 0.57\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.37       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2390000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03492313 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.242     |\n",
      "|    explained_variance   | 0.19       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.048      |\n",
      "|    n_updates            | 56720      |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.37\n",
      "SELFPLAY: new best model, bumping up generation to 61\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1167     |\n",
      "|    time_elapsed    | 7497     |\n",
      "|    total_timesteps | 2390016  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1168       |\n",
      "|    time_elapsed         | 7503       |\n",
      "|    total_timesteps      | 2392064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02873807 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.239     |\n",
      "|    explained_variance   | 0.328      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0681     |\n",
      "|    n_updates            | 56730      |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 7509        |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036627512 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0443      |\n",
      "|    n_updates            | 56740       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1170        |\n",
      "|    time_elapsed         | 7514        |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029761057 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0266      |\n",
      "|    n_updates            | 56750       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 7520        |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031079996 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0655      |\n",
      "|    n_updates            | 56760       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=0.25 +/- 0.96\n",
      "Episode length: 29.97 +/- 0.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2400000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03178387 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0348     |\n",
      "|    n_updates            | 56770      |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 62\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1172     |\n",
      "|    time_elapsed    | 7532     |\n",
      "|    total_timesteps | 2400256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 7538        |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033493996 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0425      |\n",
      "|    n_updates            | 56780       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1174       |\n",
      "|    time_elapsed         | 7544       |\n",
      "|    total_timesteps      | 2404352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03122412 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.315     |\n",
      "|    explained_variance   | 0.283      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.056      |\n",
      "|    n_updates            | 56790      |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 7549        |\n",
      "|    total_timesteps      | 2406400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023010612 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0197      |\n",
      "|    n_updates            | 56800       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1176       |\n",
      "|    time_elapsed         | 7555       |\n",
      "|    total_timesteps      | 2408448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03239318 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0.312      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.037      |\n",
      "|    n_updates            | 56810      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2410000, episode_reward=0.02 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025160244 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 56820       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1177     |\n",
      "|    time_elapsed    | 7567     |\n",
      "|    total_timesteps | 2410496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1178        |\n",
      "|    time_elapsed         | 7573        |\n",
      "|    total_timesteps      | 2412544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030374084 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.044       |\n",
      "|    n_updates            | 56830       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 7579        |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032967046 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 56840       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 7585        |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028132576 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0346      |\n",
      "|    n_updates            | 56850       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 7592        |\n",
      "|    total_timesteps      | 2418688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028041873 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0207      |\n",
      "|    n_updates            | 56860       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2420000, episode_reward=0.14 +/- 0.96\n",
      "Episode length: 30.01 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031059168 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0667      |\n",
      "|    n_updates            | 56870       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1182     |\n",
      "|    time_elapsed    | 7603     |\n",
      "|    total_timesteps | 2420736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 7609        |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030270122 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0641      |\n",
      "|    n_updates            | 56880       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1184        |\n",
      "|    time_elapsed         | 7615        |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029650548 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 56890       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 7621        |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025345586 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0681      |\n",
      "|    n_updates            | 56900       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 318        |\n",
      "|    iterations           | 1186       |\n",
      "|    time_elapsed         | 7628       |\n",
      "|    total_timesteps      | 2428928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03259244 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.29      |\n",
      "|    explained_variance   | 0.51       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00679    |\n",
      "|    n_updates            | 56910      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.154      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2430000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 29.92 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028797016 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0518      |\n",
      "|    n_updates            | 56920       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 318      |\n",
      "|    iterations      | 1187     |\n",
      "|    time_elapsed    | 7639     |\n",
      "|    total_timesteps | 2430976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 7645        |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026939034 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0641      |\n",
      "|    n_updates            | 56930       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1189        |\n",
      "|    time_elapsed         | 7651        |\n",
      "|    total_timesteps      | 2435072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028979562 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.026       |\n",
      "|    n_updates            | 56940       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 7656        |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029464096 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0189     |\n",
      "|    n_updates            | 56950       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 318         |\n",
      "|    iterations           | 1191        |\n",
      "|    time_elapsed         | 7662        |\n",
      "|    total_timesteps      | 2439168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032397155 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 56960       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2440000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 29.89 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035645656 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0461      |\n",
      "|    n_updates            | 56970       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 317      |\n",
      "|    iterations      | 1192     |\n",
      "|    time_elapsed    | 7697     |\n",
      "|    total_timesteps | 2441216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 317         |\n",
      "|    iterations           | 1193        |\n",
      "|    time_elapsed         | 7704        |\n",
      "|    total_timesteps      | 2443264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030599788 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0242      |\n",
      "|    n_updates            | 56980       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 1194        |\n",
      "|    time_elapsed         | 7741        |\n",
      "|    total_timesteps      | 2445312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033366367 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0539      |\n",
      "|    n_updates            | 56990       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 1195        |\n",
      "|    time_elapsed         | 7748        |\n",
      "|    total_timesteps      | 2447360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025880432 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0494      |\n",
      "|    n_updates            | 57000       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 1196        |\n",
      "|    time_elapsed         | 7755        |\n",
      "|    total_timesteps      | 2449408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030276049 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 57010       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2450000, episode_reward=0.37 +/- 0.90\n",
      "Episode length: 30.06 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.37        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019627752 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0504      |\n",
      "|    n_updates            | 57020       |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.37\n",
      "SELFPLAY: new best model, bumping up generation to 63\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.37     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 1197     |\n",
      "|    time_elapsed    | 7767     |\n",
      "|    total_timesteps | 2451456  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | -0.02     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 315       |\n",
      "|    iterations           | 1198      |\n",
      "|    time_elapsed         | 7772      |\n",
      "|    total_timesteps      | 2453504   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0327089 |\n",
      "|    clip_fraction        | 0.122     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.249    |\n",
      "|    explained_variance   | 0.294     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0398    |\n",
      "|    n_updates            | 57030     |\n",
      "|    policy_gradient_loss | -0.025    |\n",
      "|    value_loss           | 0.189     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 1199        |\n",
      "|    time_elapsed         | 7778        |\n",
      "|    total_timesteps      | 2455552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030434474 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.057       |\n",
      "|    n_updates            | 57040       |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 7783        |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033512324 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0765      |\n",
      "|    n_updates            | 57050       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 7789        |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036654383 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0344      |\n",
      "|    n_updates            | 57060       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2460000, episode_reward=0.14 +/- 0.98\n",
      "Episode length: 30.00 +/- 0.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2460000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03605715 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.296     |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0522     |\n",
      "|    n_updates            | 57070      |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    value_loss           | 0.22       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 1202     |\n",
      "|    time_elapsed    | 7800     |\n",
      "|    total_timesteps | 2461696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 7806        |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025059843 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 57080       |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 1204        |\n",
      "|    time_elapsed         | 7814        |\n",
      "|    total_timesteps      | 2465792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033669643 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0606      |\n",
      "|    n_updates            | 57090       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 1205       |\n",
      "|    time_elapsed         | 7820       |\n",
      "|    total_timesteps      | 2467840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02812395 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0189     |\n",
      "|    n_updates            | 57100      |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 7849        |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025034022 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0289      |\n",
      "|    n_updates            | 57110       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2470000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021408897 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 57120       |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 1207     |\n",
      "|    time_elapsed    | 7863     |\n",
      "|    total_timesteps | 2471936  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 7868        |\n",
      "|    total_timesteps      | 2473984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034741864 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0315      |\n",
      "|    n_updates            | 57130       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 7873        |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024801865 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0428      |\n",
      "|    n_updates            | 57140       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 1210       |\n",
      "|    time_elapsed         | 7879       |\n",
      "|    total_timesteps      | 2478080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05213591 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.246     |\n",
      "|    explained_variance   | 0.299      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0719     |\n",
      "|    n_updates            | 57150      |\n",
      "|    policy_gradient_loss | -0.0255    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2480000, episode_reward=0.06 +/- 1.00\n",
      "Episode length: 30.02 +/- 0.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2480000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02066091 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.26      |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0502     |\n",
      "|    n_updates            | 57160      |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 314      |\n",
      "|    iterations      | 1211     |\n",
      "|    time_elapsed    | 7892     |\n",
      "|    total_timesteps | 2480128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 1212        |\n",
      "|    time_elapsed         | 7901        |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020036254 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0828      |\n",
      "|    n_updates            | 57170       |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 7909        |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024581414 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 57180       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 1214       |\n",
      "|    time_elapsed         | 7915       |\n",
      "|    total_timesteps      | 2486272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03291225 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.254     |\n",
      "|    explained_variance   | 0.347      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0934     |\n",
      "|    n_updates            | 57190      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 1215        |\n",
      "|    time_elapsed         | 7922        |\n",
      "|    total_timesteps      | 2488320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025120666 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.233      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0105      |\n",
      "|    n_updates            | 57200       |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2490000, episode_reward=0.16 +/- 0.97\n",
      "Episode length: 29.76 +/- 2.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025085514 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.234      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0729      |\n",
      "|    n_updates            | 57210       |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 1216     |\n",
      "|    time_elapsed    | 7934     |\n",
      "|    total_timesteps | 2490368  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.28       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 1217       |\n",
      "|    time_elapsed         | 7939       |\n",
      "|    total_timesteps      | 2492416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02457169 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.225     |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0446     |\n",
      "|    n_updates            | 57220      |\n",
      "|    policy_gradient_loss | -0.0242    |\n",
      "|    value_loss           | 0.174      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 7946        |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025010493 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0521      |\n",
      "|    n_updates            | 57230       |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 7951        |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026126737 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0425      |\n",
      "|    n_updates            | 57240       |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 7957        |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023554085 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.219      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 57250       |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2500000, episode_reward=0.27 +/- 0.96\n",
      "Episode length: 30.12 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026683524 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.203      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0303      |\n",
      "|    n_updates            | 57260       |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.27\n",
      "SELFPLAY: new best model, bumping up generation to 64\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.41     |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 1221     |\n",
      "|    time_elapsed    | 7967     |\n",
      "|    total_timesteps | 2500608  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 1222       |\n",
      "|    time_elapsed         | 7973       |\n",
      "|    total_timesteps      | 2502656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02753581 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.218     |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0669     |\n",
      "|    n_updates            | 57270      |\n",
      "|    policy_gradient_loss | -0.0251    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 7979        |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031066688 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0912      |\n",
      "|    n_updates            | 57280       |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1224        |\n",
      "|    time_elapsed         | 7984        |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027989449 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0422      |\n",
      "|    n_updates            | 57290       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 7990        |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026855651 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0613      |\n",
      "|    n_updates            | 57300       |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2510000, episode_reward=0.18 +/- 0.96\n",
      "Episode length: 29.93 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029066473 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0843      |\n",
      "|    n_updates            | 57310       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.239       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 1226     |\n",
      "|    time_elapsed    | 8001     |\n",
      "|    total_timesteps | 2510848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1227        |\n",
      "|    time_elapsed         | 8006        |\n",
      "|    total_timesteps      | 2512896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027074125 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0241      |\n",
      "|    n_updates            | 57320       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 8012        |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030485291 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0677      |\n",
      "|    n_updates            | 57330       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 313        |\n",
      "|    iterations           | 1229       |\n",
      "|    time_elapsed         | 8018       |\n",
      "|    total_timesteps      | 2516992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02844696 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.268     |\n",
      "|    explained_variance   | 0.297      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0561     |\n",
      "|    n_updates            | 57340      |\n",
      "|    policy_gradient_loss | -0.0273    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1230        |\n",
      "|    time_elapsed         | 8023        |\n",
      "|    total_timesteps      | 2519040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028575871 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 57350       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2520000, episode_reward=0.06 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023142291 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.08        |\n",
      "|    n_updates            | 57360       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 313      |\n",
      "|    iterations      | 1231     |\n",
      "|    time_elapsed    | 8034     |\n",
      "|    total_timesteps | 2521088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 8040        |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024860356 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0595      |\n",
      "|    n_updates            | 57370       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1233        |\n",
      "|    time_elapsed         | 8046        |\n",
      "|    total_timesteps      | 2525184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030781735 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0587      |\n",
      "|    n_updates            | 57380       |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1234        |\n",
      "|    time_elapsed         | 8052        |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029254358 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0846      |\n",
      "|    n_updates            | 57390       |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 313         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 8058        |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038110517 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0511      |\n",
      "|    n_updates            | 57400       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2530000, episode_reward=0.40 +/- 0.89\n",
      "Episode length: 29.99 +/- 0.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024822788 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0314      |\n",
      "|    n_updates            | 57410       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.4\n",
      "SELFPLAY: new best model, bumping up generation to 65\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.38     |\n",
      "| time/              |          |\n",
      "|    fps             | 312      |\n",
      "|    iterations      | 1236     |\n",
      "|    time_elapsed    | 8096     |\n",
      "|    total_timesteps | 2531328  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 311        |\n",
      "|    iterations           | 1237       |\n",
      "|    time_elapsed         | 8124       |\n",
      "|    total_timesteps      | 2533376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03679961 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.275      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0574     |\n",
      "|    n_updates            | 57420      |\n",
      "|    policy_gradient_loss | -0.0363    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 1238       |\n",
      "|    time_elapsed         | 8153       |\n",
      "|    total_timesteps      | 2535424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03045202 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.286     |\n",
      "|    explained_variance   | 0.199      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0597     |\n",
      "|    n_updates            | 57430      |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 8182        |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027812313 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0253      |\n",
      "|    n_updates            | 57440       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 1240        |\n",
      "|    time_elapsed         | 8211        |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030347116 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0874      |\n",
      "|    n_updates            | 57450       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2540000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 29.94 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2540000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03297106 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.281     |\n",
      "|    explained_variance   | 0.257      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0432     |\n",
      "|    n_updates            | 57460      |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    value_loss           | 0.212      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.06    |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 1241     |\n",
      "|    time_elapsed    | 8246     |\n",
      "|    total_timesteps | 2541568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 8275        |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032290842 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0633      |\n",
      "|    n_updates            | 57470       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1243        |\n",
      "|    time_elapsed         | 8303        |\n",
      "|    total_timesteps      | 2545664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023597088 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0975      |\n",
      "|    n_updates            | 57480       |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 8319        |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025061471 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 57490       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 1245       |\n",
      "|    time_elapsed         | 8324       |\n",
      "|    total_timesteps      | 2549760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02737367 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0.285      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0609     |\n",
      "|    n_updates            | 57500      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.215      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2550000, episode_reward=0.10 +/- 0.98\n",
      "Episode length: 30.02 +/- 0.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2550000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02624644 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.279     |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0167     |\n",
      "|    n_updates            | 57510      |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 1246     |\n",
      "|    time_elapsed    | 8335     |\n",
      "|    total_timesteps | 2551808  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 8341        |\n",
      "|    total_timesteps      | 2553856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027551875 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0433      |\n",
      "|    n_updates            | 57520       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 8347        |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030152747 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 57530       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 8352        |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030550588 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0285      |\n",
      "|    n_updates            | 57540       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=0.17 +/- 0.96\n",
      "Episode length: 30.00 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027027786 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.038       |\n",
      "|    n_updates            | 57550       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.08    |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 1250     |\n",
      "|    time_elapsed    | 8363     |\n",
      "|    total_timesteps | 2560000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 8370        |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032636423 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 57560       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 8375        |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026988894 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0853      |\n",
      "|    n_updates            | 57570       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1253        |\n",
      "|    time_elapsed         | 8381        |\n",
      "|    total_timesteps      | 2566144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026028696 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0176      |\n",
      "|    n_updates            | 57580       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 8387        |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026766723 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0741      |\n",
      "|    n_updates            | 57590       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2570000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027139924 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.04        |\n",
      "|    n_updates            | 57600       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 1255     |\n",
      "|    time_elapsed    | 8398     |\n",
      "|    total_timesteps | 2570240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1256        |\n",
      "|    time_elapsed         | 8403        |\n",
      "|    total_timesteps      | 2572288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030961743 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0888      |\n",
      "|    n_updates            | 57610       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 8409        |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023822866 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0385      |\n",
      "|    n_updates            | 57620       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1258        |\n",
      "|    time_elapsed         | 8414        |\n",
      "|    total_timesteps      | 2576384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031538032 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0156      |\n",
      "|    n_updates            | 57630       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 8419        |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029830944 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0716      |\n",
      "|    n_updates            | 57640       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2580000, episode_reward=0.27 +/- 0.95\n",
      "Episode length: 30.04 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024735145 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 57650       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.27\n",
      "SELFPLAY: new best model, bumping up generation to 66\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 1260     |\n",
      "|    time_elapsed    | 8430     |\n",
      "|    total_timesteps | 2580480  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 1261       |\n",
      "|    time_elapsed         | 8436       |\n",
      "|    total_timesteps      | 2582528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02605505 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.281     |\n",
      "|    explained_variance   | 0.215      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.05       |\n",
      "|    n_updates            | 57660      |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    value_loss           | 0.221      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 8441        |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022593267 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 57670       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 8447        |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027215226 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0662      |\n",
      "|    n_updates            | 57680       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 8453        |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024558615 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 57690       |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2590000, episode_reward=0.01 +/- 0.99\n",
      "Episode length: 30.03 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033096857 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0533      |\n",
      "|    n_updates            | 57700       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 1265     |\n",
      "|    time_elapsed    | 8464     |\n",
      "|    total_timesteps | 2590720  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 8470        |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027536888 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0627      |\n",
      "|    n_updates            | 57710       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 8475        |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029525008 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0779      |\n",
      "|    n_updates            | 57720       |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1268        |\n",
      "|    time_elapsed         | 8480        |\n",
      "|    total_timesteps      | 2596864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034531273 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.056       |\n",
      "|    n_updates            | 57730       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 1269       |\n",
      "|    time_elapsed         | 8486       |\n",
      "|    total_timesteps      | 2598912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02803274 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.284     |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0317     |\n",
      "|    n_updates            | 57740      |\n",
      "|    policy_gradient_loss | -0.0293    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2600000, episode_reward=0.05 +/- 0.99\n",
      "Episode length: 30.01 +/- 0.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026907835 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0848      |\n",
      "|    n_updates            | 57750       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.18    |\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 1270     |\n",
      "|    time_elapsed    | 8498     |\n",
      "|    total_timesteps | 2600960  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.07      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 1271       |\n",
      "|    time_elapsed         | 8504       |\n",
      "|    total_timesteps      | 2603008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02742206 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.297      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0537     |\n",
      "|    n_updates            | 57760      |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 8510        |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024180464 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.056       |\n",
      "|    n_updates            | 57770       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 1273       |\n",
      "|    time_elapsed         | 8518       |\n",
      "|    total_timesteps      | 2607104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03548017 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.279     |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0536     |\n",
      "|    n_updates            | 57780      |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    value_loss           | 0.217      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1274        |\n",
      "|    time_elapsed         | 8524        |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028400572 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0809      |\n",
      "|    n_updates            | 57790       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2610000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023685466 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 57800       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 1275     |\n",
      "|    time_elapsed    | 8535     |\n",
      "|    total_timesteps | 2611200  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 1276       |\n",
      "|    time_elapsed         | 8540       |\n",
      "|    total_timesteps      | 2613248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03102175 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.27      |\n",
      "|    explained_variance   | 0.357      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0307     |\n",
      "|    n_updates            | 57810      |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1277        |\n",
      "|    time_elapsed         | 8545        |\n",
      "|    total_timesteps      | 2615296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024838217 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.242      |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0144      |\n",
      "|    n_updates            | 57820       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1278        |\n",
      "|    time_elapsed         | 8551        |\n",
      "|    total_timesteps      | 2617344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027007133 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 57830       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 1279       |\n",
      "|    time_elapsed         | 8557       |\n",
      "|    total_timesteps      | 2619392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02525913 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.247     |\n",
      "|    explained_variance   | 0.442      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0383     |\n",
      "|    n_updates            | 57840      |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2620000, episode_reward=0.21 +/- 0.95\n",
      "Episode length: 30.10 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029457811 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 57850       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 67\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 1280     |\n",
      "|    time_elapsed    | 8569     |\n",
      "|    total_timesteps | 2621440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1281        |\n",
      "|    time_elapsed         | 8574        |\n",
      "|    total_timesteps      | 2623488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025744017 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.091       |\n",
      "|    n_updates            | 57860       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.05      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 1282       |\n",
      "|    time_elapsed         | 8581       |\n",
      "|    total_timesteps      | 2625536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03539743 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0494     |\n",
      "|    n_updates            | 57870      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.237      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1283        |\n",
      "|    time_elapsed         | 8586        |\n",
      "|    total_timesteps      | 2627584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035822816 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0674      |\n",
      "|    n_updates            | 57880       |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1284        |\n",
      "|    time_elapsed         | 8592        |\n",
      "|    total_timesteps      | 2629632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029142994 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0312      |\n",
      "|    n_updates            | 57890       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2630000, episode_reward=0.02 +/- 0.99\n",
      "Episode length: 30.00 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030151375 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0442      |\n",
      "|    n_updates            | 57900       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 1285     |\n",
      "|    time_elapsed    | 8603     |\n",
      "|    total_timesteps | 2631680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 8609        |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036361553 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0482      |\n",
      "|    n_updates            | 57910       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1287        |\n",
      "|    time_elapsed         | 8615        |\n",
      "|    total_timesteps      | 2635776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023245469 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0498      |\n",
      "|    n_updates            | 57920       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 8621        |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027527206 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0328      |\n",
      "|    n_updates            | 57930       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 8627        |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025323538 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0379      |\n",
      "|    n_updates            | 57940       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=0.35 +/- 0.93\n",
      "Episode length: 30.05 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026690563 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0278      |\n",
      "|    n_updates            | 57950       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.35\n",
      "SELFPLAY: new best model, bumping up generation to 68\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.33     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 1290     |\n",
      "|    time_elapsed    | 8638     |\n",
      "|    total_timesteps | 2641920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1291        |\n",
      "|    time_elapsed         | 8644        |\n",
      "|    total_timesteps      | 2643968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025901143 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.033       |\n",
      "|    n_updates            | 57960       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1292        |\n",
      "|    time_elapsed         | 8652        |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026419714 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0586      |\n",
      "|    n_updates            | 57970       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 8662        |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026076771 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 57980       |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2650000, episode_reward=0.18 +/- 0.96\n",
      "Episode length: 30.02 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024502514 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0737      |\n",
      "|    n_updates            | 57990       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 1294     |\n",
      "|    time_elapsed    | 8674     |\n",
      "|    total_timesteps | 2650112  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1295        |\n",
      "|    time_elapsed         | 8682        |\n",
      "|    total_timesteps      | 2652160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026822688 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 58000       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 8688        |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025537465 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 58010       |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 8695        |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027535297 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0646      |\n",
      "|    n_updates            | 58020       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 8703        |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023515709 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0915      |\n",
      "|    n_updates            | 58030       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2660000, episode_reward=0.02 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031829003 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0557      |\n",
      "|    n_updates            | 58040       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 305      |\n",
      "|    iterations      | 1299     |\n",
      "|    time_elapsed    | 8718     |\n",
      "|    total_timesteps | 2660352  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1300        |\n",
      "|    time_elapsed         | 8725        |\n",
      "|    total_timesteps      | 2662400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034031086 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0501      |\n",
      "|    n_updates            | 58050       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 8732        |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035337366 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.233      |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0848      |\n",
      "|    n_updates            | 58060       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 305        |\n",
      "|    iterations           | 1302       |\n",
      "|    time_elapsed         | 8742       |\n",
      "|    total_timesteps      | 2666496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02556477 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.227     |\n",
      "|    explained_variance   | 0.431      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0395     |\n",
      "|    n_updates            | 58070      |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 8748        |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028233252 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.211      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0367      |\n",
      "|    n_updates            | 58080       |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2670000, episode_reward=0.22 +/- 0.97\n",
      "Episode length: 29.99 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026398579 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 58090       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 69\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 1304     |\n",
      "|    time_elapsed    | 8761     |\n",
      "|    total_timesteps | 2670592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1305        |\n",
      "|    time_elapsed         | 8769        |\n",
      "|    total_timesteps      | 2672640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026896033 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.234      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0803      |\n",
      "|    n_updates            | 58100       |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 8775        |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028248498 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0453      |\n",
      "|    n_updates            | 58110       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 1307       |\n",
      "|    time_elapsed         | 8782       |\n",
      "|    total_timesteps      | 2676736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02227143 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.239     |\n",
      "|    explained_variance   | 0.431      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.051      |\n",
      "|    n_updates            | 58120      |\n",
      "|    policy_gradient_loss | -0.0235    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1308        |\n",
      "|    time_elapsed         | 8788        |\n",
      "|    total_timesteps      | 2678784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020771118 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.21       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00844     |\n",
      "|    n_updates            | 58130       |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2680000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.41\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2680000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02427776 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.207     |\n",
      "|    explained_variance   | 0.492      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0184     |\n",
      "|    n_updates            | 58140      |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 1309     |\n",
      "|    time_elapsed    | 8800     |\n",
      "|    total_timesteps | 2680832  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 8807        |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022914706 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0665      |\n",
      "|    n_updates            | 58150       |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1311        |\n",
      "|    time_elapsed         | 8814        |\n",
      "|    total_timesteps      | 2684928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023361059 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.21       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 58160       |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1312        |\n",
      "|    time_elapsed         | 8822        |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026001874 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 58170       |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1313        |\n",
      "|    time_elapsed         | 8828        |\n",
      "|    total_timesteps      | 2689024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021878447 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 58180       |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2690000, episode_reward=0.40 +/- 0.91\n",
      "Episode length: 30.00 +/- 0.49\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30        |\n",
      "|    mean_reward          | 0.4       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2690000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0285869 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.246    |\n",
      "|    explained_variance   | 0.284     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0203    |\n",
      "|    n_updates            | 58190     |\n",
      "|    policy_gradient_loss | -0.0288   |\n",
      "|    value_loss           | 0.209     |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.4\n",
      "SELFPLAY: new best model, bumping up generation to 70\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 1314     |\n",
      "|    time_elapsed    | 8850     |\n",
      "|    total_timesteps | 2691072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1315        |\n",
      "|    time_elapsed         | 8856        |\n",
      "|    total_timesteps      | 2693120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024758205 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.09        |\n",
      "|    n_updates            | 58200       |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 8863        |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032579266 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0915      |\n",
      "|    n_updates            | 58210       |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 1317       |\n",
      "|    time_elapsed         | 8869       |\n",
      "|    total_timesteps      | 2697216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03572402 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.246     |\n",
      "|    explained_variance   | 0.315      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0479     |\n",
      "|    n_updates            | 58220      |\n",
      "|    policy_gradient_loss | -0.0245    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 8875        |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024143219 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.242      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0888      |\n",
      "|    n_updates            | 58230       |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2700000, episode_reward=0.13 +/- 0.97\n",
      "Episode length: 29.95 +/- 0.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2700000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02744718 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.237     |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0712     |\n",
      "|    n_updates            | 58240      |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 303      |\n",
      "|    iterations      | 1319     |\n",
      "|    time_elapsed    | 8887     |\n",
      "|    total_timesteps | 2701312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 8900        |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025560433 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 58250       |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 303        |\n",
      "|    iterations           | 1321       |\n",
      "|    time_elapsed         | 8908       |\n",
      "|    total_timesteps      | 2705408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02712439 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.256     |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0593     |\n",
      "|    n_updates            | 58260      |\n",
      "|    policy_gradient_loss | -0.0283    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 8915        |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021680137 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0553      |\n",
      "|    n_updates            | 58270       |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 1323        |\n",
      "|    time_elapsed         | 8921        |\n",
      "|    total_timesteps      | 2709504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028455995 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0269      |\n",
      "|    n_updates            | 58280       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2710000, episode_reward=0.13 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023053795 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 58290       |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 302      |\n",
      "|    iterations      | 1324     |\n",
      "|    time_elapsed    | 8957     |\n",
      "|    total_timesteps | 2711552  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 301        |\n",
      "|    iterations           | 1325       |\n",
      "|    time_elapsed         | 8987       |\n",
      "|    total_timesteps      | 2713600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01998775 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.217     |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0735     |\n",
      "|    n_updates            | 58300      |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 1326        |\n",
      "|    time_elapsed         | 9016        |\n",
      "|    total_timesteps      | 2715648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023675844 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.22       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 58310       |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 9045        |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017507222 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0335      |\n",
      "|    n_updates            | 58320       |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 9075        |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018070694 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.21       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0454      |\n",
      "|    n_updates            | 58330       |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=0.27 +/- 0.95\n",
      "Episode length: 30.14 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026745647 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 58340       |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.27\n",
      "SELFPLAY: new best model, bumping up generation to 71\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 298      |\n",
      "|    iterations      | 1329     |\n",
      "|    time_elapsed    | 9113     |\n",
      "|    total_timesteps | 2721792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 9142        |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024945838 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 58350       |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 9172        |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030033164 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0596      |\n",
      "|    n_updates            | 58360       |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 1332        |\n",
      "|    time_elapsed         | 9179        |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026538555 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.238      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0837      |\n",
      "|    n_updates            | 58370       |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 1333        |\n",
      "|    time_elapsed         | 9185        |\n",
      "|    total_timesteps      | 2729984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021531843 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.208      |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 58380       |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2730000, episode_reward=0.05 +/- 0.99\n",
      "Episode length: 29.97 +/- 0.41\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2730000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01918853 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.231     |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0737     |\n",
      "|    n_updates            | 58390      |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    value_loss           | 0.223      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.35     |\n",
      "| time/              |          |\n",
      "|    fps             | 297      |\n",
      "|    iterations      | 1334     |\n",
      "|    time_elapsed    | 9197     |\n",
      "|    total_timesteps | 2732032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 1335        |\n",
      "|    time_elapsed         | 9209        |\n",
      "|    total_timesteps      | 2734080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025904613 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.223      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 58400       |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | 0.32      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 296       |\n",
      "|    iterations           | 1336      |\n",
      "|    time_elapsed         | 9238      |\n",
      "|    total_timesteps      | 2736128   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0235026 |\n",
      "|    clip_fraction        | 0.109     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.234    |\n",
      "|    explained_variance   | 0.367     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0956    |\n",
      "|    n_updates            | 58410     |\n",
      "|    policy_gradient_loss | -0.0224   |\n",
      "|    value_loss           | 0.201     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 1337       |\n",
      "|    time_elapsed         | 9278       |\n",
      "|    total_timesteps      | 2738176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02200886 |\n",
      "|    clip_fraction        | 0.0991     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.237     |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0738     |\n",
      "|    n_updates            | 58420      |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2740000, episode_reward=0.46 +/- 0.87\n",
      "Episode length: 30.07 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.46        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019565582 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 58430       |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.46\n",
      "SELFPLAY: new best model, bumping up generation to 72\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 293      |\n",
      "|    iterations      | 1338     |\n",
      "|    time_elapsed    | 9323     |\n",
      "|    total_timesteps | 2740224  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 1339       |\n",
      "|    time_elapsed         | 9359       |\n",
      "|    total_timesteps      | 2742272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03426618 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.235     |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0659     |\n",
      "|    n_updates            | 58440      |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 9380        |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027827803 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0928      |\n",
      "|    n_updates            | 58450       |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 9388        |\n",
      "|    total_timesteps      | 2746368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027069144 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0602      |\n",
      "|    n_updates            | 58460       |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1342        |\n",
      "|    time_elapsed         | 9397        |\n",
      "|    total_timesteps      | 2748416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022725776 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0858      |\n",
      "|    n_updates            | 58470       |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2750000, episode_reward=0.09 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027968692 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.024       |\n",
      "|    n_updates            | 58480       |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 292      |\n",
      "|    iterations      | 1343     |\n",
      "|    time_elapsed    | 9410     |\n",
      "|    total_timesteps | 2750464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 9416        |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023241205 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0503      |\n",
      "|    n_updates            | 58490       |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1345        |\n",
      "|    time_elapsed         | 9422        |\n",
      "|    total_timesteps      | 2754560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025003735 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.04        |\n",
      "|    n_updates            | 58500       |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1346        |\n",
      "|    time_elapsed         | 9427        |\n",
      "|    total_timesteps      | 2756608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027226388 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.225      |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0419      |\n",
      "|    n_updates            | 58510       |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1347        |\n",
      "|    time_elapsed         | 9433        |\n",
      "|    total_timesteps      | 2758656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026129372 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.207      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 58520       |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2760000, episode_reward=0.49 +/- 0.87\n",
      "Episode length: 30.08 +/- 0.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.49        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027060859 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.199      |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 58530       |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.49\n",
      "SELFPLAY: new best model, bumping up generation to 73\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 292      |\n",
      "|    iterations      | 1348     |\n",
      "|    time_elapsed    | 9444     |\n",
      "|    total_timesteps | 2760704  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.04      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 1349       |\n",
      "|    time_elapsed         | 9456       |\n",
      "|    total_timesteps      | 2762752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02525526 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.205     |\n",
      "|    explained_variance   | 0.322      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0288     |\n",
      "|    n_updates            | 58540      |\n",
      "|    policy_gradient_loss | -0.0213    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1350        |\n",
      "|    time_elapsed         | 9463        |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023717083 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0635      |\n",
      "|    n_updates            | 58550       |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1351        |\n",
      "|    time_elapsed         | 9471        |\n",
      "|    total_timesteps      | 2766848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026191778 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0624      |\n",
      "|    n_updates            | 58560       |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 1352        |\n",
      "|    time_elapsed         | 9478        |\n",
      "|    total_timesteps      | 2768896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028580924 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0585      |\n",
      "|    n_updates            | 58570       |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2770000, episode_reward=0.06 +/- 0.98\n",
      "Episode length: 29.93 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025468655 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0707      |\n",
      "|    n_updates            | 58580       |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 291      |\n",
      "|    iterations      | 1353     |\n",
      "|    time_elapsed    | 9491     |\n",
      "|    total_timesteps | 2770944  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 9499        |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026184298 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0601      |\n",
      "|    n_updates            | 58590       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 1355        |\n",
      "|    time_elapsed         | 9507        |\n",
      "|    total_timesteps      | 2775040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020161873 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0747      |\n",
      "|    n_updates            | 58600       |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.46       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 1356       |\n",
      "|    time_elapsed         | 9514       |\n",
      "|    total_timesteps      | 2777088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02718429 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.236     |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0204     |\n",
      "|    n_updates            | 58610      |\n",
      "|    policy_gradient_loss | -0.0268    |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.51       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 1357       |\n",
      "|    time_elapsed         | 9521       |\n",
      "|    total_timesteps      | 2779136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02577938 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.232     |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0146     |\n",
      "|    n_updates            | 58620      |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    value_loss           | 0.129      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2780000, episode_reward=0.47 +/- 0.88\n",
      "Episode length: 30.08 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.47        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027429273 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.222      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0253      |\n",
      "|    n_updates            | 58630       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.47\n",
      "SELFPLAY: new best model, bumping up generation to 74\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 291      |\n",
      "|    iterations      | 1358     |\n",
      "|    time_elapsed    | 9535     |\n",
      "|    total_timesteps | 2781184  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 9542        |\n",
      "|    total_timesteps      | 2783232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033798404 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0527      |\n",
      "|    n_updates            | 58640       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 1360       |\n",
      "|    time_elapsed         | 9550       |\n",
      "|    total_timesteps      | 2785280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03109466 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.336     |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0337     |\n",
      "|    n_updates            | 58650      |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 9557        |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030848369 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.077       |\n",
      "|    n_updates            | 58660       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.11      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 291       |\n",
      "|    iterations           | 1362      |\n",
      "|    time_elapsed         | 9565      |\n",
      "|    total_timesteps      | 2789376   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0252748 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.318    |\n",
      "|    explained_variance   | 0.335     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0352    |\n",
      "|    n_updates            | 58670     |\n",
      "|    policy_gradient_loss | -0.0298   |\n",
      "|    value_loss           | 0.212     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2790000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 29.83 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029945623 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 58680       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 291      |\n",
      "|    iterations      | 1363     |\n",
      "|    time_elapsed    | 9578     |\n",
      "|    total_timesteps | 2791424  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | 0.04      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 291       |\n",
      "|    iterations           | 1364      |\n",
      "|    time_elapsed         | 9585      |\n",
      "|    total_timesteps      | 2793472   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0350001 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.329    |\n",
      "|    explained_variance   | 0.425     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0231    |\n",
      "|    n_updates            | 58690     |\n",
      "|    policy_gradient_loss | -0.0333   |\n",
      "|    value_loss           | 0.189     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 9593        |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030832214 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.033       |\n",
      "|    n_updates            | 58700       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 9601        |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027987463 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0467      |\n",
      "|    n_updates            | 58710       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 1367       |\n",
      "|    time_elapsed         | 9617       |\n",
      "|    total_timesteps      | 2799616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03445012 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.314     |\n",
      "|    explained_variance   | 0.484      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0687     |\n",
      "|    n_updates            | 58720      |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=0.42 +/- 0.91\n",
      "Episode length: 29.99 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.42        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031755112 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 58730       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.42\n",
      "SELFPLAY: new best model, bumping up generation to 75\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 290      |\n",
      "|    iterations      | 1368     |\n",
      "|    time_elapsed    | 9630     |\n",
      "|    total_timesteps | 2801664  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 1369       |\n",
      "|    time_elapsed         | 9647       |\n",
      "|    total_timesteps      | 2803712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03210356 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.353     |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0484     |\n",
      "|    n_updates            | 58740      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 1370        |\n",
      "|    time_elapsed         | 9654        |\n",
      "|    total_timesteps      | 2805760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029618332 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.352      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0293      |\n",
      "|    n_updates            | 58750       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 9662        |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032781817 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.357      |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0326      |\n",
      "|    n_updates            | 58760       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 1372        |\n",
      "|    time_elapsed         | 9671        |\n",
      "|    total_timesteps      | 2809856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028097827 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0568      |\n",
      "|    n_updates            | 58770       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2810000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 30.04 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032026313 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0342      |\n",
      "|    n_updates            | 58780       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 290      |\n",
      "|    iterations      | 1373     |\n",
      "|    time_elapsed    | 9693     |\n",
      "|    total_timesteps | 2811904  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.28       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 1374       |\n",
      "|    time_elapsed         | 9700       |\n",
      "|    total_timesteps      | 2813952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03317104 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.345     |\n",
      "|    explained_variance   | 0.375      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0278     |\n",
      "|    n_updates            | 58790      |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 1375       |\n",
      "|    time_elapsed         | 9708       |\n",
      "|    total_timesteps      | 2816000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03826558 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.334     |\n",
      "|    explained_variance   | 0.372      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0586     |\n",
      "|    n_updates            | 58800      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 9715        |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024177482 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0375      |\n",
      "|    n_updates            | 58810       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2820000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 30.04 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029442556 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 58820       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.15    |\n",
      "| time/              |          |\n",
      "|    fps             | 289      |\n",
      "|    iterations      | 1377     |\n",
      "|    time_elapsed    | 9729     |\n",
      "|    total_timesteps | 2820096  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 1378       |\n",
      "|    time_elapsed         | 9736       |\n",
      "|    total_timesteps      | 2822144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03174273 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.282     |\n",
      "|    explained_variance   | 0.382      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0561     |\n",
      "|    n_updates            | 58830      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 9743        |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034585282 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 58840       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.235       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 1380        |\n",
      "|    time_elapsed         | 9749        |\n",
      "|    total_timesteps      | 2826240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034199875 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00321     |\n",
      "|    n_updates            | 58850       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.05      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 1381       |\n",
      "|    time_elapsed         | 9755       |\n",
      "|    total_timesteps      | 2828288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03123019 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.346     |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0541     |\n",
      "|    n_updates            | 58860      |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2830000, episode_reward=0.20 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033456404 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0599      |\n",
      "|    n_updates            | 58870       |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 289      |\n",
      "|    iterations      | 1382     |\n",
      "|    time_elapsed    | 9766     |\n",
      "|    total_timesteps | 2830336  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.22      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 1383      |\n",
      "|    time_elapsed         | 9771      |\n",
      "|    total_timesteps      | 2832384   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0330733 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.33     |\n",
      "|    explained_variance   | 0.346     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0312    |\n",
      "|    n_updates            | 58880     |\n",
      "|    policy_gradient_loss | -0.0329   |\n",
      "|    value_loss           | 0.195     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 1384        |\n",
      "|    time_elapsed         | 9783        |\n",
      "|    total_timesteps      | 2834432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023381574 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 58890       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 1385       |\n",
      "|    time_elapsed         | 9798       |\n",
      "|    total_timesteps      | 2836480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03540255 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0175     |\n",
      "|    n_updates            | 58900      |\n",
      "|    policy_gradient_loss | -0.0337    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 1386       |\n",
      "|    time_elapsed         | 9804       |\n",
      "|    total_timesteps      | 2838528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02694385 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.306     |\n",
      "|    explained_variance   | 0.29       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0424     |\n",
      "|    n_updates            | 58910      |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2840000, episode_reward=0.14 +/- 0.99\n",
      "Episode length: 30.03 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026940387 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0424      |\n",
      "|    n_updates            | 58920       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 289      |\n",
      "|    iterations      | 1387     |\n",
      "|    time_elapsed    | 9816     |\n",
      "|    total_timesteps | 2840576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 9824        |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028701568 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0628      |\n",
      "|    n_updates            | 58930       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 9837        |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040419392 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 58940       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 1390        |\n",
      "|    time_elapsed         | 9852        |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026576199 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0716      |\n",
      "|    n_updates            | 58950       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 9858        |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027118228 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0438      |\n",
      "|    n_updates            | 58960       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2850000, episode_reward=0.13 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026189558 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0371      |\n",
      "|    n_updates            | 58970       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 1392     |\n",
      "|    time_elapsed    | 9869     |\n",
      "|    total_timesteps | 2850816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 1393        |\n",
      "|    time_elapsed         | 9874        |\n",
      "|    total_timesteps      | 2852864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029981522 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00746     |\n",
      "|    n_updates            | 58980       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 1394        |\n",
      "|    time_elapsed         | 9881        |\n",
      "|    total_timesteps      | 2854912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038177006 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 58990       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 1395       |\n",
      "|    time_elapsed         | 9887       |\n",
      "|    total_timesteps      | 2856960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02692739 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.267     |\n",
      "|    explained_variance   | 0.35       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0843     |\n",
      "|    n_updates            | 59000      |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.32       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 1396       |\n",
      "|    time_elapsed         | 9893       |\n",
      "|    total_timesteps      | 2859008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03263107 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.279     |\n",
      "|    explained_variance   | 0.324      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0192     |\n",
      "|    n_updates            | 59010      |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2860000, episode_reward=0.22 +/- 0.97\n",
      "Episode length: 30.07 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025997076 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0433      |\n",
      "|    n_updates            | 59020       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 76\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 1397     |\n",
      "|    time_elapsed    | 9932     |\n",
      "|    total_timesteps | 2861056  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 9966        |\n",
      "|    total_timesteps      | 2863104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033523828 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 59030       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 9976        |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030790336 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.068       |\n",
      "|    n_updates            | 59040       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 9981        |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029468894 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0137      |\n",
      "|    n_updates            | 59050       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1401        |\n",
      "|    time_elapsed         | 9986        |\n",
      "|    total_timesteps      | 2869248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028970331 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 59060       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2870000, episode_reward=-0.01 +/- 0.99\n",
      "Episode length: 29.98 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2870000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02553359 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.293     |\n",
      "|    explained_variance   | 0.233      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0412     |\n",
      "|    n_updates            | 59070      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 287      |\n",
      "|    iterations      | 1402     |\n",
      "|    time_elapsed    | 9998     |\n",
      "|    total_timesteps | 2871296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 10010       |\n",
      "|    total_timesteps      | 2873344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028582297 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 59080       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.11      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 1404       |\n",
      "|    time_elapsed         | 10017      |\n",
      "|    total_timesteps      | 2875392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03175173 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.273      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0754     |\n",
      "|    n_updates            | 59090      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 1405       |\n",
      "|    time_elapsed         | 10023      |\n",
      "|    total_timesteps      | 2877440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04819159 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.319     |\n",
      "|    explained_variance   | 0.324      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.057      |\n",
      "|    n_updates            | 59100      |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | -0.06     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 1406      |\n",
      "|    time_elapsed         | 10029     |\n",
      "|    total_timesteps      | 2879488   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0321993 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.315    |\n",
      "|    explained_variance   | 0.374     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0222    |\n",
      "|    n_updates            | 59110     |\n",
      "|    policy_gradient_loss | -0.0329   |\n",
      "|    value_loss           | 0.198     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=0.01 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.01       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2880000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02637465 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0444     |\n",
      "|    n_updates            | 59120      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 286      |\n",
      "|    iterations      | 1407     |\n",
      "|    time_elapsed    | 10041    |\n",
      "|    total_timesteps | 2881536  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1408        |\n",
      "|    time_elapsed         | 10048       |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028656749 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 59130       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1409        |\n",
      "|    time_elapsed         | 10055       |\n",
      "|    total_timesteps      | 2885632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027274761 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0711      |\n",
      "|    n_updates            | 59140       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 10063       |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029089808 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0766      |\n",
      "|    n_updates            | 59150       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1411       |\n",
      "|    time_elapsed         | 10095      |\n",
      "|    total_timesteps      | 2889728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03173271 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.229      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0353     |\n",
      "|    n_updates            | 59160      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2890000, episode_reward=-0.02 +/- 0.98\n",
      "Episode length: 29.83 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030487726 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0317      |\n",
      "|    n_updates            | 59170       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 285      |\n",
      "|    iterations      | 1412     |\n",
      "|    time_elapsed    | 10131    |\n",
      "|    total_timesteps | 2891776  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 10146       |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032562576 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0732      |\n",
      "|    n_updates            | 59180       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1414        |\n",
      "|    time_elapsed         | 10153       |\n",
      "|    total_timesteps      | 2895872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027514718 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0421      |\n",
      "|    n_updates            | 59190       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1415       |\n",
      "|    time_elapsed         | 10158      |\n",
      "|    total_timesteps      | 2897920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03329681 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.303     |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.027      |\n",
      "|    n_updates            | 59200      |\n",
      "|    policy_gradient_loss | -0.0343    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1416       |\n",
      "|    time_elapsed         | 10164      |\n",
      "|    total_timesteps      | 2899968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03219065 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.291     |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0306     |\n",
      "|    n_updates            | 59210      |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2900000, episode_reward=0.33 +/- 0.94\n",
      "Episode length: 30.10 +/- 0.46\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30.1      |\n",
      "|    mean_reward          | 0.33      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2900000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0274187 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.295    |\n",
      "|    explained_variance   | 0.199     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0377    |\n",
      "|    n_updates            | 59220     |\n",
      "|    policy_gradient_loss | -0.0286   |\n",
      "|    value_loss           | 0.22      |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.33\n",
      "SELFPLAY: new best model, bumping up generation to 77\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 285      |\n",
      "|    iterations      | 1417     |\n",
      "|    time_elapsed    | 10176    |\n",
      "|    total_timesteps | 2902016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1418        |\n",
      "|    time_elapsed         | 10183       |\n",
      "|    total_timesteps      | 2904064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030444229 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 59230       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1419        |\n",
      "|    time_elapsed         | 10188       |\n",
      "|    total_timesteps      | 2906112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023100683 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0793      |\n",
      "|    n_updates            | 59240       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 10194       |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025364578 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00679     |\n",
      "|    n_updates            | 59250       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2910000, episode_reward=0.00 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028182566 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00254    |\n",
      "|    n_updates            | 59260       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.07    |\n",
      "| time/              |          |\n",
      "|    fps             | 285      |\n",
      "|    iterations      | 1421     |\n",
      "|    time_elapsed    | 10205    |\n",
      "|    total_timesteps | 2910208  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 10211       |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030637614 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.0817      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0503      |\n",
      "|    n_updates            | 59270       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 10217       |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028605651 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0419      |\n",
      "|    n_updates            | 59280       |\n",
      "|    policy_gradient_loss | -0.0362     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 10223       |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029452063 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.067       |\n",
      "|    n_updates            | 59290       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1425        |\n",
      "|    time_elapsed         | 10229       |\n",
      "|    total_timesteps      | 2918400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028934717 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00614    |\n",
      "|    n_updates            | 59300       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2920000, episode_reward=-0.08 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.49\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 29.9     |\n",
      "|    mean_reward          | -0.08    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 2920000  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.027002 |\n",
      "|    clip_fraction        | 0.142    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.304   |\n",
      "|    explained_variance   | 0.366    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0643   |\n",
      "|    n_updates            | 59310    |\n",
      "|    policy_gradient_loss | -0.0302  |\n",
      "|    value_loss           | 0.196    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 285      |\n",
      "|    iterations      | 1426     |\n",
      "|    time_elapsed    | 10241    |\n",
      "|    total_timesteps | 2920448  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 10265       |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026348544 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0737      |\n",
      "|    n_updates            | 59320       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1428       |\n",
      "|    time_elapsed         | 10272      |\n",
      "|    total_timesteps      | 2924544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02950991 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.311     |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0391     |\n",
      "|    n_updates            | 59330      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1429        |\n",
      "|    time_elapsed         | 10279       |\n",
      "|    total_timesteps      | 2926592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026419375 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00728     |\n",
      "|    n_updates            | 59340       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 10285       |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027645793 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 59350       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2930000, episode_reward=0.14 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029364098 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00278    |\n",
      "|    n_updates            | 59360       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 1431     |\n",
      "|    time_elapsed    | 10297    |\n",
      "|    total_timesteps | 2930688  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1432        |\n",
      "|    time_elapsed         | 10303       |\n",
      "|    total_timesteps      | 2932736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028320774 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0332      |\n",
      "|    n_updates            | 59370       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1433       |\n",
      "|    time_elapsed         | 10309      |\n",
      "|    total_timesteps      | 2934784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03114745 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.288     |\n",
      "|    explained_variance   | 0.407      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0063     |\n",
      "|    n_updates            | 59380      |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 10316       |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030014234 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0312      |\n",
      "|    n_updates            | 59390       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1435       |\n",
      "|    time_elapsed         | 10322      |\n",
      "|    total_timesteps      | 2938880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03056844 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.307     |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00582   |\n",
      "|    n_updates            | 59400      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2940000, episode_reward=0.04 +/- 0.99\n",
      "Episode length: 29.90 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023384705 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0241      |\n",
      "|    n_updates            | 59410       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 1436     |\n",
      "|    time_elapsed    | 10334    |\n",
      "|    total_timesteps | 2940928  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1437        |\n",
      "|    time_elapsed         | 10341       |\n",
      "|    total_timesteps      | 2942976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029472707 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0458      |\n",
      "|    n_updates            | 59420       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1438        |\n",
      "|    time_elapsed         | 10347       |\n",
      "|    total_timesteps      | 2945024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030017287 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00665    |\n",
      "|    n_updates            | 59430       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 10353       |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026000425 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 59440       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 10359       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036177404 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0328      |\n",
      "|    n_updates            | 59450       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2950000, episode_reward=0.16 +/- 0.97\n",
      "Episode length: 29.93 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025115607 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 59460       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 1441     |\n",
      "|    time_elapsed    | 10371    |\n",
      "|    total_timesteps | 2951168  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1442        |\n",
      "|    time_elapsed         | 10400       |\n",
      "|    total_timesteps      | 2953216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033719834 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0104      |\n",
      "|    n_updates            | 59470       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.25      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 283       |\n",
      "|    iterations           | 1443      |\n",
      "|    time_elapsed         | 10406     |\n",
      "|    total_timesteps      | 2955264   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0330031 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.298    |\n",
      "|    explained_variance   | 0.374     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0475    |\n",
      "|    n_updates            | 59480     |\n",
      "|    policy_gradient_loss | -0.0291   |\n",
      "|    value_loss           | 0.186     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 10421       |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031757027 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00194    |\n",
      "|    n_updates            | 59490       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1445        |\n",
      "|    time_elapsed         | 10439       |\n",
      "|    total_timesteps      | 2959360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024577137 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 59500       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2960000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 30.07 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027596597 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0068      |\n",
      "|    n_updates            | 59510       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 78\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 283      |\n",
      "|    iterations      | 1446     |\n",
      "|    time_elapsed    | 10451    |\n",
      "|    total_timesteps | 2961408  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 10457       |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031805564 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 59520       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 10465       |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030679293 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0441      |\n",
      "|    n_updates            | 59530       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1449        |\n",
      "|    time_elapsed         | 10498       |\n",
      "|    total_timesteps      | 2967552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035090435 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 59540       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1450        |\n",
      "|    time_elapsed         | 10504       |\n",
      "|    total_timesteps      | 2969600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033940822 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 59550       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2970000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2970000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03525576 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.306      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0244     |\n",
      "|    n_updates            | 59560      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 282      |\n",
      "|    iterations      | 1451     |\n",
      "|    time_elapsed    | 10516    |\n",
      "|    total_timesteps | 2971648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1452        |\n",
      "|    time_elapsed         | 10521       |\n",
      "|    total_timesteps      | 2973696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026257124 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 59570       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1453        |\n",
      "|    time_elapsed         | 10527       |\n",
      "|    total_timesteps      | 2975744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027231734 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 59580       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1454       |\n",
      "|    time_elapsed         | 10533      |\n",
      "|    total_timesteps      | 2977792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03246772 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.316     |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0359     |\n",
      "|    n_updates            | 59590      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1455       |\n",
      "|    time_elapsed         | 10538      |\n",
      "|    total_timesteps      | 2979840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02719456 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.324     |\n",
      "|    explained_variance   | 0.103      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0316     |\n",
      "|    n_updates            | 59600      |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    value_loss           | 0.228      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2980000, episode_reward=0.07 +/- 0.98\n",
      "Episode length: 30.00 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029690528 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 59610       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 282      |\n",
      "|    iterations      | 1456     |\n",
      "|    time_elapsed    | 10548    |\n",
      "|    total_timesteps | 2981888  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1457       |\n",
      "|    time_elapsed         | 10554      |\n",
      "|    total_timesteps      | 2983936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03096297 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00453    |\n",
      "|    n_updates            | 59620      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1458        |\n",
      "|    time_elapsed         | 10560       |\n",
      "|    total_timesteps      | 2985984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027151776 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 59630       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 10566       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026627421 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.073       |\n",
      "|    n_updates            | 59640       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2990000, episode_reward=0.23 +/- 0.97\n",
      "Episode length: 30.02 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029836519 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0653      |\n",
      "|    n_updates            | 59650       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 79\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 282      |\n",
      "|    iterations      | 1460     |\n",
      "|    time_elapsed    | 10599    |\n",
      "|    total_timesteps | 2990080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 10605       |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025641333 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00168     |\n",
      "|    n_updates            | 59660       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1462       |\n",
      "|    time_elapsed         | 10611      |\n",
      "|    total_timesteps      | 2994176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02959826 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0361     |\n",
      "|    n_updates            | 59670      |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1463        |\n",
      "|    time_elapsed         | 10616       |\n",
      "|    total_timesteps      | 2996224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031824328 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0437      |\n",
      "|    n_updates            | 59680       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1464       |\n",
      "|    time_elapsed         | 10622      |\n",
      "|    total_timesteps      | 2998272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03105985 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0413     |\n",
      "|    n_updates            | 59690      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3000000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 30.00 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024733145 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0143      |\n",
      "|    n_updates            | 59700       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 282      |\n",
      "|    iterations      | 1465     |\n",
      "|    time_elapsed    | 10633    |\n",
      "|    total_timesteps | 3000320  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 10641       |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023787625 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 59710       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1467        |\n",
      "|    time_elapsed         | 10648       |\n",
      "|    total_timesteps      | 3004416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028391004 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0176      |\n",
      "|    n_updates            | 59720       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1468        |\n",
      "|    time_elapsed         | 10654       |\n",
      "|    total_timesteps      | 3006464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032036617 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 59730       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1469        |\n",
      "|    time_elapsed         | 10661       |\n",
      "|    total_timesteps      | 3008512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029124934 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0428      |\n",
      "|    n_updates            | 59740       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3010000, episode_reward=0.08 +/- 0.97\n",
      "Episode length: 30.06 +/- 0.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3010000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04092787 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.306     |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0614     |\n",
      "|    n_updates            | 59750      |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 282      |\n",
      "|    iterations      | 1470     |\n",
      "|    time_elapsed    | 10674    |\n",
      "|    total_timesteps | 3010560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 10704       |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027988806 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0727      |\n",
      "|    n_updates            | 59760       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1472        |\n",
      "|    time_elapsed         | 10733       |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031914376 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 59770       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.36       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 1473       |\n",
      "|    time_elapsed         | 10745      |\n",
      "|    total_timesteps      | 3016704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03040989 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0589     |\n",
      "|    n_updates            | 59780      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1474        |\n",
      "|    time_elapsed         | 10751       |\n",
      "|    total_timesteps      | 3018752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027620569 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0562      |\n",
      "|    n_updates            | 59790       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3020000, episode_reward=0.04 +/- 0.99\n",
      "Episode length: 29.97 +/- 0.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3020000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02908019 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.312     |\n",
      "|    explained_variance   | 0.426      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0175     |\n",
      "|    n_updates            | 59800      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 280      |\n",
      "|    iterations      | 1475     |\n",
      "|    time_elapsed    | 10763    |\n",
      "|    total_timesteps | 3020800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1476        |\n",
      "|    time_elapsed         | 10769       |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024231303 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 59810       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1477        |\n",
      "|    time_elapsed         | 10775       |\n",
      "|    total_timesteps      | 3024896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028496865 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0518      |\n",
      "|    n_updates            | 59820       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1478        |\n",
      "|    time_elapsed         | 10780       |\n",
      "|    total_timesteps      | 3026944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027343366 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0951      |\n",
      "|    n_updates            | 59830       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 1479       |\n",
      "|    time_elapsed         | 10786      |\n",
      "|    total_timesteps      | 3028992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02861124 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0514     |\n",
      "|    n_updates            | 59840      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3030000, episode_reward=0.10 +/- 0.99\n",
      "Episode length: 29.99 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028115485 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.073       |\n",
      "|    n_updates            | 59850       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 280      |\n",
      "|    iterations      | 1480     |\n",
      "|    time_elapsed    | 10798    |\n",
      "|    total_timesteps | 3031040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 10804       |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026230028 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0355      |\n",
      "|    n_updates            | 59860       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1482        |\n",
      "|    time_elapsed         | 10836       |\n",
      "|    total_timesteps      | 3035136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030911732 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.025       |\n",
      "|    n_updates            | 59870       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1483        |\n",
      "|    time_elapsed         | 10867       |\n",
      "|    total_timesteps      | 3037184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033790976 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0305      |\n",
      "|    n_updates            | 59880       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1484       |\n",
      "|    time_elapsed         | 10885      |\n",
      "|    total_timesteps      | 3039232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03176504 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.372      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0245     |\n",
      "|    n_updates            | 59890      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3040000, episode_reward=0.30 +/- 0.95\n",
      "Episode length: 30.04 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030129576 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0458      |\n",
      "|    n_updates            | 59900       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.3\n",
      "SELFPLAY: new best model, bumping up generation to 80\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 279      |\n",
      "|    iterations      | 1485     |\n",
      "|    time_elapsed    | 10897    |\n",
      "|    total_timesteps | 3041280  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1486        |\n",
      "|    time_elapsed         | 10904       |\n",
      "|    total_timesteps      | 3043328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025339589 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.062       |\n",
      "|    n_updates            | 59910       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1487        |\n",
      "|    time_elapsed         | 10910       |\n",
      "|    total_timesteps      | 3045376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025956314 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0726      |\n",
      "|    n_updates            | 59920       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 10917       |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031925343 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0767      |\n",
      "|    n_updates            | 59930       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1489        |\n",
      "|    time_elapsed         | 10923       |\n",
      "|    total_timesteps      | 3049472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026360933 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0198      |\n",
      "|    n_updates            | 59940       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3050000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 29.95 +/- 0.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3050000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02955542 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.299     |\n",
      "|    explained_variance   | 0.297      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00965    |\n",
      "|    n_updates            | 59950      |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 279      |\n",
      "|    iterations      | 1490     |\n",
      "|    time_elapsed    | 10937    |\n",
      "|    total_timesteps | 3051520  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1491        |\n",
      "|    time_elapsed         | 10943       |\n",
      "|    total_timesteps      | 3053568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032213643 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0178      |\n",
      "|    n_updates            | 59960       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1492        |\n",
      "|    time_elapsed         | 10949       |\n",
      "|    total_timesteps      | 3055616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030675696 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 59970       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1493        |\n",
      "|    time_elapsed         | 10956       |\n",
      "|    total_timesteps      | 3057664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024494193 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.035       |\n",
      "|    n_updates            | 59980       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1494        |\n",
      "|    time_elapsed         | 10962       |\n",
      "|    total_timesteps      | 3059712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025476485 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0403      |\n",
      "|    n_updates            | 59990       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3060000, episode_reward=0.12 +/- 0.97\n",
      "Episode length: 29.92 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024341617 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0335      |\n",
      "|    n_updates            | 60000       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1495     |\n",
      "|    time_elapsed    | 10975    |\n",
      "|    total_timesteps | 3061760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1496        |\n",
      "|    time_elapsed         | 10981       |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027024731 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0748      |\n",
      "|    n_updates            | 60010       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1497       |\n",
      "|    time_elapsed         | 10988      |\n",
      "|    total_timesteps      | 3065856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03707114 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.293     |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0576     |\n",
      "|    n_updates            | 60020      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 10994       |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028011415 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0236      |\n",
      "|    n_updates            | 60030       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 11001       |\n",
      "|    total_timesteps      | 3069952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027083322 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 60040       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3070000, episode_reward=0.07 +/- 0.99\n",
      "Episode length: 29.85 +/- 0.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3070000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02829276 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.398      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0318     |\n",
      "|    n_updates            | 60050      |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1500     |\n",
      "|    time_elapsed    | 11013    |\n",
      "|    total_timesteps | 3072000  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1501       |\n",
      "|    time_elapsed         | 11020      |\n",
      "|    total_timesteps      | 3074048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03051297 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.29      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0213     |\n",
      "|    n_updates            | 60060      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1502        |\n",
      "|    time_elapsed         | 11026       |\n",
      "|    total_timesteps      | 3076096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030209586 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0395      |\n",
      "|    n_updates            | 60070       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1503        |\n",
      "|    time_elapsed         | 11033       |\n",
      "|    total_timesteps      | 3078144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028260455 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0163      |\n",
      "|    n_updates            | 60080       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3080000, episode_reward=0.10 +/- 0.97\n",
      "Episode length: 29.94 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021678107 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0649      |\n",
      "|    n_updates            | 60090       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1504     |\n",
      "|    time_elapsed    | 11045    |\n",
      "|    total_timesteps | 3080192  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 11052       |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024470523 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 60100       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1506        |\n",
      "|    time_elapsed         | 11069       |\n",
      "|    total_timesteps      | 3084288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024668574 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0656      |\n",
      "|    n_updates            | 60110       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1507        |\n",
      "|    time_elapsed         | 11098       |\n",
      "|    total_timesteps      | 3086336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026430247 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0305      |\n",
      "|    n_updates            | 60120       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1508        |\n",
      "|    time_elapsed         | 11105       |\n",
      "|    total_timesteps      | 3088384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025605027 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00765    |\n",
      "|    n_updates            | 60130       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3090000, episode_reward=0.22 +/- 0.98\n",
      "Episode length: 29.82 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022902995 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.235      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0229      |\n",
      "|    n_updates            | 60140       |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 81\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 277      |\n",
      "|    iterations      | 1509     |\n",
      "|    time_elapsed    | 11117    |\n",
      "|    total_timesteps | 3090432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 11123       |\n",
      "|    total_timesteps      | 3092480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027200833 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0713      |\n",
      "|    n_updates            | 60150       |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1511        |\n",
      "|    time_elapsed         | 11130       |\n",
      "|    total_timesteps      | 3094528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027259406 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0474      |\n",
      "|    n_updates            | 60160       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1512        |\n",
      "|    time_elapsed         | 11136       |\n",
      "|    total_timesteps      | 3096576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027158163 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.069       |\n",
      "|    n_updates            | 60170       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1513        |\n",
      "|    time_elapsed         | 11142       |\n",
      "|    total_timesteps      | 3098624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029335447 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0562      |\n",
      "|    n_updates            | 60180       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3100000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.83 +/- 1.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.8       |\n",
      "|    mean_reward          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3100000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03008403 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.32      |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0376     |\n",
      "|    n_updates            | 60190      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 277      |\n",
      "|    iterations      | 1514     |\n",
      "|    time_elapsed    | 11153    |\n",
      "|    total_timesteps | 3100672  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1515       |\n",
      "|    time_elapsed         | 11160      |\n",
      "|    total_timesteps      | 3102720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02373416 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.32      |\n",
      "|    explained_variance   | 0.331      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00186    |\n",
      "|    n_updates            | 60200      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1516        |\n",
      "|    time_elapsed         | 11166       |\n",
      "|    total_timesteps      | 3104768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028456079 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0298      |\n",
      "|    n_updates            | 60210       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1517        |\n",
      "|    time_elapsed         | 11172       |\n",
      "|    total_timesteps      | 3106816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026603993 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0193      |\n",
      "|    n_updates            | 60220       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.11      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 1518      |\n",
      "|    time_elapsed         | 11178     |\n",
      "|    total_timesteps      | 3108864   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0323327 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.296    |\n",
      "|    explained_variance   | 0.238     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0779    |\n",
      "|    n_updates            | 60230     |\n",
      "|    policy_gradient_loss | -0.0287   |\n",
      "|    value_loss           | 0.229     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3110000, episode_reward=0.32 +/- 0.94\n",
      "Episode length: 29.87 +/- 0.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028492546 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00728     |\n",
      "|    n_updates            | 60240       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.32\n",
      "SELFPLAY: new best model, bumping up generation to 82\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1519     |\n",
      "|    time_elapsed    | 11190    |\n",
      "|    total_timesteps | 3110912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 11195       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027846701 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0375      |\n",
      "|    n_updates            | 60250       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1521        |\n",
      "|    time_elapsed         | 11202       |\n",
      "|    total_timesteps      | 3115008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031948924 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0309      |\n",
      "|    n_updates            | 60260       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 11207       |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029311467 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0314      |\n",
      "|    n_updates            | 60270       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1523        |\n",
      "|    time_elapsed         | 11214       |\n",
      "|    total_timesteps      | 3119104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034526117 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0762      |\n",
      "|    n_updates            | 60280       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=-0.01 +/- 0.97\n",
      "Episode length: 29.96 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028224735 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0596      |\n",
      "|    n_updates            | 60290       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.11    |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1524     |\n",
      "|    time_elapsed    | 11225    |\n",
      "|    total_timesteps | 3121152  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.7       |\n",
      "|    ep_rew_mean          | -0.09      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1525       |\n",
      "|    time_elapsed         | 11231      |\n",
      "|    total_timesteps      | 3123200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03197914 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.248      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0585     |\n",
      "|    n_updates            | 60300      |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.222      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1526        |\n",
      "|    time_elapsed         | 11237       |\n",
      "|    total_timesteps      | 3125248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026319373 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0773      |\n",
      "|    n_updates            | 60310       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1527        |\n",
      "|    time_elapsed         | 11243       |\n",
      "|    total_timesteps      | 3127296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024654452 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0464      |\n",
      "|    n_updates            | 60320       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1528        |\n",
      "|    time_elapsed         | 11249       |\n",
      "|    total_timesteps      | 3129344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026795123 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0547      |\n",
      "|    n_updates            | 60330       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3130000, episode_reward=-0.07 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030293219 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0767      |\n",
      "|    n_updates            | 60340       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1529     |\n",
      "|    time_elapsed    | 11261    |\n",
      "|    total_timesteps | 3131392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1530        |\n",
      "|    time_elapsed         | 11267       |\n",
      "|    total_timesteps      | 3133440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029976506 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0235      |\n",
      "|    n_updates            | 60350       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1531        |\n",
      "|    time_elapsed         | 11273       |\n",
      "|    total_timesteps      | 3135488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027991435 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0268      |\n",
      "|    n_updates            | 60360       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1532        |\n",
      "|    time_elapsed         | 11279       |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038410913 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 60370       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.11      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 1533      |\n",
      "|    time_elapsed         | 11286     |\n",
      "|    total_timesteps      | 3139584   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0318429 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.321    |\n",
      "|    explained_variance   | 0.258     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0347    |\n",
      "|    n_updates            | 60380     |\n",
      "|    policy_gradient_loss | -0.0323   |\n",
      "|    value_loss           | 0.196     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3140000, episode_reward=0.05 +/- 0.97\n",
      "Episode length: 29.96 +/- 0.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035940275 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.061       |\n",
      "|    n_updates            | 60390       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1534     |\n",
      "|    time_elapsed    | 11297    |\n",
      "|    total_timesteps | 3141632  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1535       |\n",
      "|    time_elapsed         | 11303      |\n",
      "|    total_timesteps      | 3143680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02759357 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0418     |\n",
      "|    n_updates            | 60400      |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1536       |\n",
      "|    time_elapsed         | 11309      |\n",
      "|    total_timesteps      | 3145728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03422737 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00901   |\n",
      "|    n_updates            | 60410      |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1537        |\n",
      "|    time_elapsed         | 11314       |\n",
      "|    total_timesteps      | 3147776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031280413 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 60420       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1538        |\n",
      "|    time_elapsed         | 11320       |\n",
      "|    total_timesteps      | 3149824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024988966 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000228   |\n",
      "|    n_updates            | 60430       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3150000, episode_reward=-0.03 +/- 0.97\n",
      "Episode length: 29.96 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030766452 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0579      |\n",
      "|    n_updates            | 60440       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1539     |\n",
      "|    time_elapsed    | 11331    |\n",
      "|    total_timesteps | 3151872  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1540        |\n",
      "|    time_elapsed         | 11337       |\n",
      "|    total_timesteps      | 3153920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026591063 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 60450       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1541        |\n",
      "|    time_elapsed         | 11342       |\n",
      "|    total_timesteps      | 3155968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026416037 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 60460       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1542        |\n",
      "|    time_elapsed         | 11348       |\n",
      "|    total_timesteps      | 3158016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028054543 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 60470       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3160000, episode_reward=0.14 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028955936 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00617     |\n",
      "|    n_updates            | 60480       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.3      |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1543     |\n",
      "|    time_elapsed    | 11359    |\n",
      "|    total_timesteps | 3160064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1544        |\n",
      "|    time_elapsed         | 11365       |\n",
      "|    total_timesteps      | 3162112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024872538 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0389      |\n",
      "|    n_updates            | 60490       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1545        |\n",
      "|    time_elapsed         | 11370       |\n",
      "|    total_timesteps      | 3164160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027138643 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 60500       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1546       |\n",
      "|    time_elapsed         | 11376      |\n",
      "|    total_timesteps      | 3166208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02780688 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0487     |\n",
      "|    n_updates            | 60510      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1547        |\n",
      "|    time_elapsed         | 11382       |\n",
      "|    total_timesteps      | 3168256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025529701 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0571      |\n",
      "|    n_updates            | 60520       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3170000, episode_reward=0.24 +/- 0.97\n",
      "Episode length: 30.07 +/- 0.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024205774 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0347      |\n",
      "|    n_updates            | 60530       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 83\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1548     |\n",
      "|    time_elapsed    | 11393    |\n",
      "|    total_timesteps | 3170304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 11399       |\n",
      "|    total_timesteps      | 3172352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027706701 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0239      |\n",
      "|    n_updates            | 60540       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1550        |\n",
      "|    time_elapsed         | 11404       |\n",
      "|    total_timesteps      | 3174400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026010074 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0561      |\n",
      "|    n_updates            | 60550       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1551        |\n",
      "|    time_elapsed         | 11410       |\n",
      "|    total_timesteps      | 3176448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030836036 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0135      |\n",
      "|    n_updates            | 60560       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1552        |\n",
      "|    time_elapsed         | 11416       |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028649434 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 60570       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3180000, episode_reward=0.15 +/- 0.97\n",
      "Episode length: 30.06 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030754069 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 60580       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1553     |\n",
      "|    time_elapsed    | 11427    |\n",
      "|    total_timesteps | 3180544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1554        |\n",
      "|    time_elapsed         | 11432       |\n",
      "|    total_timesteps      | 3182592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031051092 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0452      |\n",
      "|    n_updates            | 60590       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1555        |\n",
      "|    time_elapsed         | 11438       |\n",
      "|    total_timesteps      | 3184640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030228982 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0912      |\n",
      "|    n_updates            | 60600       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1556        |\n",
      "|    time_elapsed         | 11444       |\n",
      "|    total_timesteps      | 3186688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030177476 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 60610       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1557        |\n",
      "|    time_elapsed         | 11450       |\n",
      "|    total_timesteps      | 3188736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030906959 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0754      |\n",
      "|    n_updates            | 60620       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3190000, episode_reward=0.01 +/- 0.99\n",
      "Episode length: 30.07 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031944625 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0426      |\n",
      "|    n_updates            | 60630       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1558     |\n",
      "|    time_elapsed    | 11461    |\n",
      "|    total_timesteps | 3190784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1559        |\n",
      "|    time_elapsed         | 11467       |\n",
      "|    total_timesteps      | 3192832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030854233 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.074       |\n",
      "|    n_updates            | 60640       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 11473       |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025848214 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0397      |\n",
      "|    n_updates            | 60650       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1561        |\n",
      "|    time_elapsed         | 11478       |\n",
      "|    total_timesteps      | 3196928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028926367 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.047       |\n",
      "|    n_updates            | 60660       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1562        |\n",
      "|    time_elapsed         | 11484       |\n",
      "|    total_timesteps      | 3198976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032491103 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0831      |\n",
      "|    n_updates            | 60670       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 30.02 +/- 0.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3200000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03322812 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.311      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0247     |\n",
      "|    n_updates            | 60680      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1563     |\n",
      "|    time_elapsed    | 11495    |\n",
      "|    total_timesteps | 3201024  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 11502       |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029666238 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0613      |\n",
      "|    n_updates            | 60690       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1565       |\n",
      "|    time_elapsed         | 11510      |\n",
      "|    total_timesteps      | 3205120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02540605 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.26       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0316     |\n",
      "|    n_updates            | 60700      |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1566        |\n",
      "|    time_elapsed         | 11517       |\n",
      "|    total_timesteps      | 3207168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024961945 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0473      |\n",
      "|    n_updates            | 60710       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1567        |\n",
      "|    time_elapsed         | 11523       |\n",
      "|    total_timesteps      | 3209216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026417598 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0138      |\n",
      "|    n_updates            | 60720       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3210000, episode_reward=0.16 +/- 0.95\n",
      "Episode length: 30.19 +/- 0.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.2        |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030412044 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 60730       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1568     |\n",
      "|    time_elapsed    | 11534    |\n",
      "|    total_timesteps | 3211264  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1569       |\n",
      "|    time_elapsed         | 11540      |\n",
      "|    total_timesteps      | 3213312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02928711 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.276     |\n",
      "|    explained_variance   | 0.482      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0147     |\n",
      "|    n_updates            | 60740      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.165      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1570        |\n",
      "|    time_elapsed         | 11545       |\n",
      "|    total_timesteps      | 3215360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030163027 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0742      |\n",
      "|    n_updates            | 60750       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1571        |\n",
      "|    time_elapsed         | 11551       |\n",
      "|    total_timesteps      | 3217408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024576655 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00304    |\n",
      "|    n_updates            | 60760       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1572       |\n",
      "|    time_elapsed         | 11556      |\n",
      "|    total_timesteps      | 3219456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03218569 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.409      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0489     |\n",
      "|    n_updates            | 60770      |\n",
      "|    policy_gradient_loss | -0.0303    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3220000, episode_reward=0.20 +/- 0.97\n",
      "Episode length: 30.06 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035889383 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0644      |\n",
      "|    n_updates            | 60780       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1573     |\n",
      "|    time_elapsed    | 11567    |\n",
      "|    total_timesteps | 3221504  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1574        |\n",
      "|    time_elapsed         | 11573       |\n",
      "|    total_timesteps      | 3223552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032710306 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.02        |\n",
      "|    n_updates            | 60790       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1575       |\n",
      "|    time_elapsed         | 11578      |\n",
      "|    total_timesteps      | 3225600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03262355 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.253     |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00268    |\n",
      "|    n_updates            | 60800      |\n",
      "|    policy_gradient_loss | -0.0276    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1576       |\n",
      "|    time_elapsed         | 11584      |\n",
      "|    total_timesteps      | 3227648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02848731 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.249     |\n",
      "|    explained_variance   | 0.282      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0371     |\n",
      "|    n_updates            | 60810      |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.212      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1577        |\n",
      "|    time_elapsed         | 11589       |\n",
      "|    total_timesteps      | 3229696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026592724 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0443      |\n",
      "|    n_updates            | 60820       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3230000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 29.93 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028604623 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0479      |\n",
      "|    n_updates            | 60830       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1578     |\n",
      "|    time_elapsed    | 11600    |\n",
      "|    total_timesteps | 3231744  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1579        |\n",
      "|    time_elapsed         | 11606       |\n",
      "|    total_timesteps      | 3233792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023334038 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0426      |\n",
      "|    n_updates            | 60840       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1580        |\n",
      "|    time_elapsed         | 11611       |\n",
      "|    total_timesteps      | 3235840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027960781 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0688      |\n",
      "|    n_updates            | 60850       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1581       |\n",
      "|    time_elapsed         | 11617      |\n",
      "|    total_timesteps      | 3237888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03093582 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.269     |\n",
      "|    explained_variance   | 0.302      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0545     |\n",
      "|    n_updates            | 60860      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1582        |\n",
      "|    time_elapsed         | 11624       |\n",
      "|    total_timesteps      | 3239936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024205487 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 60870       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3240000, episode_reward=0.32 +/- 0.94\n",
      "Episode length: 30.00 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021966418 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0219      |\n",
      "|    n_updates            | 60880       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.32\n",
      "SELFPLAY: new best model, bumping up generation to 84\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1583     |\n",
      "|    time_elapsed    | 11635    |\n",
      "|    total_timesteps | 3241984  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1584        |\n",
      "|    time_elapsed         | 11641       |\n",
      "|    total_timesteps      | 3244032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030235551 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0262      |\n",
      "|    n_updates            | 60890       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1585        |\n",
      "|    time_elapsed         | 11647       |\n",
      "|    total_timesteps      | 3246080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026191562 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0727      |\n",
      "|    n_updates            | 60900       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1586        |\n",
      "|    time_elapsed         | 11652       |\n",
      "|    total_timesteps      | 3248128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030541101 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0301      |\n",
      "|    n_updates            | 60910       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3250000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3250000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03125566 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.331     |\n",
      "|    explained_variance   | 0.265      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0378     |\n",
      "|    n_updates            | 60920      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1587     |\n",
      "|    time_elapsed    | 11663    |\n",
      "|    total_timesteps | 3250176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 11669       |\n",
      "|    total_timesteps      | 3252224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028004577 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 60930       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1589        |\n",
      "|    time_elapsed         | 11676       |\n",
      "|    total_timesteps      | 3254272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027157106 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00788     |\n",
      "|    n_updates            | 60940       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1590       |\n",
      "|    time_elapsed         | 11682      |\n",
      "|    total_timesteps      | 3256320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03209851 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0531     |\n",
      "|    n_updates            | 60950      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1591       |\n",
      "|    time_elapsed         | 11688      |\n",
      "|    total_timesteps      | 3258368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02366261 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.269      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0339     |\n",
      "|    n_updates            | 60960      |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    value_loss           | 0.228      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3260000, episode_reward=-0.10 +/- 0.98\n",
      "Episode length: 29.90 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031754553 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0479      |\n",
      "|    n_updates            | 60970       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1592     |\n",
      "|    time_elapsed    | 11700    |\n",
      "|    total_timesteps | 3260416  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.04      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1593       |\n",
      "|    time_elapsed         | 11731      |\n",
      "|    total_timesteps      | 3262464    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03442453 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0227     |\n",
      "|    n_updates            | 60980      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1594        |\n",
      "|    time_elapsed         | 11761       |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027726773 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0553      |\n",
      "|    n_updates            | 60990       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.29      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 277       |\n",
      "|    iterations           | 1595      |\n",
      "|    time_elapsed         | 11777     |\n",
      "|    total_timesteps      | 3266560   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0423256 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.302    |\n",
      "|    explained_variance   | 0.366     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0196    |\n",
      "|    n_updates            | 61000     |\n",
      "|    policy_gradient_loss | -0.0314   |\n",
      "|    value_loss           | 0.199     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1596        |\n",
      "|    time_elapsed         | 11783       |\n",
      "|    total_timesteps      | 3268608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028221278 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00843     |\n",
      "|    n_updates            | 61010       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3270000, episode_reward=0.02 +/- 1.00\n",
      "Episode length: 29.92 +/- 0.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030555692 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0466      |\n",
      "|    n_updates            | 61020       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 277      |\n",
      "|    iterations      | 1597     |\n",
      "|    time_elapsed    | 11796    |\n",
      "|    total_timesteps | 3270656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1598        |\n",
      "|    time_elapsed         | 11802       |\n",
      "|    total_timesteps      | 3272704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024896437 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0738      |\n",
      "|    n_updates            | 61030       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1599        |\n",
      "|    time_elapsed         | 11809       |\n",
      "|    total_timesteps      | 3274752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024317052 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 61040       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1600        |\n",
      "|    time_elapsed         | 11817       |\n",
      "|    total_timesteps      | 3276800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023828743 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0296      |\n",
      "|    n_updates            | 61050       |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1601        |\n",
      "|    time_elapsed         | 11824       |\n",
      "|    total_timesteps      | 3278848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022553125 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.036       |\n",
      "|    n_updates            | 61060       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3280000, episode_reward=0.15 +/- 0.98\n",
      "Episode length: 29.88 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029830988 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0396      |\n",
      "|    n_updates            | 61070       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 277      |\n",
      "|    iterations      | 1602     |\n",
      "|    time_elapsed    | 11837    |\n",
      "|    total_timesteps | 3280896  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1603        |\n",
      "|    time_elapsed         | 11844       |\n",
      "|    total_timesteps      | 3282944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029296847 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 61080       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1604        |\n",
      "|    time_elapsed         | 11851       |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029765975 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0426      |\n",
      "|    n_updates            | 61090       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1605        |\n",
      "|    time_elapsed         | 11858       |\n",
      "|    total_timesteps      | 3287040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029103817 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0229      |\n",
      "|    n_updates            | 61100       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.04      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1606       |\n",
      "|    time_elapsed         | 11864      |\n",
      "|    total_timesteps      | 3289088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02889865 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.441      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0346     |\n",
      "|    n_updates            | 61110      |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3290000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028942943 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 61120       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 277      |\n",
      "|    iterations      | 1607     |\n",
      "|    time_elapsed    | 11877    |\n",
      "|    total_timesteps | 3291136  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1608       |\n",
      "|    time_elapsed         | 11884      |\n",
      "|    total_timesteps      | 3293184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02469087 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.277     |\n",
      "|    explained_variance   | 0.31       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0542     |\n",
      "|    n_updates            | 61130      |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1609       |\n",
      "|    time_elapsed         | 11891      |\n",
      "|    total_timesteps      | 3295232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02983604 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.267     |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0329     |\n",
      "|    n_updates            | 61140      |\n",
      "|    policy_gradient_loss | -0.0294    |\n",
      "|    value_loss           | 0.159      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1610        |\n",
      "|    time_elapsed         | 11902       |\n",
      "|    total_timesteps      | 3297280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030150069 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0311      |\n",
      "|    n_updates            | 61150       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1611        |\n",
      "|    time_elapsed         | 11917       |\n",
      "|    total_timesteps      | 3299328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037383005 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0521      |\n",
      "|    n_updates            | 61160       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3300000, episode_reward=0.26 +/- 0.96\n",
      "Episode length: 30.05 +/- 0.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032806307 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 61170       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 85\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.07    |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 1612     |\n",
      "|    time_elapsed    | 11932    |\n",
      "|    total_timesteps | 3301376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1613        |\n",
      "|    time_elapsed         | 11940       |\n",
      "|    total_timesteps      | 3303424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023713857 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0466      |\n",
      "|    n_updates            | 61180       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1614        |\n",
      "|    time_elapsed         | 11949       |\n",
      "|    total_timesteps      | 3305472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026900964 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 61190       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1615        |\n",
      "|    time_elapsed         | 11957       |\n",
      "|    total_timesteps      | 3307520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020390972 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0344      |\n",
      "|    n_updates            | 61200       |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1616        |\n",
      "|    time_elapsed         | 11966       |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025512684 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0826      |\n",
      "|    n_updates            | 61210       |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3310000, episode_reward=0.28 +/- 0.95\n",
      "Episode length: 29.97 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022839662 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0564      |\n",
      "|    n_updates            | 61220       |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.28\n",
      "SELFPLAY: new best model, bumping up generation to 86\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 1617     |\n",
      "|    time_elapsed    | 11980    |\n",
      "|    total_timesteps | 3311616  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1618        |\n",
      "|    time_elapsed         | 11987       |\n",
      "|    total_timesteps      | 3313664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022452798 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 61230       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1619        |\n",
      "|    time_elapsed         | 11994       |\n",
      "|    total_timesteps      | 3315712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023167918 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0631      |\n",
      "|    n_updates            | 61240       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1620        |\n",
      "|    time_elapsed         | 12002       |\n",
      "|    total_timesteps      | 3317760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029195122 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0143      |\n",
      "|    n_updates            | 61250       |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1621        |\n",
      "|    time_elapsed         | 12009       |\n",
      "|    total_timesteps      | 3319808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040664293 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0574      |\n",
      "|    n_updates            | 61260       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3320000, episode_reward=0.17 +/- 0.98\n",
      "Episode length: 30.02 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036170226 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0128      |\n",
      "|    n_updates            | 61270       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.08    |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 1622     |\n",
      "|    time_elapsed    | 12023    |\n",
      "|    total_timesteps | 3321856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1623        |\n",
      "|    time_elapsed         | 12032       |\n",
      "|    total_timesteps      | 3323904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031978115 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 61280       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1624        |\n",
      "|    time_elapsed         | 12038       |\n",
      "|    total_timesteps      | 3325952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034213953 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00191     |\n",
      "|    n_updates            | 61290       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 12047       |\n",
      "|    total_timesteps      | 3328000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028583243 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00544     |\n",
      "|    n_updates            | 61300       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3330000, episode_reward=0.27 +/- 0.95\n",
      "Episode length: 30.03 +/- 0.46\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30        |\n",
      "|    mean_reward          | 0.27      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3330000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0332715 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.311    |\n",
      "|    explained_variance   | 0.455     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.03      |\n",
      "|    n_updates            | 61310     |\n",
      "|    policy_gradient_loss | -0.0298   |\n",
      "|    value_loss           | 0.187     |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.27\n",
      "SELFPLAY: new best model, bumping up generation to 87\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 276      |\n",
      "|    iterations      | 1626     |\n",
      "|    time_elapsed    | 12061    |\n",
      "|    total_timesteps | 3330048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1627        |\n",
      "|    time_elapsed         | 12070       |\n",
      "|    total_timesteps      | 3332096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031853374 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0523      |\n",
      "|    n_updates            | 61320       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1628        |\n",
      "|    time_elapsed         | 12076       |\n",
      "|    total_timesteps      | 3334144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027689734 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.037       |\n",
      "|    n_updates            | 61330       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.09      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 1629       |\n",
      "|    time_elapsed         | 12085      |\n",
      "|    total_timesteps      | 3336192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03643071 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.365     |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0236     |\n",
      "|    n_updates            | 61340      |\n",
      "|    policy_gradient_loss | -0.0354    |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 1630        |\n",
      "|    time_elapsed         | 12093       |\n",
      "|    total_timesteps      | 3338240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031068783 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.354      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0325      |\n",
      "|    n_updates            | 61350       |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3340000, episode_reward=0.20 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027199926 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 61360       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 275      |\n",
      "|    iterations      | 1631     |\n",
      "|    time_elapsed    | 12106    |\n",
      "|    total_timesteps | 3340288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 12115       |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032557856 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0577      |\n",
      "|    n_updates            | 61370       |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1633        |\n",
      "|    time_elapsed         | 12123       |\n",
      "|    total_timesteps      | 3344384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026400097 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0717      |\n",
      "|    n_updates            | 61380       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1634        |\n",
      "|    time_elapsed         | 12130       |\n",
      "|    total_timesteps      | 3346432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030131515 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0285      |\n",
      "|    n_updates            | 61390       |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 1635       |\n",
      "|    time_elapsed         | 12138      |\n",
      "|    total_timesteps      | 3348480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02784938 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0575     |\n",
      "|    n_updates            | 61400      |\n",
      "|    policy_gradient_loss | -0.0315    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3350000, episode_reward=0.04 +/- 0.99\n",
      "Episode length: 29.82 +/- 1.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031550035 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 61410       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 275      |\n",
      "|    iterations      | 1636     |\n",
      "|    time_elapsed    | 12152    |\n",
      "|    total_timesteps | 3350528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1637        |\n",
      "|    time_elapsed         | 12160       |\n",
      "|    total_timesteps      | 3352576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033102803 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0534      |\n",
      "|    n_updates            | 61420       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 1638       |\n",
      "|    time_elapsed         | 12168      |\n",
      "|    total_timesteps      | 3354624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03241024 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.322     |\n",
      "|    explained_variance   | 0.389      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0458     |\n",
      "|    n_updates            | 61430      |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1639        |\n",
      "|    time_elapsed         | 12177       |\n",
      "|    total_timesteps      | 3356672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026479445 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0393      |\n",
      "|    n_updates            | 61440       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 1640       |\n",
      "|    time_elapsed         | 12184      |\n",
      "|    total_timesteps      | 3358720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03409975 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0261     |\n",
      "|    n_updates            | 61450      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=-0.04 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033442866 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0277      |\n",
      "|    n_updates            | 61460       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 275      |\n",
      "|    iterations      | 1641     |\n",
      "|    time_elapsed    | 12198    |\n",
      "|    total_timesteps | 3360768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1642        |\n",
      "|    time_elapsed         | 12206       |\n",
      "|    total_timesteps      | 3362816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025277114 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0245      |\n",
      "|    n_updates            | 61470       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1643        |\n",
      "|    time_elapsed         | 12215       |\n",
      "|    total_timesteps      | 3364864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031033378 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 61480       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.7       |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 1644       |\n",
      "|    time_elapsed         | 12224      |\n",
      "|    total_timesteps      | 3366912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02623985 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0562     |\n",
      "|    n_updates            | 61490      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1645        |\n",
      "|    time_elapsed         | 12233       |\n",
      "|    total_timesteps      | 3368960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028458547 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0502      |\n",
      "|    n_updates            | 61500       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3370000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 29.98 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027336404 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0422      |\n",
      "|    n_updates            | 61510       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 275      |\n",
      "|    iterations      | 1646     |\n",
      "|    time_elapsed    | 12248    |\n",
      "|    total_timesteps | 3371008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1647        |\n",
      "|    time_elapsed         | 12255       |\n",
      "|    total_timesteps      | 3373056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025470234 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 61520       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1648        |\n",
      "|    time_elapsed         | 12263       |\n",
      "|    total_timesteps      | 3375104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023961585 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0601      |\n",
      "|    n_updates            | 61530       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1649        |\n",
      "|    time_elapsed         | 12270       |\n",
      "|    total_timesteps      | 3377152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032553017 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00744     |\n",
      "|    n_updates            | 61540       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1650        |\n",
      "|    time_elapsed         | 12279       |\n",
      "|    total_timesteps      | 3379200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027389117 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0754      |\n",
      "|    n_updates            | 61550       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3380000, episode_reward=0.12 +/- 0.97\n",
      "Episode length: 29.95 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027761213 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 61560       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 275      |\n",
      "|    iterations      | 1651     |\n",
      "|    time_elapsed    | 12293    |\n",
      "|    total_timesteps | 3381248  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1652        |\n",
      "|    time_elapsed         | 12300       |\n",
      "|    total_timesteps      | 3383296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031123646 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00641     |\n",
      "|    n_updates            | 61570       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 1653        |\n",
      "|    time_elapsed         | 12309       |\n",
      "|    total_timesteps      | 3385344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030717108 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 61580       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 29.9     |\n",
      "|    ep_rew_mean          | 0.05     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 274      |\n",
      "|    iterations           | 1654     |\n",
      "|    time_elapsed         | 12317    |\n",
      "|    total_timesteps      | 3387392  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.031318 |\n",
      "|    clip_fraction        | 0.143    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.295   |\n",
      "|    explained_variance   | 0.391    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0873   |\n",
      "|    n_updates            | 61590    |\n",
      "|    policy_gradient_loss | -0.0312  |\n",
      "|    value_loss           | 0.2      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 1655        |\n",
      "|    time_elapsed         | 12327       |\n",
      "|    total_timesteps      | 3389440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027993998 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 61600       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3390000, episode_reward=0.24 +/- 0.94\n",
      "Episode length: 29.80 +/- 1.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027037768 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0455      |\n",
      "|    n_updates            | 61610       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 88\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 274      |\n",
      "|    iterations      | 1656     |\n",
      "|    time_elapsed    | 12347    |\n",
      "|    total_timesteps | 3391488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 1657        |\n",
      "|    time_elapsed         | 12358       |\n",
      "|    total_timesteps      | 3393536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034283414 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0269      |\n",
      "|    n_updates            | 61620       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 1658        |\n",
      "|    time_elapsed         | 12368       |\n",
      "|    total_timesteps      | 3395584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029459529 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0487      |\n",
      "|    n_updates            | 61630       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 1659        |\n",
      "|    time_elapsed         | 12380       |\n",
      "|    total_timesteps      | 3397632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026442153 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0609      |\n",
      "|    n_updates            | 61640       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 1660        |\n",
      "|    time_elapsed         | 12393       |\n",
      "|    total_timesteps      | 3399680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023627276 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0236      |\n",
      "|    n_updates            | 61650       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3400000, episode_reward=0.29 +/- 0.95\n",
      "Episode length: 30.01 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034010053 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0278      |\n",
      "|    n_updates            | 61660       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.29\n",
      "SELFPLAY: new best model, bumping up generation to 89\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 274      |\n",
      "|    iterations      | 1661     |\n",
      "|    time_elapsed    | 12407    |\n",
      "|    total_timesteps | 3401728  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 1662        |\n",
      "|    time_elapsed         | 12416       |\n",
      "|    total_timesteps      | 3403776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030811556 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0317      |\n",
      "|    n_updates            | 61670       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 1663        |\n",
      "|    time_elapsed         | 12425       |\n",
      "|    total_timesteps      | 3405824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023670577 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0668      |\n",
      "|    n_updates            | 61680       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 1664        |\n",
      "|    time_elapsed         | 12433       |\n",
      "|    total_timesteps      | 3407872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032512173 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 61690       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 1665       |\n",
      "|    time_elapsed         | 12442      |\n",
      "|    total_timesteps      | 3409920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03077422 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.342     |\n",
      "|    explained_variance   | 0.274      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0623     |\n",
      "|    n_updates            | 61700      |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3410000, episode_reward=0.16 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3410000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03246022 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.334     |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0162     |\n",
      "|    n_updates            | 61710      |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 273      |\n",
      "|    iterations      | 1666     |\n",
      "|    time_elapsed    | 12456    |\n",
      "|    total_timesteps | 3411968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1667        |\n",
      "|    time_elapsed         | 12465       |\n",
      "|    total_timesteps      | 3414016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025270201 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 61720       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1668        |\n",
      "|    time_elapsed         | 12472       |\n",
      "|    total_timesteps      | 3416064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036955766 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0688      |\n",
      "|    n_updates            | 61730       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1669        |\n",
      "|    time_elapsed         | 12481       |\n",
      "|    total_timesteps      | 3418112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029150855 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 61740       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3420000, episode_reward=0.15 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025795955 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0256      |\n",
      "|    n_updates            | 61750       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 273      |\n",
      "|    iterations      | 1670     |\n",
      "|    time_elapsed    | 12496    |\n",
      "|    total_timesteps | 3420160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1671        |\n",
      "|    time_elapsed         | 12504       |\n",
      "|    total_timesteps      | 3422208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027118921 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0744      |\n",
      "|    n_updates            | 61760       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1672        |\n",
      "|    time_elapsed         | 12511       |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026004594 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0371      |\n",
      "|    n_updates            | 61770       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1673        |\n",
      "|    time_elapsed         | 12519       |\n",
      "|    total_timesteps      | 3426304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030641153 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0465      |\n",
      "|    n_updates            | 61780       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 1674       |\n",
      "|    time_elapsed         | 12527      |\n",
      "|    total_timesteps      | 3428352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02840868 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.29      |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0265     |\n",
      "|    n_updates            | 61790      |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    value_loss           | 0.151      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3430000, episode_reward=0.22 +/- 0.97\n",
      "Episode length: 30.07 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025086805 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0282      |\n",
      "|    n_updates            | 61800       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 90\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 273      |\n",
      "|    iterations      | 1675     |\n",
      "|    time_elapsed    | 12542    |\n",
      "|    total_timesteps | 3430400  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1676        |\n",
      "|    time_elapsed         | 12550       |\n",
      "|    total_timesteps      | 3432448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026415981 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.05        |\n",
      "|    n_updates            | 61810       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1677        |\n",
      "|    time_elapsed         | 12561       |\n",
      "|    total_timesteps      | 3434496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026553333 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 61820       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1678        |\n",
      "|    time_elapsed         | 12568       |\n",
      "|    total_timesteps      | 3436544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040024377 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0596      |\n",
      "|    n_updates            | 61830       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1679        |\n",
      "|    time_elapsed         | 12575       |\n",
      "|    total_timesteps      | 3438592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030884512 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0461      |\n",
      "|    n_updates            | 61840       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3440000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.97 +/- 0.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3440000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03442348 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.319     |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0421     |\n",
      "|    n_updates            | 61850      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 273      |\n",
      "|    iterations      | 1680     |\n",
      "|    time_elapsed    | 12587    |\n",
      "|    total_timesteps | 3440640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1681        |\n",
      "|    time_elapsed         | 12594       |\n",
      "|    total_timesteps      | 3442688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025841929 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0482      |\n",
      "|    n_updates            | 61860       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1682        |\n",
      "|    time_elapsed         | 12601       |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031778872 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0266      |\n",
      "|    n_updates            | 61870       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1683        |\n",
      "|    time_elapsed         | 12608       |\n",
      "|    total_timesteps      | 3446784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029908687 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0101      |\n",
      "|    n_updates            | 61880       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 1684        |\n",
      "|    time_elapsed         | 12616       |\n",
      "|    total_timesteps      | 3448832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029195977 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 61890       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3450000, episode_reward=0.32 +/- 0.92\n",
      "Episode length: 29.97 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027632453 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0158      |\n",
      "|    n_updates            | 61900       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.32\n",
      "SELFPLAY: new best model, bumping up generation to 91\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 273      |\n",
      "|    iterations      | 1685     |\n",
      "|    time_elapsed    | 12629    |\n",
      "|    total_timesteps | 3450880  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 1686        |\n",
      "|    time_elapsed         | 12660       |\n",
      "|    total_timesteps      | 3452928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027692262 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0426      |\n",
      "|    n_updates            | 61910       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 1687        |\n",
      "|    time_elapsed         | 12695       |\n",
      "|    total_timesteps      | 3454976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026004476 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0552      |\n",
      "|    n_updates            | 61920       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1688        |\n",
      "|    time_elapsed         | 12713       |\n",
      "|    total_timesteps      | 3457024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033762913 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.348      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0387      |\n",
      "|    n_updates            | 61930       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1689        |\n",
      "|    time_elapsed         | 12719       |\n",
      "|    total_timesteps      | 3459072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026540643 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.362      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 61940       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3460000, episode_reward=0.05 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026161969 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.358      |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0394      |\n",
      "|    n_updates            | 61950       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1690     |\n",
      "|    time_elapsed    | 12733    |\n",
      "|    total_timesteps | 3461120  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 1691       |\n",
      "|    time_elapsed         | 12740      |\n",
      "|    total_timesteps      | 3463168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03179855 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0124     |\n",
      "|    n_updates            | 61960      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1692        |\n",
      "|    time_elapsed         | 12747       |\n",
      "|    total_timesteps      | 3465216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034220476 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00889    |\n",
      "|    n_updates            | 61970       |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 1693       |\n",
      "|    time_elapsed         | 12754      |\n",
      "|    total_timesteps      | 3467264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03169488 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.322     |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0263     |\n",
      "|    n_updates            | 61980      |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1694        |\n",
      "|    time_elapsed         | 12761       |\n",
      "|    total_timesteps      | 3469312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023720073 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0223      |\n",
      "|    n_updates            | 61990       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3470000, episode_reward=0.25 +/- 0.95\n",
      "Episode length: 30.00 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027488606 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 62000       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 92\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1695     |\n",
      "|    time_elapsed    | 12774    |\n",
      "|    total_timesteps | 3471360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1696        |\n",
      "|    time_elapsed         | 12782       |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024644554 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.035       |\n",
      "|    n_updates            | 62010       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1697        |\n",
      "|    time_elapsed         | 12788       |\n",
      "|    total_timesteps      | 3475456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028016763 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0693      |\n",
      "|    n_updates            | 62020       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1698        |\n",
      "|    time_elapsed         | 12796       |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029362584 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0311      |\n",
      "|    n_updates            | 62030       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1699        |\n",
      "|    time_elapsed         | 12803       |\n",
      "|    total_timesteps      | 3479552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023226053 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0375      |\n",
      "|    n_updates            | 62040       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3480000, episode_reward=-0.07 +/- 0.99\n",
      "Episode length: 29.98 +/- 0.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | -0.07      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3480000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02794505 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.31      |\n",
      "|    explained_variance   | 0.201      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0315     |\n",
      "|    n_updates            | 62050      |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.212      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1700     |\n",
      "|    time_elapsed    | 12816    |\n",
      "|    total_timesteps | 3481600  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1701        |\n",
      "|    time_elapsed         | 12826       |\n",
      "|    total_timesteps      | 3483648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024865473 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0458      |\n",
      "|    n_updates            | 62060       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1702        |\n",
      "|    time_elapsed         | 12833       |\n",
      "|    total_timesteps      | 3485696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027762268 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0045      |\n",
      "|    n_updates            | 62070       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 1703       |\n",
      "|    time_elapsed         | 12840      |\n",
      "|    total_timesteps      | 3487744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03210983 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.311     |\n",
      "|    explained_variance   | 0.255      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0781     |\n",
      "|    n_updates            | 62080      |\n",
      "|    policy_gradient_loss | -0.0331    |\n",
      "|    value_loss           | 0.22       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1704        |\n",
      "|    time_elapsed         | 12846       |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029472303 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 62090       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3490000, episode_reward=0.25 +/- 0.96\n",
      "Episode length: 30.08 +/- 0.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024522059 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0271      |\n",
      "|    n_updates            | 62100       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 93\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1705     |\n",
      "|    time_elapsed    | 12860    |\n",
      "|    total_timesteps | 3491840  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 1706       |\n",
      "|    time_elapsed         | 12867      |\n",
      "|    total_timesteps      | 3493888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03293717 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.374      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0373     |\n",
      "|    n_updates            | 62110      |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1707        |\n",
      "|    time_elapsed         | 12874       |\n",
      "|    total_timesteps      | 3495936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028493933 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0135      |\n",
      "|    n_updates            | 62120       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1708        |\n",
      "|    time_elapsed         | 12881       |\n",
      "|    total_timesteps      | 3497984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030853346 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00727     |\n",
      "|    n_updates            | 62130       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3500000, episode_reward=0.10 +/- 0.97\n",
      "Episode length: 29.97 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029069155 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000938   |\n",
      "|    n_updates            | 62140       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1709     |\n",
      "|    time_elapsed    | 12895    |\n",
      "|    total_timesteps | 3500032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1710        |\n",
      "|    time_elapsed         | 12902       |\n",
      "|    total_timesteps      | 3502080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031438787 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0138      |\n",
      "|    n_updates            | 62150       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.41        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1711        |\n",
      "|    time_elapsed         | 12910       |\n",
      "|    total_timesteps      | 3504128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032532454 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0496      |\n",
      "|    n_updates            | 62160       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1712        |\n",
      "|    time_elapsed         | 12917       |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029781442 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0029     |\n",
      "|    n_updates            | 62170       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 1713       |\n",
      "|    time_elapsed         | 12924      |\n",
      "|    total_timesteps      | 3508224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03368627 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.019      |\n",
      "|    n_updates            | 62180      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3510000, episode_reward=0.27 +/- 0.96\n",
      "Episode length: 29.94 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027054686 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0316      |\n",
      "|    n_updates            | 62190       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.27\n",
      "SELFPLAY: new best model, bumping up generation to 94\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.34     |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1714     |\n",
      "|    time_elapsed    | 12938    |\n",
      "|    total_timesteps | 3510272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1715        |\n",
      "|    time_elapsed         | 12950       |\n",
      "|    total_timesteps      | 3512320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028574087 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 62200       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.26      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 271       |\n",
      "|    iterations           | 1716      |\n",
      "|    time_elapsed         | 12958     |\n",
      "|    total_timesteps      | 3514368   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0364405 |\n",
      "|    clip_fraction        | 0.155     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.338    |\n",
      "|    explained_variance   | 0.218     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0264    |\n",
      "|    n_updates            | 62210     |\n",
      "|    policy_gradient_loss | -0.0333   |\n",
      "|    value_loss           | 0.23      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1717        |\n",
      "|    time_elapsed         | 12965       |\n",
      "|    total_timesteps      | 3516416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029511819 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 62220       |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1718        |\n",
      "|    time_elapsed         | 12972       |\n",
      "|    total_timesteps      | 3518464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027744275 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0355      |\n",
      "|    n_updates            | 62230       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=0.11 +/- 0.98\n",
      "Episode length: 29.93 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033447415 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 62240       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1719     |\n",
      "|    time_elapsed    | 12985    |\n",
      "|    total_timesteps | 3520512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 12993       |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031768046 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 62250       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 12998       |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032343376 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0362      |\n",
      "|    n_updates            | 62260       |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1722        |\n",
      "|    time_elapsed         | 13004       |\n",
      "|    total_timesteps      | 3526656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034968648 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0323      |\n",
      "|    n_updates            | 62270       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 1723       |\n",
      "|    time_elapsed         | 13010      |\n",
      "|    total_timesteps      | 3528704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03904944 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.311     |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00556    |\n",
      "|    n_updates            | 62280      |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3530000, episode_reward=0.06 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029937752 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0282      |\n",
      "|    n_updates            | 62290       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1724     |\n",
      "|    time_elapsed    | 13022    |\n",
      "|    total_timesteps | 3530752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1725        |\n",
      "|    time_elapsed         | 13028       |\n",
      "|    total_timesteps      | 3532800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032787934 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0395      |\n",
      "|    n_updates            | 62300       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1726        |\n",
      "|    time_elapsed         | 13043       |\n",
      "|    total_timesteps      | 3534848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027697599 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.071       |\n",
      "|    n_updates            | 62310       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1727        |\n",
      "|    time_elapsed         | 13048       |\n",
      "|    total_timesteps      | 3536896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036048062 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0324      |\n",
      "|    n_updates            | 62320       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 1728        |\n",
      "|    time_elapsed         | 13054       |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030245125 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0407      |\n",
      "|    n_updates            | 62330       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3540000, episode_reward=0.37 +/- 0.92\n",
      "Episode length: 29.98 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.37        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024615183 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.216      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 62340       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.37\n",
      "SELFPLAY: new best model, bumping up generation to 95\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 271      |\n",
      "|    iterations      | 1729     |\n",
      "|    time_elapsed    | 13066    |\n",
      "|    total_timesteps | 3540992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1730        |\n",
      "|    time_elapsed         | 13093       |\n",
      "|    total_timesteps      | 3543040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032197095 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.057       |\n",
      "|    n_updates            | 62350       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1731        |\n",
      "|    time_elapsed         | 13124       |\n",
      "|    total_timesteps      | 3545088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028696578 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0477      |\n",
      "|    n_updates            | 62360       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1732        |\n",
      "|    time_elapsed         | 13136       |\n",
      "|    total_timesteps      | 3547136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030735442 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0252      |\n",
      "|    n_updates            | 62370       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1733        |\n",
      "|    time_elapsed         | 13142       |\n",
      "|    total_timesteps      | 3549184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030761493 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0239      |\n",
      "|    n_updates            | 62380       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3550000, episode_reward=0.23 +/- 0.95\n",
      "Episode length: 29.99 +/- 0.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3550000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03144729 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.25       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0467     |\n",
      "|    n_updates            | 62390      |\n",
      "|    policy_gradient_loss | -0.0336    |\n",
      "|    value_loss           | 0.219      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 96\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1734     |\n",
      "|    time_elapsed    | 13153    |\n",
      "|    total_timesteps | 3551232  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1735       |\n",
      "|    time_elapsed         | 13159      |\n",
      "|    total_timesteps      | 3553280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03334552 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0634     |\n",
      "|    n_updates            | 62400      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1736        |\n",
      "|    time_elapsed         | 13165       |\n",
      "|    total_timesteps      | 3555328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024484541 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0678      |\n",
      "|    n_updates            | 62410       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1737       |\n",
      "|    time_elapsed         | 13172      |\n",
      "|    total_timesteps      | 3557376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02759482 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.347     |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0315     |\n",
      "|    n_updates            | 62420      |\n",
      "|    policy_gradient_loss | -0.0349    |\n",
      "|    value_loss           | 0.219      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1738        |\n",
      "|    time_elapsed         | 13178       |\n",
      "|    total_timesteps      | 3559424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031025928 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0474      |\n",
      "|    n_updates            | 62430       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3560000, episode_reward=0.03 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024309993 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 62440       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1739     |\n",
      "|    time_elapsed    | 13190    |\n",
      "|    total_timesteps | 3561472  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1740        |\n",
      "|    time_elapsed         | 13196       |\n",
      "|    total_timesteps      | 3563520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029435951 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 62450       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1741        |\n",
      "|    time_elapsed         | 13202       |\n",
      "|    total_timesteps      | 3565568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027290927 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0183      |\n",
      "|    n_updates            | 62460       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1742        |\n",
      "|    time_elapsed         | 13208       |\n",
      "|    total_timesteps      | 3567616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029557504 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.057       |\n",
      "|    n_updates            | 62470       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1743        |\n",
      "|    time_elapsed         | 13215       |\n",
      "|    total_timesteps      | 3569664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028760212 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 62480       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3570000, episode_reward=-0.03 +/- 0.99\n",
      "Episode length: 29.94 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025771625 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0256      |\n",
      "|    n_updates            | 62490       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | -0.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1744     |\n",
      "|    time_elapsed    | 13233    |\n",
      "|    total_timesteps | 3571712  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.7      |\n",
      "|    ep_rew_mean          | 0.11      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 269       |\n",
      "|    iterations           | 1745      |\n",
      "|    time_elapsed         | 13239     |\n",
      "|    total_timesteps      | 3573760   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0342227 |\n",
      "|    clip_fraction        | 0.156     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.329    |\n",
      "|    explained_variance   | 0.33      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0527    |\n",
      "|    n_updates            | 62500     |\n",
      "|    policy_gradient_loss | -0.0359   |\n",
      "|    value_loss           | 0.201     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1746        |\n",
      "|    time_elapsed         | 13252       |\n",
      "|    total_timesteps      | 3575808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028657291 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 62510       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1747        |\n",
      "|    time_elapsed         | 13257       |\n",
      "|    total_timesteps      | 3577856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031408086 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 62520       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1748        |\n",
      "|    time_elapsed         | 13264       |\n",
      "|    total_timesteps      | 3579904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033708774 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0214      |\n",
      "|    n_updates            | 62530       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3580000, episode_reward=0.12 +/- 0.99\n",
      "Episode length: 29.75 +/- 2.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031153858 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0489      |\n",
      "|    n_updates            | 62540       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1749     |\n",
      "|    time_elapsed    | 13275    |\n",
      "|    total_timesteps | 3581952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 13281       |\n",
      "|    total_timesteps      | 3584000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027073676 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0338      |\n",
      "|    n_updates            | 62550       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1751        |\n",
      "|    time_elapsed         | 13288       |\n",
      "|    total_timesteps      | 3586048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033491917 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0464      |\n",
      "|    n_updates            | 62560       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1752        |\n",
      "|    time_elapsed         | 13294       |\n",
      "|    total_timesteps      | 3588096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031184064 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0418      |\n",
      "|    n_updates            | 62570       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3590000, episode_reward=0.22 +/- 0.95\n",
      "Episode length: 29.99 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031586695 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0316      |\n",
      "|    n_updates            | 62580       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 97\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1753     |\n",
      "|    time_elapsed    | 13307    |\n",
      "|    total_timesteps | 3590144  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1754       |\n",
      "|    time_elapsed         | 13315      |\n",
      "|    total_timesteps      | 3592192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02732794 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.224      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0826     |\n",
      "|    n_updates            | 62590      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.219      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.03      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 269       |\n",
      "|    iterations           | 1755      |\n",
      "|    time_elapsed         | 13321     |\n",
      "|    total_timesteps      | 3594240   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0314448 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.334    |\n",
      "|    explained_variance   | 0.262     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0521    |\n",
      "|    n_updates            | 62600     |\n",
      "|    policy_gradient_loss | -0.0333   |\n",
      "|    value_loss           | 0.204     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1756       |\n",
      "|    time_elapsed         | 13327      |\n",
      "|    total_timesteps      | 3596288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03261996 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.318     |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0346     |\n",
      "|    n_updates            | 62610      |\n",
      "|    policy_gradient_loss | -0.0344    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1757       |\n",
      "|    time_elapsed         | 13332      |\n",
      "|    total_timesteps      | 3598336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04156596 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.339     |\n",
      "|    explained_variance   | 0.549      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0158     |\n",
      "|    n_updates            | 62620      |\n",
      "|    policy_gradient_loss | -0.0356    |\n",
      "|    value_loss           | 0.131      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=0.30 +/- 0.94\n",
      "Episode length: 30.00 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030808281 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0482      |\n",
      "|    n_updates            | 62630       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.3\n",
      "SELFPLAY: new best model, bumping up generation to 98\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1758     |\n",
      "|    time_elapsed    | 13344    |\n",
      "|    total_timesteps | 3600384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1759        |\n",
      "|    time_elapsed         | 13350       |\n",
      "|    total_timesteps      | 3602432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034668367 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00756     |\n",
      "|    n_updates            | 62640       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1760        |\n",
      "|    time_elapsed         | 13356       |\n",
      "|    total_timesteps      | 3604480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030511549 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000775   |\n",
      "|    n_updates            | 62650       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1761        |\n",
      "|    time_elapsed         | 13361       |\n",
      "|    total_timesteps      | 3606528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027316108 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.037       |\n",
      "|    n_updates            | 62660       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 13367       |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026192518 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0236      |\n",
      "|    n_updates            | 62670       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3610000, episode_reward=0.11 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026617782 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 62680       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.34     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1763     |\n",
      "|    time_elapsed    | 13379    |\n",
      "|    total_timesteps | 3610624  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1764        |\n",
      "|    time_elapsed         | 13386       |\n",
      "|    total_timesteps      | 3612672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028885813 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 62690       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 13393       |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029440284 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0323      |\n",
      "|    n_updates            | 62700       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1766       |\n",
      "|    time_elapsed         | 13399      |\n",
      "|    total_timesteps      | 3616768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03016984 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.278     |\n",
      "|    explained_variance   | 0.413      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00171    |\n",
      "|    n_updates            | 62710      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.18       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1767        |\n",
      "|    time_elapsed         | 13406       |\n",
      "|    total_timesteps      | 3618816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026762413 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 62720       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3620000, episode_reward=0.33 +/- 0.93\n",
      "Episode length: 30.09 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028342022 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0591      |\n",
      "|    n_updates            | 62730       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.33\n",
      "SELFPLAY: new best model, bumping up generation to 99\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1768     |\n",
      "|    time_elapsed    | 13417    |\n",
      "|    total_timesteps | 3620864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 13424       |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035716914 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 62740       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1770        |\n",
      "|    time_elapsed         | 13431       |\n",
      "|    total_timesteps      | 3624960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031307064 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 62750       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1771        |\n",
      "|    time_elapsed         | 13437       |\n",
      "|    total_timesteps      | 3627008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038909268 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0215      |\n",
      "|    n_updates            | 62760       |\n",
      "|    policy_gradient_loss | -0.0348     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 13443       |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031246591 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0208     |\n",
      "|    n_updates            | 62770       |\n",
      "|    policy_gradient_loss | -0.0332     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3630000, episode_reward=0.23 +/- 0.97\n",
      "Episode length: 30.02 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037994713 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000482   |\n",
      "|    n_updates            | 62780       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 100\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1773     |\n",
      "|    time_elapsed    | 13455    |\n",
      "|    total_timesteps | 3631104  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.13      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1774       |\n",
      "|    time_elapsed         | 13461      |\n",
      "|    total_timesteps      | 3633152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02463128 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.562      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0163     |\n",
      "|    n_updates            | 62790      |\n",
      "|    policy_gradient_loss | -0.0269    |\n",
      "|    value_loss           | 0.12       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1775        |\n",
      "|    time_elapsed         | 13468       |\n",
      "|    total_timesteps      | 3635200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025617335 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 62800       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1776        |\n",
      "|    time_elapsed         | 13475       |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028052546 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0808      |\n",
      "|    n_updates            | 62810       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1777        |\n",
      "|    time_elapsed         | 13482       |\n",
      "|    total_timesteps      | 3639296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033031814 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 62820       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3640000, episode_reward=0.03 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030026656 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0205      |\n",
      "|    n_updates            | 62830       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1778     |\n",
      "|    time_elapsed    | 13494    |\n",
      "|    total_timesteps | 3641344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 13500       |\n",
      "|    total_timesteps      | 3643392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027296733 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.04        |\n",
      "|    n_updates            | 62840       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1780        |\n",
      "|    time_elapsed         | 13506       |\n",
      "|    total_timesteps      | 3645440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030059496 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0301      |\n",
      "|    n_updates            | 62850       |\n",
      "|    policy_gradient_loss | -0.0336     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1781        |\n",
      "|    time_elapsed         | 13513       |\n",
      "|    total_timesteps      | 3647488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030743625 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 62860       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1782       |\n",
      "|    time_elapsed         | 13519      |\n",
      "|    total_timesteps      | 3649536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03277128 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.302     |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0388     |\n",
      "|    n_updates            | 62870      |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    value_loss           | 0.174      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3650000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 30.05 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031266466 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0185      |\n",
      "|    n_updates            | 62880       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 101\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1783     |\n",
      "|    time_elapsed    | 13530    |\n",
      "|    total_timesteps | 3651584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1784        |\n",
      "|    time_elapsed         | 13536       |\n",
      "|    total_timesteps      | 3653632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037806317 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0352      |\n",
      "|    n_updates            | 62890       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1785        |\n",
      "|    time_elapsed         | 13543       |\n",
      "|    total_timesteps      | 3655680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026218541 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 62900       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 13549       |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031183382 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.024       |\n",
      "|    n_updates            | 62910       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1787       |\n",
      "|    time_elapsed         | 13555      |\n",
      "|    total_timesteps      | 3659776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02656488 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0621     |\n",
      "|    n_updates            | 62920      |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    value_loss           | 0.224      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3660000, episode_reward=0.14 +/- 0.97\n",
      "Episode length: 29.93 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032398075 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0371      |\n",
      "|    n_updates            | 62930       |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1788     |\n",
      "|    time_elapsed    | 13567    |\n",
      "|    total_timesteps | 3661824  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1789       |\n",
      "|    time_elapsed         | 13573      |\n",
      "|    total_timesteps      | 3663872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02819906 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.315     |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.128      |\n",
      "|    n_updates            | 62940      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1790        |\n",
      "|    time_elapsed         | 13579       |\n",
      "|    total_timesteps      | 3665920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026146676 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 62950       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1791        |\n",
      "|    time_elapsed         | 13585       |\n",
      "|    total_timesteps      | 3667968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025987677 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0101      |\n",
      "|    n_updates            | 62960       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3670000, episode_reward=0.28 +/- 0.95\n",
      "Episode length: 30.06 +/- 0.51\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.28       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3670000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02584646 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.268      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0168     |\n",
      "|    n_updates            | 62970      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.28\n",
      "SELFPLAY: new best model, bumping up generation to 102\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1792     |\n",
      "|    time_elapsed    | 13596    |\n",
      "|    total_timesteps | 3670016  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.09      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1793       |\n",
      "|    time_elapsed         | 13602      |\n",
      "|    total_timesteps      | 3672064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02653506 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.175      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0385     |\n",
      "|    n_updates            | 62980      |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.236      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1794        |\n",
      "|    time_elapsed         | 13608       |\n",
      "|    total_timesteps      | 3674112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028500622 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0489      |\n",
      "|    n_updates            | 62990       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1795       |\n",
      "|    time_elapsed         | 13615      |\n",
      "|    total_timesteps      | 3676160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02731819 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.217      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0397     |\n",
      "|    n_updates            | 63000      |\n",
      "|    policy_gradient_loss | -0.0301    |\n",
      "|    value_loss           | 0.212      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 13622       |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031813245 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0549      |\n",
      "|    n_updates            | 63010       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3680000, episode_reward=0.18 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028888479 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 63020       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1797     |\n",
      "|    time_elapsed    | 13633    |\n",
      "|    total_timesteps | 3680256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1798        |\n",
      "|    time_elapsed         | 13639       |\n",
      "|    total_timesteps      | 3682304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027651094 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0491      |\n",
      "|    n_updates            | 63030       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.7       |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1799       |\n",
      "|    time_elapsed         | 13646      |\n",
      "|    total_timesteps      | 3684352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03469743 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.314     |\n",
      "|    explained_variance   | 0.201      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0399     |\n",
      "|    n_updates            | 63040      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1800       |\n",
      "|    time_elapsed         | 13651      |\n",
      "|    total_timesteps      | 3686400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02682494 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.315     |\n",
      "|    explained_variance   | 0.275      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0684     |\n",
      "|    n_updates            | 63050      |\n",
      "|    policy_gradient_loss | -0.03      |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1801        |\n",
      "|    time_elapsed         | 13657       |\n",
      "|    total_timesteps      | 3688448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029889898 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 63060       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3690000, episode_reward=0.22 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3690000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026403317 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0628      |\n",
      "|    n_updates            | 63070       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 103\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1802     |\n",
      "|    time_elapsed    | 13670    |\n",
      "|    total_timesteps | 3690496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 13684       |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033578455 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00867    |\n",
      "|    n_updates            | 63080       |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1804        |\n",
      "|    time_elapsed         | 13691       |\n",
      "|    total_timesteps      | 3694592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029707493 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0442      |\n",
      "|    n_updates            | 63090       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1805        |\n",
      "|    time_elapsed         | 13697       |\n",
      "|    total_timesteps      | 3696640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025249232 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0144      |\n",
      "|    n_updates            | 63100       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1806        |\n",
      "|    time_elapsed         | 13703       |\n",
      "|    total_timesteps      | 3698688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028178137 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0789      |\n",
      "|    n_updates            | 63110       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3700000, episode_reward=0.05 +/- 0.99\n",
      "Episode length: 29.97 +/- 0.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3700000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02852222 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0345     |\n",
      "|    n_updates            | 63120      |\n",
      "|    policy_gradient_loss | -0.0336    |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.14    |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1807     |\n",
      "|    time_elapsed    | 13714    |\n",
      "|    total_timesteps | 3700736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1808        |\n",
      "|    time_elapsed         | 13720       |\n",
      "|    total_timesteps      | 3702784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024535503 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 63130       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1809        |\n",
      "|    time_elapsed         | 13727       |\n",
      "|    total_timesteps      | 3704832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031721633 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 63140       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1810        |\n",
      "|    time_elapsed         | 13733       |\n",
      "|    total_timesteps      | 3706880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032310545 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.033       |\n",
      "|    n_updates            | 63150       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1811        |\n",
      "|    time_elapsed         | 13739       |\n",
      "|    total_timesteps      | 3708928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033735372 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0132     |\n",
      "|    n_updates            | 63160       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3710000, episode_reward=-0.01 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026001006 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 63170       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1812     |\n",
      "|    time_elapsed    | 13751    |\n",
      "|    total_timesteps | 3710976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1813        |\n",
      "|    time_elapsed         | 13757       |\n",
      "|    total_timesteps      | 3713024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037554905 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0245      |\n",
      "|    n_updates            | 63180       |\n",
      "|    policy_gradient_loss | -0.0369     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1814        |\n",
      "|    time_elapsed         | 13764       |\n",
      "|    total_timesteps      | 3715072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027543966 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 63190       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1815        |\n",
      "|    time_elapsed         | 13770       |\n",
      "|    total_timesteps      | 3717120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027771119 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0281      |\n",
      "|    n_updates            | 63200       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1816        |\n",
      "|    time_elapsed         | 13776       |\n",
      "|    total_timesteps      | 3719168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027392223 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0447      |\n",
      "|    n_updates            | 63210       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3720000, episode_reward=0.18 +/- 0.96\n",
      "Episode length: 29.98 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026847184 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 63220       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1817     |\n",
      "|    time_elapsed    | 13788    |\n",
      "|    total_timesteps | 3721216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1818        |\n",
      "|    time_elapsed         | 13795       |\n",
      "|    total_timesteps      | 3723264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024256015 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0157      |\n",
      "|    n_updates            | 63230       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1819        |\n",
      "|    time_elapsed         | 13801       |\n",
      "|    total_timesteps      | 3725312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028731732 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 63240       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 13807       |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024465099 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 63250       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1821        |\n",
      "|    time_elapsed         | 13814       |\n",
      "|    total_timesteps      | 3729408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026545666 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.011       |\n",
      "|    n_updates            | 63260       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3730000, episode_reward=0.13 +/- 0.99\n",
      "Episode length: 30.01 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021072391 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0302      |\n",
      "|    n_updates            | 63270       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.38     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1822     |\n",
      "|    time_elapsed    | 13825    |\n",
      "|    total_timesteps | 3731456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1823        |\n",
      "|    time_elapsed         | 13831       |\n",
      "|    total_timesteps      | 3733504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023861824 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0824      |\n",
      "|    n_updates            | 63280       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1824        |\n",
      "|    time_elapsed         | 13838       |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025266957 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0748      |\n",
      "|    n_updates            | 63290       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1825        |\n",
      "|    time_elapsed         | 13844       |\n",
      "|    total_timesteps      | 3737600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029694652 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00596     |\n",
      "|    n_updates            | 63300       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1826        |\n",
      "|    time_elapsed         | 13850       |\n",
      "|    total_timesteps      | 3739648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028087312 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.033       |\n",
      "|    n_updates            | 63310       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3740000, episode_reward=0.25 +/- 0.96\n",
      "Episode length: 30.09 +/- 0.45\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30.1      |\n",
      "|    mean_reward          | 0.25      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3740000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0296844 |\n",
      "|    clip_fraction        | 0.133     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.27     |\n",
      "|    explained_variance   | 0.317     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0597    |\n",
      "|    n_updates            | 63320     |\n",
      "|    policy_gradient_loss | -0.0302   |\n",
      "|    value_loss           | 0.194     |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 104\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1827     |\n",
      "|    time_elapsed    | 13862    |\n",
      "|    total_timesteps | 3741696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 13868       |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024735559 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 63330       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1829        |\n",
      "|    time_elapsed         | 13874       |\n",
      "|    total_timesteps      | 3745792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037397362 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0448      |\n",
      "|    n_updates            | 63340       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 13881       |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028260304 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0959      |\n",
      "|    n_updates            | 63350       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1831        |\n",
      "|    time_elapsed         | 13887       |\n",
      "|    total_timesteps      | 3749888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027848087 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0405      |\n",
      "|    n_updates            | 63360       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3750000, episode_reward=0.10 +/- 0.97\n",
      "Episode length: 29.92 +/- 0.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3750000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03344727 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0513     |\n",
      "|    n_updates            | 63370      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1832     |\n",
      "|    time_elapsed    | 13899    |\n",
      "|    total_timesteps | 3751936  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1833        |\n",
      "|    time_elapsed         | 13905       |\n",
      "|    total_timesteps      | 3753984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029891636 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0198      |\n",
      "|    n_updates            | 63380       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1834       |\n",
      "|    time_elapsed         | 13911      |\n",
      "|    total_timesteps      | 3756032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03212198 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.296     |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00251    |\n",
      "|    n_updates            | 63390      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.14       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1835        |\n",
      "|    time_elapsed         | 13918       |\n",
      "|    total_timesteps      | 3758080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028541483 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 63400       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3760000, episode_reward=0.44 +/- 0.86\n",
      "Episode length: 30.03 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.44        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021192804 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0295      |\n",
      "|    n_updates            | 63410       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.44\n",
      "SELFPLAY: new best model, bumping up generation to 105\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.31     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1836     |\n",
      "|    time_elapsed    | 13930    |\n",
      "|    total_timesteps | 3760128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 13937       |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032645665 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0166      |\n",
      "|    n_updates            | 63420       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1838        |\n",
      "|    time_elapsed         | 13943       |\n",
      "|    total_timesteps      | 3764224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033786558 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00294     |\n",
      "|    n_updates            | 63430       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1839       |\n",
      "|    time_elapsed         | 13949      |\n",
      "|    total_timesteps      | 3766272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03254954 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.359     |\n",
      "|    explained_variance   | 0.452      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00425    |\n",
      "|    n_updates            | 63440      |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1840        |\n",
      "|    time_elapsed         | 13955       |\n",
      "|    total_timesteps      | 3768320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029548675 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 63450       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3770000, episode_reward=0.17 +/- 0.98\n",
      "Episode length: 30.06 +/- 0.44\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30.1      |\n",
      "|    mean_reward          | 0.17      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3770000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0303825 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.344    |\n",
      "|    explained_variance   | 0.386     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00725   |\n",
      "|    n_updates            | 63460     |\n",
      "|    policy_gradient_loss | -0.0311   |\n",
      "|    value_loss           | 0.157     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1841     |\n",
      "|    time_elapsed    | 13967    |\n",
      "|    total_timesteps | 3770368  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.22      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 269       |\n",
      "|    iterations           | 1842      |\n",
      "|    time_elapsed         | 13975     |\n",
      "|    total_timesteps      | 3772416   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0313915 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.323    |\n",
      "|    explained_variance   | 0.474     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.042     |\n",
      "|    n_updates            | 63470     |\n",
      "|    policy_gradient_loss | -0.0302   |\n",
      "|    value_loss           | 0.187     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1843        |\n",
      "|    time_elapsed         | 13981       |\n",
      "|    total_timesteps      | 3774464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027273908 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0524      |\n",
      "|    n_updates            | 63480       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1844        |\n",
      "|    time_elapsed         | 13987       |\n",
      "|    total_timesteps      | 3776512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029651599 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0396      |\n",
      "|    n_updates            | 63490       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1845        |\n",
      "|    time_elapsed         | 13993       |\n",
      "|    total_timesteps      | 3778560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035584144 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0371      |\n",
      "|    n_updates            | 63500       |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3780000, episode_reward=0.27 +/- 0.94\n",
      "Episode length: 30.06 +/- 0.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3780000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03081236 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.441      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0166     |\n",
      "|    n_updates            | 63510      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.27\n",
      "SELFPLAY: new best model, bumping up generation to 106\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1846     |\n",
      "|    time_elapsed    | 14005    |\n",
      "|    total_timesteps | 3780608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1847        |\n",
      "|    time_elapsed         | 14012       |\n",
      "|    total_timesteps      | 3782656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028494097 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 63520       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 1848        |\n",
      "|    time_elapsed         | 14018       |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023853619 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0264      |\n",
      "|    n_updates            | 63530       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1849       |\n",
      "|    time_elapsed         | 14024      |\n",
      "|    total_timesteps      | 3786752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03468199 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.354     |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0673     |\n",
      "|    n_updates            | 63540      |\n",
      "|    policy_gradient_loss | -0.036     |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1850       |\n",
      "|    time_elapsed         | 14030      |\n",
      "|    total_timesteps      | 3788800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02526402 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.32      |\n",
      "|    explained_variance   | 0.289      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0293     |\n",
      "|    n_updates            | 63550      |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3790000, episode_reward=0.17 +/- 0.97\n",
      "Episode length: 30.02 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3790000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02727249 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.347     |\n",
      "|    explained_variance   | 0.243      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0612     |\n",
      "|    n_updates            | 63560      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.217      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1851     |\n",
      "|    time_elapsed    | 14042    |\n",
      "|    total_timesteps | 3790848  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 1852       |\n",
      "|    time_elapsed         | 14048      |\n",
      "|    total_timesteps      | 3792896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03366291 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.349     |\n",
      "|    explained_variance   | 0.29       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0287     |\n",
      "|    n_updates            | 63570      |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1853        |\n",
      "|    time_elapsed         | 14054       |\n",
      "|    total_timesteps      | 3794944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025095485 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0306      |\n",
      "|    n_updates            | 63580       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1854        |\n",
      "|    time_elapsed         | 14060       |\n",
      "|    total_timesteps      | 3796992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030281864 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0706      |\n",
      "|    n_updates            | 63590       |\n",
      "|    policy_gradient_loss | -0.0352     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1855        |\n",
      "|    time_elapsed         | 14066       |\n",
      "|    total_timesteps      | 3799040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030149357 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00105     |\n",
      "|    n_updates            | 63600       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3800000, episode_reward=0.07 +/- 0.99\n",
      "Episode length: 30.00 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026468392 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.025       |\n",
      "|    n_updates            | 63610       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1856     |\n",
      "|    time_elapsed    | 14077    |\n",
      "|    total_timesteps | 3801088  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1857       |\n",
      "|    time_elapsed         | 14083      |\n",
      "|    total_timesteps      | 3803136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03097329 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0438     |\n",
      "|    n_updates            | 63620      |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1858        |\n",
      "|    time_elapsed         | 14090       |\n",
      "|    total_timesteps      | 3805184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032248475 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0403      |\n",
      "|    n_updates            | 63630       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1859        |\n",
      "|    time_elapsed         | 14096       |\n",
      "|    total_timesteps      | 3807232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029262302 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 63640       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1860        |\n",
      "|    time_elapsed         | 14103       |\n",
      "|    total_timesteps      | 3809280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029623475 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 63650       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3810000, episode_reward=0.38 +/- 0.91\n",
      "Episode length: 30.02 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029059768 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0685      |\n",
      "|    n_updates            | 63660       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.38\n",
      "SELFPLAY: new best model, bumping up generation to 107\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1861     |\n",
      "|    time_elapsed    | 14114    |\n",
      "|    total_timesteps | 3811328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1862        |\n",
      "|    time_elapsed         | 14121       |\n",
      "|    total_timesteps      | 3813376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030320494 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0345      |\n",
      "|    n_updates            | 63670       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1863        |\n",
      "|    time_elapsed         | 14127       |\n",
      "|    total_timesteps      | 3815424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038503416 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0169      |\n",
      "|    n_updates            | 63680       |\n",
      "|    policy_gradient_loss | -0.0345     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1864        |\n",
      "|    time_elapsed         | 14133       |\n",
      "|    total_timesteps      | 3817472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027949538 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 63690       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1865        |\n",
      "|    time_elapsed         | 14139       |\n",
      "|    total_timesteps      | 3819520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030498777 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 63700       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3820000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3820000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03140218 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.349     |\n",
      "|    explained_variance   | 0.201      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0282     |\n",
      "|    n_updates            | 63710      |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.231      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1866     |\n",
      "|    time_elapsed    | 14151    |\n",
      "|    total_timesteps | 3821568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1867        |\n",
      "|    time_elapsed         | 14157       |\n",
      "|    total_timesteps      | 3823616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030985355 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 63720       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1868        |\n",
      "|    time_elapsed         | 14163       |\n",
      "|    total_timesteps      | 3825664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036595546 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 63730       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1869       |\n",
      "|    time_elapsed         | 14169      |\n",
      "|    total_timesteps      | 3827712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02819325 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.353     |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0214     |\n",
      "|    n_updates            | 63740      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1870        |\n",
      "|    time_elapsed         | 14175       |\n",
      "|    total_timesteps      | 3829760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029933162 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0716      |\n",
      "|    n_updates            | 63750       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3830000, episode_reward=0.11 +/- 0.97\n",
      "Episode length: 30.11 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026514968 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0797      |\n",
      "|    n_updates            | 63760       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1871     |\n",
      "|    time_elapsed    | 14187    |\n",
      "|    total_timesteps | 3831808  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1872        |\n",
      "|    time_elapsed         | 14193       |\n",
      "|    total_timesteps      | 3833856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030097865 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.053       |\n",
      "|    n_updates            | 63770       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1873        |\n",
      "|    time_elapsed         | 14199       |\n",
      "|    total_timesteps      | 3835904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029788861 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0552      |\n",
      "|    n_updates            | 63780       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1874        |\n",
      "|    time_elapsed         | 14205       |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029706964 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 63790       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=0.17 +/- 0.98\n",
      "Episode length: 30.04 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028819028 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 63800       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1875     |\n",
      "|    time_elapsed    | 14217    |\n",
      "|    total_timesteps | 3840000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1876        |\n",
      "|    time_elapsed         | 14224       |\n",
      "|    total_timesteps      | 3842048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031289488 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0294      |\n",
      "|    n_updates            | 63810       |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1877        |\n",
      "|    time_elapsed         | 14230       |\n",
      "|    total_timesteps      | 3844096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027927017 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0256      |\n",
      "|    n_updates            | 63820       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.02      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 1878      |\n",
      "|    time_elapsed         | 14237     |\n",
      "|    total_timesteps      | 3846144   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0271059 |\n",
      "|    clip_fraction        | 0.139     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.312    |\n",
      "|    explained_variance   | 0.2       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0635    |\n",
      "|    n_updates            | 63830     |\n",
      "|    policy_gradient_loss | -0.0321   |\n",
      "|    value_loss           | 0.215     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1879        |\n",
      "|    time_elapsed         | 14243       |\n",
      "|    total_timesteps      | 3848192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030127523 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.057       |\n",
      "|    n_updates            | 63840       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3850000, episode_reward=0.02 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023275811 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0612      |\n",
      "|    n_updates            | 63850       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1880     |\n",
      "|    time_elapsed    | 14256    |\n",
      "|    total_timesteps | 3850240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1881        |\n",
      "|    time_elapsed         | 14262       |\n",
      "|    total_timesteps      | 3852288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032091893 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.058       |\n",
      "|    n_updates            | 63860       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1882        |\n",
      "|    time_elapsed         | 14269       |\n",
      "|    total_timesteps      | 3854336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031799577 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0309      |\n",
      "|    n_updates            | 63870       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1883        |\n",
      "|    time_elapsed         | 14275       |\n",
      "|    total_timesteps      | 3856384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026323032 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 63880       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1884       |\n",
      "|    time_elapsed         | 14281      |\n",
      "|    total_timesteps      | 3858432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03454172 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.333     |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0197     |\n",
      "|    n_updates            | 63890      |\n",
      "|    policy_gradient_loss | -0.0337    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3860000, episode_reward=0.00 +/- 0.99\n",
      "Episode length: 29.96 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027675888 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0446      |\n",
      "|    n_updates            | 63900       |\n",
      "|    policy_gradient_loss | -0.0318     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1885     |\n",
      "|    time_elapsed    | 14293    |\n",
      "|    total_timesteps | 3860480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1886        |\n",
      "|    time_elapsed         | 14299       |\n",
      "|    total_timesteps      | 3862528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026739541 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0501      |\n",
      "|    n_updates            | 63910       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1887        |\n",
      "|    time_elapsed         | 14306       |\n",
      "|    total_timesteps      | 3864576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031656057 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 63920       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.28       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1888       |\n",
      "|    time_elapsed         | 14312      |\n",
      "|    total_timesteps      | 3866624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03453891 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.307     |\n",
      "|    explained_variance   | 0.221      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0679     |\n",
      "|    n_updates            | 63930      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1889        |\n",
      "|    time_elapsed         | 14318       |\n",
      "|    total_timesteps      | 3868672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028870396 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0659      |\n",
      "|    n_updates            | 63940       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3870000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.89 +/- 0.55\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 29.9      |\n",
      "|    mean_reward          | 0.06      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3870000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0317453 |\n",
      "|    clip_fraction        | 0.148     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.303    |\n",
      "|    explained_variance   | 0.339     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0158    |\n",
      "|    n_updates            | 63950     |\n",
      "|    policy_gradient_loss | -0.0343   |\n",
      "|    value_loss           | 0.205     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1890     |\n",
      "|    time_elapsed    | 14330    |\n",
      "|    total_timesteps | 3870720  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1891        |\n",
      "|    time_elapsed         | 14337       |\n",
      "|    total_timesteps      | 3872768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032928325 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0427      |\n",
      "|    n_updates            | 63960       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1892       |\n",
      "|    time_elapsed         | 14342      |\n",
      "|    total_timesteps      | 3874816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03111219 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.297     |\n",
      "|    explained_variance   | 0.235      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0626     |\n",
      "|    n_updates            | 63970      |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1893        |\n",
      "|    time_elapsed         | 14348       |\n",
      "|    total_timesteps      | 3876864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029532894 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0557      |\n",
      "|    n_updates            | 63980       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1894        |\n",
      "|    time_elapsed         | 14354       |\n",
      "|    total_timesteps      | 3878912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025873052 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.06        |\n",
      "|    n_updates            | 63990       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3880000, episode_reward=0.24 +/- 0.96\n",
      "Episode length: 30.06 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036556203 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00569    |\n",
      "|    n_updates            | 64000       |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 108\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1895     |\n",
      "|    time_elapsed    | 14365    |\n",
      "|    total_timesteps | 3880960  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1896        |\n",
      "|    time_elapsed         | 14371       |\n",
      "|    total_timesteps      | 3883008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026172223 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 64010       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1897        |\n",
      "|    time_elapsed         | 14377       |\n",
      "|    total_timesteps      | 3885056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033051647 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 64020       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1898        |\n",
      "|    time_elapsed         | 14384       |\n",
      "|    total_timesteps      | 3887104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028412852 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 64030       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1899       |\n",
      "|    time_elapsed         | 14390      |\n",
      "|    total_timesteps      | 3889152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02791982 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.326     |\n",
      "|    explained_variance   | 0.348      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0319     |\n",
      "|    n_updates            | 64040      |\n",
      "|    policy_gradient_loss | -0.034     |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3890000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030498143 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00725     |\n",
      "|    n_updates            | 64050       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1900     |\n",
      "|    time_elapsed    | 14402    |\n",
      "|    total_timesteps | 3891200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1901        |\n",
      "|    time_elapsed         | 14408       |\n",
      "|    total_timesteps      | 3893248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027644303 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 64060       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1902       |\n",
      "|    time_elapsed         | 14414      |\n",
      "|    total_timesteps      | 3895296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03229879 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00322    |\n",
      "|    n_updates            | 64070      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1903        |\n",
      "|    time_elapsed         | 14421       |\n",
      "|    total_timesteps      | 3897344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024019988 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.0958      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0448      |\n",
      "|    n_updates            | 64080       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1904        |\n",
      "|    time_elapsed         | 14427       |\n",
      "|    total_timesteps      | 3899392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031217996 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 64090       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3900000, episode_reward=0.31 +/- 0.93\n",
      "Episode length: 30.02 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024388589 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00875     |\n",
      "|    n_updates            | 64100       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.31\n",
      "SELFPLAY: new best model, bumping up generation to 109\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1905     |\n",
      "|    time_elapsed    | 14440    |\n",
      "|    total_timesteps | 3901440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1906        |\n",
      "|    time_elapsed         | 14447       |\n",
      "|    total_timesteps      | 3903488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035335608 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 64110       |\n",
      "|    policy_gradient_loss | -0.034      |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.18      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1907       |\n",
      "|    time_elapsed         | 14453      |\n",
      "|    total_timesteps      | 3905536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02693167 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.327     |\n",
      "|    explained_variance   | 0.317      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0429     |\n",
      "|    n_updates            | 64120      |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1908        |\n",
      "|    time_elapsed         | 14459       |\n",
      "|    total_timesteps      | 3907584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029829614 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 64130       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 14465       |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027936667 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0103      |\n",
      "|    n_updates            | 64140       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3910000, episode_reward=0.05 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028245755 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 64150       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1910     |\n",
      "|    time_elapsed    | 14477    |\n",
      "|    total_timesteps | 3911680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1911        |\n",
      "|    time_elapsed         | 14482       |\n",
      "|    total_timesteps      | 3913728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028427768 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0445      |\n",
      "|    n_updates            | 64160       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1912       |\n",
      "|    time_elapsed         | 14488      |\n",
      "|    total_timesteps      | 3915776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02703738 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.382      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00949    |\n",
      "|    n_updates            | 64170      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1913        |\n",
      "|    time_elapsed         | 14494       |\n",
      "|    total_timesteps      | 3917824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029966203 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0465      |\n",
      "|    n_updates            | 64180       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1914        |\n",
      "|    time_elapsed         | 14500       |\n",
      "|    total_timesteps      | 3919872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030774098 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 64190       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3920000, episode_reward=0.19 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3920000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02799248 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.235      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0374     |\n",
      "|    n_updates            | 64200      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1915     |\n",
      "|    time_elapsed    | 14512    |\n",
      "|    total_timesteps | 3921920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1916        |\n",
      "|    time_elapsed         | 14518       |\n",
      "|    total_timesteps      | 3923968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026778525 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0355      |\n",
      "|    n_updates            | 64210       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1917        |\n",
      "|    time_elapsed         | 14524       |\n",
      "|    total_timesteps      | 3926016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025664955 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00846     |\n",
      "|    n_updates            | 64220       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.08      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1918       |\n",
      "|    time_elapsed         | 14531      |\n",
      "|    total_timesteps      | 3928064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03463937 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0275     |\n",
      "|    n_updates            | 64230      |\n",
      "|    policy_gradient_loss | -0.0329    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3930000, episode_reward=0.00 +/- 0.97\n",
      "Episode length: 29.99 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027302783 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0262      |\n",
      "|    n_updates            | 64240       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1919     |\n",
      "|    time_elapsed    | 14543    |\n",
      "|    total_timesteps | 3930112  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1920        |\n",
      "|    time_elapsed         | 14549       |\n",
      "|    total_timesteps      | 3932160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034076326 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0228      |\n",
      "|    n_updates            | 64250       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1921        |\n",
      "|    time_elapsed         | 14556       |\n",
      "|    total_timesteps      | 3934208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027408343 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0336      |\n",
      "|    n_updates            | 64260       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1922        |\n",
      "|    time_elapsed         | 14562       |\n",
      "|    total_timesteps      | 3936256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028587168 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 64270       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1923        |\n",
      "|    time_elapsed         | 14568       |\n",
      "|    total_timesteps      | 3938304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026778255 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 64280       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3940000, episode_reward=0.04 +/- 0.98\n",
      "Episode length: 29.81 +/- 1.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028595433 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0209      |\n",
      "|    n_updates            | 64290       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1924     |\n",
      "|    time_elapsed    | 14580    |\n",
      "|    total_timesteps | 3940352  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1925        |\n",
      "|    time_elapsed         | 14587       |\n",
      "|    total_timesteps      | 3942400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026523031 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0321      |\n",
      "|    n_updates            | 64300       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1926        |\n",
      "|    time_elapsed         | 14593       |\n",
      "|    total_timesteps      | 3944448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028816536 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0421      |\n",
      "|    n_updates            | 64310       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1927       |\n",
      "|    time_elapsed         | 14599      |\n",
      "|    total_timesteps      | 3946496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02940478 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.271     |\n",
      "|    explained_variance   | 0.235      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0652     |\n",
      "|    n_updates            | 64320      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.16      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 1928      |\n",
      "|    time_elapsed         | 14606     |\n",
      "|    total_timesteps      | 3948544   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0337295 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.275    |\n",
      "|    explained_variance   | 0.287     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0351    |\n",
      "|    n_updates            | 64330     |\n",
      "|    policy_gradient_loss | -0.0321   |\n",
      "|    value_loss           | 0.223     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3950000, episode_reward=0.32 +/- 0.94\n",
      "Episode length: 29.98 +/- 0.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.32       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3950000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03454276 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.285     |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0417     |\n",
      "|    n_updates            | 64340      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.174      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.32\n",
      "SELFPLAY: new best model, bumping up generation to 110\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1929     |\n",
      "|    time_elapsed    | 14618    |\n",
      "|    total_timesteps | 3950592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1930        |\n",
      "|    time_elapsed         | 14625       |\n",
      "|    total_timesteps      | 3952640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029746663 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 64350       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1931        |\n",
      "|    time_elapsed         | 14632       |\n",
      "|    total_timesteps      | 3954688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026697658 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0662      |\n",
      "|    n_updates            | 64360       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.11      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1932       |\n",
      "|    time_elapsed         | 14639      |\n",
      "|    total_timesteps      | 3956736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03183456 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.324     |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.047      |\n",
      "|    n_updates            | 64370      |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1933        |\n",
      "|    time_elapsed         | 14645       |\n",
      "|    total_timesteps      | 3958784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032895457 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0736      |\n",
      "|    n_updates            | 64380       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3960000, episode_reward=0.01 +/- 0.98\n",
      "Episode length: 29.94 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039885998 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 64390       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1934     |\n",
      "|    time_elapsed    | 14657    |\n",
      "|    total_timesteps | 3960832  |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 30       |\n",
      "|    ep_rew_mean          | 0.08     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 270      |\n",
      "|    iterations           | 1935     |\n",
      "|    time_elapsed         | 14664    |\n",
      "|    total_timesteps      | 3962880  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.030051 |\n",
      "|    clip_fraction        | 0.167    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.347   |\n",
      "|    explained_variance   | 0.383    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0512   |\n",
      "|    n_updates            | 64400    |\n",
      "|    policy_gradient_loss | -0.0352  |\n",
      "|    value_loss           | 0.199    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1936        |\n",
      "|    time_elapsed         | 14670       |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030114202 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.355      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00823     |\n",
      "|    n_updates            | 64410       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.19      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 1937      |\n",
      "|    time_elapsed         | 14677     |\n",
      "|    total_timesteps      | 3966976   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0363106 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.344    |\n",
      "|    explained_variance   | 0.304     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.03      |\n",
      "|    n_updates            | 64420     |\n",
      "|    policy_gradient_loss | -0.033    |\n",
      "|    value_loss           | 0.223     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1938        |\n",
      "|    time_elapsed         | 14683       |\n",
      "|    total_timesteps      | 3969024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031353623 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0346      |\n",
      "|    n_updates            | 64430       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3970000, episode_reward=-0.10 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027597355 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 64440       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1939     |\n",
      "|    time_elapsed    | 14696    |\n",
      "|    total_timesteps | 3971072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1940        |\n",
      "|    time_elapsed         | 14703       |\n",
      "|    total_timesteps      | 3973120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034492515 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0314      |\n",
      "|    n_updates            | 64450       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1941        |\n",
      "|    time_elapsed         | 14709       |\n",
      "|    total_timesteps      | 3975168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033502974 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0163      |\n",
      "|    n_updates            | 64460       |\n",
      "|    policy_gradient_loss | -0.0338     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1942        |\n",
      "|    time_elapsed         | 14716       |\n",
      "|    total_timesteps      | 3977216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028449953 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 64470       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1943       |\n",
      "|    time_elapsed         | 14722      |\n",
      "|    total_timesteps      | 3979264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03290925 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.322     |\n",
      "|    explained_variance   | 0.408      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0099     |\n",
      "|    n_updates            | 64480      |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.168      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3980000, episode_reward=-0.08 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | -0.08      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3980000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03593512 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.306     |\n",
      "|    explained_variance   | 0.393      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0191    |\n",
      "|    n_updates            | 64490      |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.166      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1944     |\n",
      "|    time_elapsed    | 14734    |\n",
      "|    total_timesteps | 3981312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1945        |\n",
      "|    time_elapsed         | 14741       |\n",
      "|    total_timesteps      | 3983360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028430453 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0557      |\n",
      "|    n_updates            | 64500       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1946        |\n",
      "|    time_elapsed         | 14748       |\n",
      "|    total_timesteps      | 3985408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025192384 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00132    |\n",
      "|    n_updates            | 64510       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1947        |\n",
      "|    time_elapsed         | 14754       |\n",
      "|    total_timesteps      | 3987456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023815513 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 64520       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1948        |\n",
      "|    time_elapsed         | 14760       |\n",
      "|    total_timesteps      | 3989504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028221851 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00668     |\n",
      "|    n_updates            | 64530       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3990000, episode_reward=0.36 +/- 0.91\n",
      "Episode length: 29.71 +/- 2.06\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 29.7      |\n",
      "|    mean_reward          | 0.36      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3990000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0336759 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.27     |\n",
      "|    explained_variance   | 0.469     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0374    |\n",
      "|    n_updates            | 64540     |\n",
      "|    policy_gradient_loss | -0.0319   |\n",
      "|    value_loss           | 0.152     |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.36\n",
      "SELFPLAY: new best model, bumping up generation to 111\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1949     |\n",
      "|    time_elapsed    | 14772    |\n",
      "|    total_timesteps | 3991552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1950        |\n",
      "|    time_elapsed         | 14779       |\n",
      "|    total_timesteps      | 3993600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031640977 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0433      |\n",
      "|    n_updates            | 64550       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.08      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1951       |\n",
      "|    time_elapsed         | 14785      |\n",
      "|    total_timesteps      | 3995648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03336496 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.329     |\n",
      "|    explained_variance   | 0.259      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0587     |\n",
      "|    n_updates            | 64560      |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.11      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1952       |\n",
      "|    time_elapsed         | 14791      |\n",
      "|    total_timesteps      | 3997696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03526178 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.336     |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0781     |\n",
      "|    n_updates            | 64570      |\n",
      "|    policy_gradient_loss | -0.0322    |\n",
      "|    value_loss           | 0.222      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1953        |\n",
      "|    time_elapsed         | 14797       |\n",
      "|    total_timesteps      | 3999744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031902626 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 64580       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=-0.07 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.41\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30        |\n",
      "|    mean_reward          | -0.07     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4000000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0265488 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.298    |\n",
      "|    explained_variance   | 0.336     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0353    |\n",
      "|    n_updates            | 64590     |\n",
      "|    policy_gradient_loss | -0.031    |\n",
      "|    value_loss           | 0.198     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1954     |\n",
      "|    time_elapsed    | 14809    |\n",
      "|    total_timesteps | 4001792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1955        |\n",
      "|    time_elapsed         | 14816       |\n",
      "|    total_timesteps      | 4003840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030399347 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 64600       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1956       |\n",
      "|    time_elapsed         | 14822      |\n",
      "|    total_timesteps      | 4005888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03666149 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.338      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00177    |\n",
      "|    n_updates            | 64610      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 14829       |\n",
      "|    total_timesteps      | 4007936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032400474 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.062       |\n",
      "|    n_updates            | 64620       |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1958        |\n",
      "|    time_elapsed         | 14835       |\n",
      "|    total_timesteps      | 4009984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025043454 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0464      |\n",
      "|    n_updates            | 64630       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4010000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028655954 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0572      |\n",
      "|    n_updates            | 64640       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1959     |\n",
      "|    time_elapsed    | 14847    |\n",
      "|    total_timesteps | 4012032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1960        |\n",
      "|    time_elapsed         | 14854       |\n",
      "|    total_timesteps      | 4014080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029747074 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 64650       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1961        |\n",
      "|    time_elapsed         | 14860       |\n",
      "|    total_timesteps      | 4016128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027653724 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0209      |\n",
      "|    n_updates            | 64660       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1962        |\n",
      "|    time_elapsed         | 14866       |\n",
      "|    total_timesteps      | 4018176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027591567 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 64670       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4020000, episode_reward=0.17 +/- 0.98\n",
      "Episode length: 29.91 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4020000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02530261 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.298     |\n",
      "|    explained_variance   | 0.223      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0585     |\n",
      "|    n_updates            | 64680      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.227      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1963     |\n",
      "|    time_elapsed    | 14878    |\n",
      "|    total_timesteps | 4020224  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1964        |\n",
      "|    time_elapsed         | 14885       |\n",
      "|    total_timesteps      | 4022272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033798568 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 64690       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1965        |\n",
      "|    time_elapsed         | 14892       |\n",
      "|    total_timesteps      | 4024320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028933076 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0143      |\n",
      "|    n_updates            | 64700       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1966        |\n",
      "|    time_elapsed         | 14898       |\n",
      "|    total_timesteps      | 4026368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031411186 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 64710       |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 14905       |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034045286 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0617      |\n",
      "|    n_updates            | 64720       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4030000, episode_reward=0.11 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029770125 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 64730       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1968     |\n",
      "|    time_elapsed    | 14917    |\n",
      "|    total_timesteps | 4030464  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1969       |\n",
      "|    time_elapsed         | 14924      |\n",
      "|    total_timesteps      | 4032512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03248862 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0359     |\n",
      "|    n_updates            | 64740      |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1970        |\n",
      "|    time_elapsed         | 14930       |\n",
      "|    total_timesteps      | 4034560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029040646 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00623     |\n",
      "|    n_updates            | 64750       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1971        |\n",
      "|    time_elapsed         | 14937       |\n",
      "|    total_timesteps      | 4036608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028473768 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0235      |\n",
      "|    n_updates            | 64760       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1972       |\n",
      "|    time_elapsed         | 14943      |\n",
      "|    total_timesteps      | 4038656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03392888 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.281     |\n",
      "|    explained_variance   | 0.32       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0238     |\n",
      "|    n_updates            | 64770      |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4040000, episode_reward=0.03 +/- 0.98\n",
      "Episode length: 30.02 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032278154 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0579      |\n",
      "|    n_updates            | 64780       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1973     |\n",
      "|    time_elapsed    | 14955    |\n",
      "|    total_timesteps | 4040704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 14962       |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034682184 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0212      |\n",
      "|    n_updates            | 64790       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1975        |\n",
      "|    time_elapsed         | 14968       |\n",
      "|    total_timesteps      | 4044800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028980417 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.023       |\n",
      "|    n_updates            | 64800       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1976        |\n",
      "|    time_elapsed         | 14974       |\n",
      "|    total_timesteps      | 4046848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027245197 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0332      |\n",
      "|    n_updates            | 64810       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1977        |\n",
      "|    time_elapsed         | 14981       |\n",
      "|    total_timesteps      | 4048896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027232438 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 64820       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4050000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 30.00 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026371853 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0193      |\n",
      "|    n_updates            | 64830       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 112\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1978     |\n",
      "|    time_elapsed    | 14993    |\n",
      "|    total_timesteps | 4050944  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1979        |\n",
      "|    time_elapsed         | 14999       |\n",
      "|    total_timesteps      | 4052992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030565802 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 64840       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1980        |\n",
      "|    time_elapsed         | 15005       |\n",
      "|    total_timesteps      | 4055040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026866801 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0212      |\n",
      "|    n_updates            | 64850       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1981        |\n",
      "|    time_elapsed         | 15011       |\n",
      "|    total_timesteps      | 4057088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024293728 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0184      |\n",
      "|    n_updates            | 64860       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.02      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 1982      |\n",
      "|    time_elapsed         | 15017     |\n",
      "|    total_timesteps      | 4059136   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0278728 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.297    |\n",
      "|    explained_variance   | 0.239     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0346    |\n",
      "|    n_updates            | 64870     |\n",
      "|    policy_gradient_loss | -0.0299   |\n",
      "|    value_loss           | 0.214     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4060000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 29.98 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031915627 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00796     |\n",
      "|    n_updates            | 64880       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 113\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1983     |\n",
      "|    time_elapsed    | 15030    |\n",
      "|    total_timesteps | 4061184  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1984       |\n",
      "|    time_elapsed         | 15036      |\n",
      "|    total_timesteps      | 4063232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03152132 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.328      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0309     |\n",
      "|    n_updates            | 64890      |\n",
      "|    policy_gradient_loss | -0.0288    |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.11      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1985       |\n",
      "|    time_elapsed         | 15043      |\n",
      "|    total_timesteps      | 4065280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03407235 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.012      |\n",
      "|    n_updates            | 64900      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.197      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1986        |\n",
      "|    time_elapsed         | 15049       |\n",
      "|    total_timesteps      | 4067328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028909875 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00543    |\n",
      "|    n_updates            | 64910       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1987        |\n",
      "|    time_elapsed         | 15056       |\n",
      "|    total_timesteps      | 4069376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024506275 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0371      |\n",
      "|    n_updates            | 64920       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4070000, episode_reward=0.02 +/- 0.96\n",
      "Episode length: 29.93 +/- 0.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4070000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03185998 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.293     |\n",
      "|    explained_variance   | 0.422      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0307     |\n",
      "|    n_updates            | 64930      |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    value_loss           | 0.161      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 1988     |\n",
      "|    time_elapsed    | 15069    |\n",
      "|    total_timesteps | 4071424  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1989        |\n",
      "|    time_elapsed         | 15075       |\n",
      "|    total_timesteps      | 4073472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028877199 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0463      |\n",
      "|    n_updates            | 64940       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1990        |\n",
      "|    time_elapsed         | 15082       |\n",
      "|    total_timesteps      | 4075520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025370855 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 64950       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1991        |\n",
      "|    time_elapsed         | 15095       |\n",
      "|    total_timesteps      | 4077568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031459734 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0855      |\n",
      "|    n_updates            | 64960       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1992        |\n",
      "|    time_elapsed         | 15104       |\n",
      "|    total_timesteps      | 4079616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025222115 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 64970       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4080000, episode_reward=0.26 +/- 0.96\n",
      "Episode length: 29.98 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027858669 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0634      |\n",
      "|    n_updates            | 64980       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 114\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1993     |\n",
      "|    time_elapsed    | 15117    |\n",
      "|    total_timesteps | 4081664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1994        |\n",
      "|    time_elapsed         | 15124       |\n",
      "|    total_timesteps      | 4083712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027686756 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0214      |\n",
      "|    n_updates            | 64990       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 1995       |\n",
      "|    time_elapsed         | 15131      |\n",
      "|    total_timesteps      | 4085760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03138815 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.288     |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0467     |\n",
      "|    n_updates            | 65000      |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1996        |\n",
      "|    time_elapsed         | 15137       |\n",
      "|    total_timesteps      | 4087808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025476133 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.063       |\n",
      "|    n_updates            | 65010       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1997        |\n",
      "|    time_elapsed         | 15143       |\n",
      "|    total_timesteps      | 4089856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030538986 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 65020       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4090000, episode_reward=0.19 +/- 0.95\n",
      "Episode length: 29.97 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028545082 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0614      |\n",
      "|    n_updates            | 65030       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.37     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 1998     |\n",
      "|    time_elapsed    | 15156    |\n",
      "|    total_timesteps | 4091904  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 1999        |\n",
      "|    time_elapsed         | 15162       |\n",
      "|    total_timesteps      | 4093952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022629596 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0297      |\n",
      "|    n_updates            | 65040       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.15      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 2000      |\n",
      "|    time_elapsed         | 15168     |\n",
      "|    total_timesteps      | 4096000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0280657 |\n",
      "|    clip_fraction        | 0.135     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.292    |\n",
      "|    explained_variance   | 0.409     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0334    |\n",
      "|    n_updates            | 65050     |\n",
      "|    policy_gradient_loss | -0.0277   |\n",
      "|    value_loss           | 0.19      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2001       |\n",
      "|    time_elapsed         | 15176      |\n",
      "|    total_timesteps      | 4098048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02518506 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.279     |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0424     |\n",
      "|    n_updates            | 65060      |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4100000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 30.03 +/- 0.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031675335 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0555      |\n",
      "|    n_updates            | 65070       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 115\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 2002     |\n",
      "|    time_elapsed    | 15188    |\n",
      "|    total_timesteps | 4100096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2003        |\n",
      "|    time_elapsed         | 15195       |\n",
      "|    total_timesteps      | 4102144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027078293 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 65080       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2004        |\n",
      "|    time_elapsed         | 15201       |\n",
      "|    total_timesteps      | 4104192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036312595 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.038       |\n",
      "|    n_updates            | 65090       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2005        |\n",
      "|    time_elapsed         | 15206       |\n",
      "|    total_timesteps      | 4106240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034136932 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0346      |\n",
      "|    n_updates            | 65100       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2006       |\n",
      "|    time_elapsed         | 15212      |\n",
      "|    total_timesteps      | 4108288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02749978 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.367      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0494     |\n",
      "|    n_updates            | 65110      |\n",
      "|    policy_gradient_loss | -0.0267    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4110000, episode_reward=0.26 +/- 0.94\n",
      "Episode length: 29.97 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031650085 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 65120       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 116\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 269      |\n",
      "|    iterations      | 2007     |\n",
      "|    time_elapsed    | 15223    |\n",
      "|    total_timesteps | 4110336  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2008        |\n",
      "|    time_elapsed         | 15229       |\n",
      "|    total_timesteps      | 4112384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033939015 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.046       |\n",
      "|    n_updates            | 65130       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2009        |\n",
      "|    time_elapsed         | 15235       |\n",
      "|    total_timesteps      | 4114432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029715689 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 65140       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2010        |\n",
      "|    time_elapsed         | 15241       |\n",
      "|    total_timesteps      | 4116480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030332305 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00136    |\n",
      "|    n_updates            | 65150       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2011        |\n",
      "|    time_elapsed         | 15247       |\n",
      "|    total_timesteps      | 4118528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030142851 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 65160       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4120000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.44\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4120000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03476131 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.286     |\n",
      "|    explained_variance   | 0.503      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0189     |\n",
      "|    n_updates            | 65170      |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 0.165      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2012     |\n",
      "|    time_elapsed    | 15258    |\n",
      "|    total_timesteps | 4120576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2013        |\n",
      "|    time_elapsed         | 15263       |\n",
      "|    total_timesteps      | 4122624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030934677 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0492      |\n",
      "|    n_updates            | 65180       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2014        |\n",
      "|    time_elapsed         | 15269       |\n",
      "|    total_timesteps      | 4124672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028021814 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 65190       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2015        |\n",
      "|    time_elapsed         | 15275       |\n",
      "|    total_timesteps      | 4126720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032539126 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.077       |\n",
      "|    n_updates            | 65200       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2016        |\n",
      "|    time_elapsed         | 15280       |\n",
      "|    total_timesteps      | 4128768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027924445 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 65210       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4130000, episode_reward=0.32 +/- 0.94\n",
      "Episode length: 29.96 +/- 0.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.32       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4130000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02742166 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.265     |\n",
      "|    explained_variance   | 0.245      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.072      |\n",
      "|    n_updates            | 65220      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.32\n",
      "SELFPLAY: new best model, bumping up generation to 117\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2017     |\n",
      "|    time_elapsed    | 15292    |\n",
      "|    total_timesteps | 4130816  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2018       |\n",
      "|    time_elapsed         | 15297      |\n",
      "|    total_timesteps      | 4132864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03188516 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.27      |\n",
      "|    explained_variance   | 0.263      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0428     |\n",
      "|    n_updates            | 65230      |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2019       |\n",
      "|    time_elapsed         | 15303      |\n",
      "|    total_timesteps      | 4134912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03549707 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.307      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0483     |\n",
      "|    n_updates            | 65240      |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2020        |\n",
      "|    time_elapsed         | 15308       |\n",
      "|    total_timesteps      | 4136960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026495248 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 65250       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2021        |\n",
      "|    time_elapsed         | 15314       |\n",
      "|    total_timesteps      | 4139008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029904332 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0473      |\n",
      "|    n_updates            | 65260       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.235       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4140000, episode_reward=-0.08 +/- 0.99\n",
      "Episode length: 29.97 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031202424 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0365      |\n",
      "|    n_updates            | 65270       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2022     |\n",
      "|    time_elapsed    | 15325    |\n",
      "|    total_timesteps | 4141056  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2023        |\n",
      "|    time_elapsed         | 15331       |\n",
      "|    total_timesteps      | 4143104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022789873 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 65280       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2024        |\n",
      "|    time_elapsed         | 15337       |\n",
      "|    total_timesteps      | 4145152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034083188 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0228      |\n",
      "|    n_updates            | 65290       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2025        |\n",
      "|    time_elapsed         | 15344       |\n",
      "|    total_timesteps      | 4147200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032314256 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.063       |\n",
      "|    n_updates            | 65300       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2026        |\n",
      "|    time_elapsed         | 15350       |\n",
      "|    total_timesteps      | 4149248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024288215 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0395      |\n",
      "|    n_updates            | 65310       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4150000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025973774 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0289      |\n",
      "|    n_updates            | 65320       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2027     |\n",
      "|    time_elapsed    | 15363    |\n",
      "|    total_timesteps | 4151296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2028        |\n",
      "|    time_elapsed         | 15370       |\n",
      "|    total_timesteps      | 4153344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034401502 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0204      |\n",
      "|    n_updates            | 65330       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2029        |\n",
      "|    time_elapsed         | 15376       |\n",
      "|    total_timesteps      | 4155392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023076136 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0678      |\n",
      "|    n_updates            | 65340       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2030        |\n",
      "|    time_elapsed         | 15382       |\n",
      "|    total_timesteps      | 4157440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024616696 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0705      |\n",
      "|    n_updates            | 65350       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2031        |\n",
      "|    time_elapsed         | 15388       |\n",
      "|    total_timesteps      | 4159488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026684374 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0391      |\n",
      "|    n_updates            | 65360       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4160000, episode_reward=0.04 +/- 0.98\n",
      "Episode length: 29.86 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029813573 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 65370       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2032     |\n",
      "|    time_elapsed    | 15399    |\n",
      "|    total_timesteps | 4161536  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2033        |\n",
      "|    time_elapsed         | 15406       |\n",
      "|    total_timesteps      | 4163584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028756808 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 65380       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2034        |\n",
      "|    time_elapsed         | 15416       |\n",
      "|    total_timesteps      | 4165632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030112159 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 65390       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2035        |\n",
      "|    time_elapsed         | 15422       |\n",
      "|    total_timesteps      | 4167680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034601167 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0445      |\n",
      "|    n_updates            | 65400       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2036        |\n",
      "|    time_elapsed         | 15428       |\n",
      "|    total_timesteps      | 4169728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031639308 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0474      |\n",
      "|    n_updates            | 65410       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4170000, episode_reward=0.31 +/- 0.95\n",
      "Episode length: 30.02 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.31       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4170000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02582494 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.285     |\n",
      "|    explained_variance   | 0.303      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0561     |\n",
      "|    n_updates            | 65420      |\n",
      "|    policy_gradient_loss | -0.0306    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.31\n",
      "SELFPLAY: new best model, bumping up generation to 118\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2037     |\n",
      "|    time_elapsed    | 15441    |\n",
      "|    total_timesteps | 4171776  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2038        |\n",
      "|    time_elapsed         | 15446       |\n",
      "|    total_timesteps      | 4173824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037324145 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 65430       |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2039        |\n",
      "|    time_elapsed         | 15453       |\n",
      "|    total_timesteps      | 4175872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030541489 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.35       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0107      |\n",
      "|    n_updates            | 65440       |\n",
      "|    policy_gradient_loss | -0.035      |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2040        |\n",
      "|    time_elapsed         | 15459       |\n",
      "|    total_timesteps      | 4177920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029375564 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0331      |\n",
      "|    n_updates            | 65450       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2041        |\n",
      "|    time_elapsed         | 15467       |\n",
      "|    total_timesteps      | 4179968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031441722 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 65460       |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4180000, episode_reward=0.09 +/- 0.97\n",
      "Episode length: 30.02 +/- 0.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4180000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02806539 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.242      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00361    |\n",
      "|    n_updates            | 65470      |\n",
      "|    policy_gradient_loss | -0.0337    |\n",
      "|    value_loss           | 0.225      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2042     |\n",
      "|    time_elapsed    | 15480    |\n",
      "|    total_timesteps | 4182016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2043        |\n",
      "|    time_elapsed         | 15486       |\n",
      "|    total_timesteps      | 4184064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026997237 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.048       |\n",
      "|    n_updates            | 65480       |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2044       |\n",
      "|    time_elapsed         | 15492      |\n",
      "|    total_timesteps      | 4186112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02899282 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.264      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0599     |\n",
      "|    n_updates            | 65490      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.29       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2045       |\n",
      "|    time_elapsed         | 15498      |\n",
      "|    total_timesteps      | 4188160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03650766 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.298     |\n",
      "|    explained_variance   | 0.432      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0371     |\n",
      "|    n_updates            | 65500      |\n",
      "|    policy_gradient_loss | -0.0323    |\n",
      "|    value_loss           | 0.165      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4190000, episode_reward=0.33 +/- 0.93\n",
      "Episode length: 30.01 +/- 0.44\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.33       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4190000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03091326 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0238     |\n",
      "|    n_updates            | 65510      |\n",
      "|    policy_gradient_loss | -0.0325    |\n",
      "|    value_loss           | 0.167      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.33\n",
      "SELFPLAY: new best model, bumping up generation to 119\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2046     |\n",
      "|    time_elapsed    | 15511    |\n",
      "|    total_timesteps | 4190208  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2047        |\n",
      "|    time_elapsed         | 15518       |\n",
      "|    total_timesteps      | 4192256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031026343 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0769      |\n",
      "|    n_updates            | 65520       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2048        |\n",
      "|    time_elapsed         | 15524       |\n",
      "|    total_timesteps      | 4194304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035273015 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0139      |\n",
      "|    n_updates            | 65530       |\n",
      "|    policy_gradient_loss | -0.0355     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2049       |\n",
      "|    time_elapsed         | 15530      |\n",
      "|    total_timesteps      | 4196352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03618609 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.316     |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0228     |\n",
      "|    n_updates            | 65540      |\n",
      "|    policy_gradient_loss | -0.0336    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2050        |\n",
      "|    time_elapsed         | 15536       |\n",
      "|    total_timesteps      | 4198400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031002767 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0187      |\n",
      "|    n_updates            | 65550       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4200000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 30.05 +/- 0.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4200000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03550557 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00234    |\n",
      "|    n_updates            | 65560      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 120\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2051     |\n",
      "|    time_elapsed    | 15547    |\n",
      "|    total_timesteps | 4200448  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.03      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 2052      |\n",
      "|    time_elapsed         | 15553     |\n",
      "|    total_timesteps      | 4202496   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0258051 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.306    |\n",
      "|    explained_variance   | 0.242     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00645  |\n",
      "|    n_updates            | 65570     |\n",
      "|    policy_gradient_loss | -0.0308   |\n",
      "|    value_loss           | 0.197     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2053        |\n",
      "|    time_elapsed         | 15561       |\n",
      "|    total_timesteps      | 4204544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036570817 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 65580       |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2054        |\n",
      "|    time_elapsed         | 15567       |\n",
      "|    total_timesteps      | 4206592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030186448 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 65590       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2055       |\n",
      "|    time_elapsed         | 15574      |\n",
      "|    total_timesteps      | 4208640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03342679 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.348     |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0364     |\n",
      "|    n_updates            | 65600      |\n",
      "|    policy_gradient_loss | -0.0358    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4210000, episode_reward=0.20 +/- 0.96\n",
      "Episode length: 30.05 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033518843 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0154      |\n",
      "|    n_updates            | 65610       |\n",
      "|    policy_gradient_loss | -0.0346     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2056     |\n",
      "|    time_elapsed    | 15585    |\n",
      "|    total_timesteps | 4210688  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2057        |\n",
      "|    time_elapsed         | 15615       |\n",
      "|    total_timesteps      | 4212736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036221664 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0478      |\n",
      "|    n_updates            | 65620       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2058        |\n",
      "|    time_elapsed         | 15643       |\n",
      "|    total_timesteps      | 4214784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028439129 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 65630       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2059        |\n",
      "|    time_elapsed         | 15673       |\n",
      "|    total_timesteps      | 4216832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030908287 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0523      |\n",
      "|    n_updates            | 65640       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2060        |\n",
      "|    time_elapsed         | 15704       |\n",
      "|    total_timesteps      | 4218880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027765572 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0748      |\n",
      "|    n_updates            | 65650       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4220000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 30.04 +/- 0.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040547445 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.043       |\n",
      "|    n_updates            | 65660       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2061     |\n",
      "|    time_elapsed    | 15737    |\n",
      "|    total_timesteps | 4220928  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2062        |\n",
      "|    time_elapsed         | 15744       |\n",
      "|    total_timesteps      | 4222976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027540196 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0367      |\n",
      "|    n_updates            | 65670       |\n",
      "|    policy_gradient_loss | -0.0334     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2063        |\n",
      "|    time_elapsed         | 15750       |\n",
      "|    total_timesteps      | 4225024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034818776 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 65680       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2064        |\n",
      "|    time_elapsed         | 15756       |\n",
      "|    total_timesteps      | 4227072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032962993 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0139      |\n",
      "|    n_updates            | 65690       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2065        |\n",
      "|    time_elapsed         | 15763       |\n",
      "|    total_timesteps      | 4229120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029855516 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00529     |\n",
      "|    n_updates            | 65700       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4230000, episode_reward=0.10 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030136589 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0461      |\n",
      "|    n_updates            | 65710       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2066     |\n",
      "|    time_elapsed    | 15775    |\n",
      "|    total_timesteps | 4231168  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2067       |\n",
      "|    time_elapsed         | 15782      |\n",
      "|    total_timesteps      | 4233216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02866663 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.312     |\n",
      "|    explained_variance   | 0.199      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0612     |\n",
      "|    n_updates            | 65720      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.229      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2068        |\n",
      "|    time_elapsed         | 15789       |\n",
      "|    total_timesteps      | 4235264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030991513 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0494      |\n",
      "|    n_updates            | 65730       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2069        |\n",
      "|    time_elapsed         | 15795       |\n",
      "|    total_timesteps      | 4237312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026544688 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0381      |\n",
      "|    n_updates            | 65740       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2070        |\n",
      "|    time_elapsed         | 15802       |\n",
      "|    total_timesteps      | 4239360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027729778 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0455      |\n",
      "|    n_updates            | 65750       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4240000, episode_reward=0.13 +/- 0.96\n",
      "Episode length: 29.90 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030610967 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0332      |\n",
      "|    n_updates            | 65760       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2071     |\n",
      "|    time_elapsed    | 15816    |\n",
      "|    total_timesteps | 4241408  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2072        |\n",
      "|    time_elapsed         | 15822       |\n",
      "|    total_timesteps      | 4243456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028824184 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00487     |\n",
      "|    n_updates            | 65770       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2073       |\n",
      "|    time_elapsed         | 15828      |\n",
      "|    total_timesteps      | 4245504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02527181 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0574     |\n",
      "|    n_updates            | 65780      |\n",
      "|    policy_gradient_loss | -0.0321    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2074       |\n",
      "|    time_elapsed         | 15835      |\n",
      "|    total_timesteps      | 4247552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03253992 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0102     |\n",
      "|    n_updates            | 65790      |\n",
      "|    policy_gradient_loss | -0.0355    |\n",
      "|    value_loss           | 0.167      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2075       |\n",
      "|    time_elapsed         | 15842      |\n",
      "|    total_timesteps      | 4249600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02429815 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.312     |\n",
      "|    explained_variance   | 0.39       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0294     |\n",
      "|    n_updates            | 65800      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4250000, episode_reward=0.03 +/- 0.99\n",
      "Episode length: 29.93 +/- 0.55\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4250000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02979394 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.318     |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00463    |\n",
      "|    n_updates            | 65810      |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2076     |\n",
      "|    time_elapsed    | 15854    |\n",
      "|    total_timesteps | 4251648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2077        |\n",
      "|    time_elapsed         | 15861       |\n",
      "|    total_timesteps      | 4253696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026440889 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.011       |\n",
      "|    n_updates            | 65820       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2078       |\n",
      "|    time_elapsed         | 15868      |\n",
      "|    total_timesteps      | 4255744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03229024 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.317     |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0321     |\n",
      "|    n_updates            | 65830      |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2079        |\n",
      "|    time_elapsed         | 15875       |\n",
      "|    total_timesteps      | 4257792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027297229 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00356    |\n",
      "|    n_updates            | 65840       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2080        |\n",
      "|    time_elapsed         | 15881       |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025412902 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0489      |\n",
      "|    n_updates            | 65850       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4260000, episode_reward=0.15 +/- 0.98\n",
      "Episode length: 29.90 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031813655 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 65860       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2081     |\n",
      "|    time_elapsed    | 15893    |\n",
      "|    total_timesteps | 4261888  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2082        |\n",
      "|    time_elapsed         | 15899       |\n",
      "|    total_timesteps      | 4263936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027139578 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 65870       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2083        |\n",
      "|    time_elapsed         | 15906       |\n",
      "|    total_timesteps      | 4265984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034700826 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0171      |\n",
      "|    n_updates            | 65880       |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2084       |\n",
      "|    time_elapsed         | 15913      |\n",
      "|    total_timesteps      | 4268032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03433109 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.311     |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0357     |\n",
      "|    n_updates            | 65890      |\n",
      "|    policy_gradient_loss | -0.0335    |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4270000, episode_reward=0.23 +/- 0.97\n",
      "Episode length: 30.02 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028426439 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0329      |\n",
      "|    n_updates            | 65900       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 121\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.3      |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2085     |\n",
      "|    time_elapsed    | 15925    |\n",
      "|    total_timesteps | 4270080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2086        |\n",
      "|    time_elapsed         | 15932       |\n",
      "|    total_timesteps      | 4272128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025750417 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0338      |\n",
      "|    n_updates            | 65910       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2087        |\n",
      "|    time_elapsed         | 15940       |\n",
      "|    total_timesteps      | 4274176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024335802 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 65920       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2088        |\n",
      "|    time_elapsed         | 15947       |\n",
      "|    total_timesteps      | 4276224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034973495 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0264      |\n",
      "|    n_updates            | 65930       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2089        |\n",
      "|    time_elapsed         | 15954       |\n",
      "|    total_timesteps      | 4278272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033986665 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00043     |\n",
      "|    n_updates            | 65940       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4280000, episode_reward=0.11 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028960574 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0254      |\n",
      "|    n_updates            | 65950       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2090     |\n",
      "|    time_elapsed    | 15965    |\n",
      "|    total_timesteps | 4280320  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2091        |\n",
      "|    time_elapsed         | 15971       |\n",
      "|    total_timesteps      | 4282368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025102817 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0301      |\n",
      "|    n_updates            | 65960       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2092        |\n",
      "|    time_elapsed         | 15978       |\n",
      "|    total_timesteps      | 4284416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023930622 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00942     |\n",
      "|    n_updates            | 65970       |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2093        |\n",
      "|    time_elapsed         | 15984       |\n",
      "|    total_timesteps      | 4286464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028032519 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0493      |\n",
      "|    n_updates            | 65980       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2094        |\n",
      "|    time_elapsed         | 15990       |\n",
      "|    total_timesteps      | 4288512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027245808 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 65990       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4290000, episode_reward=0.25 +/- 0.96\n",
      "Episode length: 30.06 +/- 0.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4290000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03224566 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.315     |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.018      |\n",
      "|    n_updates            | 66000      |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 122\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2095     |\n",
      "|    time_elapsed    | 16001    |\n",
      "|    total_timesteps | 4290560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2096        |\n",
      "|    time_elapsed         | 16008       |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028069029 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0514      |\n",
      "|    n_updates            | 66010       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2097        |\n",
      "|    time_elapsed         | 16015       |\n",
      "|    total_timesteps      | 4294656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026158096 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0341      |\n",
      "|    n_updates            | 66020       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2098        |\n",
      "|    time_elapsed         | 16021       |\n",
      "|    total_timesteps      | 4296704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029123005 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 66030       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | -0.01     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 268       |\n",
      "|    iterations           | 2099      |\n",
      "|    time_elapsed         | 16028     |\n",
      "|    total_timesteps      | 4298752   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0248859 |\n",
      "|    clip_fraction        | 0.124     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.287    |\n",
      "|    explained_variance   | 0.293     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0202    |\n",
      "|    n_updates            | 66040     |\n",
      "|    policy_gradient_loss | -0.0285   |\n",
      "|    value_loss           | 0.203     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4300000, episode_reward=0.01 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023006221 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0526      |\n",
      "|    n_updates            | 66050       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2100     |\n",
      "|    time_elapsed    | 16039    |\n",
      "|    total_timesteps | 4300800  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.22      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 268       |\n",
      "|    iterations           | 2101      |\n",
      "|    time_elapsed         | 16046     |\n",
      "|    total_timesteps      | 4302848   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0287905 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.295    |\n",
      "|    explained_variance   | 0.182     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.055     |\n",
      "|    n_updates            | 66060     |\n",
      "|    policy_gradient_loss | -0.0292   |\n",
      "|    value_loss           | 0.21      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2102        |\n",
      "|    time_elapsed         | 16052       |\n",
      "|    total_timesteps      | 4304896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026132751 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0433      |\n",
      "|    n_updates            | 66070       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2103       |\n",
      "|    time_elapsed         | 16060      |\n",
      "|    total_timesteps      | 4306944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02716703 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0294     |\n",
      "|    n_updates            | 66080      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2104       |\n",
      "|    time_elapsed         | 16066      |\n",
      "|    total_timesteps      | 4308992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03188725 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.277     |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0376     |\n",
      "|    n_updates            | 66090      |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.193      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4310000, episode_reward=0.09 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026176134 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0425      |\n",
      "|    n_updates            | 66100       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2105     |\n",
      "|    time_elapsed    | 16079    |\n",
      "|    total_timesteps | 4311040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2106        |\n",
      "|    time_elapsed         | 16084       |\n",
      "|    total_timesteps      | 4313088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029025842 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.019       |\n",
      "|    n_updates            | 66110       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2107        |\n",
      "|    time_elapsed         | 16090       |\n",
      "|    total_timesteps      | 4315136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030548807 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0493      |\n",
      "|    n_updates            | 66120       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2108        |\n",
      "|    time_elapsed         | 16095       |\n",
      "|    total_timesteps      | 4317184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029004395 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 66130       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2109        |\n",
      "|    time_elapsed         | 16101       |\n",
      "|    total_timesteps      | 4319232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031485613 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00876    |\n",
      "|    n_updates            | 66140       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=0.37 +/- 0.92\n",
      "Episode length: 30.08 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.37        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024222132 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.023       |\n",
      "|    n_updates            | 66150       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.37\n",
      "SELFPLAY: new best model, bumping up generation to 123\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2110     |\n",
      "|    time_elapsed    | 16112    |\n",
      "|    total_timesteps | 4321280  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2111        |\n",
      "|    time_elapsed         | 16118       |\n",
      "|    total_timesteps      | 4323328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024786904 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 66160       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2112        |\n",
      "|    time_elapsed         | 16125       |\n",
      "|    total_timesteps      | 4325376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036436114 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0507      |\n",
      "|    n_updates            | 66170       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2113        |\n",
      "|    time_elapsed         | 16131       |\n",
      "|    total_timesteps      | 4327424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028879112 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 66180       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2114        |\n",
      "|    time_elapsed         | 16139       |\n",
      "|    total_timesteps      | 4329472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023867313 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 66190       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4330000, episode_reward=0.06 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028596686 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 66200       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2115     |\n",
      "|    time_elapsed    | 16151    |\n",
      "|    total_timesteps | 4331520  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 16157       |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028965287 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0382      |\n",
      "|    n_updates            | 66210       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2117        |\n",
      "|    time_elapsed         | 16163       |\n",
      "|    total_timesteps      | 4335616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031202128 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 66220       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2118        |\n",
      "|    time_elapsed         | 16169       |\n",
      "|    total_timesteps      | 4337664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022908926 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0774      |\n",
      "|    n_updates            | 66230       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2119        |\n",
      "|    time_elapsed         | 16175       |\n",
      "|    total_timesteps      | 4339712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025920575 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0647      |\n",
      "|    n_updates            | 66240       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4340000, episode_reward=0.28 +/- 0.95\n",
      "Episode length: 29.74 +/- 2.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028125858 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0583      |\n",
      "|    n_updates            | 66250       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.28\n",
      "SELFPLAY: new best model, bumping up generation to 124\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2120     |\n",
      "|    time_elapsed    | 16186    |\n",
      "|    total_timesteps | 4341760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2121        |\n",
      "|    time_elapsed         | 16192       |\n",
      "|    total_timesteps      | 4343808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025718581 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0469      |\n",
      "|    n_updates            | 66260       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2122       |\n",
      "|    time_elapsed         | 16198      |\n",
      "|    total_timesteps      | 4345856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02965208 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.29      |\n",
      "|    explained_variance   | 0.235      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.022      |\n",
      "|    n_updates            | 66270      |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.212      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2123        |\n",
      "|    time_elapsed         | 16205       |\n",
      "|    total_timesteps      | 4347904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027737703 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 66280       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.29       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2124       |\n",
      "|    time_elapsed         | 16210      |\n",
      "|    total_timesteps      | 4349952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02568364 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.273     |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0543     |\n",
      "|    n_updates            | 66290      |\n",
      "|    policy_gradient_loss | -0.0278    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4350000, episode_reward=0.12 +/- 0.98\n",
      "Episode length: 29.98 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022721779 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0271      |\n",
      "|    n_updates            | 66300       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2125     |\n",
      "|    time_elapsed    | 16221    |\n",
      "|    total_timesteps | 4352000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2126        |\n",
      "|    time_elapsed         | 16227       |\n",
      "|    total_timesteps      | 4354048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024978843 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0502      |\n",
      "|    n_updates            | 66310       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2127        |\n",
      "|    time_elapsed         | 16233       |\n",
      "|    total_timesteps      | 4356096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029756237 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 66320       |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2128        |\n",
      "|    time_elapsed         | 16240       |\n",
      "|    total_timesteps      | 4358144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026054153 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00826     |\n",
      "|    n_updates            | 66330       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4360000, episode_reward=0.11 +/- 0.95\n",
      "Episode length: 30.01 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030310027 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0138      |\n",
      "|    n_updates            | 66340       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2129     |\n",
      "|    time_elapsed    | 16251    |\n",
      "|    total_timesteps | 4360192  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2130        |\n",
      "|    time_elapsed         | 16257       |\n",
      "|    total_timesteps      | 4362240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026548281 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 66350       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | 0.25      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 268       |\n",
      "|    iterations           | 2131      |\n",
      "|    time_elapsed         | 16265     |\n",
      "|    total_timesteps      | 4364288   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0266993 |\n",
      "|    clip_fraction        | 0.129     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.281    |\n",
      "|    explained_variance   | 0.322     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0636    |\n",
      "|    n_updates            | 66360     |\n",
      "|    policy_gradient_loss | -0.0279   |\n",
      "|    value_loss           | 0.209     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.31       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2132       |\n",
      "|    time_elapsed         | 16271      |\n",
      "|    total_timesteps      | 4366336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03009383 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.268     |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0917     |\n",
      "|    n_updates            | 66370      |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2133        |\n",
      "|    time_elapsed         | 16277       |\n",
      "|    total_timesteps      | 4368384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026833687 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 66380       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4370000, episode_reward=0.25 +/- 0.94\n",
      "Episode length: 30.02 +/- 0.40\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4370000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03258487 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.289     |\n",
      "|    explained_variance   | 0.321      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.032      |\n",
      "|    n_updates            | 66390      |\n",
      "|    policy_gradient_loss | -0.0294    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 125\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2134     |\n",
      "|    time_elapsed    | 16290    |\n",
      "|    total_timesteps | 4370432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2135        |\n",
      "|    time_elapsed         | 16297       |\n",
      "|    total_timesteps      | 4372480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027251955 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0466      |\n",
      "|    n_updates            | 66400       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2136        |\n",
      "|    time_elapsed         | 16304       |\n",
      "|    total_timesteps      | 4374528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029775985 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0577      |\n",
      "|    n_updates            | 66410       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2137        |\n",
      "|    time_elapsed         | 16311       |\n",
      "|    total_timesteps      | 4376576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028929133 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0306      |\n",
      "|    n_updates            | 66420       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2138        |\n",
      "|    time_elapsed         | 16318       |\n",
      "|    total_timesteps      | 4378624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025569621 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0165      |\n",
      "|    n_updates            | 66430       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4380000, episode_reward=0.15 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031071553 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0958      |\n",
      "|    n_updates            | 66440       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2139     |\n",
      "|    time_elapsed    | 16330    |\n",
      "|    total_timesteps | 4380672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2140        |\n",
      "|    time_elapsed         | 16336       |\n",
      "|    total_timesteps      | 4382720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030404098 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.052       |\n",
      "|    n_updates            | 66450       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.09       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2141       |\n",
      "|    time_elapsed         | 16343      |\n",
      "|    total_timesteps      | 4384768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02273624 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.275     |\n",
      "|    explained_variance   | 0.428      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0418     |\n",
      "|    n_updates            | 66460      |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2142        |\n",
      "|    time_elapsed         | 16350       |\n",
      "|    total_timesteps      | 4386816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025301343 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0795      |\n",
      "|    n_updates            | 66470       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2143        |\n",
      "|    time_elapsed         | 16356       |\n",
      "|    total_timesteps      | 4388864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022960749 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 66480       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4390000, episode_reward=0.34 +/- 0.92\n",
      "Episode length: 29.98 +/- 0.37\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.34       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4390000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03221947 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.261     |\n",
      "|    explained_variance   | 0.346      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.016      |\n",
      "|    n_updates            | 66490      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.34\n",
      "SELFPLAY: new best model, bumping up generation to 126\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2144     |\n",
      "|    time_elapsed    | 16368    |\n",
      "|    total_timesteps | 4390912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2145        |\n",
      "|    time_elapsed         | 16374       |\n",
      "|    total_timesteps      | 4392960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025212929 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.056       |\n",
      "|    n_updates            | 66500       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2146        |\n",
      "|    time_elapsed         | 16380       |\n",
      "|    total_timesteps      | 4395008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030940542 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.342      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0471      |\n",
      "|    n_updates            | 66510       |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2147       |\n",
      "|    time_elapsed         | 16386      |\n",
      "|    total_timesteps      | 4397056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03133828 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.331     |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0322     |\n",
      "|    n_updates            | 66520      |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2148        |\n",
      "|    time_elapsed         | 16391       |\n",
      "|    total_timesteps      | 4399104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031187706 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.034       |\n",
      "|    n_updates            | 66530       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4400000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.66 +/- 2.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028909132 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0563      |\n",
      "|    n_updates            | 66540       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.03     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2149     |\n",
      "|    time_elapsed    | 16403    |\n",
      "|    total_timesteps | 4401152  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2150        |\n",
      "|    time_elapsed         | 16410       |\n",
      "|    total_timesteps      | 4403200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026106775 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0359      |\n",
      "|    n_updates            | 66550       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2151        |\n",
      "|    time_elapsed         | 16417       |\n",
      "|    total_timesteps      | 4405248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025622793 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 66560       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2152        |\n",
      "|    time_elapsed         | 16423       |\n",
      "|    total_timesteps      | 4407296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031613935 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0281      |\n",
      "|    n_updates            | 66570       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2153        |\n",
      "|    time_elapsed         | 16431       |\n",
      "|    total_timesteps      | 4409344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028411195 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 66580       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4410000, episode_reward=0.02 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030092318 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0323      |\n",
      "|    n_updates            | 66590       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2154     |\n",
      "|    time_elapsed    | 16442    |\n",
      "|    total_timesteps | 4411392  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2155       |\n",
      "|    time_elapsed         | 16447      |\n",
      "|    total_timesteps      | 4413440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02344624 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.304     |\n",
      "|    explained_variance   | 0.306      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0546     |\n",
      "|    n_updates            | 66600      |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2156       |\n",
      "|    time_elapsed         | 16455      |\n",
      "|    total_timesteps      | 4415488    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02959273 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.303     |\n",
      "|    explained_variance   | 0.324      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0215     |\n",
      "|    n_updates            | 66610      |\n",
      "|    policy_gradient_loss | -0.0311    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2157       |\n",
      "|    time_elapsed         | 16461      |\n",
      "|    total_timesteps      | 4417536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02669233 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.246      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.036      |\n",
      "|    n_updates            | 66620      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2158        |\n",
      "|    time_elapsed         | 16467       |\n",
      "|    total_timesteps      | 4419584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029411744 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 66630       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4420000, episode_reward=0.25 +/- 0.94\n",
      "Episode length: 29.99 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030590866 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0556      |\n",
      "|    n_updates            | 66640       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 127\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | -0.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2159     |\n",
      "|    time_elapsed    | 16478    |\n",
      "|    total_timesteps | 4421632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2160        |\n",
      "|    time_elapsed         | 16484       |\n",
      "|    total_timesteps      | 4423680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026160557 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0727      |\n",
      "|    n_updates            | 66650       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2161        |\n",
      "|    time_elapsed         | 16490       |\n",
      "|    total_timesteps      | 4425728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031982616 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 66660       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2162        |\n",
      "|    time_elapsed         | 16496       |\n",
      "|    total_timesteps      | 4427776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024181135 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0254      |\n",
      "|    n_updates            | 66670       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.31       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2163       |\n",
      "|    time_elapsed         | 16503      |\n",
      "|    total_timesteps      | 4429824    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02782862 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.262     |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0472     |\n",
      "|    n_updates            | 66680      |\n",
      "|    policy_gradient_loss | -0.0257    |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4430000, episode_reward=0.02 +/- 1.00\n",
      "Episode length: 30.00 +/- 0.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039108388 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0427      |\n",
      "|    n_updates            | 66690       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2164     |\n",
      "|    time_elapsed    | 16514    |\n",
      "|    total_timesteps | 4431872  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2165        |\n",
      "|    time_elapsed         | 16521       |\n",
      "|    total_timesteps      | 4433920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025169495 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.219      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 66700       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2166        |\n",
      "|    time_elapsed         | 16528       |\n",
      "|    total_timesteps      | 4435968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029659892 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0646      |\n",
      "|    n_updates            | 66710       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2167        |\n",
      "|    time_elapsed         | 16535       |\n",
      "|    total_timesteps      | 4438016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026253153 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0413      |\n",
      "|    n_updates            | 66720       |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4440000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 30.05 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026557025 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0624      |\n",
      "|    n_updates            | 66730       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2168     |\n",
      "|    time_elapsed    | 16549    |\n",
      "|    total_timesteps | 4440064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2169        |\n",
      "|    time_elapsed         | 16556       |\n",
      "|    total_timesteps      | 4442112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029330023 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 66740       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2170        |\n",
      "|    time_elapsed         | 16563       |\n",
      "|    total_timesteps      | 4444160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025745954 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.238      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0509      |\n",
      "|    n_updates            | 66750       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2171        |\n",
      "|    time_elapsed         | 16591       |\n",
      "|    total_timesteps      | 4446208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023786362 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.212      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 66760       |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2172        |\n",
      "|    time_elapsed         | 16620       |\n",
      "|    total_timesteps      | 4448256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024685621 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0336      |\n",
      "|    n_updates            | 66770       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4450000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024697741 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 66780       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 267      |\n",
      "|    iterations      | 2173     |\n",
      "|    time_elapsed    | 16654    |\n",
      "|    total_timesteps | 4450304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2174        |\n",
      "|    time_elapsed         | 16682       |\n",
      "|    total_timesteps      | 4452352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021390159 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0796      |\n",
      "|    n_updates            | 66790       |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2175        |\n",
      "|    time_elapsed         | 16704       |\n",
      "|    total_timesteps      | 4454400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025175184 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0211      |\n",
      "|    n_updates            | 66800       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2176        |\n",
      "|    time_elapsed         | 16711       |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025667196 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0779      |\n",
      "|    n_updates            | 66810       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2177        |\n",
      "|    time_elapsed         | 16717       |\n",
      "|    total_timesteps      | 4458496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022466533 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0545      |\n",
      "|    n_updates            | 66820       |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4460000, episode_reward=0.19 +/- 0.97\n",
      "Episode length: 30.00 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030140953 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0465      |\n",
      "|    n_updates            | 66830       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2178     |\n",
      "|    time_elapsed    | 16728    |\n",
      "|    total_timesteps | 4460544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2179        |\n",
      "|    time_elapsed         | 16735       |\n",
      "|    total_timesteps      | 4462592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025490083 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 66840       |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2180       |\n",
      "|    time_elapsed         | 16741      |\n",
      "|    total_timesteps      | 4464640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02405696 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.222     |\n",
      "|    explained_variance   | 0.408      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.039      |\n",
      "|    n_updates            | 66850      |\n",
      "|    policy_gradient_loss | -0.0265    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2181        |\n",
      "|    time_elapsed         | 16747       |\n",
      "|    total_timesteps      | 4466688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020465732 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.211      |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0428      |\n",
      "|    n_updates            | 66860       |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2182        |\n",
      "|    time_elapsed         | 16752       |\n",
      "|    total_timesteps      | 4468736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026956059 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.221      |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0888      |\n",
      "|    n_updates            | 66870       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4470000, episode_reward=0.17 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025647435 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.216      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.025       |\n",
      "|    n_updates            | 66880       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2183     |\n",
      "|    time_elapsed    | 16765    |\n",
      "|    total_timesteps | 4470784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2184        |\n",
      "|    time_elapsed         | 16772       |\n",
      "|    total_timesteps      | 4472832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027737942 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.234      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.05        |\n",
      "|    n_updates            | 66890       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.29       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2185       |\n",
      "|    time_elapsed         | 16778      |\n",
      "|    total_timesteps      | 4474880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02295266 |\n",
      "|    clip_fraction        | 0.0982     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.206     |\n",
      "|    explained_variance   | 0.355      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0495     |\n",
      "|    n_updates            | 66900      |\n",
      "|    policy_gradient_loss | -0.0231    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2186        |\n",
      "|    time_elapsed         | 16783       |\n",
      "|    total_timesteps      | 4476928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024518192 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0383      |\n",
      "|    n_updates            | 66910       |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2187        |\n",
      "|    time_elapsed         | 16789       |\n",
      "|    total_timesteps      | 4478976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022774734 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.201      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 66920       |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4480000, episode_reward=0.30 +/- 0.94\n",
      "Episode length: 30.06 +/- 0.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024907462 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.213      |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 66930       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.3\n",
      "SELFPLAY: new best model, bumping up generation to 128\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2188     |\n",
      "|    time_elapsed    | 16801    |\n",
      "|    total_timesteps | 4481024  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2189        |\n",
      "|    time_elapsed         | 16807       |\n",
      "|    total_timesteps      | 4483072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027129272 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0473      |\n",
      "|    n_updates            | 66940       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2190        |\n",
      "|    time_elapsed         | 16812       |\n",
      "|    total_timesteps      | 4485120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027717449 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0179      |\n",
      "|    n_updates            | 66950       |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2191        |\n",
      "|    time_elapsed         | 16819       |\n",
      "|    total_timesteps      | 4487168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022368615 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0617      |\n",
      "|    n_updates            | 66960       |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2192        |\n",
      "|    time_elapsed         | 16826       |\n",
      "|    total_timesteps      | 4489216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028532352 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0736      |\n",
      "|    n_updates            | 66970       |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4490000, episode_reward=0.28 +/- 0.95\n",
      "Episode length: 30.02 +/- 0.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029524904 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.089       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0462      |\n",
      "|    n_updates            | 66980       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.28\n",
      "SELFPLAY: new best model, bumping up generation to 129\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2193     |\n",
      "|    time_elapsed    | 16837    |\n",
      "|    total_timesteps | 4491264  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2194        |\n",
      "|    time_elapsed         | 16844       |\n",
      "|    total_timesteps      | 4493312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026271181 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 66990       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2195       |\n",
      "|    time_elapsed         | 16851      |\n",
      "|    total_timesteps      | 4495360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02289655 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0254     |\n",
      "|    n_updates            | 67000      |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2196        |\n",
      "|    time_elapsed         | 16858       |\n",
      "|    total_timesteps      | 4497408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022444088 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0359      |\n",
      "|    n_updates            | 67010       |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2197       |\n",
      "|    time_elapsed         | 16864      |\n",
      "|    total_timesteps      | 4499456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03112137 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.26      |\n",
      "|    explained_variance   | 0.327      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00662    |\n",
      "|    n_updates            | 67020      |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    value_loss           | 0.215      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4500000, episode_reward=0.03 +/- 0.99\n",
      "Episode length: 29.93 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027048364 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0354      |\n",
      "|    n_updates            | 67030       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2198     |\n",
      "|    time_elapsed    | 16877    |\n",
      "|    total_timesteps | 4501504  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2199        |\n",
      "|    time_elapsed         | 16883       |\n",
      "|    total_timesteps      | 4503552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031525563 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 67040       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2200       |\n",
      "|    time_elapsed         | 16889      |\n",
      "|    total_timesteps      | 4505600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02198791 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.242     |\n",
      "|    explained_variance   | 0.15       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0533     |\n",
      "|    n_updates            | 67050      |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 0.229      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2201        |\n",
      "|    time_elapsed         | 16896       |\n",
      "|    total_timesteps      | 4507648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024761075 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0766      |\n",
      "|    n_updates            | 67060       |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2202        |\n",
      "|    time_elapsed         | 16903       |\n",
      "|    total_timesteps      | 4509696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024304833 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0392      |\n",
      "|    n_updates            | 67070       |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4510000, episode_reward=0.40 +/- 0.91\n",
      "Episode length: 30.03 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024573985 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.246      |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0548      |\n",
      "|    n_updates            | 67080       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.4\n",
      "SELFPLAY: new best model, bumping up generation to 130\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2203     |\n",
      "|    time_elapsed    | 16916    |\n",
      "|    total_timesteps | 4511744  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2204       |\n",
      "|    time_elapsed         | 16922      |\n",
      "|    total_timesteps      | 4513792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02535731 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.26      |\n",
      "|    explained_variance   | 0.274      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0542     |\n",
      "|    n_updates            | 67090      |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    value_loss           | 0.23       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2205        |\n",
      "|    time_elapsed         | 16929       |\n",
      "|    total_timesteps      | 4515840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028124103 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0584      |\n",
      "|    n_updates            | 67100       |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | 0.12      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 266       |\n",
      "|    iterations           | 2206      |\n",
      "|    time_elapsed         | 16936     |\n",
      "|    total_timesteps      | 4517888   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0239111 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.298    |\n",
      "|    explained_variance   | 0.297     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0373    |\n",
      "|    n_updates            | 67110     |\n",
      "|    policy_gradient_loss | -0.0276   |\n",
      "|    value_loss           | 0.215     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2207        |\n",
      "|    time_elapsed         | 16941       |\n",
      "|    total_timesteps      | 4519936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025208205 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0557      |\n",
      "|    n_updates            | 67120       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4520000, episode_reward=0.10 +/- 0.98\n",
      "Episode length: 30.01 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028617352 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0596      |\n",
      "|    n_updates            | 67130       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.08    |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2208     |\n",
      "|    time_elapsed    | 16953    |\n",
      "|    total_timesteps | 4521984  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2209        |\n",
      "|    time_elapsed         | 16958       |\n",
      "|    total_timesteps      | 4524032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030547613 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0814      |\n",
      "|    n_updates            | 67140       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.13      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2210       |\n",
      "|    time_elapsed         | 16964      |\n",
      "|    total_timesteps      | 4526080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02888897 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.3       |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0492     |\n",
      "|    n_updates            | 67150      |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.21       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2211        |\n",
      "|    time_elapsed         | 16969       |\n",
      "|    total_timesteps      | 4528128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025887417 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.084       |\n",
      "|    n_updates            | 67160       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4530000, episode_reward=0.20 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025874836 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0496      |\n",
      "|    n_updates            | 67170       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2212     |\n",
      "|    time_elapsed    | 16980    |\n",
      "|    total_timesteps | 4530176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 16986       |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026731245 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0639      |\n",
      "|    n_updates            | 67180       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2214       |\n",
      "|    time_elapsed         | 16991      |\n",
      "|    total_timesteps      | 4534272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02810149 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.266     |\n",
      "|    explained_variance   | 0.31       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0801     |\n",
      "|    n_updates            | 67190      |\n",
      "|    policy_gradient_loss | -0.0252    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2215        |\n",
      "|    time_elapsed         | 16996       |\n",
      "|    total_timesteps      | 4536320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023776567 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0641      |\n",
      "|    n_updates            | 67200       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2216        |\n",
      "|    time_elapsed         | 17002       |\n",
      "|    total_timesteps      | 4538368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036123883 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0617      |\n",
      "|    n_updates            | 67210       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4540000, episode_reward=0.15 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021866573 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 67220       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2217     |\n",
      "|    time_elapsed    | 17013    |\n",
      "|    total_timesteps | 4540416  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2218        |\n",
      "|    time_elapsed         | 17018       |\n",
      "|    total_timesteps      | 4542464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024487523 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0577      |\n",
      "|    n_updates            | 67230       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2219       |\n",
      "|    time_elapsed         | 17023      |\n",
      "|    total_timesteps      | 4544512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02647284 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.265     |\n",
      "|    explained_variance   | 0.315      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0572     |\n",
      "|    n_updates            | 67240      |\n",
      "|    policy_gradient_loss | -0.0268    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2220       |\n",
      "|    time_elapsed         | 17029      |\n",
      "|    total_timesteps      | 4546560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02330923 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.271     |\n",
      "|    explained_variance   | 0.293      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.03       |\n",
      "|    n_updates            | 67250      |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    value_loss           | 0.224      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2221        |\n",
      "|    time_elapsed         | 17034       |\n",
      "|    total_timesteps      | 4548608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025688834 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 67260       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4550000, episode_reward=0.00 +/- 0.98\n",
      "Episode length: 29.93 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026848653 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.043       |\n",
      "|    n_updates            | 67270       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2222     |\n",
      "|    time_elapsed    | 17045    |\n",
      "|    total_timesteps | 4550656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2223        |\n",
      "|    time_elapsed         | 17050       |\n",
      "|    total_timesteps      | 4552704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022881966 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0725      |\n",
      "|    n_updates            | 67280       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2224        |\n",
      "|    time_elapsed         | 17055       |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018389935 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0602      |\n",
      "|    n_updates            | 67290       |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2225        |\n",
      "|    time_elapsed         | 17061       |\n",
      "|    total_timesteps      | 4556800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030573111 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0391      |\n",
      "|    n_updates            | 67300       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2226        |\n",
      "|    time_elapsed         | 17066       |\n",
      "|    total_timesteps      | 4558848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027319018 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0189      |\n",
      "|    n_updates            | 67310       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4560000, episode_reward=0.11 +/- 0.99\n",
      "Episode length: 30.05 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024225477 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0189      |\n",
      "|    n_updates            | 67320       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 267      |\n",
      "|    iterations      | 2227     |\n",
      "|    time_elapsed    | 17077    |\n",
      "|    total_timesteps | 4560896  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2228        |\n",
      "|    time_elapsed         | 17082       |\n",
      "|    total_timesteps      | 4562944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027612709 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0921      |\n",
      "|    n_updates            | 67330       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2229        |\n",
      "|    time_elapsed         | 17087       |\n",
      "|    total_timesteps      | 4564992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030451028 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0418      |\n",
      "|    n_updates            | 67340       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2230        |\n",
      "|    time_elapsed         | 17093       |\n",
      "|    total_timesteps      | 4567040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024317283 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 67350       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2231       |\n",
      "|    time_elapsed         | 17099      |\n",
      "|    total_timesteps      | 4569088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02590907 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.263     |\n",
      "|    explained_variance   | 0.405      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0384     |\n",
      "|    n_updates            | 67360      |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.189      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4570000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 30.05 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025164574 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.242      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0204      |\n",
      "|    n_updates            | 67370       |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.06    |\n",
      "| time/              |          |\n",
      "|    fps             | 267      |\n",
      "|    iterations      | 2232     |\n",
      "|    time_elapsed    | 17109    |\n",
      "|    total_timesteps | 4571136  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2233        |\n",
      "|    time_elapsed         | 17114       |\n",
      "|    total_timesteps      | 4573184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029621016 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0524      |\n",
      "|    n_updates            | 67380       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2234       |\n",
      "|    time_elapsed         | 17120      |\n",
      "|    total_timesteps      | 4575232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02442664 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.247     |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0653     |\n",
      "|    n_updates            | 67390      |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    value_loss           | 0.213      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2235        |\n",
      "|    time_elapsed         | 17125       |\n",
      "|    total_timesteps      | 4577280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036412623 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0473      |\n",
      "|    n_updates            | 67400       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2236       |\n",
      "|    time_elapsed         | 17131      |\n",
      "|    total_timesteps      | 4579328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02493339 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.25      |\n",
      "|    explained_variance   | 0.237      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0369     |\n",
      "|    n_updates            | 67410      |\n",
      "|    policy_gradient_loss | -0.0257    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4580000, episode_reward=0.17 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4580000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02567277 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.249     |\n",
      "|    explained_variance   | 0.28       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0467     |\n",
      "|    n_updates            | 67420      |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 267      |\n",
      "|    iterations      | 2237     |\n",
      "|    time_elapsed    | 17141    |\n",
      "|    total_timesteps | 4581376  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2238       |\n",
      "|    time_elapsed         | 17147      |\n",
      "|    total_timesteps      | 4583424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02492588 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.247     |\n",
      "|    explained_variance   | 0.374      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0153     |\n",
      "|    n_updates            | 67430      |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2239        |\n",
      "|    time_elapsed         | 17152       |\n",
      "|    total_timesteps      | 4585472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032365054 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0417      |\n",
      "|    n_updates            | 67440       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2240        |\n",
      "|    time_elapsed         | 17158       |\n",
      "|    total_timesteps      | 4587520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031525042 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0689      |\n",
      "|    n_updates            | 67450       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2241        |\n",
      "|    time_elapsed         | 17165       |\n",
      "|    total_timesteps      | 4589568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029922413 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 67460       |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4590000, episode_reward=0.32 +/- 0.94\n",
      "Episode length: 30.01 +/- 0.44\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.32       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4590000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02394431 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.243     |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0231     |\n",
      "|    n_updates            | 67470      |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.32\n",
      "SELFPLAY: new best model, bumping up generation to 131\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 267      |\n",
      "|    iterations      | 2242     |\n",
      "|    time_elapsed    | 17176    |\n",
      "|    total_timesteps | 4591616  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2243       |\n",
      "|    time_elapsed         | 17182      |\n",
      "|    total_timesteps      | 4593664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03452196 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.309     |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0314     |\n",
      "|    n_updates            | 67480      |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2244       |\n",
      "|    time_elapsed         | 17188      |\n",
      "|    total_timesteps      | 4595712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03238976 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.319     |\n",
      "|    explained_variance   | 0.341      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0447     |\n",
      "|    n_updates            | 67490      |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2245        |\n",
      "|    time_elapsed         | 17194       |\n",
      "|    total_timesteps      | 4597760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030470189 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 67500       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2246        |\n",
      "|    time_elapsed         | 17200       |\n",
      "|    total_timesteps      | 4599808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028108375 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.326      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0576      |\n",
      "|    n_updates            | 67510       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4600000, episode_reward=0.14 +/- 0.96\n",
      "Episode length: 30.03 +/- 0.52\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.14       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02938301 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.311     |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0448     |\n",
      "|    n_updates            | 67520      |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    value_loss           | 0.222      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 267      |\n",
      "|    iterations      | 2247     |\n",
      "|    time_elapsed    | 17212    |\n",
      "|    total_timesteps | 4601856  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2248       |\n",
      "|    time_elapsed         | 17218      |\n",
      "|    total_timesteps      | 4603904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02067279 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.307     |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0348     |\n",
      "|    n_updates            | 67530      |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.07      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2249       |\n",
      "|    time_elapsed         | 17224      |\n",
      "|    total_timesteps      | 4605952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02799983 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.297     |\n",
      "|    explained_variance   | 0.277      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0175     |\n",
      "|    n_updates            | 67540      |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.218      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2250       |\n",
      "|    time_elapsed         | 17256      |\n",
      "|    total_timesteps      | 4608000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03080038 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.296     |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0537     |\n",
      "|    n_updates            | 67550      |\n",
      "|    policy_gradient_loss | -0.0312    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4610000, episode_reward=0.08 +/- 0.99\n",
      "Episode length: 29.95 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024758605 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0347      |\n",
      "|    n_updates            | 67560       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 2251     |\n",
      "|    time_elapsed    | 17293    |\n",
      "|    total_timesteps | 4610048  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.04      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2252       |\n",
      "|    time_elapsed         | 17324      |\n",
      "|    total_timesteps      | 4612096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02013383 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.266     |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0274     |\n",
      "|    n_updates            | 67570      |\n",
      "|    policy_gradient_loss | -0.029     |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2253        |\n",
      "|    time_elapsed         | 17359       |\n",
      "|    total_timesteps      | 4614144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033026632 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0282      |\n",
      "|    n_updates            | 67580       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2254        |\n",
      "|    time_elapsed         | 17382       |\n",
      "|    total_timesteps      | 4616192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024335183 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 67590       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2255        |\n",
      "|    time_elapsed         | 17391       |\n",
      "|    total_timesteps      | 4618240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024910875 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.064       |\n",
      "|    n_updates            | 67600       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4620000, episode_reward=0.23 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.51\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4620000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02760986 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.278     |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0432     |\n",
      "|    n_updates            | 67610      |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.202      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 132\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2256     |\n",
      "|    time_elapsed    | 17405    |\n",
      "|    total_timesteps | 4620288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2257        |\n",
      "|    time_elapsed         | 17413       |\n",
      "|    total_timesteps      | 4622336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028273214 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0197      |\n",
      "|    n_updates            | 67620       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2258       |\n",
      "|    time_elapsed         | 17420      |\n",
      "|    total_timesteps      | 4624384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03105078 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.281     |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0843     |\n",
      "|    n_updates            | 67630      |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2259        |\n",
      "|    time_elapsed         | 17427       |\n",
      "|    total_timesteps      | 4626432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034275178 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0367      |\n",
      "|    n_updates            | 67640       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2260        |\n",
      "|    time_elapsed         | 17435       |\n",
      "|    total_timesteps      | 4628480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026675902 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0547      |\n",
      "|    n_updates            | 67650       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.235       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4630000, episode_reward=0.22 +/- 0.95\n",
      "Episode length: 29.95 +/- 0.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021196283 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0452      |\n",
      "|    n_updates            | 67660       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 133\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.05     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2261     |\n",
      "|    time_elapsed    | 17450    |\n",
      "|    total_timesteps | 4630528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2262        |\n",
      "|    time_elapsed         | 17457       |\n",
      "|    total_timesteps      | 4632576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024616204 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.061       |\n",
      "|    n_updates            | 67670       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2263       |\n",
      "|    time_elapsed         | 17464      |\n",
      "|    total_timesteps      | 4634624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02974213 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.299     |\n",
      "|    explained_variance   | 0.297      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.09       |\n",
      "|    n_updates            | 67680      |\n",
      "|    policy_gradient_loss | -0.0298    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2264        |\n",
      "|    time_elapsed         | 17472       |\n",
      "|    total_timesteps      | 4636672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022563789 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0626      |\n",
      "|    n_updates            | 67690       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2265       |\n",
      "|    time_elapsed         | 17481      |\n",
      "|    total_timesteps      | 4638720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02606011 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.295     |\n",
      "|    explained_variance   | 0.129      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0346     |\n",
      "|    n_updates            | 67700      |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    value_loss           | 0.24       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4640000, episode_reward=-0.05 +/- 0.97\n",
      "Episode length: 30.00 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029251106 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 67710       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2266     |\n",
      "|    time_elapsed    | 17493    |\n",
      "|    total_timesteps | 4640768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2267        |\n",
      "|    time_elapsed         | 17499       |\n",
      "|    total_timesteps      | 4642816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026373375 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0573      |\n",
      "|    n_updates            | 67720       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2268        |\n",
      "|    time_elapsed         | 17506       |\n",
      "|    total_timesteps      | 4644864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024765436 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 67730       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2269        |\n",
      "|    time_elapsed         | 17514       |\n",
      "|    total_timesteps      | 4646912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030120362 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 67740       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2270        |\n",
      "|    time_elapsed         | 17521       |\n",
      "|    total_timesteps      | 4648960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026751572 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0605      |\n",
      "|    n_updates            | 67750       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4650000, episode_reward=0.18 +/- 0.96\n",
      "Episode length: 29.96 +/- 0.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4650000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03250376 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.269     |\n",
      "|    explained_variance   | 0.318      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0962     |\n",
      "|    n_updates            | 67760      |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2271     |\n",
      "|    time_elapsed    | 17535    |\n",
      "|    total_timesteps | 4651008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2272        |\n",
      "|    time_elapsed         | 17542       |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023317575 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0851      |\n",
      "|    n_updates            | 67770       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2273        |\n",
      "|    time_elapsed         | 17550       |\n",
      "|    total_timesteps      | 4655104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030251741 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0316      |\n",
      "|    n_updates            | 67780       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2274        |\n",
      "|    time_elapsed         | 17558       |\n",
      "|    total_timesteps      | 4657152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029836465 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0341      |\n",
      "|    n_updates            | 67790       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2275        |\n",
      "|    time_elapsed         | 17565       |\n",
      "|    total_timesteps      | 4659200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025929153 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0368      |\n",
      "|    n_updates            | 67800       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4660000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.99 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026996437 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 67810       |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2276     |\n",
      "|    time_elapsed    | 17578    |\n",
      "|    total_timesteps | 4661248  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2277        |\n",
      "|    time_elapsed         | 17587       |\n",
      "|    total_timesteps      | 4663296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033891663 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0722      |\n",
      "|    n_updates            | 67820       |\n",
      "|    policy_gradient_loss | -0.0326     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2278        |\n",
      "|    time_elapsed         | 17596       |\n",
      "|    total_timesteps      | 4665344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023467679 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0581      |\n",
      "|    n_updates            | 67830       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2279       |\n",
      "|    time_elapsed         | 17604      |\n",
      "|    total_timesteps      | 4667392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02546915 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.261     |\n",
      "|    explained_variance   | 0.443      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0282     |\n",
      "|    n_updates            | 67840      |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2280        |\n",
      "|    time_elapsed         | 17611       |\n",
      "|    total_timesteps      | 4669440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025608972 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0499      |\n",
      "|    n_updates            | 67850       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4670000, episode_reward=0.14 +/- 0.98\n",
      "Episode length: 30.00 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025463263 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0474      |\n",
      "|    n_updates            | 67860       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2281     |\n",
      "|    time_elapsed    | 17623    |\n",
      "|    total_timesteps | 4671488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2282        |\n",
      "|    time_elapsed         | 17629       |\n",
      "|    total_timesteps      | 4673536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028108967 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 67870       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2283        |\n",
      "|    time_elapsed         | 17636       |\n",
      "|    total_timesteps      | 4675584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025802536 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.035       |\n",
      "|    n_updates            | 67880       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2284        |\n",
      "|    time_elapsed         | 17643       |\n",
      "|    total_timesteps      | 4677632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027736235 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0507      |\n",
      "|    n_updates            | 67890       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2285       |\n",
      "|    time_elapsed         | 17650      |\n",
      "|    total_timesteps      | 4679680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02683103 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.252     |\n",
      "|    explained_variance   | 0.233      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0254     |\n",
      "|    n_updates            | 67900      |\n",
      "|    policy_gradient_loss | -0.0283    |\n",
      "|    value_loss           | 0.223      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4680000, episode_reward=0.09 +/- 0.98\n",
      "Episode length: 30.05 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021138124 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.234      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 67910       |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2286     |\n",
      "|    time_elapsed    | 17663    |\n",
      "|    total_timesteps | 4681728  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.29       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2287       |\n",
      "|    time_elapsed         | 17671      |\n",
      "|    total_timesteps      | 4683776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252303 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.266     |\n",
      "|    explained_variance   | 0.338      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0684     |\n",
      "|    n_updates            | 67920      |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2288        |\n",
      "|    time_elapsed         | 17678       |\n",
      "|    total_timesteps      | 4685824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026452083 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0441      |\n",
      "|    n_updates            | 67930       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2289       |\n",
      "|    time_elapsed         | 17685      |\n",
      "|    total_timesteps      | 4687872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03474183 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.272     |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0388     |\n",
      "|    n_updates            | 67940      |\n",
      "|    policy_gradient_loss | -0.0266    |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2290        |\n",
      "|    time_elapsed         | 17692       |\n",
      "|    total_timesteps      | 4689920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031348117 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0555      |\n",
      "|    n_updates            | 67950       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4690000, episode_reward=0.17 +/- 0.97\n",
      "Episode length: 29.99 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4690000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031324957 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0198      |\n",
      "|    n_updates            | 67960       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2291     |\n",
      "|    time_elapsed    | 17705    |\n",
      "|    total_timesteps | 4691968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2292        |\n",
      "|    time_elapsed         | 17712       |\n",
      "|    total_timesteps      | 4694016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029604407 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0272      |\n",
      "|    n_updates            | 67970       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2293        |\n",
      "|    time_elapsed         | 17718       |\n",
      "|    total_timesteps      | 4696064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029825673 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0621      |\n",
      "|    n_updates            | 67980       |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2294        |\n",
      "|    time_elapsed         | 17725       |\n",
      "|    total_timesteps      | 4698112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022334563 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0712      |\n",
      "|    n_updates            | 67990       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4700000, episode_reward=0.26 +/- 0.96\n",
      "Episode length: 29.93 +/- 0.79\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4700000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02680854 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.276     |\n",
      "|    explained_variance   | 0.29       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0326     |\n",
      "|    n_updates            | 68000      |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 134\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2295     |\n",
      "|    time_elapsed    | 17737    |\n",
      "|    total_timesteps | 4700160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2296        |\n",
      "|    time_elapsed         | 17745       |\n",
      "|    total_timesteps      | 4702208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027536456 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0309      |\n",
      "|    n_updates            | 68010       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2297        |\n",
      "|    time_elapsed         | 17752       |\n",
      "|    total_timesteps      | 4704256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028468039 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00793     |\n",
      "|    n_updates            | 68020       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2298        |\n",
      "|    time_elapsed         | 17758       |\n",
      "|    total_timesteps      | 4706304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026398387 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.334      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 68030       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2299        |\n",
      "|    time_elapsed         | 17765       |\n",
      "|    total_timesteps      | 4708352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028727045 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0384      |\n",
      "|    n_updates            | 68040       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4710000, episode_reward=0.17 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043456376 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.327      |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0461      |\n",
      "|    n_updates            | 68050       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2300     |\n",
      "|    time_elapsed    | 17777    |\n",
      "|    total_timesteps | 4710400  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2301        |\n",
      "|    time_elapsed         | 17783       |\n",
      "|    total_timesteps      | 4712448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027929332 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.336      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 68060       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2302        |\n",
      "|    time_elapsed         | 17790       |\n",
      "|    total_timesteps      | 4714496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027841004 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.333      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 68070       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2303        |\n",
      "|    time_elapsed         | 17796       |\n",
      "|    total_timesteps      | 4716544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025600234 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 68080       |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2304        |\n",
      "|    time_elapsed         | 17803       |\n",
      "|    total_timesteps      | 4718592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025437092 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0921      |\n",
      "|    n_updates            | 68090       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4720000, episode_reward=0.02 +/- 1.00\n",
      "Episode length: 29.99 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024295406 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0475      |\n",
      "|    n_updates            | 68100       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2305     |\n",
      "|    time_elapsed    | 17815    |\n",
      "|    total_timesteps | 4720640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2306        |\n",
      "|    time_elapsed         | 17822       |\n",
      "|    total_timesteps      | 4722688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029928213 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0515      |\n",
      "|    n_updates            | 68110       |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2307        |\n",
      "|    time_elapsed         | 17828       |\n",
      "|    total_timesteps      | 4724736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040433913 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0934      |\n",
      "|    n_updates            | 68120       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2308        |\n",
      "|    time_elapsed         | 17834       |\n",
      "|    total_timesteps      | 4726784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025882974 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 68130       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2309        |\n",
      "|    time_elapsed         | 17841       |\n",
      "|    total_timesteps      | 4728832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031742655 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0071     |\n",
      "|    n_updates            | 68140       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4730000, episode_reward=0.22 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024841597 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.036       |\n",
      "|    n_updates            | 68150       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.22\n",
      "SELFPLAY: new best model, bumping up generation to 135\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2310     |\n",
      "|    time_elapsed    | 17853    |\n",
      "|    total_timesteps | 4730880  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2311        |\n",
      "|    time_elapsed         | 17862       |\n",
      "|    total_timesteps      | 4732928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030961614 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0437      |\n",
      "|    n_updates            | 68160       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2312        |\n",
      "|    time_elapsed         | 17868       |\n",
      "|    total_timesteps      | 4734976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028778173 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 68170       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2313        |\n",
      "|    time_elapsed         | 17875       |\n",
      "|    total_timesteps      | 4737024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037440144 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0172      |\n",
      "|    n_updates            | 68180       |\n",
      "|    policy_gradient_loss | -0.0323     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2314        |\n",
      "|    time_elapsed         | 17881       |\n",
      "|    total_timesteps      | 4739072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036568694 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0443      |\n",
      "|    n_updates            | 68190       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4740000, episode_reward=0.09 +/- 0.99\n",
      "Episode length: 29.93 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026459519 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0632      |\n",
      "|    n_updates            | 68200       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2315     |\n",
      "|    time_elapsed    | 17893    |\n",
      "|    total_timesteps | 4741120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2316        |\n",
      "|    time_elapsed         | 17899       |\n",
      "|    total_timesteps      | 4743168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029297438 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0624      |\n",
      "|    n_updates            | 68210       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2317       |\n",
      "|    time_elapsed         | 17905      |\n",
      "|    total_timesteps      | 4745216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02714662 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.266     |\n",
      "|    explained_variance   | 0.328      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0225     |\n",
      "|    n_updates            | 68220      |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2318        |\n",
      "|    time_elapsed         | 17911       |\n",
      "|    total_timesteps      | 4747264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027754594 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0546      |\n",
      "|    n_updates            | 68230       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2319        |\n",
      "|    time_elapsed         | 17917       |\n",
      "|    total_timesteps      | 4749312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026545227 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0116      |\n",
      "|    n_updates            | 68240       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4750000, episode_reward=0.27 +/- 0.96\n",
      "Episode length: 29.94 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024208495 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 68250       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.27\n",
      "SELFPLAY: new best model, bumping up generation to 136\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2320     |\n",
      "|    time_elapsed    | 17929    |\n",
      "|    total_timesteps | 4751360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2321        |\n",
      "|    time_elapsed         | 17936       |\n",
      "|    total_timesteps      | 4753408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027964119 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0903      |\n",
      "|    n_updates            | 68260       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2322        |\n",
      "|    time_elapsed         | 17942       |\n",
      "|    total_timesteps      | 4755456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024363816 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0375      |\n",
      "|    n_updates            | 68270       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2323        |\n",
      "|    time_elapsed         | 17948       |\n",
      "|    total_timesteps      | 4757504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025692359 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0343      |\n",
      "|    n_updates            | 68280       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2324        |\n",
      "|    time_elapsed         | 17955       |\n",
      "|    total_timesteps      | 4759552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025583705 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.283      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0475      |\n",
      "|    n_updates            | 68290       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4760000, episode_reward=-0.11 +/- 0.98\n",
      "Episode length: 29.96 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030635156 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0239      |\n",
      "|    n_updates            | 68300       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2325     |\n",
      "|    time_elapsed    | 17967    |\n",
      "|    total_timesteps | 4761600  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2326        |\n",
      "|    time_elapsed         | 17973       |\n",
      "|    total_timesteps      | 4763648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027827935 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0185      |\n",
      "|    n_updates            | 68310       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2327        |\n",
      "|    time_elapsed         | 17979       |\n",
      "|    total_timesteps      | 4765696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024521042 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 68320       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2328        |\n",
      "|    time_elapsed         | 17985       |\n",
      "|    total_timesteps      | 4767744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026756354 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0403      |\n",
      "|    n_updates            | 68330       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2329       |\n",
      "|    time_elapsed         | 17992      |\n",
      "|    total_timesteps      | 4769792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02571835 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.276     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0223     |\n",
      "|    n_updates            | 68340      |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4770000, episode_reward=0.20 +/- 0.96\n",
      "Episode length: 29.98 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4770000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02737717 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.294     |\n",
      "|    explained_variance   | 0.275      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.042      |\n",
      "|    n_updates            | 68350      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.221      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2330     |\n",
      "|    time_elapsed    | 18004    |\n",
      "|    total_timesteps | 4771840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2331        |\n",
      "|    time_elapsed         | 18010       |\n",
      "|    total_timesteps      | 4773888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025242718 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0381      |\n",
      "|    n_updates            | 68360       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.21      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 265       |\n",
      "|    iterations           | 2332      |\n",
      "|    time_elapsed         | 18016     |\n",
      "|    total_timesteps      | 4775936   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0198181 |\n",
      "|    clip_fraction        | 0.109     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.25     |\n",
      "|    explained_variance   | 0.286     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.039     |\n",
      "|    n_updates            | 68370     |\n",
      "|    policy_gradient_loss | -0.0238   |\n",
      "|    value_loss           | 0.221     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2333        |\n",
      "|    time_elapsed         | 18022       |\n",
      "|    total_timesteps      | 4777984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025725376 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0909      |\n",
      "|    n_updates            | 68380       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4780000, episode_reward=0.24 +/- 0.96\n",
      "Episode length: 29.88 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019140974 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.248      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0654      |\n",
      "|    n_updates            | 68390       |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.24\n",
      "SELFPLAY: new best model, bumping up generation to 137\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2334     |\n",
      "|    time_elapsed    | 18034    |\n",
      "|    total_timesteps | 4780032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2335        |\n",
      "|    time_elapsed         | 18042       |\n",
      "|    total_timesteps      | 4782080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020945938 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.247      |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 68400       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.235       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2336        |\n",
      "|    time_elapsed         | 18048       |\n",
      "|    total_timesteps      | 4784128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028065687 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0293      |\n",
      "|    n_updates            | 68410       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2337        |\n",
      "|    time_elapsed         | 18054       |\n",
      "|    total_timesteps      | 4786176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030531831 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0729      |\n",
      "|    n_updates            | 68420       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2338        |\n",
      "|    time_elapsed         | 18061       |\n",
      "|    total_timesteps      | 4788224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029614769 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0376      |\n",
      "|    n_updates            | 68430       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4790000, episode_reward=0.35 +/- 0.92\n",
      "Episode length: 30.05 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028650315 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0181      |\n",
      "|    n_updates            | 68440       |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.35\n",
      "SELFPLAY: new best model, bumping up generation to 138\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2339     |\n",
      "|    time_elapsed    | 18075    |\n",
      "|    total_timesteps | 4790272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2340        |\n",
      "|    time_elapsed         | 18082       |\n",
      "|    total_timesteps      | 4792320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031246379 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0534      |\n",
      "|    n_updates            | 68450       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2341       |\n",
      "|    time_elapsed         | 18089      |\n",
      "|    total_timesteps      | 4794368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02528717 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.26      |\n",
      "|    explained_variance   | 0.406      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.056      |\n",
      "|    n_updates            | 68460      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2342        |\n",
      "|    time_elapsed         | 18110       |\n",
      "|    total_timesteps      | 4796416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030355297 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0459      |\n",
      "|    n_updates            | 68470       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2343       |\n",
      "|    time_elapsed         | 18117      |\n",
      "|    total_timesteps      | 4798464    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02539182 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.244     |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0665     |\n",
      "|    n_updates            | 68480      |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=0.10 +/- 0.97\n",
      "Episode length: 30.04 +/- 0.58\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30        |\n",
      "|    mean_reward          | 0.1       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4800000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0277287 |\n",
      "|    clip_fraction        | 0.123     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.236    |\n",
      "|    explained_variance   | 0.305     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0173    |\n",
      "|    n_updates            | 68490     |\n",
      "|    policy_gradient_loss | -0.0272   |\n",
      "|    value_loss           | 0.179     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2344     |\n",
      "|    time_elapsed    | 18128    |\n",
      "|    total_timesteps | 4800512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2345        |\n",
      "|    time_elapsed         | 18136       |\n",
      "|    total_timesteps      | 4802560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025706548 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0463      |\n",
      "|    n_updates            | 68500       |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2346        |\n",
      "|    time_elapsed         | 18142       |\n",
      "|    total_timesteps      | 4804608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030047944 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0775      |\n",
      "|    n_updates            | 68510       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2347        |\n",
      "|    time_elapsed         | 18149       |\n",
      "|    total_timesteps      | 4806656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033973802 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0347      |\n",
      "|    n_updates            | 68520       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2348        |\n",
      "|    time_elapsed         | 18156       |\n",
      "|    total_timesteps      | 4808704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027176524 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0643      |\n",
      "|    n_updates            | 68530       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4810000, episode_reward=0.16 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4810000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02171091 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.236     |\n",
      "|    explained_variance   | 0.352      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0518     |\n",
      "|    n_updates            | 68540      |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2349     |\n",
      "|    time_elapsed    | 18168    |\n",
      "|    total_timesteps | 4810752  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2350       |\n",
      "|    time_elapsed         | 18178      |\n",
      "|    total_timesteps      | 4812800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02955148 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.229     |\n",
      "|    explained_variance   | 0.403      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0443     |\n",
      "|    n_updates            | 68550      |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2351        |\n",
      "|    time_elapsed         | 18200       |\n",
      "|    total_timesteps      | 4814848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021509068 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.231      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0387      |\n",
      "|    n_updates            | 68560       |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2352        |\n",
      "|    time_elapsed         | 18206       |\n",
      "|    total_timesteps      | 4816896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019052893 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 68570       |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2353        |\n",
      "|    time_elapsed         | 18213       |\n",
      "|    total_timesteps      | 4818944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028609991 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0411      |\n",
      "|    n_updates            | 68580       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4820000, episode_reward=0.20 +/- 0.96\n",
      "Episode length: 29.90 +/- 1.12\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4820000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02816752 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.209     |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.039      |\n",
      "|    n_updates            | 68590      |\n",
      "|    policy_gradient_loss | -0.0244    |\n",
      "|    value_loss           | 0.195      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2354     |\n",
      "|    time_elapsed    | 18224    |\n",
      "|    total_timesteps | 4820992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2355        |\n",
      "|    time_elapsed         | 18230       |\n",
      "|    total_timesteps      | 4823040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024390504 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.215      |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 68600       |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2356        |\n",
      "|    time_elapsed         | 18236       |\n",
      "|    total_timesteps      | 4825088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030353332 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.204      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0592      |\n",
      "|    n_updates            | 68610       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2357        |\n",
      "|    time_elapsed         | 18242       |\n",
      "|    total_timesteps      | 4827136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025746671 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.219      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0485      |\n",
      "|    n_updates            | 68620       |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2358        |\n",
      "|    time_elapsed         | 18249       |\n",
      "|    total_timesteps      | 4829184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024237743 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.206      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.045       |\n",
      "|    n_updates            | 68630       |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4830000, episode_reward=0.06 +/- 1.00\n",
      "Episode length: 29.91 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031303592 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.188      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 68640       |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2359     |\n",
      "|    time_elapsed    | 18260    |\n",
      "|    total_timesteps | 4831232  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2360        |\n",
      "|    time_elapsed         | 18267       |\n",
      "|    total_timesteps      | 4833280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023774711 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.209      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0232      |\n",
      "|    n_updates            | 68650       |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.35      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 264       |\n",
      "|    iterations           | 2361      |\n",
      "|    time_elapsed         | 18273     |\n",
      "|    total_timesteps      | 4835328   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0270876 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.221    |\n",
      "|    explained_variance   | 0.429     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0458    |\n",
      "|    n_updates            | 68660     |\n",
      "|    policy_gradient_loss | -0.0252   |\n",
      "|    value_loss           | 0.182     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2362        |\n",
      "|    time_elapsed         | 18279       |\n",
      "|    total_timesteps      | 4837376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025268529 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.233      |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00998     |\n",
      "|    n_updates            | 68670       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2363        |\n",
      "|    time_elapsed         | 18286       |\n",
      "|    total_timesteps      | 4839424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025780678 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 68680       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4840000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 29.97 +/- 0.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4840000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02729703 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.221     |\n",
      "|    explained_variance   | 0.318      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0513     |\n",
      "|    n_updates            | 68690      |\n",
      "|    policy_gradient_loss | -0.0269    |\n",
      "|    value_loss           | 0.161      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.4      |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2364     |\n",
      "|    time_elapsed    | 18299    |\n",
      "|    total_timesteps | 4841472  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2365        |\n",
      "|    time_elapsed         | 18306       |\n",
      "|    total_timesteps      | 4843520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024317468 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 68700       |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2366        |\n",
      "|    time_elapsed         | 18313       |\n",
      "|    total_timesteps      | 4845568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025351005 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.043       |\n",
      "|    n_updates            | 68710       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2367        |\n",
      "|    time_elapsed         | 18320       |\n",
      "|    total_timesteps      | 4847616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022758529 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0585      |\n",
      "|    n_updates            | 68720       |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2368        |\n",
      "|    time_elapsed         | 18326       |\n",
      "|    total_timesteps      | 4849664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025119334 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.077       |\n",
      "|    n_updates            | 68730       |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4850000, episode_reward=0.30 +/- 0.93\n",
      "Episode length: 29.98 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021108907 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.207      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 68740       |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.3\n",
      "SELFPLAY: new best model, bumping up generation to 139\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2369     |\n",
      "|    time_elapsed    | 18338    |\n",
      "|    total_timesteps | 4851712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2370        |\n",
      "|    time_elapsed         | 18345       |\n",
      "|    total_timesteps      | 4853760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027256267 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0382      |\n",
      "|    n_updates            | 68750       |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2371        |\n",
      "|    time_elapsed         | 18351       |\n",
      "|    total_timesteps      | 4855808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035891667 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0603      |\n",
      "|    n_updates            | 68760       |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2372        |\n",
      "|    time_elapsed         | 18357       |\n",
      "|    total_timesteps      | 4857856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029048247 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0594      |\n",
      "|    n_updates            | 68770       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.23      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2373       |\n",
      "|    time_elapsed         | 18363      |\n",
      "|    total_timesteps      | 4859904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02986959 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.287     |\n",
      "|    explained_variance   | 0.266      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0606     |\n",
      "|    n_updates            | 68780      |\n",
      "|    policy_gradient_loss | -0.0266    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4860000, episode_reward=0.14 +/- 0.98\n",
      "Episode length: 30.06 +/- 0.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031609714 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0496      |\n",
      "|    n_updates            | 68790       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2374     |\n",
      "|    time_elapsed    | 18375    |\n",
      "|    total_timesteps | 4861952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2375        |\n",
      "|    time_elapsed         | 18382       |\n",
      "|    total_timesteps      | 4864000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035027057 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0676      |\n",
      "|    n_updates            | 68800       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2376        |\n",
      "|    time_elapsed         | 18389       |\n",
      "|    total_timesteps      | 4866048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029108478 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0086      |\n",
      "|    n_updates            | 68810       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2377       |\n",
      "|    time_elapsed         | 18395      |\n",
      "|    total_timesteps      | 4868096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03438168 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.256     |\n",
      "|    explained_variance   | 0.433      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0571     |\n",
      "|    n_updates            | 68820      |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4870000, episode_reward=-0.02 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029405925 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.047       |\n",
      "|    n_updates            | 68830       |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2378     |\n",
      "|    time_elapsed    | 18408    |\n",
      "|    total_timesteps | 4870144  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2379        |\n",
      "|    time_elapsed         | 18416       |\n",
      "|    total_timesteps      | 4872192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026770089 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 68840       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2380        |\n",
      "|    time_elapsed         | 18423       |\n",
      "|    total_timesteps      | 4874240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028244052 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.232      |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0096      |\n",
      "|    n_updates            | 68850       |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2381        |\n",
      "|    time_elapsed         | 18452       |\n",
      "|    total_timesteps      | 4876288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036692858 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.232      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0296      |\n",
      "|    n_updates            | 68860       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2382        |\n",
      "|    time_elapsed         | 18480       |\n",
      "|    total_timesteps      | 4878336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034194306 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 68870       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4880000, episode_reward=0.20 +/- 0.96\n",
      "Episode length: 29.99 +/- 0.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027481982 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.237      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00282     |\n",
      "|    n_updates            | 68880       |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.37     |\n",
      "| time/              |          |\n",
      "|    fps             | 263      |\n",
      "|    iterations      | 2383     |\n",
      "|    time_elapsed    | 18514    |\n",
      "|    total_timesteps | 4880384  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 2384       |\n",
      "|    time_elapsed         | 18542      |\n",
      "|    total_timesteps      | 4882432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02585417 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.222     |\n",
      "|    explained_variance   | 0.516      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0245     |\n",
      "|    n_updates            | 68890      |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2385        |\n",
      "|    time_elapsed         | 18578       |\n",
      "|    total_timesteps      | 4884480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022486709 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.21       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0455      |\n",
      "|    n_updates            | 68900       |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2386        |\n",
      "|    time_elapsed         | 18619       |\n",
      "|    total_timesteps      | 4886528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025947839 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.196      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0304      |\n",
      "|    n_updates            | 68910       |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.35        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2387        |\n",
      "|    time_elapsed         | 18651       |\n",
      "|    total_timesteps      | 4888576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030237317 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.214      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0343      |\n",
      "|    n_updates            | 68920       |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4890000, episode_reward=0.26 +/- 0.92\n",
      "Episode length: 29.97 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031522695 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0347      |\n",
      "|    n_updates            | 68930       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 140\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 261      |\n",
      "|    iterations      | 2388     |\n",
      "|    time_elapsed    | 18683    |\n",
      "|    total_timesteps | 4890624  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 261        |\n",
      "|    iterations           | 2389       |\n",
      "|    time_elapsed         | 18714      |\n",
      "|    total_timesteps      | 4892672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03648568 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.256     |\n",
      "|    explained_variance   | 0.407      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0476     |\n",
      "|    n_updates            | 68940      |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    value_loss           | 0.174      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 2390        |\n",
      "|    time_elapsed         | 18745       |\n",
      "|    total_timesteps      | 4894720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029919785 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0489      |\n",
      "|    n_updates            | 68950       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 2391        |\n",
      "|    time_elapsed         | 18772       |\n",
      "|    total_timesteps      | 4896768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035954725 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0335      |\n",
      "|    n_updates            | 68960       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 2392        |\n",
      "|    time_elapsed         | 18802       |\n",
      "|    total_timesteps      | 4898816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029747957 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0458      |\n",
      "|    n_updates            | 68970       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4900000, episode_reward=0.08 +/- 0.98\n",
      "Episode length: 29.83 +/- 1.86\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.8       |\n",
      "|    mean_reward          | 0.08       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4900000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02761657 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.297     |\n",
      "|    explained_variance   | 0.444      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0396     |\n",
      "|    n_updates            | 68980      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 260      |\n",
      "|    iterations      | 2393     |\n",
      "|    time_elapsed    | 18839    |\n",
      "|    total_timesteps | 4900864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 2394        |\n",
      "|    time_elapsed         | 18868       |\n",
      "|    total_timesteps      | 4902912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027698696 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.04        |\n",
      "|    n_updates            | 68990       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 259         |\n",
      "|    iterations           | 2395        |\n",
      "|    time_elapsed         | 18898       |\n",
      "|    total_timesteps      | 4904960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034048513 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000947   |\n",
      "|    n_updates            | 69000       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.3        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 259        |\n",
      "|    iterations           | 2396       |\n",
      "|    time_elapsed         | 18928      |\n",
      "|    total_timesteps      | 4907008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03337262 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0122     |\n",
      "|    n_updates            | 69010      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 2397        |\n",
      "|    time_elapsed         | 18958       |\n",
      "|    total_timesteps      | 4909056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029262682 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0292      |\n",
      "|    n_updates            | 69020       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4910000, episode_reward=0.15 +/- 0.96\n",
      "Episode length: 30.01 +/- 0.52\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30        |\n",
      "|    mean_reward          | 0.15      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4910000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0343764 |\n",
      "|    clip_fraction        | 0.124     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.265    |\n",
      "|    explained_variance   | 0.394     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.042     |\n",
      "|    n_updates            | 69030     |\n",
      "|    policy_gradient_loss | -0.0278   |\n",
      "|    value_loss           | 0.188     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.19     |\n",
      "| time/              |          |\n",
      "|    fps             | 258      |\n",
      "|    iterations      | 2398     |\n",
      "|    time_elapsed    | 18993    |\n",
      "|    total_timesteps | 4911104  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 258        |\n",
      "|    iterations           | 2399       |\n",
      "|    time_elapsed         | 19024      |\n",
      "|    total_timesteps      | 4913152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03213729 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.279     |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0528     |\n",
      "|    n_updates            | 69040      |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 2400        |\n",
      "|    time_elapsed         | 19059       |\n",
      "|    total_timesteps      | 4915200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040013388 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0423      |\n",
      "|    n_updates            | 69050       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 257         |\n",
      "|    iterations           | 2401        |\n",
      "|    time_elapsed         | 19092       |\n",
      "|    total_timesteps      | 4917248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034959704 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 69060       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.3        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 257        |\n",
      "|    iterations           | 2402       |\n",
      "|    time_elapsed         | 19123      |\n",
      "|    total_timesteps      | 4919296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03144453 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.277     |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0137     |\n",
      "|    n_updates            | 69070      |\n",
      "|    policy_gradient_loss | -0.0284    |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4920000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 29.89 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029240038 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0215      |\n",
      "|    n_updates            | 69080       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 141\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 256      |\n",
      "|    iterations      | 2403     |\n",
      "|    time_elapsed    | 19160    |\n",
      "|    total_timesteps | 4921344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 2404        |\n",
      "|    time_elapsed         | 19191       |\n",
      "|    total_timesteps      | 4923392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032807536 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 69090       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 2405        |\n",
      "|    time_elapsed         | 19222       |\n",
      "|    total_timesteps      | 4925440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025778309 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0503      |\n",
      "|    n_updates            | 69100       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 2406        |\n",
      "|    time_elapsed         | 19251       |\n",
      "|    total_timesteps      | 4927488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037543472 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 69110       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 255        |\n",
      "|    iterations           | 2407       |\n",
      "|    time_elapsed         | 19281      |\n",
      "|    total_timesteps      | 4929536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03182774 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00158    |\n",
      "|    n_updates            | 69120      |\n",
      "|    policy_gradient_loss | -0.0314    |\n",
      "|    value_loss           | 0.181      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4930000, episode_reward=0.31 +/- 0.95\n",
      "Episode length: 29.99 +/- 0.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.31       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4930000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02860212 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.253     |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0371     |\n",
      "|    n_updates            | 69130      |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.31\n",
      "SELFPLAY: new best model, bumping up generation to 142\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 255      |\n",
      "|    iterations      | 2408     |\n",
      "|    time_elapsed    | 19318    |\n",
      "|    total_timesteps | 4931584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2409        |\n",
      "|    time_elapsed         | 19348       |\n",
      "|    total_timesteps      | 4933632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030484516 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.018       |\n",
      "|    n_updates            | 69140       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2410       |\n",
      "|    time_elapsed         | 19379      |\n",
      "|    total_timesteps      | 4935680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03711821 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.28      |\n",
      "|    explained_variance   | 0.229      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0452     |\n",
      "|    n_updates            | 69150      |\n",
      "|    policy_gradient_loss | -0.0288    |\n",
      "|    value_loss           | 0.224      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2411        |\n",
      "|    time_elapsed         | 19408       |\n",
      "|    total_timesteps      | 4937728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031398322 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.322      |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 69160       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2412        |\n",
      "|    time_elapsed         | 19419       |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029532969 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0611      |\n",
      "|    n_updates            | 69170       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4940000, episode_reward=0.10 +/- 0.98\n",
      "Episode length: 29.98 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029267773 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0446      |\n",
      "|    n_updates            | 69180       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2413     |\n",
      "|    time_elapsed    | 19433    |\n",
      "|    total_timesteps | 4941824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2414        |\n",
      "|    time_elapsed         | 19440       |\n",
      "|    total_timesteps      | 4943872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029719248 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0647      |\n",
      "|    n_updates            | 69190       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2415        |\n",
      "|    time_elapsed         | 19448       |\n",
      "|    total_timesteps      | 4945920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029697377 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 69200       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2416       |\n",
      "|    time_elapsed         | 19457      |\n",
      "|    total_timesteps      | 4947968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02619802 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.157      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.06       |\n",
      "|    n_updates            | 69210      |\n",
      "|    policy_gradient_loss | -0.0265    |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4950000, episode_reward=0.18 +/- 0.97\n",
      "Episode length: 29.97 +/- 0.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039063755 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.06        |\n",
      "|    n_updates            | 69220       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2417     |\n",
      "|    time_elapsed    | 19469    |\n",
      "|    total_timesteps | 4950016  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.38       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2418       |\n",
      "|    time_elapsed         | 19476      |\n",
      "|    total_timesteps      | 4952064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02664433 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.28      |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0568     |\n",
      "|    n_updates            | 69230      |\n",
      "|    policy_gradient_loss | -0.0284    |\n",
      "|    value_loss           | 0.188      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.47       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2419       |\n",
      "|    time_elapsed         | 19483      |\n",
      "|    total_timesteps      | 4954112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03313736 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.271     |\n",
      "|    explained_variance   | 0.428      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0281     |\n",
      "|    n_updates            | 69240      |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    value_loss           | 0.129      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2420        |\n",
      "|    time_elapsed         | 19490       |\n",
      "|    total_timesteps      | 4956160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036199383 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 69250       |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2421        |\n",
      "|    time_elapsed         | 19497       |\n",
      "|    total_timesteps      | 4958208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024065863 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0379      |\n",
      "|    n_updates            | 69260       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4960000, episode_reward=0.31 +/- 0.95\n",
      "Episode length: 29.92 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030162193 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0896      |\n",
      "|    n_updates            | 69270       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.31\n",
      "SELFPLAY: new best model, bumping up generation to 143\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2422     |\n",
      "|    time_elapsed    | 19508    |\n",
      "|    total_timesteps | 4960256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2423        |\n",
      "|    time_elapsed         | 19516       |\n",
      "|    total_timesteps      | 4962304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030038195 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0378      |\n",
      "|    n_updates            | 69280       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2424        |\n",
      "|    time_elapsed         | 19522       |\n",
      "|    total_timesteps      | 4964352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030620791 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00107     |\n",
      "|    n_updates            | 69290       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2425        |\n",
      "|    time_elapsed         | 19528       |\n",
      "|    total_timesteps      | 4966400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030228078 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0169      |\n",
      "|    n_updates            | 69300       |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2426        |\n",
      "|    time_elapsed         | 19535       |\n",
      "|    total_timesteps      | 4968448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030420098 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0184      |\n",
      "|    n_updates            | 69310       |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4970000, episode_reward=0.19 +/- 0.98\n",
      "Episode length: 29.87 +/- 1.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030111982 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 69320       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.24     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2427     |\n",
      "|    time_elapsed    | 19547    |\n",
      "|    total_timesteps | 4970496  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2428       |\n",
      "|    time_elapsed         | 19553      |\n",
      "|    total_timesteps      | 4972544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03185057 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.62       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00924    |\n",
      "|    n_updates            | 69330      |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2429        |\n",
      "|    time_elapsed         | 19559       |\n",
      "|    total_timesteps      | 4974592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027202336 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 69340       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2430        |\n",
      "|    time_elapsed         | 19566       |\n",
      "|    total_timesteps      | 4976640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024672136 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00502     |\n",
      "|    n_updates            | 69350       |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2431        |\n",
      "|    time_elapsed         | 19572       |\n",
      "|    total_timesteps      | 4978688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035137996 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0153      |\n",
      "|    n_updates            | 69360       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4980000, episode_reward=0.06 +/- 0.99\n",
      "Episode length: 29.99 +/- 0.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025434006 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0822      |\n",
      "|    n_updates            | 69370       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2432     |\n",
      "|    time_elapsed    | 19585    |\n",
      "|    total_timesteps | 4980736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2433        |\n",
      "|    time_elapsed         | 19591       |\n",
      "|    total_timesteps      | 4982784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026549224 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00936     |\n",
      "|    n_updates            | 69380       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2434        |\n",
      "|    time_elapsed         | 19598       |\n",
      "|    total_timesteps      | 4984832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040828757 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 69390       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2435       |\n",
      "|    time_elapsed         | 19604      |\n",
      "|    total_timesteps      | 4986880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03348595 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.3       |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0156     |\n",
      "|    n_updates            | 69400      |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2436        |\n",
      "|    time_elapsed         | 19610       |\n",
      "|    total_timesteps      | 4988928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031500075 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0701      |\n",
      "|    n_updates            | 69410       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4990000, episode_reward=0.17 +/- 0.96\n",
      "Episode length: 30.03 +/- 0.52\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30        |\n",
      "|    mean_reward          | 0.17      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4990000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0296249 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.288    |\n",
      "|    explained_variance   | 0.422     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0295    |\n",
      "|    n_updates            | 69420     |\n",
      "|    policy_gradient_loss | -0.0275   |\n",
      "|    value_loss           | 0.171     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.16     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2437     |\n",
      "|    time_elapsed    | 19622    |\n",
      "|    total_timesteps | 4990976  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2438       |\n",
      "|    time_elapsed         | 19628      |\n",
      "|    total_timesteps      | 4993024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03698478 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.283     |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0545     |\n",
      "|    n_updates            | 69430      |\n",
      "|    policy_gradient_loss | -0.0302    |\n",
      "|    value_loss           | 0.171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2439        |\n",
      "|    time_elapsed         | 19634       |\n",
      "|    total_timesteps      | 4995072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027178012 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.069       |\n",
      "|    n_updates            | 69440       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2440        |\n",
      "|    time_elapsed         | 19641       |\n",
      "|    total_timesteps      | 4997120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032073013 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.054       |\n",
      "|    n_updates            | 69450       |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2441        |\n",
      "|    time_elapsed         | 19648       |\n",
      "|    total_timesteps      | 4999168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027563076 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0478      |\n",
      "|    n_updates            | 69460       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000000, episode_reward=0.38 +/- 0.91\n",
      "Episode length: 30.00 +/- 0.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038495965 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0125      |\n",
      "|    n_updates            | 69470       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.38\n",
      "SELFPLAY: new best model, bumping up generation to 144\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2442     |\n",
      "|    time_elapsed    | 19660    |\n",
      "|    total_timesteps | 5001216  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2443       |\n",
      "|    time_elapsed         | 19666      |\n",
      "|    total_timesteps      | 5003264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03369668 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | 0.39       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0498     |\n",
      "|    n_updates            | 69480      |\n",
      "|    policy_gradient_loss | -0.0275    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2444        |\n",
      "|    time_elapsed         | 19672       |\n",
      "|    total_timesteps      | 5005312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028708477 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0403      |\n",
      "|    n_updates            | 69490       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2445        |\n",
      "|    time_elapsed         | 19679       |\n",
      "|    total_timesteps      | 5007360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029743064 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0741      |\n",
      "|    n_updates            | 69500       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2446        |\n",
      "|    time_elapsed         | 19685       |\n",
      "|    total_timesteps      | 5009408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033084318 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00399     |\n",
      "|    n_updates            | 69510       |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5010000, episode_reward=0.26 +/- 0.94\n",
      "Episode length: 29.99 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025035542 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0158      |\n",
      "|    n_updates            | 69520       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 145\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2447     |\n",
      "|    time_elapsed    | 19697    |\n",
      "|    total_timesteps | 5011456  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2448       |\n",
      "|    time_elapsed         | 19703      |\n",
      "|    total_timesteps      | 5013504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04094062 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.319     |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0167     |\n",
      "|    n_updates            | 69530      |\n",
      "|    policy_gradient_loss | -0.0341    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2449        |\n",
      "|    time_elapsed         | 19709       |\n",
      "|    total_timesteps      | 5015552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033065256 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 69540       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2450        |\n",
      "|    time_elapsed         | 19715       |\n",
      "|    total_timesteps      | 5017600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028229073 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 69550       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2451        |\n",
      "|    time_elapsed         | 19721       |\n",
      "|    total_timesteps      | 5019648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025843114 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 69560       |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5020000, episode_reward=0.03 +/- 0.98\n",
      "Episode length: 30.03 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031941675 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.073       |\n",
      "|    n_updates            | 69570       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2452     |\n",
      "|    time_elapsed    | 19732    |\n",
      "|    total_timesteps | 5021696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2453        |\n",
      "|    time_elapsed         | 19738       |\n",
      "|    total_timesteps      | 5023744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027426666 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00406    |\n",
      "|    n_updates            | 69580       |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2454       |\n",
      "|    time_elapsed         | 19744      |\n",
      "|    total_timesteps      | 5025792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03243112 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.306     |\n",
      "|    explained_variance   | 0.415      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0281     |\n",
      "|    n_updates            | 69590      |\n",
      "|    policy_gradient_loss | -0.0295    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2455        |\n",
      "|    time_elapsed         | 19750       |\n",
      "|    total_timesteps      | 5027840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039502665 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 69600       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2456        |\n",
      "|    time_elapsed         | 19756       |\n",
      "|    total_timesteps      | 5029888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027512461 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0317      |\n",
      "|    n_updates            | 69610       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5030000, episode_reward=0.12 +/- 0.99\n",
      "Episode length: 30.04 +/- 0.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029593457 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00647    |\n",
      "|    n_updates            | 69620       |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2457     |\n",
      "|    time_elapsed    | 19767    |\n",
      "|    total_timesteps | 5031936  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2458        |\n",
      "|    time_elapsed         | 19774       |\n",
      "|    total_timesteps      | 5033984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025100634 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0716      |\n",
      "|    n_updates            | 69630       |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2459        |\n",
      "|    time_elapsed         | 19780       |\n",
      "|    total_timesteps      | 5036032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029683283 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.307      |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00616     |\n",
      "|    n_updates            | 69640       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2460       |\n",
      "|    time_elapsed         | 19786      |\n",
      "|    total_timesteps      | 5038080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03345694 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.442      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0204     |\n",
      "|    n_updates            | 69650      |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    value_loss           | 0.167      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=5040000, episode_reward=0.25 +/- 0.96\n",
      "Episode length: 29.94 +/- 0.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.25       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5040000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03618706 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.315     |\n",
      "|    explained_variance   | 0.376      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0119     |\n",
      "|    n_updates            | 69660      |\n",
      "|    policy_gradient_loss | -0.0332    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.25\n",
      "SELFPLAY: new best model, bumping up generation to 146\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2461     |\n",
      "|    time_elapsed    | 19798    |\n",
      "|    total_timesteps | 5040128  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | 0.06      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 254       |\n",
      "|    iterations           | 2462      |\n",
      "|    time_elapsed         | 19805     |\n",
      "|    total_timesteps      | 5042176   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0313377 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.307    |\n",
      "|    explained_variance   | 0.299     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0438    |\n",
      "|    n_updates            | 69670     |\n",
      "|    policy_gradient_loss | -0.0313   |\n",
      "|    value_loss           | 0.2       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2463        |\n",
      "|    time_elapsed         | 19811       |\n",
      "|    total_timesteps      | 5044224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026310649 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 69680       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2464       |\n",
      "|    time_elapsed         | 19817      |\n",
      "|    total_timesteps      | 5046272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03535642 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.308     |\n",
      "|    explained_variance   | 0.221      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0275     |\n",
      "|    n_updates            | 69690      |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.191      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2465        |\n",
      "|    time_elapsed         | 19823       |\n",
      "|    total_timesteps      | 5048320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028136432 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0493      |\n",
      "|    n_updates            | 69700       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5050000, episode_reward=0.02 +/- 0.98\n",
      "Episode length: 29.99 +/- 0.50\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 30        |\n",
      "|    mean_reward          | 0.02      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 5050000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0324107 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.289    |\n",
      "|    explained_variance   | 0.353     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00513   |\n",
      "|    n_updates            | 69710     |\n",
      "|    policy_gradient_loss | -0.0312   |\n",
      "|    value_loss           | 0.179     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2466     |\n",
      "|    time_elapsed    | 19834    |\n",
      "|    total_timesteps | 5050368  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2467        |\n",
      "|    time_elapsed         | 19840       |\n",
      "|    total_timesteps      | 5052416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031732813 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0342      |\n",
      "|    n_updates            | 69720       |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2468        |\n",
      "|    time_elapsed         | 19846       |\n",
      "|    total_timesteps      | 5054464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027606918 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0549      |\n",
      "|    n_updates            | 69730       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2469        |\n",
      "|    time_elapsed         | 19853       |\n",
      "|    total_timesteps      | 5056512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030914973 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 69740       |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2470        |\n",
      "|    time_elapsed         | 19859       |\n",
      "|    total_timesteps      | 5058560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026729882 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 69750       |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5060000, episode_reward=0.20 +/- 0.97\n",
      "Episode length: 30.03 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030590948 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.037       |\n",
      "|    n_updates            | 69760       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2471     |\n",
      "|    time_elapsed    | 19870    |\n",
      "|    total_timesteps | 5060608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2472        |\n",
      "|    time_elapsed         | 19876       |\n",
      "|    total_timesteps      | 5062656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030718146 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.255      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0477      |\n",
      "|    n_updates            | 69770       |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2473        |\n",
      "|    time_elapsed         | 19883       |\n",
      "|    total_timesteps      | 5064704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028131843 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0741      |\n",
      "|    n_updates            | 69780       |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2474       |\n",
      "|    time_elapsed         | 19889      |\n",
      "|    total_timesteps      | 5066752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02734721 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.262     |\n",
      "|    explained_variance   | 0.399      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0104     |\n",
      "|    n_updates            | 69790      |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2475        |\n",
      "|    time_elapsed         | 19895       |\n",
      "|    total_timesteps      | 5068800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024543094 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0621      |\n",
      "|    n_updates            | 69800       |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5070000, episode_reward=0.09 +/- 0.96\n",
      "Episode length: 30.03 +/- 0.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032813035 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 69810       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2476     |\n",
      "|    time_elapsed    | 19906    |\n",
      "|    total_timesteps | 5070848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2477        |\n",
      "|    time_elapsed         | 19912       |\n",
      "|    total_timesteps      | 5072896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028940676 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0387      |\n",
      "|    n_updates            | 69820       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.18       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2478       |\n",
      "|    time_elapsed         | 19919      |\n",
      "|    total_timesteps      | 5074944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03266257 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.265     |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0433     |\n",
      "|    n_updates            | 69830      |\n",
      "|    policy_gradient_loss | -0.027     |\n",
      "|    value_loss           | 0.186      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2479       |\n",
      "|    time_elapsed         | 19925      |\n",
      "|    total_timesteps      | 5076992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03012354 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.281     |\n",
      "|    explained_variance   | 0.346      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0684     |\n",
      "|    n_updates            | 69840      |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.3         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2480        |\n",
      "|    time_elapsed         | 19931       |\n",
      "|    total_timesteps      | 5079040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027120892 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.019       |\n",
      "|    n_updates            | 69850       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5080000, episode_reward=0.04 +/- 0.99\n",
      "Episode length: 29.97 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028279155 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 69860       |\n",
      "|    policy_gradient_loss | -0.0275     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.33     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2481     |\n",
      "|    time_elapsed    | 19942    |\n",
      "|    total_timesteps | 5081088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2482        |\n",
      "|    time_elapsed         | 19951       |\n",
      "|    total_timesteps      | 5083136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026923835 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0663      |\n",
      "|    n_updates            | 69870       |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2483        |\n",
      "|    time_elapsed         | 19958       |\n",
      "|    total_timesteps      | 5085184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032174844 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00754     |\n",
      "|    n_updates            | 69880       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2484        |\n",
      "|    time_elapsed         | 19964       |\n",
      "|    total_timesteps      | 5087232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032235667 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0625      |\n",
      "|    n_updates            | 69890       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2485       |\n",
      "|    time_elapsed         | 19970      |\n",
      "|    total_timesteps      | 5089280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02836399 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.298     |\n",
      "|    explained_variance   | 0.353      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0382     |\n",
      "|    n_updates            | 69900      |\n",
      "|    policy_gradient_loss | -0.03      |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=5090000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 30.08 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024836069 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 69910       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 147\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.08     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2486     |\n",
      "|    time_elapsed    | 19982    |\n",
      "|    total_timesteps | 5091328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2487        |\n",
      "|    time_elapsed         | 19988       |\n",
      "|    total_timesteps      | 5093376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026644446 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 69920       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2488        |\n",
      "|    time_elapsed         | 19995       |\n",
      "|    total_timesteps      | 5095424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024277024 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 69930       |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.02       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2489       |\n",
      "|    time_elapsed         | 20001      |\n",
      "|    total_timesteps      | 5097472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03450111 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0342     |\n",
      "|    n_updates            | 69940      |\n",
      "|    policy_gradient_loss | -0.03      |\n",
      "|    value_loss           | 0.173      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2490        |\n",
      "|    time_elapsed         | 20007       |\n",
      "|    total_timesteps      | 5099520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035037063 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0456      |\n",
      "|    n_updates            | 69950       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5100000, episode_reward=0.18 +/- 0.97\n",
      "Episode length: 30.05 +/- 0.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033463478 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0529      |\n",
      "|    n_updates            | 69960       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.1      |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2491     |\n",
      "|    time_elapsed    | 20019    |\n",
      "|    total_timesteps | 5101568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2492        |\n",
      "|    time_elapsed         | 20025       |\n",
      "|    total_timesteps      | 5103616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032044273 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 69970       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2493       |\n",
      "|    time_elapsed         | 20032      |\n",
      "|    total_timesteps      | 5105664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02922387 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.494      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00983    |\n",
      "|    n_updates            | 69980      |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2494        |\n",
      "|    time_elapsed         | 20038       |\n",
      "|    total_timesteps      | 5107712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029269364 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.019       |\n",
      "|    n_updates            | 69990       |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30        |\n",
      "|    ep_rew_mean          | 0.12      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 254       |\n",
      "|    iterations           | 2495      |\n",
      "|    time_elapsed         | 20044     |\n",
      "|    total_timesteps      | 5109760   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0283105 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.286    |\n",
      "|    explained_variance   | 0.552     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.051     |\n",
      "|    n_updates            | 70000     |\n",
      "|    policy_gradient_loss | -0.0282   |\n",
      "|    value_loss           | 0.169     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=5110000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 30.08 +/- 0.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5110000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02762639 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.284     |\n",
      "|    explained_variance   | 0.376      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0603     |\n",
      "|    n_updates            | 70010      |\n",
      "|    policy_gradient_loss | -0.0257    |\n",
      "|    value_loss           | 0.201      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 148\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2496     |\n",
      "|    time_elapsed    | 20056    |\n",
      "|    total_timesteps | 5111808  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2497        |\n",
      "|    time_elapsed         | 20063       |\n",
      "|    total_timesteps      | 5113856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030214667 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00103    |\n",
      "|    n_updates            | 70020       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2498       |\n",
      "|    time_elapsed         | 20070      |\n",
      "|    total_timesteps      | 5115904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02235092 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.324     |\n",
      "|    explained_variance   | 0.452      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0265     |\n",
      "|    n_updates            | 70030      |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 254        |\n",
      "|    iterations           | 2499       |\n",
      "|    time_elapsed         | 20076      |\n",
      "|    total_timesteps      | 5117952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03324908 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.312     |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0264     |\n",
      "|    n_updates            | 70040      |\n",
      "|    policy_gradient_loss | -0.0313    |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=5120000, episode_reward=0.26 +/- 0.96\n",
      "Episode length: 30.01 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031049225 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0244      |\n",
      "|    n_updates            | 70050       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 149\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.43     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2500     |\n",
      "|    time_elapsed    | 20088    |\n",
      "|    total_timesteps | 5120000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.47        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2501        |\n",
      "|    time_elapsed         | 20095       |\n",
      "|    total_timesteps      | 5122048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037075236 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 70060       |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2502        |\n",
      "|    time_elapsed         | 20101       |\n",
      "|    total_timesteps      | 5124096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024388587 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 70070       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2503        |\n",
      "|    time_elapsed         | 20108       |\n",
      "|    total_timesteps      | 5126144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028513052 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0684      |\n",
      "|    n_updates            | 70080       |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2504        |\n",
      "|    time_elapsed         | 20114       |\n",
      "|    total_timesteps      | 5128192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023376886 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0215      |\n",
      "|    n_updates            | 70090       |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5130000, episode_reward=0.23 +/- 0.96\n",
      "Episode length: 30.07 +/- 0.55\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.23       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5130000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03232406 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.298     |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00932    |\n",
      "|    n_updates            | 70100      |\n",
      "|    policy_gradient_loss | -0.0316    |\n",
      "|    value_loss           | 0.24       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.23\n",
      "SELFPLAY: new best model, bumping up generation to 150\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2505     |\n",
      "|    time_elapsed    | 20126    |\n",
      "|    total_timesteps | 5130240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2506        |\n",
      "|    time_elapsed         | 20134       |\n",
      "|    total_timesteps      | 5132288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025516994 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 70110       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2507        |\n",
      "|    time_elapsed         | 20140       |\n",
      "|    total_timesteps      | 5134336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029092198 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0135      |\n",
      "|    n_updates            | 70120       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2508        |\n",
      "|    time_elapsed         | 20147       |\n",
      "|    total_timesteps      | 5136384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026488371 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00769     |\n",
      "|    n_updates            | 70130       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2509        |\n",
      "|    time_elapsed         | 20154       |\n",
      "|    total_timesteps      | 5138432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023274329 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0218      |\n",
      "|    n_updates            | 70140       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5140000, episode_reward=0.17 +/- 0.96\n",
      "Episode length: 29.99 +/- 0.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028084172 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.267      |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0178      |\n",
      "|    n_updates            | 70150       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.07     |\n",
      "| time/              |          |\n",
      "|    fps             | 254      |\n",
      "|    iterations      | 2510     |\n",
      "|    time_elapsed    | 20190    |\n",
      "|    total_timesteps | 5140480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 2511        |\n",
      "|    time_elapsed         | 20226       |\n",
      "|    total_timesteps      | 5142528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024428556 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0562      |\n",
      "|    n_updates            | 70160       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 253         |\n",
      "|    iterations           | 2512        |\n",
      "|    time_elapsed         | 20256       |\n",
      "|    total_timesteps      | 5144576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033443246 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0181      |\n",
      "|    n_updates            | 70170       |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 253         |\n",
      "|    iterations           | 2513        |\n",
      "|    time_elapsed         | 20287       |\n",
      "|    total_timesteps      | 5146624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023826644 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.266      |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0671      |\n",
      "|    n_updates            | 70180       |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.41       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 253        |\n",
      "|    iterations           | 2514       |\n",
      "|    time_elapsed         | 20318      |\n",
      "|    total_timesteps      | 5148672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02730987 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.244     |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0638     |\n",
      "|    n_updates            | 70190      |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=5150000, episode_reward=0.11 +/- 0.99\n",
      "Episode length: 30.01 +/- 0.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5150000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03290146 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.255     |\n",
      "|    explained_variance   | 0.29       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0437     |\n",
      "|    n_updates            | 70200      |\n",
      "|    policy_gradient_loss | -0.0277    |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.35     |\n",
      "| time/              |          |\n",
      "|    fps             | 253      |\n",
      "|    iterations      | 2515     |\n",
      "|    time_elapsed    | 20355    |\n",
      "|    total_timesteps | 5150720  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2516        |\n",
      "|    time_elapsed         | 20387       |\n",
      "|    total_timesteps      | 5152768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024694394 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.259      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0015     |\n",
      "|    n_updates            | 70210       |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2517        |\n",
      "|    time_elapsed         | 20395       |\n",
      "|    total_timesteps      | 5154816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043419868 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0405      |\n",
      "|    n_updates            | 70220       |\n",
      "|    policy_gradient_loss | -0.0282     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2518       |\n",
      "|    time_elapsed         | 20401      |\n",
      "|    total_timesteps      | 5156864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02770421 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.238     |\n",
      "|    explained_variance   | 0.46       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0564     |\n",
      "|    n_updates            | 70230      |\n",
      "|    policy_gradient_loss | -0.0233    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.38       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2519       |\n",
      "|    time_elapsed         | 20406      |\n",
      "|    total_timesteps      | 5158912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02415187 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.253     |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00104   |\n",
      "|    n_updates            | 70240      |\n",
      "|    policy_gradient_loss | -0.0263    |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=5160000, episode_reward=0.29 +/- 0.94\n",
      "Episode length: 30.01 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034692414 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.244      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0622      |\n",
      "|    n_updates            | 70250       |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.29\n",
      "SELFPLAY: new best model, bumping up generation to 151\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.36     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2520     |\n",
      "|    time_elapsed    | 20418    |\n",
      "|    total_timesteps | 5160960  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | -0.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2521       |\n",
      "|    time_elapsed         | 20425      |\n",
      "|    total_timesteps      | 5163008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04114843 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.255     |\n",
      "|    explained_variance   | 0.297      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0537     |\n",
      "|    n_updates            | 70260      |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    value_loss           | 0.212      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2522        |\n",
      "|    time_elapsed         | 20431       |\n",
      "|    total_timesteps      | 5165056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034957618 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0699      |\n",
      "|    n_updates            | 70270       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2523        |\n",
      "|    time_elapsed         | 20437       |\n",
      "|    total_timesteps      | 5167104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027063623 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0809      |\n",
      "|    n_updates            | 70280       |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2524        |\n",
      "|    time_elapsed         | 20443       |\n",
      "|    total_timesteps      | 5169152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027264055 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 70290       |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5170000, episode_reward=0.03 +/- 0.97\n",
      "Episode length: 29.98 +/- 0.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.03       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5170000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02896199 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.285     |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0849     |\n",
      "|    n_updates            | 70300      |\n",
      "|    policy_gradient_loss | -0.0264    |\n",
      "|    value_loss           | 0.211      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.18     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2525     |\n",
      "|    time_elapsed    | 20455    |\n",
      "|    total_timesteps | 5171200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2526        |\n",
      "|    time_elapsed         | 20461       |\n",
      "|    total_timesteps      | 5173248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025488041 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0788      |\n",
      "|    n_updates            | 70310       |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2527        |\n",
      "|    time_elapsed         | 20467       |\n",
      "|    total_timesteps      | 5175296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027884334 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0159      |\n",
      "|    n_updates            | 70320       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2528        |\n",
      "|    time_elapsed         | 20474       |\n",
      "|    total_timesteps      | 5177344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024002602 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.26       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0447      |\n",
      "|    n_updates            | 70330       |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2529        |\n",
      "|    time_elapsed         | 20481       |\n",
      "|    total_timesteps      | 5179392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031666633 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.076       |\n",
      "|    n_updates            | 70340       |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5180000, episode_reward=-0.02 +/- 0.99\n",
      "Episode length: 29.91 +/- 0.49\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 29.9      |\n",
      "|    mean_reward          | -0.02     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 5180000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0331127 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.29     |\n",
      "|    explained_variance   | 0.352     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0627    |\n",
      "|    n_updates            | 70350     |\n",
      "|    policy_gradient_loss | -0.0335   |\n",
      "|    value_loss           | 0.207     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.36     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2530     |\n",
      "|    time_elapsed    | 20493    |\n",
      "|    total_timesteps | 5181440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2531        |\n",
      "|    time_elapsed         | 20499       |\n",
      "|    total_timesteps      | 5183488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023674449 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0598      |\n",
      "|    n_updates            | 70360       |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2532        |\n",
      "|    time_elapsed         | 20506       |\n",
      "|    total_timesteps      | 5185536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033647493 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0707      |\n",
      "|    n_updates            | 70370       |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2533        |\n",
      "|    time_elapsed         | 20513       |\n",
      "|    total_timesteps      | 5187584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026987862 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0383      |\n",
      "|    n_updates            | 70380       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2534        |\n",
      "|    time_elapsed         | 20519       |\n",
      "|    total_timesteps      | 5189632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020645155 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 70390       |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5190000, episode_reward=0.26 +/- 0.96\n",
      "Episode length: 29.92 +/- 0.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.26       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5190000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02905559 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.261     |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0527     |\n",
      "|    n_updates            | 70400      |\n",
      "|    policy_gradient_loss | -0.0274    |\n",
      "|    value_loss           | 0.228      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.26\n",
      "SELFPLAY: new best model, bumping up generation to 152\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | -0.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2535     |\n",
      "|    time_elapsed    | 20530    |\n",
      "|    total_timesteps | 5191680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2536        |\n",
      "|    time_elapsed         | 20537       |\n",
      "|    total_timesteps      | 5193728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035779636 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00487     |\n",
      "|    n_updates            | 70410       |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2537        |\n",
      "|    time_elapsed         | 20543       |\n",
      "|    total_timesteps      | 5195776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035322886 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.331      |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00734     |\n",
      "|    n_updates            | 70420       |\n",
      "|    policy_gradient_loss | -0.0341     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2538        |\n",
      "|    time_elapsed         | 20549       |\n",
      "|    total_timesteps      | 5197824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038663372 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0675      |\n",
      "|    n_updates            | 70430       |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2539        |\n",
      "|    time_elapsed         | 20555       |\n",
      "|    total_timesteps      | 5199872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027463332 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 70440       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5200000, episode_reward=0.13 +/- 0.97\n",
      "Episode length: 30.03 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029076058 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.282      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 70450       |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.17     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2540     |\n",
      "|    time_elapsed    | 20566    |\n",
      "|    total_timesteps | 5201920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2541        |\n",
      "|    time_elapsed         | 20574       |\n",
      "|    total_timesteps      | 5203968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029319476 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0415      |\n",
      "|    n_updates            | 70460       |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2542       |\n",
      "|    time_elapsed         | 20580      |\n",
      "|    total_timesteps      | 5206016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03788226 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.202      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0467     |\n",
      "|    n_updates            | 70470      |\n",
      "|    policy_gradient_loss | -0.0315    |\n",
      "|    value_loss           | 0.231      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2543        |\n",
      "|    time_elapsed         | 20586       |\n",
      "|    total_timesteps      | 5208064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024484519 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 70480       |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5210000, episode_reward=0.21 +/- 0.97\n",
      "Episode length: 30.00 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033259425 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0499      |\n",
      "|    n_updates            | 70490       |\n",
      "|    policy_gradient_loss | -0.0303     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 153\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | 0.13     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2544     |\n",
      "|    time_elapsed    | 20597    |\n",
      "|    total_timesteps | 5210112  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2545        |\n",
      "|    time_elapsed         | 20604       |\n",
      "|    total_timesteps      | 5212160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028847076 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0489      |\n",
      "|    n_updates            | 70500       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2546        |\n",
      "|    time_elapsed         | 20610       |\n",
      "|    total_timesteps      | 5214208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032226134 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0425      |\n",
      "|    n_updates            | 70510       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 253        |\n",
      "|    iterations           | 2547       |\n",
      "|    time_elapsed         | 20617      |\n",
      "|    total_timesteps      | 5216256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03367009 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.259      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0282     |\n",
      "|    n_updates            | 70520      |\n",
      "|    policy_gradient_loss | -0.0319    |\n",
      "|    value_loss           | 0.216      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2548        |\n",
      "|    time_elapsed         | 20643       |\n",
      "|    total_timesteps      | 5218304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027102485 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0738      |\n",
      "|    n_updates            | 70530       |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5220000, episode_reward=0.12 +/- 0.96\n",
      "Episode length: 29.89 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030882474 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 70540       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.02     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2549     |\n",
      "|    time_elapsed    | 20676    |\n",
      "|    total_timesteps | 5220352  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2550        |\n",
      "|    time_elapsed         | 20704       |\n",
      "|    total_timesteps      | 5222400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030597396 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0627      |\n",
      "|    n_updates            | 70550       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2551        |\n",
      "|    time_elapsed         | 20732       |\n",
      "|    total_timesteps      | 5224448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024149837 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 70560       |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.17       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 2552       |\n",
      "|    time_elapsed         | 20755      |\n",
      "|    total_timesteps      | 5226496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02489111 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | 0.281      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0517     |\n",
      "|    n_updates            | 70570      |\n",
      "|    policy_gradient_loss | -0.0265    |\n",
      "|    value_loss           | 0.209      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2553        |\n",
      "|    time_elapsed         | 20761       |\n",
      "|    total_timesteps      | 5228544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032470807 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 70580       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5230000, episode_reward=0.13 +/- 0.98\n",
      "Episode length: 29.92 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027333781 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0579      |\n",
      "|    n_updates            | 70590       |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 251      |\n",
      "|    iterations      | 2554     |\n",
      "|    time_elapsed    | 20772    |\n",
      "|    total_timesteps | 5230592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2555        |\n",
      "|    time_elapsed         | 20778       |\n",
      "|    total_timesteps      | 5232640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028923398 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 70600       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2556        |\n",
      "|    time_elapsed         | 20783       |\n",
      "|    total_timesteps      | 5234688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033209834 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0831      |\n",
      "|    n_updates            | 70610       |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2557        |\n",
      "|    time_elapsed         | 20789       |\n",
      "|    total_timesteps      | 5236736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029048596 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0412      |\n",
      "|    n_updates            | 70620       |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2558        |\n",
      "|    time_elapsed         | 20795       |\n",
      "|    total_timesteps      | 5238784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025757944 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000154    |\n",
      "|    n_updates            | 70630       |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5240000, episode_reward=0.14 +/- 0.98\n",
      "Episode length: 29.91 +/- 0.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029047465 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 70640       |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 251      |\n",
      "|    iterations      | 2559     |\n",
      "|    time_elapsed    | 20806    |\n",
      "|    total_timesteps | 5240832  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2560        |\n",
      "|    time_elapsed         | 20813       |\n",
      "|    total_timesteps      | 5242880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024099402 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0131      |\n",
      "|    n_updates            | 70650       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.22       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 251        |\n",
      "|    iterations           | 2561       |\n",
      "|    time_elapsed         | 20818      |\n",
      "|    total_timesteps      | 5244928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03189943 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.306     |\n",
      "|    explained_variance   | 0.249      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0378     |\n",
      "|    n_updates            | 70660      |\n",
      "|    policy_gradient_loss | -0.0304    |\n",
      "|    value_loss           | 0.204      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2562        |\n",
      "|    time_elapsed         | 20824       |\n",
      "|    total_timesteps      | 5246976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026254762 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0322      |\n",
      "|    n_updates            | 70670       |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.8      |\n",
      "|    ep_rew_mean          | 0.12      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 2563      |\n",
      "|    time_elapsed         | 20830     |\n",
      "|    total_timesteps      | 5249024   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0277955 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.315    |\n",
      "|    explained_variance   | 0.228     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.101     |\n",
      "|    n_updates            | 70680     |\n",
      "|    policy_gradient_loss | -0.0322   |\n",
      "|    value_loss           | 0.228     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=5250000, episode_reward=0.14 +/- 0.97\n",
      "Episode length: 30.03 +/- 0.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031224336 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0773      |\n",
      "|    n_updates            | 70690       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 251      |\n",
      "|    iterations      | 2564     |\n",
      "|    time_elapsed    | 20841    |\n",
      "|    total_timesteps | 5251072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 251         |\n",
      "|    iterations           | 2565        |\n",
      "|    time_elapsed         | 20848       |\n",
      "|    total_timesteps      | 5253120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027667308 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0818      |\n",
      "|    n_updates            | 70700       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2566        |\n",
      "|    time_elapsed         | 20853       |\n",
      "|    total_timesteps      | 5255168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026792865 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.301      |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0444      |\n",
      "|    n_updates            | 70710       |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2567        |\n",
      "|    time_elapsed         | 20859       |\n",
      "|    total_timesteps      | 5257216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024353534 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0617      |\n",
      "|    n_updates            | 70720       |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2568        |\n",
      "|    time_elapsed         | 20865       |\n",
      "|    total_timesteps      | 5259264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026373066 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0297      |\n",
      "|    n_updates            | 70730       |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5260000, episode_reward=-0.03 +/- 0.98\n",
      "Episode length: 29.98 +/- 0.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023179524 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00015     |\n",
      "|    n_updates            | 70740       |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2569     |\n",
      "|    time_elapsed    | 20876    |\n",
      "|    total_timesteps | 5261312  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2570       |\n",
      "|    time_elapsed         | 20883      |\n",
      "|    total_timesteps      | 5263360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02526748 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.301     |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0771     |\n",
      "|    n_updates            | 70750      |\n",
      "|    policy_gradient_loss | -0.0315    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2571        |\n",
      "|    time_elapsed         | 20888       |\n",
      "|    total_timesteps      | 5265408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029317137 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 70760       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2572        |\n",
      "|    time_elapsed         | 20894       |\n",
      "|    total_timesteps      | 5267456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026242731 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.318      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 70770       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.06        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2573        |\n",
      "|    time_elapsed         | 20900       |\n",
      "|    total_timesteps      | 5269504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028894257 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 70780       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5270000, episode_reward=0.16 +/- 0.98\n",
      "Episode length: 29.92 +/- 0.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033107217 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 70790       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.04     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2574     |\n",
      "|    time_elapsed    | 20911    |\n",
      "|    total_timesteps | 5271552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2575        |\n",
      "|    time_elapsed         | 20917       |\n",
      "|    total_timesteps      | 5273600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024488462 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.054       |\n",
      "|    n_updates            | 70800       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2576        |\n",
      "|    time_elapsed         | 20922       |\n",
      "|    total_timesteps      | 5275648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025049517 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0373      |\n",
      "|    n_updates            | 70810       |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2577        |\n",
      "|    time_elapsed         | 20928       |\n",
      "|    total_timesteps      | 5277696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025088698 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00401     |\n",
      "|    n_updates            | 70820       |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2578        |\n",
      "|    time_elapsed         | 20934       |\n",
      "|    total_timesteps      | 5279744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028238146 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 70830       |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5280000, episode_reward=0.14 +/- 0.97\n",
      "Episode length: 30.01 +/- 0.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029228916 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00149     |\n",
      "|    n_updates            | 70840       |\n",
      "|    policy_gradient_loss | -0.0311     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2579     |\n",
      "|    time_elapsed    | 20945    |\n",
      "|    total_timesteps | 5281792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2580        |\n",
      "|    time_elapsed         | 20951       |\n",
      "|    total_timesteps      | 5283840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029313307 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.31       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0156      |\n",
      "|    n_updates            | 70850       |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2581        |\n",
      "|    time_elapsed         | 20957       |\n",
      "|    total_timesteps      | 5285888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036226653 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 70860       |\n",
      "|    policy_gradient_loss | -0.0337     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2582        |\n",
      "|    time_elapsed         | 20963       |\n",
      "|    total_timesteps      | 5287936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028558033 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0602      |\n",
      "|    n_updates            | 70870       |\n",
      "|    policy_gradient_loss | -0.0288     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2583        |\n",
      "|    time_elapsed         | 20969       |\n",
      "|    total_timesteps      | 5289984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034021102 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0645      |\n",
      "|    n_updates            | 70880       |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5290000, episode_reward=0.21 +/- 0.96\n",
      "Episode length: 30.04 +/- 0.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.21       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5290000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03163365 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.314     |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0332     |\n",
      "|    n_updates            | 70890      |\n",
      "|    policy_gradient_loss | -0.0326    |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "SELFPLAY: mean_reward achieved: 0.21\n",
      "SELFPLAY: new best model, bumping up generation to 154\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.11    |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2584     |\n",
      "|    time_elapsed    | 20980    |\n",
      "|    total_timesteps | 5292032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2585        |\n",
      "|    time_elapsed         | 20986       |\n",
      "|    total_timesteps      | 5294080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039123487 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 70900       |\n",
      "|    policy_gradient_loss | -0.0314     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | -0.17      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2586       |\n",
      "|    time_elapsed         | 20992      |\n",
      "|    total_timesteps      | 5296128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02849719 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.318     |\n",
      "|    explained_variance   | 0.353      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.052      |\n",
      "|    n_updates            | 70910      |\n",
      "|    policy_gradient_loss | -0.0327    |\n",
      "|    value_loss           | 0.205      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2587        |\n",
      "|    time_elapsed         | 20998       |\n",
      "|    total_timesteps      | 5298176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031644203 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 70920       |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5300000, episode_reward=0.11 +/- 0.99\n",
      "Episode length: 29.87 +/- 0.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5300000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02489115 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.232      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0157     |\n",
      "|    n_updates            | 70930      |\n",
      "|    policy_gradient_loss | -0.0309    |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.08    |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2588     |\n",
      "|    time_elapsed    | 21009    |\n",
      "|    total_timesteps | 5300224  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.01       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2589       |\n",
      "|    time_elapsed         | 21015      |\n",
      "|    total_timesteps      | 5302272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02921598 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.332     |\n",
      "|    explained_variance   | 0.263      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0538     |\n",
      "|    n_updates            | 70940      |\n",
      "|    policy_gradient_loss | -0.0333    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2590        |\n",
      "|    time_elapsed         | 21021       |\n",
      "|    total_timesteps      | 5304320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025697239 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0332      |\n",
      "|    n_updates            | 70950       |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.06      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2591       |\n",
      "|    time_elapsed         | 21027      |\n",
      "|    total_timesteps      | 5306368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03751187 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.321     |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.033      |\n",
      "|    n_updates            | 70960      |\n",
      "|    policy_gradient_loss | -0.0318    |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2592        |\n",
      "|    time_elapsed         | 21032       |\n",
      "|    total_timesteps      | 5308416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028855143 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.325      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 70970       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5310000, episode_reward=0.04 +/- 1.00\n",
      "Episode length: 30.02 +/- 0.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026895897 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0426      |\n",
      "|    n_updates            | 70980       |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.06     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2593     |\n",
      "|    time_elapsed    | 21043    |\n",
      "|    total_timesteps | 5310464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2594        |\n",
      "|    time_elapsed         | 21050       |\n",
      "|    total_timesteps      | 5312512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034469817 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0387      |\n",
      "|    n_updates            | 70990       |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2595        |\n",
      "|    time_elapsed         | 21056       |\n",
      "|    total_timesteps      | 5314560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025793556 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 71000       |\n",
      "|    policy_gradient_loss | -0.0325     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2596        |\n",
      "|    time_elapsed         | 21061       |\n",
      "|    total_timesteps      | 5316608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027879218 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.074       |\n",
      "|    n_updates            | 71010       |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2597        |\n",
      "|    time_elapsed         | 21068       |\n",
      "|    total_timesteps      | 5318656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033080444 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0339      |\n",
      "|    n_updates            | 71020       |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5320000, episode_reward=-0.04 +/- 0.99\n",
      "Episode length: 29.92 +/- 0.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027677372 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0678      |\n",
      "|    n_updates            | 71030       |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.15     |\n",
      "| time/              |          |\n",
      "|    fps             | 252      |\n",
      "|    iterations      | 2598     |\n",
      "|    time_elapsed    | 21079    |\n",
      "|    total_timesteps | 5320704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.31        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2599        |\n",
      "|    time_elapsed         | 21085       |\n",
      "|    total_timesteps      | 5322752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027583469 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 71040       |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2600        |\n",
      "|    time_elapsed         | 21091       |\n",
      "|    total_timesteps      | 5324800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027667975 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00451     |\n",
      "|    n_updates            | 71050       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 252        |\n",
      "|    iterations           | 2601       |\n",
      "|    time_elapsed         | 21097      |\n",
      "|    total_timesteps      | 5326848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03042652 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.273     |\n",
      "|    explained_variance   | 0.327      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.041      |\n",
      "|    n_updates            | 71060      |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 0.199      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.24        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2602        |\n",
      "|    time_elapsed         | 21104       |\n",
      "|    total_timesteps      | 5328896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027830414 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 71070       |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = OthelloEnv()\n",
    "env = Monitor(env=env)\n",
    "env = FlattenObservation(env)\n",
    "\n",
    "starting_model_filepath = 'history_00000385'\n",
    "\n",
    "# model = MaskablePPO(policy=MaskableActorCriticPolicy, env=env, verbose=1)\n",
    "model = MaskablePPO.load(starting_model_filepath, env=env)\n",
    "\n",
    "start_model_copy = model.load(starting_model_filepath)\n",
    "env.unwrapped.change_to_latest_agent(start_model_copy)\n",
    "\n",
    "\n",
    "env_eval = OthelloEnv()\n",
    "env_eval = Monitor(env=env_eval)\n",
    "env_eval = FlattenObservation(env_eval)\n",
    "\n",
    "env_eval = DummyVecEnv(env_fns=[lambda: env_eval])\n",
    "env_eval.envs[0].unwrapped.change_to_latest_agent(start_model_copy)\n",
    "\n",
    "\n",
    "\n",
    "eval_callback = SelfPlayCallback(\n",
    "    env,\n",
    "    env_eval,\n",
    "    best_model_save_path=LOGDIR,\n",
    "    log_path=LOGDIR,\n",
    "    eval_freq=EVAL_FREQ,\n",
    "    n_eval_episodes=EVAL_EPISODES,\n",
    "    deterministic=False \n",
    "    )\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=NUM_TIMESTEPS, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1076a2e9-f6ec-4ace-a5c7-6d6863935c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('board',\n",
       "              array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                     [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                     [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                     [0, 0, 0, 1, 2, 0, 0, 0],\n",
       "                     [0, 0, 0, 2, 1, 0, 0, 0],\n",
       "                     [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                     [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                     [0, 0, 0, 0, 0, 0, 0, 0]])),\n",
       "             ('player', 1)])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.unwrapped.get_obs()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "19b6d5cf-09f8-463b-a95d-3a9add321149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs = spaces.flatten(env.unwrapped.observation_space, obs)\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8ed10-d6d0-4363-9516-89dda14fd7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f7da2c24-2262-4c6c-8464-ae1cb2390730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(22), None)\n",
      "(array(29), None)\n",
      "(array(41), None)\n",
      "(array(28), None)\n",
      "(array(5), None)\n",
      "(array(46), None)\n",
      "(array(24), None)\n",
      "(array(13), None)\n",
      "(array(40), None)\n",
      "(array(59), None)\n",
      "(array(13), None)\n",
      "(array(45), None)\n",
      "(array(18), None)\n",
      "(array(62), None)\n",
      "(array(51), None)\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print(model.predict(new_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ede4294c-f6cf-4fff-b4ae-83f2a1c14ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 2, 2,\n",
       "       1, 2, 1, 0, 2, 2, 1, 1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 0, 0, 1, 0,\n",
       "       2, 2, 1, 1, 0, 2, 1, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 0, 2, 0, 0, 1])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc4e49-8b25-4a20-9d99-6e9b04d61b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0969e-6711-4e9a-9ceb-3e6ea3b9d304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5ec1f886-e37f-496d-b6e5-dd33ccd191fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_eval = OthelloEnv()\n",
    "env_eval = Monitor(env=env_eval)\n",
    "env_eval = FlattenObservation(env_eval)\n",
    "\n",
    "env_eval = DummyVecEnv(env_fns=[lambda: env_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2b4b5155-d19f-4bc2-91da-bbc09b488fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MaskablePPO.load('ppo_masked_selfplay/history_00000385.zip')\n",
    "model_random = MaskablePPO.load('ppo_masked_selfplay/history_00000170.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9b6d8668-3386-434d-97b8-a8ed3ba6ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_eval.envs[0].unwrapped.change_to_latest_agent(model_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d252cb9d-8f37-4209-9da1-80252d48d806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep done - 310.\n",
      "Ep done - 320.\n",
      "Ep done - 330.\n",
      "Ep done - 340.\n",
      "Ep done - 350.\n",
      "Ep done - 360.\n",
      "Ep done - 370.\n",
      "Ep done - 380.\n",
      "Ep done - 390.\n",
      "Ep done - 400.\n"
     ]
    }
   ],
   "source": [
    "episode_rewards, episode_lengths = evaluate_policy(\n",
    "                model1,\n",
    "                env_eval,\n",
    "                n_eval_episodes=100,                \n",
    "                deterministic=True,\n",
    "                return_episode_rewards=True,\n",
    "                warn=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3527ceef-0eb6-4e5c-bf97-1e83b354a502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed67b8-6289-4c32-970e-362e1f44165d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7ebfd-6326-45c0-be8e-0bc89976894e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "ml-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
