CUDA Available: True
CPU Model: Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz
GPU Model: NVIDIA GeForce RTX 2070 SUPER
2024-06-06 00:55:03.403306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-06 00:55:03.513203: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-06-06 00:55:04.181219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/student/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/cuda-11.8/lib64:/opt/cuda-11.8/extras/CUPTI/lib64:/opt/cuda-11.8/lib64/stubs:/opt/cuda-11.8/targets/x86_64-linux/lib
2024-06-06 00:55:04.181282: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/student/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/cuda-11.8/lib64:/opt/cuda-11.8/extras/CUPTI/lib64:/opt/cuda-11.8/lib64/stubs:/opt/cuda-11.8/targets/x86_64-linux/lib
2024-06-06 00:55:04.181290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
CUDA available: True
Using cuda device
Wrapping the env in a DummyVecEnv.
Ep done - 10.
Ep done - 20.
Ep done - 30.
Ep done - 40.
Ep done - 50.
Ep done - 60.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | -0.206   |
| time/              |          |
|    fps             | 409      |
|    iterations      | 1        |
|    time_elapsed    | 5        |
|    total_timesteps | 2048     |
---------------------------------
Ep done - 70.
Ep done - 80.
Ep done - 90.
Ep done - 100.
Ep done - 110.
Ep done - 120.
Ep done - 130.
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 30           |
|    ep_rew_mean          | -0.07        |
| time/                   |              |
|    fps                  | 372          |
|    iterations           | 2            |
|    time_elapsed         | 10           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0103657665 |
|    clip_fraction        | 0.084        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | -0.502       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.042       |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.0418      |
|    value_loss           | 0.152        |
------------------------------------------
Ep done - 140.
Ep done - 150.
Ep done - 160.
Ep done - 170.
Ep done - 180.
Ep done - 190.
Ep done - 200.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | -0.1        |
| time/                   |             |
|    fps                  | 363         |
|    iterations           | 3           |
|    time_elapsed         | 16          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.012514505 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.0745      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0481     |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0501     |
|    value_loss           | 0.122       |
-----------------------------------------
Ep done - 210.
Ep done - 220.
Ep done - 230.
Ep done - 240.
Ep done - 250.
Ep done - 260.
Ep done - 270.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 358         |
|    iterations           | 4           |
|    time_elapsed         | 22          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011819868 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0354     |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0518     |
|    value_loss           | 0.133       |
-----------------------------------------
Ep done - 280.
Ep done - 290.
Ep done - 300.
Ep done - 310.
Ep done - 320.
Ep done - 330.
Ep done - 340.
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 30           |
|    ep_rew_mean          | 0.11         |
| time/                   |              |
|    fps                  | 356          |
|    iterations           | 5            |
|    time_elapsed         | 28           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.0125063425 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.219        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0425      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.0551      |
|    value_loss           | 0.131        |
------------------------------------------
Ep done - 350.
Ep done - 360.
Ep done - 370.
Ep done - 380.
Ep done - 390.
Ep done - 400.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 354         |
|    iterations           | 6           |
|    time_elapsed         | 34          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.012778956 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.126       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0454     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0545     |
|    value_loss           | 0.143       |
-----------------------------------------
Ep done - 410.
Ep done - 420.
Ep done - 430.
Ep done - 440.
Ep done - 450.
Ep done - 460.
Ep done - 470.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 353         |
|    iterations           | 7           |
|    time_elapsed         | 40          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.013066502 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | -0.00364    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0447     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0555     |
|    value_loss           | 0.134       |
-----------------------------------------
Ep done - 480.
Ep done - 490.
Ep done - 500.
Ep done - 510.
Ep done - 520.
Ep done - 530.
Ep done - 540.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 352         |
|    iterations           | 8           |
|    time_elapsed         | 46          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.012816839 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.0572      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0441     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0558     |
|    value_loss           | 0.132       |
-----------------------------------------
Ep done - 550.
Ep done - 560.
Ep done - 570.
Ep done - 580.
Ep done - 590.
Ep done - 600.
Ep done - 610.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 351         |
|    iterations           | 9           |
|    time_elapsed         | 52          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.012960166 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.182       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0753     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0566     |
|    value_loss           | 0.123       |
-----------------------------------------
Ep done - 620.
Ep done - 630.
Ep done - 640.
Ep done - 650.
Ep done - 660.
Ep done - 10.
Ep done - 20.
Ep done - 30.
Ep done - 40.
Ep done - 50.
Ep done - 60.
Ep done - 70.
Ep done - 80.
Ep done - 90.
Ep done - 100.
Ep done - 110.
Ep done - 120.
Ep done - 130.
Ep done - 140.
Ep done - 150.
Ep done - 160.
Ep done - 170.
Ep done - 180.
Ep done - 190.
Ep done - 200.
Eval num_timesteps=20000, episode_reward=0.37 +/- 0.91
Episode length: 30.08 +/- 0.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.37        |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.013120193 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0623     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0557     |
|    value_loss           | 0.127       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.37
SELFPLAY: new best model, bumping up generation to 1
Ep done - 670.
Ep done - 680.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    fps             | 287      |
|    iterations      | 10       |
|    time_elapsed    | 71       |
|    total_timesteps | 20480    |
---------------------------------
Ep done - 690.
Ep done - 700.
Ep done - 710.
Ep done - 720.
Ep done - 730.
Ep done - 740.
Ep done - 750.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 291         |
|    iterations           | 11          |
|    time_elapsed         | 77          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.014281873 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.17        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0717     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0613     |
|    value_loss           | 0.116       |
-----------------------------------------
Ep done - 760.
Ep done - 770.
Ep done - 780.
Ep done - 790.
Ep done - 800.
Ep done - 810.
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 29.8         |
|    ep_rew_mean          | 0.22         |
| time/                   |              |
|    fps                  | 295          |
|    iterations           | 12           |
|    time_elapsed         | 83           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0145590305 |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.82        |
|    explained_variance   | 0.0366       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0311      |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.057       |
|    value_loss           | 0.146        |
------------------------------------------
Ep done - 820.
Ep done - 830.
Ep done - 840.
Ep done - 850.
Ep done - 860.
Ep done - 870.
Ep done - 880.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 298         |
|    iterations           | 13          |
|    time_elapsed         | 89          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.014494885 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.0893      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0537     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0597     |
|    value_loss           | 0.133       |
-----------------------------------------
Ep done - 890.
Ep done - 900.
Ep done - 910.
Ep done - 920.
Ep done - 930.
Ep done - 940.
Ep done - 950.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 301         |
|    iterations           | 14          |
|    time_elapsed         | 94          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.014915355 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.182       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0768     |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0595     |
|    value_loss           | 0.137       |
-----------------------------------------
Ep done - 960.
Ep done - 970.
Ep done - 980.
Ep done - 990.
Ep done - 1000.
Ep done - 1010.
Ep done - 1020.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 304         |
|    iterations           | 15          |
|    time_elapsed         | 100         |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 0.014790594 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0646     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0592     |
|    value_loss           | 0.133       |
-----------------------------------------
Ep done - 1030.
Ep done - 1040.
Ep done - 1050.
Ep done - 1060.
Ep done - 1070.
Ep done - 1080.
Ep done - 1090.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 306         |
|    iterations           | 16          |
|    time_elapsed         | 106         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.013716448 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.0146      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0608     |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.0579     |
|    value_loss           | 0.131       |
-----------------------------------------
Ep done - 1100.
Ep done - 1110.
Ep done - 1120.
Ep done - 1130.
Ep done - 1140.
Ep done - 1150.
Ep done - 1160.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.23       |
| time/                   |            |
|    fps                  | 308        |
|    iterations           | 17         |
|    time_elapsed         | 112        |
|    total_timesteps      | 34816      |
| train/                  |            |
|    approx_kl            | 0.01488697 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.71      |
|    explained_variance   | 0.252      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0709    |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.0609    |
|    value_loss           | 0.119      |
----------------------------------------
Ep done - 1170.
Ep done - 1180.
Ep done - 1190.
Ep done - 1200.
Ep done - 1210.
Ep done - 1220.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 310         |
|    iterations           | 18          |
|    time_elapsed         | 118         |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.015786264 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.37        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0442     |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0604     |
|    value_loss           | 0.115       |
-----------------------------------------
Ep done - 1230.
Ep done - 1240.
Ep done - 1250.
Ep done - 1260.
Ep done - 1270.
Ep done - 1280.
Ep done - 1290.
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 30           |
|    ep_rew_mean          | 0.35         |
| time/                   |              |
|    fps                  | 311          |
|    iterations           | 19           |
|    time_elapsed         | 124          |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0151733635 |
|    clip_fraction        | 0.18         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.72        |
|    explained_variance   | 0.136        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0731      |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.0622      |
|    value_loss           | 0.131        |
------------------------------------------
Ep done - 1300.
Ep done - 1310.
Ep done - 1320.
Ep done - 1330.
Ep done - 210.
Ep done - 220.
Ep done - 230.
Ep done - 240.
Ep done - 250.
Ep done - 260.
Ep done - 270.
Ep done - 280.
Ep done - 290.
Ep done - 300.
Ep done - 310.
Ep done - 320.
Ep done - 330.
Ep done - 340.
Ep done - 350.
Ep done - 360.
Ep done - 370.
Ep done - 380.
Ep done - 390.
Ep done - 400.
Eval num_timesteps=40000, episode_reward=0.34 +/- 0.92
Episode length: 29.99 +/- 0.50
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 30           |
|    mean_reward          | 0.34         |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0148672955 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.68        |
|    explained_variance   | 0.0556       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0726      |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.0597      |
|    value_loss           | 0.133        |
------------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.34
SELFPLAY: new best model, bumping up generation to 2
Ep done - 1340.
Ep done - 1350.
Ep done - 1360.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    fps             | 285      |
|    iterations      | 20       |
|    time_elapsed    | 143      |
|    total_timesteps | 40960    |
---------------------------------
Ep done - 1370.
Ep done - 1380.
Ep done - 1390.
Ep done - 1400.
Ep done - 1410.
Ep done - 1420.
Ep done - 1430.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.09       |
| time/                   |             |
|    fps                  | 287         |
|    iterations           | 21          |
|    time_elapsed         | 149         |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.018050857 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.163       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0615     |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0645     |
|    value_loss           | 0.127       |
-----------------------------------------
Ep done - 1440.
Ep done - 1450.
Ep done - 1460.
Ep done - 1470.
Ep done - 1480.
Ep done - 1490.
Ep done - 1500.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.07       |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 22          |
|    time_elapsed         | 155         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.015472909 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.296       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0452     |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0581     |
|    value_loss           | 0.136       |
-----------------------------------------
Ep done - 1510.
Ep done - 1520.
Ep done - 1530.
Ep done - 1540.
Ep done - 1550.
Ep done - 1560.
Ep done - 1570.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.03       |
| time/                   |             |
|    fps                  | 291         |
|    iterations           | 23          |
|    time_elapsed         | 161         |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.015094496 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.62       |
|    explained_variance   | 0.0639      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0606     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0581     |
|    value_loss           | 0.148       |
-----------------------------------------
Ep done - 1580.
Ep done - 1590.
Ep done - 1600.
Ep done - 1610.
Ep done - 1620.
Ep done - 1630.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 293         |
|    iterations           | 24          |
|    time_elapsed         | 167         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.016009517 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.6        |
|    explained_variance   | 0.0576      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0419     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0579     |
|    value_loss           | 0.147       |
-----------------------------------------
Ep done - 1640.
Ep done - 1650.
Ep done - 1660.
Ep done - 1670.
Ep done - 1680.
Ep done - 1690.
Ep done - 1700.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 294         |
|    iterations           | 25          |
|    time_elapsed         | 173         |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.014597852 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.215       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0385     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0568     |
|    value_loss           | 0.137       |
-----------------------------------------
Ep done - 1710.
Ep done - 1720.
Ep done - 1730.
Ep done - 1740.
Ep done - 1750.
Ep done - 1760.
Ep done - 1770.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 296         |
|    iterations           | 26          |
|    time_elapsed         | 179         |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.014691584 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.213       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0478     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.057      |
|    value_loss           | 0.132       |
-----------------------------------------
Ep done - 1780.
Ep done - 1790.
Ep done - 1800.
Ep done - 1810.
Ep done - 1820.
Ep done - 1830.
Ep done - 1840.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 297         |
|    iterations           | 27          |
|    time_elapsed         | 185         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.015809294 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.136       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0499     |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0589     |
|    value_loss           | 0.137       |
-----------------------------------------
Ep done - 1850.
Ep done - 1860.
Ep done - 1870.
Ep done - 1880.
Ep done - 1890.
Ep done - 1900.
Ep done - 1910.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 299         |
|    iterations           | 28          |
|    time_elapsed         | 191         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.017684108 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.162       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0707     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0594     |
|    value_loss           | 0.137       |
-----------------------------------------
Ep done - 1920.
Ep done - 1930.
Ep done - 1940.
Ep done - 1950.
Ep done - 1960.
Ep done - 1970.
Ep done - 1980.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 300         |
|    iterations           | 29          |
|    time_elapsed         | 197         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.014831435 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0384     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0562     |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 1990.
Ep done - 2000.
Ep done - 410.
Ep done - 420.
Ep done - 430.
Ep done - 440.
Ep done - 450.
Ep done - 460.
Ep done - 470.
Ep done - 480.
Ep done - 490.
Ep done - 500.
Ep done - 510.
Ep done - 520.
Ep done - 530.
Ep done - 540.
Ep done - 550.
Ep done - 560.
Ep done - 570.
Ep done - 580.
Ep done - 590.
Ep done - 600.
Eval num_timesteps=60000, episode_reward=0.33 +/- 0.93
Episode length: 30.05 +/- 0.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.33        |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.016565656 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.52       |
|    explained_variance   | 0.205       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0646     |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0614     |
|    value_loss           | 0.123       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.33
SELFPLAY: new best model, bumping up generation to 3
Ep done - 2010.
Ep done - 2020.
Ep done - 2030.
Ep done - 2040.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    fps             | 283      |
|    iterations      | 30       |
|    time_elapsed    | 216      |
|    total_timesteps | 61440    |
---------------------------------
Ep done - 2050.
Ep done - 2060.
Ep done - 2070.
Ep done - 2080.
Ep done - 2090.
Ep done - 2100.
Ep done - 2110.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.01       |
| time/                   |             |
|    fps                  | 284         |
|    iterations           | 31          |
|    time_elapsed         | 222         |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.015729167 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0368     |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0567     |
|    value_loss           | 0.141       |
-----------------------------------------
Ep done - 2120.
Ep done - 2130.
Ep done - 2140.
Ep done - 2150.
Ep done - 2160.
Ep done - 2170.
Ep done - 2180.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 29.9      |
|    ep_rew_mean          | -0.08     |
| time/                   |           |
|    fps                  | 286       |
|    iterations           | 32        |
|    time_elapsed         | 228       |
|    total_timesteps      | 65536     |
| train/                  |           |
|    approx_kl            | 0.0148082 |
|    clip_fraction        | 0.162     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.47     |
|    explained_variance   | 0.191     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0131   |
|    n_updates            | 310       |
|    policy_gradient_loss | -0.0557   |
|    value_loss           | 0.138     |
---------------------------------------
Ep done - 2190.
Ep done - 2200.
Ep done - 2210.
Ep done - 2220.
Ep done - 2230.
Ep done - 2240.
Ep done - 2250.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 287         |
|    iterations           | 33          |
|    time_elapsed         | 235         |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.014867909 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | 0.289       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0163     |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0547     |
|    value_loss           | 0.14        |
-----------------------------------------
Ep done - 2260.
Ep done - 2270.
Ep done - 2280.
Ep done - 2290.
Ep done - 2300.
Ep done - 2310.
Ep done - 2320.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 288         |
|    iterations           | 34          |
|    time_elapsed         | 241         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.015198429 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | 0.321       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0425     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0564     |
|    value_loss           | 0.143       |
-----------------------------------------
Ep done - 2330.
Ep done - 2340.
Ep done - 2350.
Ep done - 2360.
Ep done - 2370.
Ep done - 2380.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 289         |
|    iterations           | 35          |
|    time_elapsed         | 247         |
|    total_timesteps      | 71680       |
| train/                  |             |
|    approx_kl            | 0.015533848 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | 0.0915      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0514     |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0559     |
|    value_loss           | 0.144       |
-----------------------------------------
Ep done - 2390.
Ep done - 2400.
Ep done - 2410.
Ep done - 2420.
Ep done - 2430.
Ep done - 2440.
Ep done - 2450.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 290         |
|    iterations           | 36          |
|    time_elapsed         | 253         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.016392447 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | 0.154       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0385     |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.0601     |
|    value_loss           | 0.127       |
-----------------------------------------
Ep done - 2460.
Ep done - 2470.
Ep done - 2480.
Ep done - 2490.
Ep done - 2500.
Ep done - 2510.
Ep done - 2520.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 291         |
|    iterations           | 37          |
|    time_elapsed         | 259         |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.015211087 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0643     |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0575     |
|    value_loss           | 0.143       |
-----------------------------------------
Ep done - 2530.
Ep done - 2540.
Ep done - 2550.
Ep done - 2560.
Ep done - 2570.
Ep done - 2580.
Ep done - 2590.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.4         |
| time/                   |             |
|    fps                  | 292         |
|    iterations           | 38          |
|    time_elapsed         | 265         |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.014590285 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.4        |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0361     |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0537     |
|    value_loss           | 0.141       |
-----------------------------------------
Ep done - 2600.
Ep done - 2610.
Ep done - 2620.
Ep done - 2630.
Ep done - 2640.
Ep done - 2650.
Ep done - 2660.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.28       |
| time/                   |            |
|    fps                  | 293        |
|    iterations           | 39         |
|    time_elapsed         | 271        |
|    total_timesteps      | 79872      |
| train/                  |            |
|    approx_kl            | 0.01599773 |
|    clip_fraction        | 0.176      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.41      |
|    explained_variance   | 0.221      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0455    |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.0583    |
|    value_loss           | 0.136      |
----------------------------------------
Ep done - 610.
Ep done - 620.
Ep done - 630.
Ep done - 640.
Ep done - 650.
Ep done - 660.
Ep done - 670.
Ep done - 680.
Ep done - 690.
Ep done - 700.
Ep done - 710.
Ep done - 720.
Ep done - 730.
Ep done - 740.
Ep done - 750.
Ep done - 760.
Ep done - 770.
Ep done - 780.
Ep done - 790.
Ep done - 800.
Eval num_timesteps=80000, episode_reward=0.18 +/- 0.96
Episode length: 30.02 +/- 0.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.185       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.017553722 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | 0.34        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0701     |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0598     |
|    value_loss           | 0.127       |
-----------------------------------------
Ep done - 2670.
Ep done - 2680.
Ep done - 2690.
Ep done - 2700.
Ep done - 2710.
Ep done - 2720.
Ep done - 2730.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 40       |
|    time_elapsed    | 291      |
|    total_timesteps | 81920    |
---------------------------------
Ep done - 2740.
Ep done - 2750.
Ep done - 2760.
Ep done - 2770.
Ep done - 2780.
Ep done - 2790.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.4         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 41          |
|    time_elapsed         | 298         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.016579349 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.35       |
|    explained_variance   | 0.231       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0387     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0576     |
|    value_loss           | 0.129       |
-----------------------------------------
Ep done - 2800.
Ep done - 2810.
Ep done - 2820.
Ep done - 2830.
Ep done - 2840.
Ep done - 2850.
Ep done - 2860.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.42        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 42          |
|    time_elapsed         | 304         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.015871994 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.0717      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0454     |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0554     |
|    value_loss           | 0.12        |
-----------------------------------------
Ep done - 2870.
Ep done - 2880.
Ep done - 2890.
Ep done - 2900.
Ep done - 2910.
Ep done - 2920.
Ep done - 2930.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.8       |
|    ep_rew_mean          | 0.27       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 43         |
|    time_elapsed         | 311        |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.01591288 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.34      |
|    explained_variance   | 0.23       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0421    |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0556    |
|    value_loss           | 0.14       |
----------------------------------------
Ep done - 2940.
Ep done - 2950.
Ep done - 2960.
Ep done - 2970.
Ep done - 2980.
Ep done - 2990.
Ep done - 3000.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.34       |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 44         |
|    time_elapsed         | 318        |
|    total_timesteps      | 90112      |
| train/                  |            |
|    approx_kl            | 0.01648929 |
|    clip_fraction        | 0.168      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.34      |
|    explained_variance   | -0.0918    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0622    |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0541    |
|    value_loss           | 0.134      |
----------------------------------------
Ep done - 3010.
Ep done - 3020.
Ep done - 3030.
Ep done - 3040.
Ep done - 3050.
Ep done - 3060.
Ep done - 3070.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.22        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 45          |
|    time_elapsed         | 328         |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.016638186 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.0965      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.046      |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0564     |
|    value_loss           | 0.131       |
-----------------------------------------
Ep done - 3080.
Ep done - 3090.
Ep done - 3100.
Ep done - 3110.
Ep done - 3120.
Ep done - 3130.
Ep done - 3140.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 46          |
|    time_elapsed         | 334         |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.015819967 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.0425      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0639     |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0567     |
|    value_loss           | 0.132       |
-----------------------------------------
Ep done - 3150.
Ep done - 3160.
Ep done - 3170.
Ep done - 3180.
Ep done - 3190.
Ep done - 3200.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.34        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 47          |
|    time_elapsed         | 340         |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.014994148 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.36       |
|    explained_variance   | -0.0364     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00422     |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0549     |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 3210.
Ep done - 3220.
Ep done - 3230.
Ep done - 3240.
Ep done - 3250.
Ep done - 3260.
Ep done - 3270.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.32       |
| time/                   |            |
|    fps                  | 284        |
|    iterations           | 48         |
|    time_elapsed         | 345        |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.01610304 |
|    clip_fraction        | 0.162      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.31      |
|    explained_variance   | 0.00711    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0531    |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.0548    |
|    value_loss           | 0.146      |
----------------------------------------
Ep done - 3280.
Ep done - 3290.
Ep done - 3300.
Ep done - 3310.
Ep done - 3320.
Ep done - 3330.
Ep done - 810.
Ep done - 820.
Ep done - 830.
Ep done - 840.
Ep done - 850.
Ep done - 860.
Ep done - 870.
Ep done - 880.
Ep done - 890.
Ep done - 900.
Ep done - 910.
Ep done - 920.
Ep done - 930.
Ep done - 940.
Ep done - 950.
Ep done - 960.
Ep done - 970.
Ep done - 980.
Ep done - 990.
Ep done - 1000.
Eval num_timesteps=100000, episode_reward=0.28 +/- 0.94
Episode length: 29.99 +/- 0.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.28        |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.016496744 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.0501      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0571     |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0578     |
|    value_loss           | 0.137       |
-----------------------------------------
Ep done - 3340.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.35     |
| time/              |          |
|    fps             | 275      |
|    iterations      | 49       |
|    time_elapsed    | 364      |
|    total_timesteps | 100352   |
---------------------------------
Ep done - 3350.
Ep done - 3360.
Ep done - 3370.
Ep done - 3380.
Ep done - 3390.
Ep done - 3400.
Ep done - 3410.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 276         |
|    iterations           | 50          |
|    time_elapsed         | 370         |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.017361289 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0521     |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0567     |
|    value_loss           | 0.119       |
-----------------------------------------
Ep done - 3420.
Ep done - 3430.
Ep done - 3440.
Ep done - 3450.
Ep done - 3460.
Ep done - 3470.
Ep done - 3480.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.34        |
| time/                   |             |
|    fps                  | 277         |
|    iterations           | 51          |
|    time_elapsed         | 376         |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.017294321 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0725     |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0591     |
|    value_loss           | 0.121       |
-----------------------------------------
Ep done - 3490.
Ep done - 3500.
Ep done - 3510.
Ep done - 3520.
Ep done - 3530.
Ep done - 3540.
Ep done - 3550.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.48        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 52          |
|    time_elapsed         | 382         |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.017140605 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | 0.282       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0409     |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0565     |
|    value_loss           | 0.127       |
-----------------------------------------
Ep done - 3560.
Ep done - 3570.
Ep done - 3580.
Ep done - 3590.
Ep done - 3600.
Ep done - 3610.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 53          |
|    time_elapsed         | 387         |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.017001284 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.3        |
|    explained_variance   | 0.116       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0754     |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.056      |
|    value_loss           | 0.118       |
-----------------------------------------
Ep done - 3620.
Ep done - 3630.
Ep done - 3640.
Ep done - 3650.
Ep done - 3660.
Ep done - 3670.
Ep done - 3680.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 54          |
|    time_elapsed         | 393         |
|    total_timesteps      | 110592      |
| train/                  |             |
|    approx_kl            | 0.016114112 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | 0.198       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0486     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0538     |
|    value_loss           | 0.125       |
-----------------------------------------
Ep done - 3690.
Ep done - 3700.
Ep done - 3710.
Ep done - 3720.
Ep done - 3730.
Ep done - 3740.
Ep done - 3750.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.52        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 55          |
|    time_elapsed         | 399         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.016962174 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0354     |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0529     |
|    value_loss           | 0.138       |
-----------------------------------------
Ep done - 3760.
Ep done - 3770.
Ep done - 3780.
Ep done - 3790.
Ep done - 3800.
Ep done - 3810.
Ep done - 3820.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.42        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 56          |
|    time_elapsed         | 405         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.016264947 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.21       |
|    explained_variance   | 0.0454      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0476     |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0531     |
|    value_loss           | 0.106       |
-----------------------------------------
Ep done - 3830.
Ep done - 3840.
Ep done - 3850.
Ep done - 3860.
Ep done - 3870.
Ep done - 3880.
Ep done - 3890.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.2        |
|    ep_rew_mean          | 0.7         |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 57          |
|    time_elapsed         | 411         |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.017764958 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0507     |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0537     |
|    value_loss           | 0.113       |
-----------------------------------------
Ep done - 3900.
Ep done - 3910.
Ep done - 3920.
Ep done - 3930.
Ep done - 3940.
Ep done - 3950.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.49        |
| time/                   |             |
|    fps                  | 284         |
|    iterations           | 58          |
|    time_elapsed         | 417         |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.017877812 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | 0.00143     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.062      |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0527     |
|    value_loss           | 0.0667      |
-----------------------------------------
Ep done - 3960.
Ep done - 3970.
Ep done - 3980.
Ep done - 3990.
Ep done - 1010.
Ep done - 1020.
Ep done - 1030.
Ep done - 1040.
Ep done - 1050.
Ep done - 1060.
Ep done - 1070.
Ep done - 1080.
Ep done - 1090.
Ep done - 1100.
Ep done - 1110.
Ep done - 1120.
Ep done - 1130.
Ep done - 1140.
Ep done - 1150.
Ep done - 1160.
Ep done - 1170.
Ep done - 1180.
Ep done - 1190.
Ep done - 1200.
Eval num_timesteps=120000, episode_reward=0.47 +/- 0.85
Episode length: 30.00 +/- 0.52
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.465       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.014661934 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | 0.323       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0666     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.106       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.465
SELFPLAY: new best model, bumping up generation to 4
Ep done - 4000.
Ep done - 4010.
Ep done - 4020.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.33     |
| time/              |          |
|    fps             | 277      |
|    iterations      | 59       |
|    time_elapsed    | 435      |
|    total_timesteps | 120832   |
---------------------------------
Ep done - 4030.
Ep done - 4040.
Ep done - 4050.
Ep done - 4060.
Ep done - 4070.
Ep done - 4080.
Ep done - 4090.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 60          |
|    time_elapsed         | 441         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.017513297 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.18       |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.059      |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0533     |
|    value_loss           | 0.133       |
-----------------------------------------
Ep done - 4100.
Ep done - 4110.
Ep done - 4120.
Ep done - 4130.
Ep done - 4140.
Ep done - 4150.
Ep done - 4160.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 61          |
|    time_elapsed         | 447         |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.016251259 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | -0.041      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0241     |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0526     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 4170.
Ep done - 4180.
Ep done - 4190.
Ep done - 4200.
Ep done - 4210.
Ep done - 4220.
Ep done - 4230.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.13       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 62         |
|    time_elapsed         | 453        |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.01687716 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.19      |
|    explained_variance   | 0.167      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0546    |
|    n_updates            | 610        |
|    policy_gradient_loss | -0.0536    |
|    value_loss           | 0.165      |
----------------------------------------
Ep done - 4240.
Ep done - 4250.
Ep done - 4260.
Ep done - 4270.
Ep done - 4280.
Ep done - 4290.
Ep done - 4300.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 63          |
|    time_elapsed         | 459         |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.016880266 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.15       |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0234     |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.052      |
|    value_loss           | 0.144       |
-----------------------------------------
Ep done - 4310.
Ep done - 4320.
Ep done - 4330.
Ep done - 4340.
Ep done - 4350.
Ep done - 4360.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 64          |
|    time_elapsed         | 465         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.016675837 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.19       |
|    explained_variance   | 0.254       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0393     |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0536     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 4370.
Ep done - 4380.
Ep done - 4390.
Ep done - 4400.
Ep done - 4410.
Ep done - 4420.
Ep done - 4430.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 65          |
|    time_elapsed         | 471         |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.016522389 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.17       |
|    explained_variance   | 0.0844      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0163     |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0516     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 4440.
Ep done - 4450.
Ep done - 4460.
Ep done - 4470.
Ep done - 4480.
Ep done - 4490.
Ep done - 4500.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 66          |
|    time_elapsed         | 477         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.016481334 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.14       |
|    explained_variance   | 0.0117      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0137     |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0517     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 4510.
Ep done - 4520.
Ep done - 4530.
Ep done - 4540.
Ep done - 4550.
Ep done - 4560.
Ep done - 4570.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 284         |
|    iterations           | 67          |
|    time_elapsed         | 482         |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.016096428 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.12       |
|    explained_variance   | 0.164       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00852    |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0513     |
|    value_loss           | 0.144       |
-----------------------------------------
Ep done - 4580.
Ep done - 4590.
Ep done - 4600.
Ep done - 4610.
Ep done - 4620.
Ep done - 4630.
Ep done - 4640.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 284         |
|    iterations           | 68          |
|    time_elapsed         | 488         |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.015763303 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.13       |
|    explained_variance   | 0.0351      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0643     |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0533     |
|    value_loss           | 0.141       |
-----------------------------------------
Ep done - 4650.
Ep done - 4660.
Ep done - 1210.
Ep done - 1220.
Ep done - 1230.
Ep done - 1240.
Ep done - 1250.
Ep done - 1260.
Ep done - 1270.
Ep done - 1280.
Ep done - 1290.
Ep done - 1300.
Ep done - 1310.
Ep done - 1320.
Ep done - 1330.
Ep done - 1340.
Ep done - 1350.
Ep done - 1360.
Ep done - 1370.
Ep done - 1380.
Ep done - 1390.
Ep done - 1400.
Eval num_timesteps=140000, episode_reward=0.23 +/- 0.95
Episode length: 30.00 +/- 0.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.225      |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.01709611 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.1       |
|    explained_variance   | 0.133      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0422    |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.0541    |
|    value_loss           | 0.148      |
----------------------------------------
Ep done - 4670.
Ep done - 4680.
Ep done - 4690.
Ep done - 4700.
Ep done - 4710.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 69       |
|    time_elapsed    | 507      |
|    total_timesteps | 141312   |
---------------------------------
Ep done - 4720.
Ep done - 4730.
Ep done - 4740.
Ep done - 4750.
Ep done - 4760.
Ep done - 4770.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 70          |
|    time_elapsed         | 513         |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.016543146 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | 0.145       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0563     |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.052      |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 4780.
Ep done - 4790.
Ep done - 4800.
Ep done - 4810.
Ep done - 4820.
Ep done - 4830.
Ep done - 4840.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 71          |
|    time_elapsed         | 519         |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.016567834 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0219     |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.053      |
|    value_loss           | 0.144       |
-----------------------------------------
Ep done - 4850.
Ep done - 4860.
Ep done - 4870.
Ep done - 4880.
Ep done - 4890.
Ep done - 4900.
Ep done - 4910.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.34        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 72          |
|    time_elapsed         | 525         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.016619928 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.128       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0507     |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0533     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 4920.
Ep done - 4930.
Ep done - 4940.
Ep done - 4950.
Ep done - 4960.
Ep done - 4970.
Ep done - 4980.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.45        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 73          |
|    time_elapsed         | 530         |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.016093811 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | 0.157       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0338     |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0511     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 4990.
Ep done - 5000.
Ep done - 5010.
Ep done - 5020.
Ep done - 5030.
Ep done - 5040.
Ep done - 5050.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 74          |
|    time_elapsed         | 536         |
|    total_timesteps      | 151552      |
| train/                  |             |
|    approx_kl            | 0.015637869 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | 0.0661      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0248     |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0488     |
|    value_loss           | 0.13        |
-----------------------------------------
Ep done - 5060.
Ep done - 5070.
Ep done - 5080.
Ep done - 5090.
Ep done - 5100.
Ep done - 5110.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.26        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 75          |
|    time_elapsed         | 542         |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.016442262 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.141       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0327     |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0516     |
|    value_loss           | 0.149       |
-----------------------------------------
Ep done - 5120.
Ep done - 5130.
Ep done - 5140.
Ep done - 5150.
Ep done - 5160.
Ep done - 5170.
Ep done - 5180.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.33       |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 76         |
|    time_elapsed         | 548        |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.01787345 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.04      |
|    explained_variance   | 0.151      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0308    |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.051     |
|    value_loss           | 0.153      |
----------------------------------------
Ep done - 5190.
Ep done - 5200.
Ep done - 5210.
Ep done - 5220.
Ep done - 5230.
Ep done - 5240.
Ep done - 5250.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.22       |
| time/                   |            |
|    fps                  | 284        |
|    iterations           | 77         |
|    time_elapsed         | 554        |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.01921147 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.07      |
|    explained_variance   | 0.169      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0353    |
|    n_updates            | 760        |
|    policy_gradient_loss | -0.0507    |
|    value_loss           | 0.163      |
----------------------------------------
Ep done - 5260.
Ep done - 5270.
Ep done - 5280.
Ep done - 5290.
Ep done - 5300.
Ep done - 5310.
Ep done - 5320.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 284         |
|    iterations           | 78          |
|    time_elapsed         | 560         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.019924233 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.09       |
|    explained_variance   | -0.0702     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0541     |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0547     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 5330.
Ep done - 1410.
Ep done - 1420.
Ep done - 1430.
Ep done - 1440.
Ep done - 1450.
Ep done - 1460.
Ep done - 1470.
Ep done - 1480.
Ep done - 1490.
Ep done - 1500.
Ep done - 1510.
Ep done - 1520.
Ep done - 1530.
Ep done - 1540.
Ep done - 1550.
Ep done - 1560.
Ep done - 1570.
Ep done - 1580.
Ep done - 1590.
Ep done - 1600.
Eval num_timesteps=160000, episode_reward=0.42 +/- 0.89
Episode length: 30.07 +/- 0.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.42        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.016779944 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | 0.0502      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0422     |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.141       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.42
SELFPLAY: new best model, bumping up generation to 5
Ep done - 5340.
Ep done - 5350.
Ep done - 5360.
Ep done - 5370.
Ep done - 5380.
Ep done - 5390.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.37     |
| time/              |          |
|    fps             | 279      |
|    iterations      | 79       |
|    time_elapsed    | 579      |
|    total_timesteps | 161792   |
---------------------------------
Ep done - 5400.
Ep done - 5410.
Ep done - 5420.
Ep done - 5430.
Ep done - 5440.
Ep done - 5450.
Ep done - 5460.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 80          |
|    time_elapsed         | 585         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.017049704 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0618     |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.13        |
-----------------------------------------
Ep done - 5470.
Ep done - 5480.
Ep done - 5490.
Ep done - 5500.
Ep done - 5510.
Ep done - 5520.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.04       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 81          |
|    time_elapsed         | 591         |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.017147707 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.06       |
|    explained_variance   | 0.0299      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0369     |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.0504     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 5530.
Ep done - 5540.
Ep done - 5550.
Ep done - 5560.
Ep done - 5570.
Ep done - 5580.
Ep done - 5590.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.11       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 82          |
|    time_elapsed         | 597         |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.016840234 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.07       |
|    explained_variance   | 0.0863      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0398     |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0508     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 5600.
Ep done - 5610.
Ep done - 5620.
Ep done - 5630.
Ep done - 5640.
Ep done - 5650.
Ep done - 5660.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | -0.09      |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 83         |
|    time_elapsed         | 603        |
|    total_timesteps      | 169984     |
| train/                  |            |
|    approx_kl            | 0.01760051 |
|    clip_fraction        | 0.181      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.04      |
|    explained_variance   | 0.135      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0303    |
|    n_updates            | 820        |
|    policy_gradient_loss | -0.0525    |
|    value_loss           | 0.161      |
----------------------------------------
Ep done - 5670.
Ep done - 5680.
Ep done - 5690.
Ep done - 5700.
Ep done - 5710.
Ep done - 5720.
Ep done - 5730.
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 29.9         |
|    ep_rew_mean          | 0            |
| time/                   |              |
|    fps                  | 282          |
|    iterations           | 84           |
|    time_elapsed         | 609          |
|    total_timesteps      | 172032       |
| train/                  |              |
|    approx_kl            | 0.0152353365 |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.04        |
|    explained_variance   | 0.00425      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0217      |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.0485      |
|    value_loss           | 0.171        |
------------------------------------------
Ep done - 5740.
Ep done - 5750.
Ep done - 5760.
Ep done - 5770.
Ep done - 5780.
Ep done - 5790.
Ep done - 5800.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | -0.08      |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 85         |
|    time_elapsed         | 614        |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.01626753 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.998     |
|    explained_variance   | 0.129      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0252    |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.0492    |
|    value_loss           | 0.15       |
----------------------------------------
Ep done - 5810.
Ep done - 5820.
Ep done - 5830.
Ep done - 5840.
Ep done - 5850.
Ep done - 5860.
Ep done - 5870.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.15       |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 86          |
|    time_elapsed         | 620         |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.019873116 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.0594      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0459     |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0538     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 5880.
Ep done - 5890.
Ep done - 5900.
Ep done - 5910.
Ep done - 5920.
Ep done - 5930.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.01        |
| time/                   |             |
|    fps                  | 284         |
|    iterations           | 87          |
|    time_elapsed         | 626         |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.016141556 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0295     |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.148       |
-----------------------------------------
Ep done - 5940.
Ep done - 5950.
Ep done - 5960.
Ep done - 5970.
Ep done - 5980.
Ep done - 5990.
Ep done - 6000.
Ep done - 1610.
Ep done - 1620.
Ep done - 1630.
Ep done - 1640.
Ep done - 1650.
Ep done - 1660.
Ep done - 1670.
Ep done - 1680.
Ep done - 1690.
Ep done - 1700.
Ep done - 1710.
Ep done - 1720.
Ep done - 1730.
Ep done - 1740.
Ep done - 1750.
Ep done - 1760.
Ep done - 1770.
Ep done - 1780.
Ep done - 1790.
Ep done - 1800.
Eval num_timesteps=180000, episode_reward=0.28 +/- 0.94
Episode length: 29.95 +/- 1.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.285       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.016516816 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00986    |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.151       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.12     |
| time/              |          |
|    fps             | 279      |
|    iterations      | 88       |
|    time_elapsed    | 645      |
|    total_timesteps | 180224   |
---------------------------------
Ep done - 6010.
Ep done - 6020.
Ep done - 6030.
Ep done - 6040.
Ep done - 6050.
Ep done - 6060.
Ep done - 6070.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.11        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 89          |
|    time_elapsed         | 651         |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.015430394 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.957      |
|    explained_variance   | 0.0698      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0282     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 6080.
Ep done - 6090.
Ep done - 6100.
Ep done - 6110.
Ep done - 6120.
Ep done - 6130.
Ep done - 6140.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.06       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 90         |
|    time_elapsed         | 657        |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.01826426 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.977     |
|    explained_variance   | -0.00173   |
|    learning_rate        | 0.0003     |
|    loss                 | -0.02      |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.0518    |
|    value_loss           | 0.169      |
----------------------------------------
Ep done - 6150.
Ep done - 6160.
Ep done - 6170.
Ep done - 6180.
Ep done - 6190.
Ep done - 6200.
Ep done - 6210.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.09       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 91         |
|    time_elapsed         | 663        |
|    total_timesteps      | 186368     |
| train/                  |            |
|    approx_kl            | 0.01761029 |
|    clip_fraction        | 0.176      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.968     |
|    explained_variance   | 0.204      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0274    |
|    n_updates            | 900        |
|    policy_gradient_loss | -0.0505    |
|    value_loss           | 0.136      |
----------------------------------------
Ep done - 6220.
Ep done - 6230.
Ep done - 6240.
Ep done - 6250.
Ep done - 6260.
Ep done - 6270.
Ep done - 6280.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 92          |
|    time_elapsed         | 669         |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.016838914 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.943      |
|    explained_variance   | 0.0399      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00882    |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 6290.
Ep done - 6300.
Ep done - 6310.
Ep done - 6320.
Ep done - 6330.
Ep done - 6340.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 93          |
|    time_elapsed         | 675         |
|    total_timesteps      | 190464      |
| train/                  |             |
|    approx_kl            | 0.017844986 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.942      |
|    explained_variance   | 0.139       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0325     |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.13        |
-----------------------------------------
Ep done - 6350.
Ep done - 6360.
Ep done - 6370.
Ep done - 6380.
Ep done - 6390.
Ep done - 6400.
Ep done - 6410.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 94          |
|    time_elapsed         | 681         |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.016740143 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.964      |
|    explained_variance   | 0.227       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0286     |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.139       |
-----------------------------------------
Ep done - 6420.
Ep done - 6430.
Ep done - 6440.
Ep done - 6450.
Ep done - 6460.
Ep done - 6470.
Ep done - 6480.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 95          |
|    time_elapsed         | 688         |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.016784636 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.978      |
|    explained_variance   | -0.0166     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0211     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0469     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 6490.
Ep done - 6500.
Ep done - 6510.
Ep done - 6520.
Ep done - 6530.
Ep done - 6540.
Ep done - 6550.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.27       |
| time/                   |            |
|    fps                  | 283        |
|    iterations           | 96         |
|    time_elapsed         | 694        |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.01891192 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.984     |
|    explained_variance   | 0.244      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00264    |
|    n_updates            | 950        |
|    policy_gradient_loss | -0.0522    |
|    value_loss           | 0.144      |
----------------------------------------
Ep done - 6560.
Ep done - 6570.
Ep done - 6580.
Ep done - 6590.
Ep done - 6600.
Ep done - 6610.
Ep done - 6620.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 97          |
|    time_elapsed         | 700         |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.018186515 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.943      |
|    explained_variance   | 0.105       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0462     |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 6630.
Ep done - 6640.
Ep done - 6650.
Ep done - 6660.
Ep done - 1810.
Ep done - 1820.
Ep done - 1830.
Ep done - 1840.
Ep done - 1850.
Ep done - 1860.
Ep done - 1870.
Ep done - 1880.
Ep done - 1890.
Ep done - 1900.
Ep done - 1910.
Ep done - 1920.
Ep done - 1930.
Ep done - 1940.
Ep done - 1950.
Ep done - 1960.
Ep done - 1970.
Ep done - 1980.
Ep done - 1990.
Ep done - 2000.
Eval num_timesteps=200000, episode_reward=0.08 +/- 0.98
Episode length: 30.02 +/- 0.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.08       |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.01599786 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.978     |
|    explained_variance   | 0.0333     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00947   |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.0477    |
|    value_loss           | 0.167      |
----------------------------------------
Ep done - 6670.
Ep done - 6680.
Ep done - 6690.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    fps             | 279      |
|    iterations      | 98       |
|    time_elapsed    | 719      |
|    total_timesteps | 200704   |
---------------------------------
Ep done - 6700.
Ep done - 6710.
Ep done - 6720.
Ep done - 6730.
Ep done - 6740.
Ep done - 6750.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 99          |
|    time_elapsed         | 725         |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.015808454 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.962      |
|    explained_variance   | 0.129       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0246     |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 6760.
Ep done - 6770.
Ep done - 6780.
Ep done - 6790.
Ep done - 6800.
Ep done - 6810.
Ep done - 6820.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.2        |
| time/                   |            |
|    fps                  | 279        |
|    iterations           | 100        |
|    time_elapsed         | 731        |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.01908243 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.937     |
|    explained_variance   | 0.0948     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0364    |
|    n_updates            | 990        |
|    policy_gradient_loss | -0.0517    |
|    value_loss           | 0.146      |
----------------------------------------
Ep done - 6830.
Ep done - 6840.
Ep done - 6850.
Ep done - 6860.
Ep done - 6870.
Ep done - 6880.
Ep done - 6890.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 101         |
|    time_elapsed         | 737         |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.015535876 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.933      |
|    explained_variance   | 0.0762      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0191     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0482     |
|    value_loss           | 0.144       |
-----------------------------------------
Ep done - 6900.
Ep done - 6910.
Ep done - 6920.
Ep done - 6930.
Ep done - 6940.
Ep done - 6950.
Ep done - 6960.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 102         |
|    time_elapsed         | 744         |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.016684242 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.924      |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0421     |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 6970.
Ep done - 6980.
Ep done - 6990.
Ep done - 7000.
Ep done - 7010.
Ep done - 7020.
Ep done - 7030.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 103         |
|    time_elapsed         | 750         |
|    total_timesteps      | 210944      |
| train/                  |             |
|    approx_kl            | 0.018689957 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.937      |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0292     |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0482     |
|    value_loss           | 0.147       |
-----------------------------------------
Ep done - 7040.
Ep done - 7050.
Ep done - 7060.
Ep done - 7070.
Ep done - 7080.
Ep done - 7090.
Ep done - 7100.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.32        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 104         |
|    time_elapsed         | 756         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.016922276 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.926      |
|    explained_variance   | 0.183       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0128     |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.051      |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 7110.
Ep done - 7120.
Ep done - 7130.
Ep done - 7140.
Ep done - 7150.
Ep done - 7160.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.52       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 105        |
|    time_elapsed         | 763        |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.01782674 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.925     |
|    explained_variance   | 0.311      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.047     |
|    n_updates            | 1040       |
|    policy_gradient_loss | -0.0489    |
|    value_loss           | 0.112      |
----------------------------------------
Ep done - 7170.
Ep done - 7180.
Ep done - 7190.
Ep done - 7200.
Ep done - 7210.
Ep done - 7220.
Ep done - 7230.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.45        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 106         |
|    time_elapsed         | 773         |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.017479617 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.923      |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0252     |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.047      |
|    value_loss           | 0.108       |
-----------------------------------------
Ep done - 7240.
Ep done - 7250.
Ep done - 7260.
Ep done - 7270.
Ep done - 7280.
Ep done - 7290.
Ep done - 7300.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 107         |
|    time_elapsed         | 779         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.017470438 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.948      |
|    explained_variance   | 0.0301      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0358     |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0478     |
|    value_loss           | 0.149       |
-----------------------------------------
Ep done - 7310.
Ep done - 7320.
Ep done - 7330.
Ep done - 2010.
Ep done - 2020.
Ep done - 2030.
Ep done - 2040.
Ep done - 2050.
Ep done - 2060.
Ep done - 2070.
Ep done - 2080.
Ep done - 2090.
Ep done - 2100.
Ep done - 2110.
Ep done - 2120.
Ep done - 2130.
Ep done - 2140.
Ep done - 2150.
Ep done - 2160.
Ep done - 2170.
Ep done - 2180.
Ep done - 2190.
Ep done - 2200.
Eval num_timesteps=220000, episode_reward=0.35 +/- 0.92
Episode length: 29.95 +/- 1.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.355       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.017934402 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.944      |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0188     |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.15        |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.355
SELFPLAY: new best model, bumping up generation to 6
Ep done - 7340.
Ep done - 7350.
Ep done - 7360.
Ep done - 7370.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | -0.02    |
| time/              |          |
|    fps             | 277      |
|    iterations      | 108      |
|    time_elapsed    | 797      |
|    total_timesteps | 221184   |
---------------------------------
Ep done - 7380.
Ep done - 7390.
Ep done - 7400.
Ep done - 7410.
Ep done - 7420.
Ep done - 7430.
Ep done - 7440.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | -0.18       |
| time/                   |             |
|    fps                  | 277         |
|    iterations           | 109         |
|    time_elapsed         | 803         |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.017320551 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.957      |
|    explained_variance   | 0.261       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0503     |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 7450.
Ep done - 7460.
Ep done - 7470.
Ep done - 7480.
Ep done - 7490.
Ep done - 7500.
Ep done - 7510.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.03       |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 110        |
|    time_elapsed         | 809        |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.01809552 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.975     |
|    explained_variance   | 0.203      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.038     |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.0513    |
|    value_loss           | 0.159      |
----------------------------------------
Ep done - 7520.
Ep done - 7530.
Ep done - 7540.
Ep done - 7550.
Ep done - 7560.
Ep done - 7570.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.03        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 111         |
|    time_elapsed         | 815         |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.019129343 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.938      |
|    explained_variance   | 0.315       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0203     |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.144       |
-----------------------------------------
Ep done - 7580.
Ep done - 7590.
Ep done - 7600.
Ep done - 7610.
Ep done - 7620.
Ep done - 7630.
Ep done - 7640.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.01       |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 112         |
|    time_elapsed         | 820         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.017987903 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.991      |
|    explained_variance   | 0.36        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0199     |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.149       |
-----------------------------------------
Ep done - 7650.
Ep done - 7660.
Ep done - 7670.
Ep done - 7680.
Ep done - 7690.
Ep done - 7700.
Ep done - 7710.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 113         |
|    time_elapsed         | 826         |
|    total_timesteps      | 231424      |
| train/                  |             |
|    approx_kl            | 0.019038498 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.949      |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00631    |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 7720.
Ep done - 7730.
Ep done - 7740.
Ep done - 7750.
Ep done - 7760.
Ep done - 7770.
Ep done - 7780.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.01       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 114         |
|    time_elapsed         | 832         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.018410545 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.963      |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0317     |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.0522     |
|    value_loss           | 0.146       |
-----------------------------------------
Ep done - 7790.
Ep done - 7800.
Ep done - 7810.
Ep done - 7820.
Ep done - 7830.
Ep done - 7840.
Ep done - 7850.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 115         |
|    time_elapsed         | 838         |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.019639177 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.988      |
|    explained_variance   | 0.337       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0405     |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0556     |
|    value_loss           | 0.139       |
-----------------------------------------
Ep done - 7860.
Ep done - 7870.
Ep done - 7880.
Ep done - 7890.
Ep done - 7900.
Ep done - 7910.
Ep done - 7920.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.01        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 116         |
|    time_elapsed         | 843         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.017805107 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.944      |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0286     |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 7930.
Ep done - 7940.
Ep done - 7950.
Ep done - 7960.
Ep done - 7970.
Ep done - 7980.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.14       |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 117         |
|    time_elapsed         | 849         |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.020165745 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.952      |
|    explained_variance   | 0.236       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.002      |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0525     |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 7990.
Ep done - 8000.
Ep done - 2210.
Ep done - 2220.
Ep done - 2230.
Ep done - 2240.
Ep done - 2250.
Ep done - 2260.
Ep done - 2270.
Ep done - 2280.
Ep done - 2290.
Ep done - 2300.
Ep done - 2310.
Ep done - 2320.
Ep done - 2330.
Ep done - 2340.
Ep done - 2350.
Ep done - 2360.
Ep done - 2370.
Ep done - 2380.
Ep done - 2390.
Ep done - 2400.
Eval num_timesteps=240000, episode_reward=0.20 +/- 0.95
Episode length: 30.01 +/- 0.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.205       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.019095175 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.965      |
|    explained_variance   | 0.157       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0335     |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0526     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 8010.
Ep done - 8020.
Ep done - 8030.
Ep done - 8040.
Ep done - 8050.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | -0.12    |
| time/              |          |
|    fps             | 278      |
|    iterations      | 118      |
|    time_elapsed    | 867      |
|    total_timesteps | 241664   |
---------------------------------
Ep done - 8060.
Ep done - 8070.
Ep done - 8080.
Ep done - 8090.
Ep done - 8100.
Ep done - 8110.
Ep done - 8120.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 119         |
|    time_elapsed         | 873         |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.018946886 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.957      |
|    explained_variance   | 0.15        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.026      |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 8130.
Ep done - 8140.
Ep done - 8150.
Ep done - 8160.
Ep done - 8170.
Ep done - 8180.
Ep done - 8190.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 120         |
|    time_elapsed         | 879         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.019163731 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.921      |
|    explained_variance   | 0.152       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0402     |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.051      |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 8200.
Ep done - 8210.
Ep done - 8220.
Ep done - 8230.
Ep done - 8240.
Ep done - 8250.
Ep done - 8260.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.07       |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 121         |
|    time_elapsed         | 885         |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.018452823 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.904      |
|    explained_variance   | 0.0782      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00073    |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 8270.
Ep done - 8280.
Ep done - 8290.
Ep done - 8300.
Ep done - 8310.
Ep done - 8320.
Ep done - 8330.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 122         |
|    time_elapsed         | 890         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.019769453 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.922      |
|    explained_variance   | 0.227       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0318     |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0495     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 8340.
Ep done - 8350.
Ep done - 8360.
Ep done - 8370.
Ep done - 8380.
Ep done - 8390.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 123         |
|    time_elapsed         | 896         |
|    total_timesteps      | 251904      |
| train/                  |             |
|    approx_kl            | 0.018482126 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.926      |
|    explained_variance   | 0.236       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0351     |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.05       |
|    value_loss           | 0.147       |
-----------------------------------------
Ep done - 8400.
Ep done - 8410.
Ep done - 8420.
Ep done - 8430.
Ep done - 8440.
Ep done - 8450.
Ep done - 8460.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 124         |
|    time_elapsed         | 902         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.018682105 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.922      |
|    explained_variance   | 0.113       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.03       |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0537     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 8470.
Ep done - 8480.
Ep done - 8490.
Ep done - 8500.
Ep done - 8510.
Ep done - 8520.
Ep done - 8530.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 125         |
|    time_elapsed         | 908         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.017471362 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.891      |
|    explained_variance   | 0.153       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.033      |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0467     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 8540.
Ep done - 8550.
Ep done - 8560.
Ep done - 8570.
Ep done - 8580.
Ep done - 8590.
Ep done - 8600.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 126         |
|    time_elapsed         | 914         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.015813919 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.876      |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00345    |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0456     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 8610.
Ep done - 8620.
Ep done - 8630.
Ep done - 8640.
Ep done - 8650.
Ep done - 8660.
Ep done - 2410.
Ep done - 2420.
Ep done - 2430.
Ep done - 2440.
Ep done - 2450.
Ep done - 2460.
Ep done - 2470.
Ep done - 2480.
Ep done - 2490.
Ep done - 2500.
Ep done - 2510.
Ep done - 2520.
Ep done - 2530.
Ep done - 2540.
Ep done - 2550.
Ep done - 2560.
Ep done - 2570.
Ep done - 2580.
Ep done - 2590.
Ep done - 2600.
Eval num_timesteps=260000, episode_reward=0.23 +/- 0.97
Episode length: 29.90 +/- 1.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.225       |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.018259197 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.904      |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0156     |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0483     |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 8670.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 127      |
|    time_elapsed    | 932      |
|    total_timesteps | 260096   |
---------------------------------
Ep done - 8680.
Ep done - 8690.
Ep done - 8700.
Ep done - 8710.
Ep done - 8720.
Ep done - 8730.
Ep done - 8740.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 128         |
|    time_elapsed         | 938         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.019632706 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.903      |
|    explained_variance   | 0.186       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00934    |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 8750.
Ep done - 8760.
Ep done - 8770.
Ep done - 8780.
Ep done - 8790.
Ep done - 8800.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 129         |
|    time_elapsed         | 943         |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.018074954 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.901      |
|    explained_variance   | 0.095       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0261     |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 8810.
Ep done - 8820.
Ep done - 8830.
Ep done - 8840.
Ep done - 8850.
Ep done - 8860.
Ep done - 8870.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 130         |
|    time_elapsed         | 949         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.016910404 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.88       |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0275     |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.136       |
-----------------------------------------
Ep done - 8880.
Ep done - 8890.
Ep done - 8900.
Ep done - 8910.
Ep done - 8920.
Ep done - 8930.
Ep done - 8940.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30        |
|    ep_rew_mean          | 0.26      |
| time/                   |           |
|    fps                  | 280       |
|    iterations           | 131       |
|    time_elapsed         | 955       |
|    total_timesteps      | 268288    |
| train/                  |           |
|    approx_kl            | 0.0188395 |
|    clip_fraction        | 0.177     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.854    |
|    explained_variance   | 0.145     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0228   |
|    n_updates            | 1300      |
|    policy_gradient_loss | -0.0492   |
|    value_loss           | 0.149     |
---------------------------------------
Ep done - 8950.
Ep done - 8960.
Ep done - 8970.
Ep done - 8980.
Ep done - 8990.
Ep done - 9000.
Ep done - 9010.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.32        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 132         |
|    time_elapsed         | 961         |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 0.019368362 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.883      |
|    explained_variance   | 0.205       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0375     |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.0514     |
|    value_loss           | 0.133       |
-----------------------------------------
Ep done - 9020.
Ep done - 9030.
Ep done - 9040.
Ep done - 9050.
Ep done - 9060.
Ep done - 9070.
Ep done - 9080.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.3        |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 133        |
|    time_elapsed         | 967        |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.01745636 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.851     |
|    explained_variance   | 0.318      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0252    |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.0491    |
|    value_loss           | 0.146      |
----------------------------------------
Ep done - 9090.
Ep done - 9100.
Ep done - 9110.
Ep done - 9120.
Ep done - 9130.
Ep done - 9140.
Ep done - 9150.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 134         |
|    time_elapsed         | 972         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.018491125 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.847      |
|    explained_variance   | 0.228       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0184     |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.153       |
-----------------------------------------
Ep done - 9160.
Ep done - 9170.
Ep done - 9180.
Ep done - 9190.
Ep done - 9200.
Ep done - 9210.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 135         |
|    time_elapsed         | 978         |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.018340599 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.852      |
|    explained_variance   | 0.268       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0378     |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.125       |
-----------------------------------------
Ep done - 9220.
Ep done - 9230.
Ep done - 9240.
Ep done - 9250.
Ep done - 9260.
Ep done - 9270.
Ep done - 9280.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 136         |
|    time_elapsed         | 984         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.018271534 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.863      |
|    explained_variance   | 0.282       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0158     |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 9290.
Ep done - 9300.
Ep done - 9310.
Ep done - 9320.
Ep done - 9330.
Ep done - 2610.
Ep done - 2620.
Ep done - 2630.
Ep done - 2640.
Ep done - 2650.
Ep done - 2660.
Ep done - 2670.
Ep done - 2680.
Ep done - 2690.
Ep done - 2700.
Ep done - 2710.
Ep done - 2720.
Ep done - 2730.
Ep done - 2740.
Ep done - 2750.
Ep done - 2760.
Ep done - 2770.
Ep done - 2780.
Ep done - 2790.
Ep done - 2800.
Eval num_timesteps=280000, episode_reward=0.24 +/- 0.96
Episode length: 29.97 +/- 0.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.245       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.018167038 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.847      |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00694     |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 9340.
Ep done - 9350.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.33     |
| time/              |          |
|    fps             | 279      |
|    iterations      | 137      |
|    time_elapsed    | 1002     |
|    total_timesteps | 280576   |
---------------------------------
Ep done - 9360.
Ep done - 9370.
Ep done - 9380.
Ep done - 9390.
Ep done - 9400.
Ep done - 9410.
Ep done - 9420.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 138         |
|    time_elapsed         | 1008        |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.018289015 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.871      |
|    explained_variance   | 0.241       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.016      |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.135       |
-----------------------------------------
Ep done - 9430.
Ep done - 9440.
Ep done - 9450.
Ep done - 9460.
Ep done - 9470.
Ep done - 9480.
Ep done - 9490.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 139         |
|    time_elapsed         | 1014        |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.021375898 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.893      |
|    explained_variance   | 0.253       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0527     |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0523     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 9500.
Ep done - 9510.
Ep done - 9520.
Ep done - 9530.
Ep done - 9540.
Ep done - 9550.
Ep done - 9560.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 140         |
|    time_elapsed         | 1020        |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.019102497 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.856      |
|    explained_variance   | 0.252       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00443    |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.049      |
|    value_loss           | 0.136       |
-----------------------------------------
Ep done - 9570.
Ep done - 9580.
Ep done - 9590.
Ep done - 9600.
Ep done - 9610.
Ep done - 9620.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.26        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 141         |
|    time_elapsed         | 1026        |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.019125205 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.895      |
|    explained_variance   | 0.304       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0538     |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.149       |
-----------------------------------------
Ep done - 9630.
Ep done - 9640.
Ep done - 9650.
Ep done - 9660.
Ep done - 9670.
Ep done - 9680.
Ep done - 9690.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 142         |
|    time_elapsed         | 1032        |
|    total_timesteps      | 290816      |
| train/                  |             |
|    approx_kl            | 0.020739555 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.882      |
|    explained_variance   | 0.224       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0356     |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.0511     |
|    value_loss           | 0.139       |
-----------------------------------------
Ep done - 9700.
Ep done - 9710.
Ep done - 9720.
Ep done - 9730.
Ep done - 9740.
Ep done - 9750.
Ep done - 9760.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 143         |
|    time_elapsed         | 1037        |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.019141633 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.866      |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00197     |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0488     |
|    value_loss           | 0.148       |
-----------------------------------------
Ep done - 9770.
Ep done - 9780.
Ep done - 9790.
Ep done - 9800.
Ep done - 9810.
Ep done - 9820.
Ep done - 9830.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 144         |
|    time_elapsed         | 1043        |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.021299208 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.894      |
|    explained_variance   | 0.355       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0267     |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0534     |
|    value_loss           | 0.149       |
-----------------------------------------
Ep done - 9840.
Ep done - 9850.
Ep done - 9860.
Ep done - 9870.
Ep done - 9880.
Ep done - 9890.
Ep done - 9900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 145         |
|    time_elapsed         | 1049        |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.020085186 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.873      |
|    explained_variance   | 0.081       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.012      |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 9910.
Ep done - 9920.
Ep done - 9930.
Ep done - 9940.
Ep done - 9950.
Ep done - 9960.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.32        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 146         |
|    time_elapsed         | 1055        |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.018149678 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.862      |
|    explained_variance   | 0.213       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.018      |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.05       |
|    value_loss           | 0.136       |
-----------------------------------------
Ep done - 9970.
Ep done - 9980.
Ep done - 9990.
Ep done - 10000.
Ep done - 2810.
Ep done - 2820.
Ep done - 2830.
Ep done - 2840.
Ep done - 2850.
Ep done - 2860.
Ep done - 2870.
Ep done - 2880.
Ep done - 2890.
Ep done - 2900.
Ep done - 2910.
Ep done - 2920.
Ep done - 2930.
Ep done - 2940.
Ep done - 2950.
Ep done - 2960.
Ep done - 2970.
Ep done - 2980.
Ep done - 2990.
Ep done - 3000.
Eval num_timesteps=300000, episode_reward=0.35 +/- 0.92
Episode length: 29.95 +/- 1.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.355       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.019294877 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.826      |
|    explained_variance   | 0.319       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.031      |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0471     |
|    value_loss           | 0.142       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.355
SELFPLAY: new best model, bumping up generation to 7
Ep done - 10010.
Ep done - 10020.
Ep done - 10030.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.2      |
| time/              |          |
|    fps             | 280      |
|    iterations      | 147      |
|    time_elapsed    | 1073     |
|    total_timesteps | 301056   |
---------------------------------
Ep done - 10040.
Ep done - 10050.
Ep done - 10060.
Ep done - 10070.
Ep done - 10080.
Ep done - 10090.
Ep done - 10100.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 148         |
|    time_elapsed         | 1079        |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.017961506 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.888      |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0145     |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0489     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 10110.
Ep done - 10120.
Ep done - 10130.
Ep done - 10140.
Ep done - 10150.
Ep done - 10160.
Ep done - 10170.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.01       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 149         |
|    time_elapsed         | 1085        |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.016336672 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.883      |
|    explained_variance   | 0.282       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0354     |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.0455     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 10180.
Ep done - 10190.
Ep done - 10200.
Ep done - 10210.
Ep done - 10220.
Ep done - 10230.
Ep done - 10240.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 150         |
|    time_elapsed         | 1091        |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.018651461 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.888      |
|    explained_variance   | 0.295       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0195     |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.0497     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 10250.
Ep done - 10260.
Ep done - 10270.
Ep done - 10280.
Ep done - 10290.
Ep done - 10300.
Ep done - 10310.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.11        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 151         |
|    time_elapsed         | 1097        |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.020006564 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.872      |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0111     |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.158       |
-----------------------------------------
Ep done - 10320.
Ep done - 10330.
Ep done - 10340.
Ep done - 10350.
Ep done - 10360.
Ep done - 10370.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.39        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 152         |
|    time_elapsed         | 1103        |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.018223638 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.872      |
|    explained_variance   | 0.253       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0252     |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 10380.
Ep done - 10390.
Ep done - 10400.
Ep done - 10410.
Ep done - 10420.
Ep done - 10430.
Ep done - 10440.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.02       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 153        |
|    time_elapsed         | 1109       |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.01812636 |
|    clip_fraction        | 0.163      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.858     |
|    explained_variance   | 0.319      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0423    |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.0479    |
|    value_loss           | 0.118      |
----------------------------------------
Ep done - 10450.
Ep done - 10460.
Ep done - 10470.
Ep done - 10480.
Ep done - 10490.
Ep done - 10500.
Ep done - 10510.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 154         |
|    time_elapsed         | 1115        |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.020680243 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.885      |
|    explained_variance   | 0.219       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00306     |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.166       |
-----------------------------------------
Ep done - 10520.
Ep done - 10530.
Ep done - 10540.
Ep done - 10550.
Ep done - 10560.
Ep done - 10570.
Ep done - 10580.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 155         |
|    time_elapsed         | 1121        |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.018212214 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.867      |
|    explained_variance   | 0.334       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0315     |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 10590.
Ep done - 10600.
Ep done - 10610.
Ep done - 10620.
Ep done - 10630.
Ep done - 10640.
Ep done - 10650.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 156         |
|    time_elapsed         | 1127        |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.017012985 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.862      |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0364     |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.0483     |
|    value_loss           | 0.166       |
-----------------------------------------
Ep done - 10660.
Ep done - 10670.
Ep done - 3010.
Ep done - 3020.
Ep done - 3030.
Ep done - 3040.
Ep done - 3050.
Ep done - 3060.
Ep done - 3070.
Ep done - 3080.
Ep done - 3090.
Ep done - 3100.
Ep done - 3110.
Ep done - 3120.
Ep done - 3130.
Ep done - 3140.
Ep done - 3150.
Ep done - 3160.
Ep done - 3170.
Ep done - 3180.
Ep done - 3190.
Ep done - 3200.
Eval num_timesteps=320000, episode_reward=0.28 +/- 0.95
Episode length: 30.05 +/- 0.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.275       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.019166932 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.813      |
|    explained_variance   | 0.275       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0503     |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 10680.
Ep done - 10690.
Ep done - 10700.
Ep done - 10710.
Ep done - 10720.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 157      |
|    time_elapsed    | 1146     |
|    total_timesteps | 321536   |
---------------------------------
Ep done - 10730.
Ep done - 10740.
Ep done - 10750.
Ep done - 10760.
Ep done - 10770.
Ep done - 10780.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.26        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 158         |
|    time_elapsed         | 1152        |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.020679902 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.838      |
|    explained_variance   | 0.12        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0132      |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.0487     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 10790.
Ep done - 10800.
Ep done - 10810.
Ep done - 10820.
Ep done - 10830.
Ep done - 10840.
Ep done - 10850.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 159         |
|    time_elapsed         | 1158        |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.020450868 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.823      |
|    explained_variance   | 0.295       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0117     |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 10860.
Ep done - 10870.
Ep done - 10880.
Ep done - 10890.
Ep done - 10900.
Ep done - 10910.
Ep done - 10920.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.12       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 160        |
|    time_elapsed         | 1164       |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.01904229 |
|    clip_fraction        | 0.169      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.849     |
|    explained_variance   | 0.25       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00618   |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.0479    |
|    value_loss           | 0.158      |
----------------------------------------
Ep done - 10930.
Ep done - 10940.
Ep done - 10950.
Ep done - 10960.
Ep done - 10970.
Ep done - 10980.
Ep done - 10990.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 161         |
|    time_elapsed         | 1170        |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.018427689 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.837      |
|    explained_variance   | 0.2         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0218     |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 11000.
Ep done - 11010.
Ep done - 11020.
Ep done - 11030.
Ep done - 11040.
Ep done - 11050.
Ep done - 11060.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 162         |
|    time_elapsed         | 1176        |
|    total_timesteps      | 331776      |
| train/                  |             |
|    approx_kl            | 0.016833575 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.833      |
|    explained_variance   | 0.0993      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00132    |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 11070.
Ep done - 11080.
Ep done - 11090.
Ep done - 11100.
Ep done - 11110.
Ep done - 11120.
Ep done - 11130.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 163         |
|    time_elapsed         | 1182        |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.018837057 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.826      |
|    explained_variance   | 0.0894      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0643     |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.0488     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 11140.
Ep done - 11150.
Ep done - 11160.
Ep done - 11170.
Ep done - 11180.
Ep done - 11190.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.32       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 164        |
|    time_elapsed         | 1188       |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.02049912 |
|    clip_fraction        | 0.176      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.83      |
|    explained_variance   | 0.263      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0383    |
|    n_updates            | 1630       |
|    policy_gradient_loss | -0.0499    |
|    value_loss           | 0.146      |
----------------------------------------
Ep done - 11200.
Ep done - 11210.
Ep done - 11220.
Ep done - 11230.
Ep done - 11240.
Ep done - 11250.
Ep done - 11260.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.42        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 165         |
|    time_elapsed         | 1194        |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.019016188 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.827      |
|    explained_variance   | 0.218       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0476     |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.0479     |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 11270.
Ep done - 11280.
Ep done - 11290.
Ep done - 11300.
Ep done - 11310.
Ep done - 11320.
Ep done - 11330.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.46        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 166         |
|    time_elapsed         | 1201        |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.018598353 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.792      |
|    explained_variance   | 0.12        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0533     |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 3210.
Ep done - 3220.
Ep done - 3230.
Ep done - 3240.
Ep done - 3250.
Ep done - 3260.
Ep done - 3270.
Ep done - 3280.
Ep done - 3290.
Ep done - 3300.
Ep done - 3310.
Ep done - 3320.
Ep done - 3330.
Ep done - 3340.
Ep done - 3350.
Ep done - 3360.
Ep done - 3370.
Ep done - 3380.
Ep done - 3390.
Ep done - 3400.
Eval num_timesteps=340000, episode_reward=0.28 +/- 0.94
Episode length: 29.96 +/- 0.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.285       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.018141039 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.797      |
|    explained_variance   | 0.12        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0473     |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.125       |
-----------------------------------------
Ep done - 11340.
Ep done - 11350.
Ep done - 11360.
Ep done - 11370.
Ep done - 11380.
Ep done - 11390.
Ep done - 11400.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    fps             | 279      |
|    iterations      | 167      |
|    time_elapsed    | 1225     |
|    total_timesteps | 342016   |
---------------------------------
Ep done - 11410.
Ep done - 11420.
Ep done - 11430.
Ep done - 11440.
Ep done - 11450.
Ep done - 11460.
Ep done - 11470.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 168         |
|    time_elapsed         | 1231        |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.020981085 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.793      |
|    explained_variance   | 0.354       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0185     |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.0487     |
|    value_loss           | 0.146       |
-----------------------------------------
Ep done - 11480.
Ep done - 11490.
Ep done - 11500.
Ep done - 11510.
Ep done - 11520.
Ep done - 11530.
Ep done - 11540.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 169         |
|    time_elapsed         | 1236        |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.018547064 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.792      |
|    explained_variance   | 0.156       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0137     |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.046      |
|    value_loss           | 0.144       |
-----------------------------------------
Ep done - 11550.
Ep done - 11560.
Ep done - 11570.
Ep done - 11580.
Ep done - 11590.
Ep done - 11600.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.43        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 170         |
|    time_elapsed         | 1242        |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.018347714 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.777      |
|    explained_variance   | 0.267       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0118     |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 11610.
Ep done - 11620.
Ep done - 11630.
Ep done - 11640.
Ep done - 11650.
Ep done - 11660.
Ep done - 11670.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.39       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 171        |
|    time_elapsed         | 1248       |
|    total_timesteps      | 350208     |
| train/                  |            |
|    approx_kl            | 0.02041609 |
|    clip_fraction        | 0.173      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.756     |
|    explained_variance   | 0.237      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0346    |
|    n_updates            | 1700       |
|    policy_gradient_loss | -0.0463    |
|    value_loss           | 0.132      |
----------------------------------------
Ep done - 11680.
Ep done - 11690.
Ep done - 11700.
Ep done - 11710.
Ep done - 11720.
Ep done - 11730.
Ep done - 11740.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.34        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 172         |
|    time_elapsed         | 1254        |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.019771457 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.768      |
|    explained_variance   | 0.379       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0267     |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.0445     |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 11750.
Ep done - 11760.
Ep done - 11770.
Ep done - 11780.
Ep done - 11790.
Ep done - 11800.
Ep done - 11810.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 173         |
|    time_elapsed         | 1259        |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.019362248 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.771      |
|    explained_variance   | 0.326       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0127     |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.14        |
-----------------------------------------
Ep done - 11820.
Ep done - 11830.
Ep done - 11840.
Ep done - 11850.
Ep done - 11860.
Ep done - 11870.
Ep done - 11880.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 174         |
|    time_elapsed         | 1265        |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.019238591 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.77       |
|    explained_variance   | 0.3         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0278     |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.049      |
|    value_loss           | 0.147       |
-----------------------------------------
Ep done - 11890.
Ep done - 11900.
Ep done - 11910.
Ep done - 11920.
Ep done - 11930.
Ep done - 11940.
Ep done - 11950.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.29       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 175        |
|    time_elapsed         | 1271       |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.01919906 |
|    clip_fraction        | 0.171      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.754     |
|    explained_variance   | 0.134      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0399    |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.0464    |
|    value_loss           | 0.133      |
----------------------------------------
Ep done - 11960.
Ep done - 11970.
Ep done - 11980.
Ep done - 11990.
Ep done - 12000.
Ep done - 3410.
Ep done - 3420.
Ep done - 3430.
Ep done - 3440.
Ep done - 3450.
Ep done - 3460.
Ep done - 3470.
Ep done - 3480.
Ep done - 3490.
Ep done - 3500.
Ep done - 3510.
Ep done - 3520.
Ep done - 3530.
Ep done - 3540.
Ep done - 3550.
Ep done - 3560.
Ep done - 3570.
Ep done - 3580.
Ep done - 3590.
Ep done - 3600.
Eval num_timesteps=360000, episode_reward=0.30 +/- 0.94
Episode length: 30.07 +/- 0.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.305       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.017671686 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.756      |
|    explained_variance   | 0.257       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0364     |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.0454     |
|    value_loss           | 0.143       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.305
SELFPLAY: new best model, bumping up generation to 8
Ep done - 12010.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    fps             | 279      |
|    iterations      | 176      |
|    time_elapsed    | 1289     |
|    total_timesteps | 360448   |
---------------------------------
Ep done - 12020.
Ep done - 12030.
Ep done - 12040.
Ep done - 12050.
Ep done - 12060.
Ep done - 12070.
Ep done - 12080.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.02       |
| time/                   |            |
|    fps                  | 279        |
|    iterations           | 177        |
|    time_elapsed         | 1295       |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.01932632 |
|    clip_fraction        | 0.171      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.785     |
|    explained_variance   | 0.19       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0162    |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.0484    |
|    value_loss           | 0.164      |
----------------------------------------
Ep done - 12090.
Ep done - 12100.
Ep done - 12110.
Ep done - 12120.
Ep done - 12130.
Ep done - 12140.
Ep done - 12150.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.13       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 178         |
|    time_elapsed         | 1301        |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.020947304 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.821      |
|    explained_variance   | 0.263       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0177     |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0501     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 12160.
Ep done - 12170.
Ep done - 12180.
Ep done - 12190.
Ep done - 12200.
Ep done - 12210.
Ep done - 12220.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.11       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 179         |
|    time_elapsed         | 1306        |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.020001318 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.848      |
|    explained_variance   | 0.141       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0467     |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.05       |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 12230.
Ep done - 12240.
Ep done - 12250.
Ep done - 12260.
Ep done - 12270.
Ep done - 12280.
Ep done - 12290.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.04       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 180         |
|    time_elapsed         | 1312        |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.020593967 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.817      |
|    explained_variance   | 0.304       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0423     |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 12300.
Ep done - 12310.
Ep done - 12320.
Ep done - 12330.
Ep done - 12340.
Ep done - 12350.
Ep done - 12360.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | -0.03       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 181         |
|    time_elapsed         | 1318        |
|    total_timesteps      | 370688      |
| train/                  |             |
|    approx_kl            | 0.019768303 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.816      |
|    explained_variance   | 0.19        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0313     |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0496     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 12370.
Ep done - 12380.
Ep done - 12390.
Ep done - 12400.
Ep done - 12410.
Ep done - 12420.
Ep done - 12430.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.8       |
|    ep_rew_mean          | -0.07      |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 182        |
|    time_elapsed         | 1324       |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.02069901 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.821     |
|    explained_variance   | 0.228      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0344    |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.0502    |
|    value_loss           | 0.164      |
----------------------------------------
Ep done - 12440.
Ep done - 12450.
Ep done - 12460.
Ep done - 12470.
Ep done - 12480.
Ep done - 12490.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 183         |
|    time_elapsed         | 1329        |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.019933764 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.798      |
|    explained_variance   | 0.368       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0218     |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0487     |
|    value_loss           | 0.139       |
-----------------------------------------
Ep done - 12500.
Ep done - 12510.
Ep done - 12520.
Ep done - 12530.
Ep done - 12540.
Ep done - 12550.
Ep done - 12560.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.01        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 184         |
|    time_elapsed         | 1335        |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.020770658 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.772      |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0155     |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0495     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 12570.
Ep done - 12580.
Ep done - 12590.
Ep done - 12600.
Ep done - 12610.
Ep done - 12620.
Ep done - 12630.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 185         |
|    time_elapsed         | 1341        |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.022172004 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.784      |
|    explained_variance   | 0.279       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0154     |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 12640.
Ep done - 12650.
Ep done - 12660.
Ep done - 12670.
Ep done - 3610.
Ep done - 3620.
Ep done - 3630.
Ep done - 3640.
Ep done - 3650.
Ep done - 3660.
Ep done - 3670.
Ep done - 3680.
Ep done - 3690.
Ep done - 3700.
Ep done - 3710.
Ep done - 3720.
Ep done - 3730.
Ep done - 3740.
Ep done - 3750.
Ep done - 3760.
Ep done - 3770.
Ep done - 3780.
Ep done - 3790.
Ep done - 3800.
Eval num_timesteps=380000, episode_reward=-0.03 +/- 0.99
Episode length: 30.01 +/- 0.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | -0.025      |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.020954516 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.83       |
|    explained_variance   | 0.279       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0179     |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.0522     |
|    value_loss           | 0.158       |
-----------------------------------------
Ep done - 12680.
Ep done - 12690.
Ep done - 12700.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 186      |
|    time_elapsed    | 1359     |
|    total_timesteps | 380928   |
---------------------------------
Ep done - 12710.
Ep done - 12720.
Ep done - 12730.
Ep done - 12740.
Ep done - 12750.
Ep done - 12760.
Ep done - 12770.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 187         |
|    time_elapsed         | 1365        |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.018803228 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.802      |
|    explained_variance   | 0.213       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0345     |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.153       |
-----------------------------------------
Ep done - 12780.
Ep done - 12790.
Ep done - 12800.
Ep done - 12810.
Ep done - 12820.
Ep done - 12830.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.12       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 188        |
|    time_elapsed         | 1371       |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.02044179 |
|    clip_fraction        | 0.177      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.794     |
|    explained_variance   | 0.0775     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0109     |
|    n_updates            | 1870       |
|    policy_gradient_loss | -0.0472    |
|    value_loss           | 0.18       |
----------------------------------------
Ep done - 12840.
Ep done - 12850.
Ep done - 12860.
Ep done - 12870.
Ep done - 12880.
Ep done - 12890.
Ep done - 12900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 189         |
|    time_elapsed         | 1377        |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.018743683 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.807      |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0431     |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.0464     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 12910.
Ep done - 12920.
Ep done - 12930.
Ep done - 12940.
Ep done - 12950.
Ep done - 12960.
Ep done - 12970.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 190         |
|    time_elapsed         | 1382        |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.021111414 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.807      |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00817    |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 12980.
Ep done - 12990.
Ep done - 13000.
Ep done - 13010.
Ep done - 13020.
Ep done - 13030.
Ep done - 13040.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 191         |
|    time_elapsed         | 1388        |
|    total_timesteps      | 391168      |
| train/                  |             |
|    approx_kl            | 0.022795305 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.798      |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0229     |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 13050.
Ep done - 13060.
Ep done - 13070.
Ep done - 13080.
Ep done - 13090.
Ep done - 13100.
Ep done - 13110.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.08       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 192        |
|    time_elapsed         | 1394       |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.01937896 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.821     |
|    explained_variance   | 0.219      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00498   |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.0491    |
|    value_loss           | 0.153      |
----------------------------------------
Ep done - 13120.
Ep done - 13130.
Ep done - 13140.
Ep done - 13150.
Ep done - 13160.
Ep done - 13170.
Ep done - 13180.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 193         |
|    time_elapsed         | 1400        |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.019575821 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.81       |
|    explained_variance   | 0.348       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0283     |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 13190.
Ep done - 13200.
Ep done - 13210.
Ep done - 13220.
Ep done - 13230.
Ep done - 13240.
Ep done - 13250.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 29.8      |
|    ep_rew_mean          | 0.19      |
| time/                   |           |
|    fps                  | 282       |
|    iterations           | 194       |
|    time_elapsed         | 1406      |
|    total_timesteps      | 397312    |
| train/                  |           |
|    approx_kl            | 0.0194528 |
|    clip_fraction        | 0.181     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.77     |
|    explained_variance   | 0.327     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0407   |
|    n_updates            | 1930      |
|    policy_gradient_loss | -0.0499   |
|    value_loss           | 0.171     |
---------------------------------------
Ep done - 13260.
Ep done - 13270.
Ep done - 13280.
Ep done - 13290.
Ep done - 13300.
Ep done - 13310.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.02        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 195         |
|    time_elapsed         | 1411        |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.020878531 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.765      |
|    explained_variance   | 0.152       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0285     |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 13320.
Ep done - 13330.
Ep done - 3810.
Ep done - 3820.
Ep done - 3830.
Ep done - 3840.
Ep done - 3850.
Ep done - 3860.
Ep done - 3870.
Ep done - 3880.
Ep done - 3890.
Ep done - 3900.
Ep done - 3910.
Ep done - 3920.
Ep done - 3930.
Ep done - 3940.
Ep done - 3950.
Ep done - 3960.
Ep done - 3970.
Ep done - 3980.
Ep done - 3990.
Ep done - 4000.
Eval num_timesteps=400000, episode_reward=0.09 +/- 0.99
Episode length: 30.02 +/- 0.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.09        |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.020472758 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.768      |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.13e-05    |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0469     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 13340.
Ep done - 13350.
Ep done - 13360.
Ep done - 13370.
Ep done - 13380.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 196      |
|    time_elapsed    | 1430     |
|    total_timesteps | 401408   |
---------------------------------
Ep done - 13390.
Ep done - 13400.
Ep done - 13410.
Ep done - 13420.
Ep done - 13430.
Ep done - 13440.
Ep done - 13450.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 197         |
|    time_elapsed         | 1435        |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.022455042 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.785      |
|    explained_variance   | 0.26        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0105      |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.165       |
-----------------------------------------
Ep done - 13460.
Ep done - 13470.
Ep done - 13480.
Ep done - 13490.
Ep done - 13500.
Ep done - 13510.
Ep done - 13520.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 198         |
|    time_elapsed         | 1441        |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.020113006 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.793      |
|    explained_variance   | 0.264       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0162     |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 13530.
Ep done - 13540.
Ep done - 13550.
Ep done - 13560.
Ep done - 13570.
Ep done - 13580.
Ep done - 13590.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.1        |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 199        |
|    time_elapsed         | 1447       |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.01945295 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.752     |
|    explained_variance   | 0.181      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0255    |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.0433    |
|    value_loss           | 0.191      |
----------------------------------------
Ep done - 13600.
Ep done - 13610.
Ep done - 13620.
Ep done - 13630.
Ep done - 13640.
Ep done - 13650.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 200         |
|    time_elapsed         | 1453        |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.021609731 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.744      |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0424     |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 13660.
Ep done - 13670.
Ep done - 13680.
Ep done - 13690.
Ep done - 13700.
Ep done - 13710.
Ep done - 13720.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 201         |
|    time_elapsed         | 1459        |
|    total_timesteps      | 411648      |
| train/                  |             |
|    approx_kl            | 0.020494912 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.759      |
|    explained_variance   | 0.345       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00204    |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.0495     |
|    value_loss           | 0.146       |
-----------------------------------------
Ep done - 13730.
Ep done - 13740.
Ep done - 13750.
Ep done - 13760.
Ep done - 13770.
Ep done - 13780.
Ep done - 13790.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 202         |
|    time_elapsed         | 1464        |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.019118553 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.775      |
|    explained_variance   | 0.329       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0253     |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.0457     |
|    value_loss           | 0.158       |
-----------------------------------------
Ep done - 13800.
Ep done - 13810.
Ep done - 13820.
Ep done - 13830.
Ep done - 13840.
Ep done - 13850.
Ep done - 13860.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 203         |
|    time_elapsed         | 1470        |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.020863736 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.735      |
|    explained_variance   | -0.068      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0292     |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.0458     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 13870.
Ep done - 13880.
Ep done - 13890.
Ep done - 13900.
Ep done - 13910.
Ep done - 13920.
Ep done - 13930.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 204         |
|    time_elapsed         | 1476        |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.020151403 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.75       |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0141     |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.149       |
-----------------------------------------
Ep done - 13940.
Ep done - 13950.
Ep done - 13960.
Ep done - 13970.
Ep done - 13980.
Ep done - 13990.
Ep done - 14000.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 205         |
|    time_elapsed         | 1482        |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.020130405 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.747      |
|    explained_variance   | 0.378       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0137      |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.047      |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 4010.
Ep done - 4020.
Ep done - 4030.
Ep done - 4040.
Ep done - 4050.
Ep done - 4060.
Ep done - 4070.
Ep done - 4080.
Ep done - 4090.
Ep done - 4100.
Ep done - 4110.
Ep done - 4120.
Ep done - 4130.
Ep done - 4140.
Ep done - 4150.
Ep done - 4160.
Ep done - 4170.
Ep done - 4180.
Ep done - 4190.
Ep done - 4200.
Eval num_timesteps=420000, episode_reward=0.20 +/- 0.96
Episode length: 29.98 +/- 0.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.2         |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.023784144 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.772      |
|    explained_variance   | 0.114       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00879    |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 14010.
Ep done - 14020.
Ep done - 14030.
Ep done - 14040.
Ep done - 14050.
Ep done - 14060.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 206      |
|    time_elapsed    | 1500     |
|    total_timesteps | 421888   |
---------------------------------
Ep done - 14070.
Ep done - 14080.
Ep done - 14090.
Ep done - 14100.
Ep done - 14110.
Ep done - 14120.
Ep done - 14130.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 207         |
|    time_elapsed         | 1506        |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.022404734 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.793      |
|    explained_variance   | 0.321       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0116     |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 14140.
Ep done - 14150.
Ep done - 14160.
Ep done - 14170.
Ep done - 14180.
Ep done - 14190.
Ep done - 14200.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.8       |
|    ep_rew_mean          | 0.21       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 208        |
|    time_elapsed         | 1512       |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.02108277 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.782     |
|    explained_variance   | 0.238      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0105    |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0495    |
|    value_loss           | 0.179      |
----------------------------------------
Ep done - 14210.
Ep done - 14220.
Ep done - 14230.
Ep done - 14240.
Ep done - 14250.
Ep done - 14260.
Ep done - 14270.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30        |
|    ep_rew_mean          | 0.1       |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 209       |
|    time_elapsed         | 1518      |
|    total_timesteps      | 428032    |
| train/                  |           |
|    approx_kl            | 0.0215961 |
|    clip_fraction        | 0.181     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.762    |
|    explained_variance   | 0.217     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.00566  |
|    n_updates            | 2080      |
|    policy_gradient_loss | -0.0492   |
|    value_loss           | 0.17      |
---------------------------------------
Ep done - 14280.
Ep done - 14290.
Ep done - 14300.
Ep done - 14310.
Ep done - 14320.
Ep done - 14330.
Ep done - 14340.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 210         |
|    time_elapsed         | 1524        |
|    total_timesteps      | 430080      |
| train/                  |             |
|    approx_kl            | 0.024285212 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.758      |
|    explained_variance   | 0.208       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0315     |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0476     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 14350.
Ep done - 14360.
Ep done - 14370.
Ep done - 14380.
Ep done - 14390.
Ep done - 14400.
Ep done - 14410.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 211         |
|    time_elapsed         | 1530        |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.021868914 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.761      |
|    explained_variance   | 0.06        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00147    |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 14420.
Ep done - 14430.
Ep done - 14440.
Ep done - 14450.
Ep done - 14460.
Ep done - 14470.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.35        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 212         |
|    time_elapsed         | 1535        |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.024130212 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.773      |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0117     |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0491     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 14480.
Ep done - 14490.
Ep done - 14500.
Ep done - 14510.
Ep done - 14520.
Ep done - 14530.
Ep done - 14540.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.36        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 213         |
|    time_elapsed         | 1541        |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.020675097 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.754      |
|    explained_variance   | 0.118       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0231     |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.146       |
-----------------------------------------
Ep done - 14550.
Ep done - 14560.
Ep done - 14570.
Ep done - 14580.
Ep done - 14590.
Ep done - 14600.
Ep done - 14610.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.04       |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 214         |
|    time_elapsed         | 1547        |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.020247716 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.764      |
|    explained_variance   | 0.246       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0357     |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 14620.
Ep done - 14630.
Ep done - 14640.
Ep done - 14650.
Ep done - 14660.
Ep done - 14670.
Ep done - 4210.
Ep done - 4220.
Ep done - 4230.
Ep done - 4240.
Ep done - 4250.
Ep done - 4260.
Ep done - 4270.
Ep done - 4280.
Ep done - 4290.
Ep done - 4300.
Ep done - 4310.
Ep done - 4320.
Ep done - 4330.
Ep done - 4340.
Ep done - 4350.
Ep done - 4360.
Ep done - 4370.
Ep done - 4380.
Ep done - 4390.
Ep done - 4400.
Eval num_timesteps=440000, episode_reward=0.23 +/- 0.96
Episode length: 29.98 +/- 0.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.225       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.021955555 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.771      |
|    explained_variance   | 0.175       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00341    |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.0502     |
|    value_loss           | 0.179       |
-----------------------------------------
Ep done - 14680.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.04     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 215      |
|    time_elapsed    | 1566     |
|    total_timesteps | 440320   |
---------------------------------
Ep done - 14690.
Ep done - 14700.
Ep done - 14710.
Ep done - 14720.
Ep done - 14730.
Ep done - 14740.
Ep done - 14750.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 216         |
|    time_elapsed         | 1572        |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.021158718 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.75       |
|    explained_variance   | 0.172       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0111     |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.0448     |
|    value_loss           | 0.179       |
-----------------------------------------
Ep done - 14760.
Ep done - 14770.
Ep done - 14780.
Ep done - 14790.
Ep done - 14800.
Ep done - 14810.
Ep done - 14820.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 217         |
|    time_elapsed         | 1578        |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.024341594 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.744      |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0186     |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.0512     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 14830.
Ep done - 14840.
Ep done - 14850.
Ep done - 14860.
Ep done - 14870.
Ep done - 14880.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 218         |
|    time_elapsed         | 1584        |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.021891948 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.767      |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0389     |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0501     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 14890.
Ep done - 14900.
Ep done - 14910.
Ep done - 14920.
Ep done - 14930.
Ep done - 14940.
Ep done - 14950.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.39        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 219         |
|    time_elapsed         | 1589        |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.021375295 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.738      |
|    explained_variance   | 0.212       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.026      |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.15        |
-----------------------------------------
Ep done - 14960.
Ep done - 14970.
Ep done - 14980.
Ep done - 14990.
Ep done - 15000.
Ep done - 15010.
Ep done - 15020.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.31       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 220        |
|    time_elapsed         | 1595       |
|    total_timesteps      | 450560     |
| train/                  |            |
|    approx_kl            | 0.02090779 |
|    clip_fraction        | 0.173      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.744     |
|    explained_variance   | 0.295      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00363   |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.0476    |
|    value_loss           | 0.148      |
----------------------------------------
Ep done - 15030.
Ep done - 15040.
Ep done - 15050.
Ep done - 15060.
Ep done - 15070.
Ep done - 15080.
Ep done - 15090.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 221         |
|    time_elapsed         | 1602        |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.021117765 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.751      |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00261     |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 15100.
Ep done - 15110.
Ep done - 15120.
Ep done - 15130.
Ep done - 15140.
Ep done - 15150.
Ep done - 15160.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.25       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 222        |
|    time_elapsed         | 1608       |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.02223378 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.748     |
|    explained_variance   | 0.31       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0422    |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.0494    |
|    value_loss           | 0.152      |
----------------------------------------
Ep done - 15170.
Ep done - 15180.
Ep done - 15190.
Ep done - 15200.
Ep done - 15210.
Ep done - 15220.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.31       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 223        |
|    time_elapsed         | 1614       |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.02198115 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.736     |
|    explained_variance   | 0.289      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0357    |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0481    |
|    value_loss           | 0.145      |
----------------------------------------
Ep done - 15230.
Ep done - 15240.
Ep done - 15250.
Ep done - 15260.
Ep done - 15270.
Ep done - 15280.
Ep done - 15290.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 224         |
|    time_elapsed         | 1620        |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.020416759 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.72       |
|    explained_variance   | 0.233       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0235     |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.047      |
|    value_loss           | 0.153       |
-----------------------------------------
Ep done - 15300.
Ep done - 15310.
Ep done - 15320.
Ep done - 15330.
Ep done - 15340.
Ep done - 4410.
Ep done - 4420.
Ep done - 4430.
Ep done - 4440.
Ep done - 4450.
Ep done - 4460.
Ep done - 4470.
Ep done - 4480.
Ep done - 4490.
Ep done - 4500.
Ep done - 4510.
Ep done - 4520.
Ep done - 4530.
Ep done - 4540.
Ep done - 4550.
Ep done - 4560.
Ep done - 4570.
Ep done - 4580.
Ep done - 4590.
Ep done - 4600.
Eval num_timesteps=460000, episode_reward=0.17 +/- 0.97
Episode length: 30.03 +/- 0.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.165       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.020904243 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.732      |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0253     |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 15350.
Ep done - 15360.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 225      |
|    time_elapsed    | 1639     |
|    total_timesteps | 460800   |
---------------------------------
Ep done - 15370.
Ep done - 15380.
Ep done - 15390.
Ep done - 15400.
Ep done - 15410.
Ep done - 15420.
Ep done - 15430.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 226         |
|    time_elapsed         | 1645        |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.024943294 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.721      |
|    explained_variance   | 0.218       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0138     |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 15440.
Ep done - 15450.
Ep done - 15460.
Ep done - 15470.
Ep done - 15480.
Ep done - 15490.
Ep done - 15500.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 227         |
|    time_elapsed         | 1651        |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.023379723 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.728      |
|    explained_variance   | 0.145       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0532     |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.049      |
|    value_loss           | 0.142       |
-----------------------------------------
Ep done - 15510.
Ep done - 15520.
Ep done - 15530.
Ep done - 15540.
Ep done - 15550.
Ep done - 15560.
Ep done - 15570.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 228         |
|    time_elapsed         | 1658        |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.024024967 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.743      |
|    explained_variance   | 0.272       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.038      |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.148       |
-----------------------------------------
Ep done - 15580.
Ep done - 15590.
Ep done - 15600.
Ep done - 15610.
Ep done - 15620.
Ep done - 15630.
Ep done - 15640.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 229         |
|    time_elapsed         | 1664        |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.025177317 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.724      |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00521    |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 15650.
Ep done - 15660.
Ep done - 15670.
Ep done - 15680.
Ep done - 15690.
Ep done - 15700.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.22        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 230         |
|    time_elapsed         | 1671        |
|    total_timesteps      | 471040      |
| train/                  |             |
|    approx_kl            | 0.024163518 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.744      |
|    explained_variance   | 0.129       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00243     |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0513     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 15710.
Ep done - 15720.
Ep done - 15730.
Ep done - 15740.
Ep done - 15750.
Ep done - 15760.
Ep done - 15770.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 231         |
|    time_elapsed         | 1681        |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.021665227 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.732      |
|    explained_variance   | 0.0673      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0182     |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.0489     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 15780.
Ep done - 15790.
Ep done - 15800.
Ep done - 15810.
Ep done - 15820.
Ep done - 15830.
Ep done - 15840.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 232         |
|    time_elapsed         | 1686        |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.025415659 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.747      |
|    explained_variance   | 0.204       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0243     |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0501     |
|    value_loss           | 0.139       |
-----------------------------------------
Ep done - 15850.
Ep done - 15860.
Ep done - 15870.
Ep done - 15880.
Ep done - 15890.
Ep done - 15900.
Ep done - 15910.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 233         |
|    time_elapsed         | 1692        |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.019628746 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.76       |
|    explained_variance   | 0.186       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0077     |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 15920.
Ep done - 15930.
Ep done - 15940.
Ep done - 15950.
Ep done - 15960.
Ep done - 15970.
Ep done - 15980.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.26       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 234        |
|    time_elapsed         | 1698       |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.02218869 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.768     |
|    explained_variance   | 0.128      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0374    |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.0472    |
|    value_loss           | 0.16       |
----------------------------------------
Ep done - 15990.
Ep done - 16000.
Ep done - 4610.
Ep done - 4620.
Ep done - 4630.
Ep done - 4640.
Ep done - 4650.
Ep done - 4660.
Ep done - 4670.
Ep done - 4680.
Ep done - 4690.
Ep done - 4700.
Ep done - 4710.
Ep done - 4720.
Ep done - 4730.
Ep done - 4740.
Ep done - 4750.
Ep done - 4760.
Ep done - 4770.
Ep done - 4780.
Ep done - 4790.
Ep done - 4800.
Eval num_timesteps=480000, episode_reward=0.30 +/- 0.94
Episode length: 30.05 +/- 0.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.305       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.019839874 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.765      |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000371   |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.166       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.305
SELFPLAY: new best model, bumping up generation to 9
Ep done - 16010.
Ep done - 16020.
Ep done - 16030.
Ep done - 16040.
Ep done - 16050.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.7     |
|    ep_rew_mean     | 0.05     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 235      |
|    time_elapsed    | 1716     |
|    total_timesteps | 481280   |
---------------------------------
Ep done - 16060.
Ep done - 16070.
Ep done - 16080.
Ep done - 16090.
Ep done - 16100.
Ep done - 16110.
Ep done - 16120.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.17       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 236         |
|    time_elapsed         | 1722        |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.025632834 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.803      |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0211     |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.056      |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 16130.
Ep done - 16140.
Ep done - 16150.
Ep done - 16160.
Ep done - 16170.
Ep done - 16180.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.13       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 237         |
|    time_elapsed         | 1728        |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.021321237 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.821      |
|    explained_variance   | 0.172       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0268     |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.153       |
-----------------------------------------
Ep done - 16190.
Ep done - 16200.
Ep done - 16210.
Ep done - 16220.
Ep done - 16230.
Ep done - 16240.
Ep done - 16250.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 238         |
|    time_elapsed         | 1733        |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.021517526 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.813      |
|    explained_variance   | 0.131       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0131      |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0476     |
|    value_loss           | 0.204       |
-----------------------------------------
Ep done - 16260.
Ep done - 16270.
Ep done - 16280.
Ep done - 16290.
Ep done - 16300.
Ep done - 16310.
Ep done - 16320.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 239         |
|    time_elapsed         | 1739        |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.022981998 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.807      |
|    explained_variance   | 0.265       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0284     |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.0501     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 16330.
Ep done - 16340.
Ep done - 16350.
Ep done - 16360.
Ep done - 16370.
Ep done - 16380.
Ep done - 16390.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 240         |
|    time_elapsed         | 1745        |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.025572155 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.809      |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0245     |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 16400.
Ep done - 16410.
Ep done - 16420.
Ep done - 16430.
Ep done - 16440.
Ep done - 16450.
Ep done - 16460.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 241         |
|    time_elapsed         | 1751        |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.021918116 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.821      |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0312     |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0505     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 16470.
Ep done - 16480.
Ep done - 16490.
Ep done - 16500.
Ep done - 16510.
Ep done - 16520.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 242         |
|    time_elapsed         | 1757        |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.022045596 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.823      |
|    explained_variance   | 0.3         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0164     |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 16530.
Ep done - 16540.
Ep done - 16550.
Ep done - 16560.
Ep done - 16570.
Ep done - 16580.
Ep done - 16590.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30        |
|    ep_rew_mean          | 0.1       |
| time/                   |           |
|    fps                  | 282       |
|    iterations           | 243       |
|    time_elapsed         | 1762      |
|    total_timesteps      | 497664    |
| train/                  |           |
|    approx_kl            | 0.0214266 |
|    clip_fraction        | 0.206     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.82     |
|    explained_variance   | 0.294     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.033    |
|    n_updates            | 2420      |
|    policy_gradient_loss | -0.0494   |
|    value_loss           | 0.144     |
---------------------------------------
Ep done - 16600.
Ep done - 16610.
Ep done - 16620.
Ep done - 16630.
Ep done - 16640.
Ep done - 16650.
Ep done - 16660.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.08       |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 244         |
|    time_elapsed         | 1768        |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.022856649 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.833      |
|    explained_variance   | 0.148       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.015      |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0512     |
|    value_loss           | 0.189       |
-----------------------------------------
Ep done - 16670.
Ep done - 4810.
Ep done - 4820.
Ep done - 4830.
Ep done - 4840.
Ep done - 4850.
Ep done - 4860.
Ep done - 4870.
Ep done - 4880.
Ep done - 4890.
Ep done - 4900.
Ep done - 4910.
Ep done - 4920.
Ep done - 4930.
Ep done - 4940.
Ep done - 4950.
Ep done - 4960.
Ep done - 4970.
Ep done - 4980.
Ep done - 4990.
Ep done - 5000.
Eval num_timesteps=500000, episode_reward=-0.16 +/- 0.98
Episode length: 29.95 +/- 0.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | -0.16       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.024969019 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.851      |
|    explained_variance   | 0.141       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0147     |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 16680.
Ep done - 16690.
Ep done - 16700.
Ep done - 16710.
Ep done - 16720.
Ep done - 16730.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 245      |
|    time_elapsed    | 1786     |
|    total_timesteps | 501760   |
---------------------------------
Ep done - 16740.
Ep done - 16750.
Ep done - 16760.
Ep done - 16770.
Ep done - 16780.
Ep done - 16790.
Ep done - 16800.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.04       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 246         |
|    time_elapsed         | 1792        |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.021187615 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.805      |
|    explained_variance   | 0.0637      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00953    |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.0482     |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 16810.
Ep done - 16820.
Ep done - 16830.
Ep done - 16840.
Ep done - 16850.
Ep done - 16860.
Ep done - 16870.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.05       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 247        |
|    time_elapsed         | 1798       |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.02173858 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.823     |
|    explained_variance   | 0.26       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0482    |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0498    |
|    value_loss           | 0.154      |
----------------------------------------
Ep done - 16880.
Ep done - 16890.
Ep done - 16900.
Ep done - 16910.
Ep done - 16920.
Ep done - 16930.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.16       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 248        |
|    time_elapsed         | 1804       |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.02413901 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.826     |
|    explained_variance   | 0.205      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0393    |
|    n_updates            | 2470       |
|    policy_gradient_loss | -0.0535    |
|    value_loss           | 0.171      |
----------------------------------------
Ep done - 16940.
Ep done - 16950.
Ep done - 16960.
Ep done - 16970.
Ep done - 16980.
Ep done - 16990.
Ep done - 17000.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 249         |
|    time_elapsed         | 1810        |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.022689492 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.825      |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0108     |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.166       |
-----------------------------------------
Ep done - 17010.
Ep done - 17020.
Ep done - 17030.
Ep done - 17040.
Ep done - 17050.
Ep done - 17060.
Ep done - 17070.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.36        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 250         |
|    time_elapsed         | 1815        |
|    total_timesteps      | 512000      |
| train/                  |             |
|    approx_kl            | 0.024391029 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.786      |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0303     |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.0553     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 17080.
Ep done - 17090.
Ep done - 17100.
Ep done - 17110.
Ep done - 17120.
Ep done - 17130.
Ep done - 17140.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 251         |
|    time_elapsed         | 1821        |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.020207338 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.768      |
|    explained_variance   | 0.169       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0203     |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 17150.
Ep done - 17160.
Ep done - 17170.
Ep done - 17180.
Ep done - 17190.
Ep done - 17200.
Ep done - 17210.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 252         |
|    time_elapsed         | 1827        |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.021965481 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.785      |
|    explained_variance   | 0.3         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0164     |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 17220.
Ep done - 17230.
Ep done - 17240.
Ep done - 17250.
Ep done - 17260.
Ep done - 17270.
Ep done - 17280.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 253         |
|    time_elapsed         | 1833        |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.022316653 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.817      |
|    explained_variance   | 0.221       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0138     |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 17290.
Ep done - 17300.
Ep done - 17310.
Ep done - 17320.
Ep done - 17330.
Ep done - 17340.
Ep done - 5010.
Ep done - 5020.
Ep done - 5030.
Ep done - 5040.
Ep done - 5050.
Ep done - 5060.
Ep done - 5070.
Ep done - 5080.
Ep done - 5090.
Ep done - 5100.
Ep done - 5110.
Ep done - 5120.
Ep done - 5130.
Ep done - 5140.
Ep done - 5150.
Ep done - 5160.
Ep done - 5170.
Ep done - 5180.
Ep done - 5190.
Ep done - 5200.
Eval num_timesteps=520000, episode_reward=0.07 +/- 0.99
Episode length: 29.86 +/- 1.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.065       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.022574192 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.788      |
|    explained_variance   | 0.233       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0206     |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.151       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.13     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 254      |
|    time_elapsed    | 1851     |
|    total_timesteps | 520192   |
---------------------------------
Ep done - 17350.
Ep done - 17360.
Ep done - 17370.
Ep done - 17380.
Ep done - 17390.
Ep done - 17400.
Ep done - 17410.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30.1      |
|    ep_rew_mean          | 0.19      |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 255       |
|    time_elapsed         | 1857      |
|    total_timesteps      | 522240    |
| train/                  |           |
|    approx_kl            | 0.0197169 |
|    clip_fraction        | 0.177     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.792    |
|    explained_variance   | 0.128     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0238    |
|    n_updates            | 2540      |
|    policy_gradient_loss | -0.0481   |
|    value_loss           | 0.193     |
---------------------------------------
Ep done - 17420.
Ep done - 17430.
Ep done - 17440.
Ep done - 17450.
Ep done - 17460.
Ep done - 17470.
Ep done - 17480.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.1        |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 256        |
|    time_elapsed         | 1863       |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.02300649 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.764     |
|    explained_variance   | 0.00295    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0132     |
|    n_updates            | 2550       |
|    policy_gradient_loss | -0.0469    |
|    value_loss           | 0.181      |
----------------------------------------
Ep done - 17490.
Ep done - 17500.
Ep done - 17510.
Ep done - 17520.
Ep done - 17530.
Ep done - 17540.
Ep done - 17550.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.02       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 257        |
|    time_elapsed         | 1868       |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.02184664 |
|    clip_fraction        | 0.19       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.773     |
|    explained_variance   | 0.229      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0388    |
|    n_updates            | 2560       |
|    policy_gradient_loss | -0.0514    |
|    value_loss           | 0.15       |
----------------------------------------
Ep done - 17560.
Ep done - 17570.
Ep done - 17580.
Ep done - 17590.
Ep done - 17600.
Ep done - 17610.
Ep done - 17620.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 29.9      |
|    ep_rew_mean          | 0         |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 258       |
|    time_elapsed         | 1874      |
|    total_timesteps      | 528384    |
| train/                  |           |
|    approx_kl            | 0.0224926 |
|    clip_fraction        | 0.189     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.753    |
|    explained_variance   | 0.214     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0285   |
|    n_updates            | 2570      |
|    policy_gradient_loss | -0.0477   |
|    value_loss           | 0.17      |
---------------------------------------
Ep done - 17630.
Ep done - 17640.
Ep done - 17650.
Ep done - 17660.
Ep done - 17670.
Ep done - 17680.
Ep done - 17690.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.11        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 259         |
|    time_elapsed         | 1880        |
|    total_timesteps      | 530432      |
| train/                  |             |
|    approx_kl            | 0.022080993 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.756      |
|    explained_variance   | 0.276       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0311     |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0501     |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 17700.
Ep done - 17710.
Ep done - 17720.
Ep done - 17730.
Ep done - 17740.
Ep done - 17750.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 260         |
|    time_elapsed         | 1886        |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.018981054 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.75       |
|    explained_variance   | 0.0916      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00415    |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.046      |
|    value_loss           | 0.188       |
-----------------------------------------
Ep done - 17760.
Ep done - 17770.
Ep done - 17780.
Ep done - 17790.
Ep done - 17800.
Ep done - 17810.
Ep done - 17820.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 261         |
|    time_elapsed         | 1892        |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.020431008 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.747      |
|    explained_variance   | 0.0359      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0222      |
|    n_updates            | 2600        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.176       |
-----------------------------------------
Ep done - 17830.
Ep done - 17840.
Ep done - 17850.
Ep done - 17860.
Ep done - 17870.
Ep done - 17880.
Ep done - 17890.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 262         |
|    time_elapsed         | 1898        |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.021607988 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.765      |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0478     |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 17900.
Ep done - 17910.
Ep done - 17920.
Ep done - 17930.
Ep done - 17940.
Ep done - 17950.
Ep done - 17960.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 263         |
|    time_elapsed         | 1903        |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.021839265 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.771      |
|    explained_variance   | -0.0146     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0193     |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.0483     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 17970.
Ep done - 17980.
Ep done - 17990.
Ep done - 18000.
Ep done - 5210.
Ep done - 5220.
Ep done - 5230.
Ep done - 5240.
Ep done - 5250.
Ep done - 5260.
Ep done - 5270.
Ep done - 5280.
Ep done - 5290.
Ep done - 5300.
Ep done - 5310.
Ep done - 5320.
Ep done - 5330.
Ep done - 5340.
Ep done - 5350.
Ep done - 5360.
Ep done - 5370.
Ep done - 5380.
Ep done - 5390.
Ep done - 5400.
Eval num_timesteps=540000, episode_reward=0.15 +/- 0.98
Episode length: 29.93 +/- 1.52
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.155       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.022549268 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.774      |
|    explained_variance   | -0.000521   |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0303     |
|    n_updates            | 2630        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 18010.
Ep done - 18020.
Ep done - 18030.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 264      |
|    time_elapsed    | 1922     |
|    total_timesteps | 540672   |
---------------------------------
Ep done - 18040.
Ep done - 18050.
Ep done - 18060.
Ep done - 18070.
Ep done - 18080.
Ep done - 18090.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 265         |
|    time_elapsed         | 1928        |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.019698186 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.741      |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00121    |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.0467     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 18100.
Ep done - 18110.
Ep done - 18120.
Ep done - 18130.
Ep done - 18140.
Ep done - 18150.
Ep done - 18160.
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 30       |
|    ep_rew_mean          | 0.04     |
| time/                   |          |
|    fps                  | 281      |
|    iterations           | 266      |
|    time_elapsed         | 1934     |
|    total_timesteps      | 544768   |
| train/                  |          |
|    approx_kl            | 0.025966 |
|    clip_fraction        | 0.202    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.737   |
|    explained_variance   | 0.291    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0131  |
|    n_updates            | 2650     |
|    policy_gradient_loss | -0.0517  |
|    value_loss           | 0.159    |
--------------------------------------
Ep done - 18170.
Ep done - 18180.
Ep done - 18190.
Ep done - 18200.
Ep done - 18210.
Ep done - 18220.
Ep done - 18230.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 267         |
|    time_elapsed         | 1940        |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.023166558 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.765      |
|    explained_variance   | 0.0375      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00753    |
|    n_updates            | 2660        |
|    policy_gradient_loss | -0.0512     |
|    value_loss           | 0.187       |
-----------------------------------------
Ep done - 18240.
Ep done - 18250.
Ep done - 18260.
Ep done - 18270.
Ep done - 18280.
Ep done - 18290.
Ep done - 18300.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 268         |
|    time_elapsed         | 1945        |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.022891516 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.761      |
|    explained_variance   | 0.154       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.022      |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.158       |
-----------------------------------------
Ep done - 18310.
Ep done - 18320.
Ep done - 18330.
Ep done - 18340.
Ep done - 18350.
Ep done - 18360.
Ep done - 18370.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 269         |
|    time_elapsed         | 1951        |
|    total_timesteps      | 550912      |
| train/                  |             |
|    approx_kl            | 0.022347094 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.756      |
|    explained_variance   | 0.176       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0384     |
|    n_updates            | 2680        |
|    policy_gradient_loss | -0.0453     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 18380.
Ep done - 18390.
Ep done - 18400.
Ep done - 18410.
Ep done - 18420.
Ep done - 18430.
Ep done - 18440.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 270         |
|    time_elapsed         | 1957        |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.021324629 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.793      |
|    explained_variance   | 0.0797      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0178     |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.0489     |
|    value_loss           | 0.158       |
-----------------------------------------
Ep done - 18450.
Ep done - 18460.
Ep done - 18470.
Ep done - 18480.
Ep done - 18490.
Ep done - 18500.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | -0.04      |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 271        |
|    time_elapsed         | 1963       |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.02354687 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.792     |
|    explained_variance   | 0.143      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0144    |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.0531    |
|    value_loss           | 0.164      |
----------------------------------------
Ep done - 18510.
Ep done - 18520.
Ep done - 18530.
Ep done - 18540.
Ep done - 18550.
Ep done - 18560.
Ep done - 18570.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.06       |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 272         |
|    time_elapsed         | 1969        |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.025786102 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.81       |
|    explained_variance   | 0.17        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000799   |
|    n_updates            | 2710        |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.179       |
-----------------------------------------
Ep done - 18580.
Ep done - 18590.
Ep done - 18600.
Ep done - 18610.
Ep done - 18620.
Ep done - 18630.
Ep done - 18640.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 283         |
|    iterations           | 273         |
|    time_elapsed         | 1975        |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.023946378 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.783      |
|    explained_variance   | 0.23        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0237     |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 18650.
Ep done - 18660.
Ep done - 18670.
Ep done - 5410.
Ep done - 5420.
Ep done - 5430.
Ep done - 5440.
Ep done - 5450.
Ep done - 5460.
Ep done - 5470.
Ep done - 5480.
Ep done - 5490.
Ep done - 5500.
Ep done - 5510.
Ep done - 5520.
Ep done - 5530.
Ep done - 5540.
Ep done - 5550.
Ep done - 5560.
Ep done - 5570.
Ep done - 5580.
Ep done - 5590.
Ep done - 5600.
Eval num_timesteps=560000, episode_reward=0.17 +/- 0.98
Episode length: 30.06 +/- 0.66
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.165       |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.026307754 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.759      |
|    explained_variance   | 0.129       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0192     |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.0504     |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 18680.
Ep done - 18690.
Ep done - 18700.
Ep done - 18710.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 274      |
|    time_elapsed    | 1994     |
|    total_timesteps | 561152   |
---------------------------------
Ep done - 18720.
Ep done - 18730.
Ep done - 18740.
Ep done - 18750.
Ep done - 18760.
Ep done - 18770.
Ep done - 18780.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.03       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 275         |
|    time_elapsed         | 1999        |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.021527486 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.778      |
|    explained_variance   | 0.241       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00642    |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.0524     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 18790.
Ep done - 18800.
Ep done - 18810.
Ep done - 18820.
Ep done - 18830.
Ep done - 18840.
Ep done - 18850.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.19       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 276        |
|    time_elapsed         | 2005       |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.02208127 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.775     |
|    explained_variance   | 0.188      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0627    |
|    n_updates            | 2750       |
|    policy_gradient_loss | -0.0486    |
|    value_loss           | 0.175      |
----------------------------------------
Ep done - 18860.
Ep done - 18870.
Ep done - 18880.
Ep done - 18890.
Ep done - 18900.
Ep done - 18910.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 277         |
|    time_elapsed         | 2011        |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.023298368 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.751      |
|    explained_variance   | 0.0566      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0254     |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.0487     |
|    value_loss           | 0.179       |
-----------------------------------------
Ep done - 18920.
Ep done - 18930.
Ep done - 18940.
Ep done - 18950.
Ep done - 18960.
Ep done - 18970.
Ep done - 18980.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30        |
|    ep_rew_mean          | 0.19      |
| time/                   |           |
|    fps                  | 282       |
|    iterations           | 278       |
|    time_elapsed         | 2017      |
|    total_timesteps      | 569344    |
| train/                  |           |
|    approx_kl            | 0.0248583 |
|    clip_fraction        | 0.203     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.751    |
|    explained_variance   | 0.145     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0289   |
|    n_updates            | 2770      |
|    policy_gradient_loss | -0.0506   |
|    value_loss           | 0.17      |
---------------------------------------
Ep done - 18990.
Ep done - 19000.
Ep done - 19010.
Ep done - 19020.
Ep done - 19030.
Ep done - 19040.
Ep done - 19050.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 279         |
|    time_elapsed         | 2023        |
|    total_timesteps      | 571392      |
| train/                  |             |
|    approx_kl            | 0.024478778 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.755      |
|    explained_variance   | 0.161       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0412     |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.165       |
-----------------------------------------
Ep done - 19060.
Ep done - 19070.
Ep done - 19080.
Ep done - 19090.
Ep done - 19100.
Ep done - 19110.
Ep done - 19120.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 280         |
|    time_elapsed         | 2029        |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.020436645 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.742      |
|    explained_variance   | 0.219       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00708     |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0496     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 19130.
Ep done - 19140.
Ep done - 19150.
Ep done - 19160.
Ep done - 19170.
Ep done - 19180.
Ep done - 19190.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.26        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 281         |
|    time_elapsed         | 2035        |
|    total_timesteps      | 575488      |
| train/                  |             |
|    approx_kl            | 0.023472961 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.732      |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0125     |
|    n_updates            | 2800        |
|    policy_gradient_loss | -0.05       |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 19200.
Ep done - 19210.
Ep done - 19220.
Ep done - 19230.
Ep done - 19240.
Ep done - 19250.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.09       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 282        |
|    time_elapsed         | 2042       |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.02128544 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.744     |
|    explained_variance   | 0.00919    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0267    |
|    n_updates            | 2810       |
|    policy_gradient_loss | -0.0472    |
|    value_loss           | 0.175      |
----------------------------------------
Ep done - 19260.
Ep done - 19270.
Ep done - 19280.
Ep done - 19290.
Ep done - 19300.
Ep done - 19310.
Ep done - 19320.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.7        |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 283         |
|    time_elapsed         | 2048        |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.022149587 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.743      |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.023      |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 19330.
Ep done - 19340.
Ep done - 5610.
Ep done - 5620.
Ep done - 5630.
Ep done - 5640.
Ep done - 5650.
Ep done - 5660.
Ep done - 5670.
Ep done - 5680.
Ep done - 5690.
Ep done - 5700.
Ep done - 5710.
Ep done - 5720.
Ep done - 5730.
Ep done - 5740.
Ep done - 5750.
Ep done - 5760.
Ep done - 5770.
Ep done - 5780.
Ep done - 5790.
Ep done - 5800.
Eval num_timesteps=580000, episode_reward=0.04 +/- 0.98
Episode length: 29.99 +/- 0.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.04        |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.023669047 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.777      |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0192     |
|    n_updates            | 2830        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 19350.
Ep done - 19360.
Ep done - 19370.
Ep done - 19380.
Ep done - 19390.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.7     |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    fps             | 281      |
|    iterations      | 284      |
|    time_elapsed    | 2067     |
|    total_timesteps | 581632   |
---------------------------------
Ep done - 19400.
Ep done - 19410.
Ep done - 19420.
Ep done - 19430.
Ep done - 19440.
Ep done - 19450.
Ep done - 19460.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 285         |
|    time_elapsed         | 2073        |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.023129538 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.773      |
|    explained_variance   | 0.132       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0168     |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.0527     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 19470.
Ep done - 19480.
Ep done - 19490.
Ep done - 19500.
Ep done - 19510.
Ep done - 19520.
Ep done - 19530.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 286         |
|    time_elapsed         | 2080        |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.026834434 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.772      |
|    explained_variance   | 0.0971      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0355     |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.0465     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 19540.
Ep done - 19550.
Ep done - 19560.
Ep done - 19570.
Ep done - 19580.
Ep done - 19590.
Ep done - 19600.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.7        |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 287         |
|    time_elapsed         | 2086        |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.023978332 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.803      |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0584     |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.051      |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 19610.
Ep done - 19620.
Ep done - 19630.
Ep done - 19640.
Ep done - 19650.
Ep done - 19660.
Ep done - 19670.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.8       |
|    ep_rew_mean          | 0.28       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 288        |
|    time_elapsed         | 2093       |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.02385804 |
|    clip_fraction        | 0.19       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.775     |
|    explained_variance   | 0.151      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00189    |
|    n_updates            | 2870       |
|    policy_gradient_loss | -0.0497    |
|    value_loss           | 0.176      |
----------------------------------------
Ep done - 19680.
Ep done - 19690.
Ep done - 19700.
Ep done - 19710.
Ep done - 19720.
Ep done - 19730.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 289         |
|    time_elapsed         | 2099        |
|    total_timesteps      | 591872      |
| train/                  |             |
|    approx_kl            | 0.024084482 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.765      |
|    explained_variance   | 0.197       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0263     |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.0546     |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 19740.
Ep done - 19750.
Ep done - 19760.
Ep done - 19770.
Ep done - 19780.
Ep done - 19790.
Ep done - 19800.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 290         |
|    time_elapsed         | 2109        |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.023180608 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.763      |
|    explained_variance   | 0.198       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0145     |
|    n_updates            | 2890        |
|    policy_gradient_loss | -0.0533     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 19810.
Ep done - 19820.
Ep done - 19830.
Ep done - 19840.
Ep done - 19850.
Ep done - 19860.
Ep done - 19870.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 291         |
|    time_elapsed         | 2115        |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.023845095 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.769      |
|    explained_variance   | 0.199       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0132     |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 19880.
Ep done - 19890.
Ep done - 19900.
Ep done - 19910.
Ep done - 19920.
Ep done - 19930.
Ep done - 19940.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 292         |
|    time_elapsed         | 2121        |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.022946957 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.757      |
|    explained_variance   | 0.0809      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00931     |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.0464     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 19950.
Ep done - 19960.
Ep done - 19970.
Ep done - 19980.
Ep done - 19990.
Ep done - 20000.
Ep done - 20010.
Ep done - 5810.
Ep done - 5820.
Ep done - 5830.
Ep done - 5840.
Ep done - 5850.
Ep done - 5860.
Ep done - 5870.
Ep done - 5880.
Ep done - 5890.
Ep done - 5900.
Ep done - 5910.
Ep done - 5920.
Ep done - 5930.
Ep done - 5940.
Ep done - 5950.
Ep done - 5960.
Ep done - 5970.
Ep done - 5980.
Ep done - 5990.
Ep done - 6000.
Eval num_timesteps=600000, episode_reward=0.07 +/- 0.98
Episode length: 29.89 +/- 1.78
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.07        |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.025891215 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.761      |
|    explained_variance   | 0.119       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0117     |
|    n_updates            | 2920        |
|    policy_gradient_loss | -0.0525     |
|    value_loss           | 0.157       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.23     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 293      |
|    time_elapsed    | 2139     |
|    total_timesteps | 600064   |
---------------------------------
Ep done - 20020.
Ep done - 20030.
Ep done - 20040.
Ep done - 20050.
Ep done - 20060.
Ep done - 20070.
Ep done - 20080.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 294         |
|    time_elapsed         | 2145        |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.022669695 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.734      |
|    explained_variance   | 0.254       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0427     |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.0504     |
|    value_loss           | 0.143       |
-----------------------------------------
Ep done - 20090.
Ep done - 20100.
Ep done - 20110.
Ep done - 20120.
Ep done - 20130.
Ep done - 20140.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.25       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 295        |
|    time_elapsed         | 2151       |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.02227497 |
|    clip_fraction        | 0.195      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.763     |
|    explained_variance   | 0.269      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0153    |
|    n_updates            | 2940       |
|    policy_gradient_loss | -0.0501    |
|    value_loss           | 0.172      |
----------------------------------------
Ep done - 20150.
Ep done - 20160.
Ep done - 20170.
Ep done - 20180.
Ep done - 20190.
Ep done - 20200.
Ep done - 20210.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 296         |
|    time_elapsed         | 2156        |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.023547612 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.736      |
|    explained_variance   | 0.342       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0304     |
|    n_updates            | 2950        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 20220.
Ep done - 20230.
Ep done - 20240.
Ep done - 20250.
Ep done - 20260.
Ep done - 20270.
Ep done - 20280.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 297         |
|    time_elapsed         | 2162        |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.025182767 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.757      |
|    explained_variance   | 0.191       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00576    |
|    n_updates            | 2960        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 20290.
Ep done - 20300.
Ep done - 20310.
Ep done - 20320.
Ep done - 20330.
Ep done - 20340.
Ep done - 20350.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30.1      |
|    ep_rew_mean          | 0.1       |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 298       |
|    time_elapsed         | 2168      |
|    total_timesteps      | 610304    |
| train/                  |           |
|    approx_kl            | 0.0257506 |
|    clip_fraction        | 0.206     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.795    |
|    explained_variance   | 0.232     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0111   |
|    n_updates            | 2970      |
|    policy_gradient_loss | -0.0542   |
|    value_loss           | 0.163     |
---------------------------------------
Ep done - 20360.
Ep done - 20370.
Ep done - 20380.
Ep done - 20390.
Ep done - 20400.
Ep done - 20410.
Ep done - 20420.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 299         |
|    time_elapsed         | 2174        |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.023375776 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.762      |
|    explained_variance   | 0.244       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0325     |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.0523     |
|    value_loss           | 0.166       |
-----------------------------------------
Ep done - 20430.
Ep done - 20440.
Ep done - 20450.
Ep done - 20460.
Ep done - 20470.
Ep done - 20480.
Ep done - 20490.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 300         |
|    time_elapsed         | 2179        |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.026734376 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.764      |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0114     |
|    n_updates            | 2990        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 20500.
Ep done - 20510.
Ep done - 20520.
Ep done - 20530.
Ep done - 20540.
Ep done - 20550.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 301         |
|    time_elapsed         | 2185        |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.024240324 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.756      |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0145     |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.0495     |
|    value_loss           | 0.178       |
-----------------------------------------
Ep done - 20560.
Ep done - 20570.
Ep done - 20580.
Ep done - 20590.
Ep done - 20600.
Ep done - 20610.
Ep done - 20620.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 302         |
|    time_elapsed         | 2191        |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.022939764 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.763      |
|    explained_variance   | 0.22        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0312     |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 20630.
Ep done - 20640.
Ep done - 20650.
Ep done - 20660.
Ep done - 20670.
Ep done - 6010.
Ep done - 6020.
Ep done - 6030.
Ep done - 6040.
Ep done - 6050.
Ep done - 6060.
Ep done - 6070.
Ep done - 6080.
Ep done - 6090.
Ep done - 6100.
Ep done - 6110.
Ep done - 6120.
Ep done - 6130.
Ep done - 6140.
Ep done - 6150.
Ep done - 6160.
Ep done - 6170.
Ep done - 6180.
Ep done - 6190.
Ep done - 6200.
Eval num_timesteps=620000, episode_reward=0.21 +/- 0.97
Episode length: 29.98 +/- 0.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.21       |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.02347439 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.743     |
|    explained_variance   | 0.128      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0477    |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.0524    |
|    value_loss           | 0.175      |
----------------------------------------
Ep done - 20680.
Ep done - 20690.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 303      |
|    time_elapsed    | 2209     |
|    total_timesteps | 620544   |
---------------------------------
Ep done - 20700.
Ep done - 20710.
Ep done - 20720.
Ep done - 20730.
Ep done - 20740.
Ep done - 20750.
Ep done - 20760.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 304         |
|    time_elapsed         | 2215        |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.023220971 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.737      |
|    explained_variance   | -0.018      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0272     |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 20770.
Ep done - 20780.
Ep done - 20790.
Ep done - 20800.
Ep done - 20810.
Ep done - 20820.
Ep done - 20830.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 305         |
|    time_elapsed         | 2221        |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.024713054 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.767      |
|    explained_variance   | 0.217       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0242     |
|    n_updates            | 3040        |
|    policy_gradient_loss | -0.0547     |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 20840.
Ep done - 20850.
Ep done - 20860.
Ep done - 20870.
Ep done - 20880.
Ep done - 20890.
Ep done - 20900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 306         |
|    time_elapsed         | 2227        |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.023257166 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.722      |
|    explained_variance   | 0.209       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000745   |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 20910.
Ep done - 20920.
Ep done - 20930.
Ep done - 20940.
Ep done - 20950.
Ep done - 20960.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 307         |
|    time_elapsed         | 2232        |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.025111213 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.727      |
|    explained_variance   | 0.118       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0385     |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.0538     |
|    value_loss           | 0.176       |
-----------------------------------------
Ep done - 20970.
Ep done - 20980.
Ep done - 20990.
Ep done - 21000.
Ep done - 21010.
Ep done - 21020.
Ep done - 21030.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 308         |
|    time_elapsed         | 2238        |
|    total_timesteps      | 630784      |
| train/                  |             |
|    approx_kl            | 0.021455694 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.757      |
|    explained_variance   | 0.273       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.027      |
|    n_updates            | 3070        |
|    policy_gradient_loss | -0.0507     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 21040.
Ep done - 21050.
Ep done - 21060.
Ep done - 21070.
Ep done - 21080.
Ep done - 21090.
Ep done - 21100.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 309         |
|    time_elapsed         | 2244        |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.021388294 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.73       |
|    explained_variance   | 0.188       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0206     |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.183       |
-----------------------------------------
Ep done - 21110.
Ep done - 21120.
Ep done - 21130.
Ep done - 21140.
Ep done - 21150.
Ep done - 21160.
Ep done - 21170.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 310         |
|    time_elapsed         | 2250        |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.027889838 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.708      |
|    explained_variance   | 0.139       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0573     |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.0489     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 21180.
Ep done - 21190.
Ep done - 21200.
Ep done - 21210.
Ep done - 21220.
Ep done - 21230.
Ep done - 21240.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 311         |
|    time_elapsed         | 2256        |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.024344603 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.731      |
|    explained_variance   | 0.129       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0154     |
|    n_updates            | 3100        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 21250.
Ep done - 21260.
Ep done - 21270.
Ep done - 21280.
Ep done - 21290.
Ep done - 21300.
Ep done - 21310.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.15       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 312        |
|    time_elapsed         | 2261       |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.02504835 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.708     |
|    explained_variance   | 0.146      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0113     |
|    n_updates            | 3110       |
|    policy_gradient_loss | -0.0519    |
|    value_loss           | 0.177      |
----------------------------------------
Ep done - 21320.
Ep done - 21330.
Ep done - 21340.
Ep done - 6210.
Ep done - 6220.
Ep done - 6230.
Ep done - 6240.
Ep done - 6250.
Ep done - 6260.
Ep done - 6270.
Ep done - 6280.
Ep done - 6290.
Ep done - 6300.
Ep done - 6310.
Ep done - 6320.
Ep done - 6330.
Ep done - 6340.
Ep done - 6350.
Ep done - 6360.
Ep done - 6370.
Ep done - 6380.
Ep done - 6390.
Ep done - 6400.
Eval num_timesteps=640000, episode_reward=0.22 +/- 0.98
Episode length: 30.00 +/- 0.67
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.22       |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.02377625 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.731     |
|    explained_variance   | 0.133      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0394    |
|    n_updates            | 3120       |
|    policy_gradient_loss | -0.0497    |
|    value_loss           | 0.162      |
----------------------------------------
Ep done - 21350.
Ep done - 21360.
Ep done - 21370.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 313      |
|    time_elapsed    | 2280     |
|    total_timesteps | 641024   |
---------------------------------
Ep done - 21380.
Ep done - 21390.
Ep done - 21400.
Ep done - 21410.
Ep done - 21420.
Ep done - 21430.
Ep done - 21440.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.34       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 314        |
|    time_elapsed         | 2285       |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.02494311 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.725     |
|    explained_variance   | 0.12       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.026     |
|    n_updates            | 3130       |
|    policy_gradient_loss | -0.0506    |
|    value_loss           | 0.149      |
----------------------------------------
Ep done - 21450.
Ep done - 21460.
Ep done - 21470.
Ep done - 21480.
Ep done - 21490.
Ep done - 21500.
Ep done - 21510.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.24       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 315        |
|    time_elapsed         | 2291       |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.02194402 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.734     |
|    explained_variance   | 0.156      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0121     |
|    n_updates            | 3140       |
|    policy_gradient_loss | -0.0475    |
|    value_loss           | 0.174      |
----------------------------------------
Ep done - 21520.
Ep done - 21530.
Ep done - 21540.
Ep done - 21550.
Ep done - 21560.
Ep done - 21570.
Ep done - 21580.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.33       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 316        |
|    time_elapsed         | 2297       |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.02771064 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.742     |
|    explained_variance   | 0.266      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0386    |
|    n_updates            | 3150       |
|    policy_gradient_loss | -0.0513    |
|    value_loss           | 0.157      |
----------------------------------------
Ep done - 21590.
Ep done - 21600.
Ep done - 21610.
Ep done - 21620.
Ep done - 21630.
Ep done - 21640.
Ep done - 21650.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 317         |
|    time_elapsed         | 2303        |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.027589053 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.727      |
|    explained_variance   | 0.0867      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0017      |
|    n_updates            | 3160        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.149       |
-----------------------------------------
Ep done - 21660.
Ep done - 21670.
Ep done - 21680.
Ep done - 21690.
Ep done - 21700.
Ep done - 21710.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 318         |
|    time_elapsed         | 2309        |
|    total_timesteps      | 651264      |
| train/                  |             |
|    approx_kl            | 0.023151422 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.73       |
|    explained_variance   | 0.213       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00908    |
|    n_updates            | 3170        |
|    policy_gradient_loss | -0.0517     |
|    value_loss           | 0.148       |
-----------------------------------------
Ep done - 21720.
Ep done - 21730.
Ep done - 21740.
Ep done - 21750.
Ep done - 21760.
Ep done - 21770.
Ep done - 21780.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 319         |
|    time_elapsed         | 2314        |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.025787879 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.749      |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0196     |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.052      |
|    value_loss           | 0.178       |
-----------------------------------------
Ep done - 21790.
Ep done - 21800.
Ep done - 21810.
Ep done - 21820.
Ep done - 21830.
Ep done - 21840.
Ep done - 21850.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 320         |
|    time_elapsed         | 2320        |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.026217993 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.736      |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0252     |
|    n_updates            | 3190        |
|    policy_gradient_loss | -0.0527     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 21860.
Ep done - 21870.
Ep done - 21880.
Ep done - 21890.
Ep done - 21900.
Ep done - 21910.
Ep done - 21920.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.01        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 321         |
|    time_elapsed         | 2326        |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.023256224 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.73       |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.022      |
|    n_updates            | 3200        |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 21930.
Ep done - 21940.
Ep done - 21950.
Ep done - 21960.
Ep done - 21970.
Ep done - 21980.
Ep done - 21990.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.2        |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 322        |
|    time_elapsed         | 2332       |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.02565222 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.726     |
|    explained_variance   | 0.17       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0126    |
|    n_updates            | 3210       |
|    policy_gradient_loss | -0.0495    |
|    value_loss           | 0.182      |
----------------------------------------
Ep done - 22000.
Ep done - 6410.
Ep done - 6420.
Ep done - 6430.
Ep done - 6440.
Ep done - 6450.
Ep done - 6460.
Ep done - 6470.
Ep done - 6480.
Ep done - 6490.
Ep done - 6500.
Ep done - 6510.
Ep done - 6520.
Ep done - 6530.
Ep done - 6540.
Ep done - 6550.
Ep done - 6560.
Ep done - 6570.
Ep done - 6580.
Ep done - 6590.
Ep done - 6600.
Eval num_timesteps=660000, episode_reward=0.28 +/- 0.95
Episode length: 30.07 +/- 0.63
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.275       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.024691135 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.707      |
|    explained_variance   | 0.0492      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0391     |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.172       |
-----------------------------------------
Ep done - 22010.
Ep done - 22020.
Ep done - 22030.
Ep done - 22040.
Ep done - 22050.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.26     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 323      |
|    time_elapsed    | 2350     |
|    total_timesteps | 661504   |
---------------------------------
Ep done - 22060.
Ep done - 22070.
Ep done - 22080.
Ep done - 22090.
Ep done - 22100.
Ep done - 22110.
Ep done - 22120.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.22        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 324         |
|    time_elapsed         | 2356        |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.026352797 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.724      |
|    explained_variance   | 0.149       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0191     |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 22130.
Ep done - 22140.
Ep done - 22150.
Ep done - 22160.
Ep done - 22170.
Ep done - 22180.
Ep done - 22190.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 325         |
|    time_elapsed         | 2362        |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.024078928 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.707      |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00936    |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 22200.
Ep done - 22210.
Ep done - 22220.
Ep done - 22230.
Ep done - 22240.
Ep done - 22250.
Ep done - 22260.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.21       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 326        |
|    time_elapsed         | 2368       |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.02507887 |
|    clip_fraction        | 0.196      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.735     |
|    explained_variance   | 0.13       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0345    |
|    n_updates            | 3250       |
|    policy_gradient_loss | -0.0517    |
|    value_loss           | 0.168      |
----------------------------------------
Ep done - 22270.
Ep done - 22280.
Ep done - 22290.
Ep done - 22300.
Ep done - 22310.
Ep done - 22320.
Ep done - 22330.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 327         |
|    time_elapsed         | 2374        |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.022821037 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.717      |
|    explained_variance   | 0.275       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00441    |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.0483     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 22340.
Ep done - 22350.
Ep done - 22360.
Ep done - 22370.
Ep done - 22380.
Ep done - 22390.
Ep done - 22400.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 328         |
|    time_elapsed         | 2380        |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.027815577 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.726      |
|    explained_variance   | 0.171       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0235     |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 22410.
Ep done - 22420.
Ep done - 22430.
Ep done - 22440.
Ep done - 22450.
Ep done - 22460.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 329         |
|    time_elapsed         | 2386        |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.023546249 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.718      |
|    explained_variance   | 0.0483      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.011      |
|    n_updates            | 3280        |
|    policy_gradient_loss | -0.0478     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 22470.
Ep done - 22480.
Ep done - 22490.
Ep done - 22500.
Ep done - 22510.
Ep done - 22520.
Ep done - 22530.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 330         |
|    time_elapsed         | 2392        |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.023626316 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.734      |
|    explained_variance   | 0.229       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0334     |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.0518     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 22540.
Ep done - 22550.
Ep done - 22560.
Ep done - 22570.
Ep done - 22580.
Ep done - 22590.
Ep done - 22600.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 331         |
|    time_elapsed         | 2398        |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.024221849 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.73       |
|    explained_variance   | 0.112       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0466     |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.0504     |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 22610.
Ep done - 22620.
Ep done - 22630.
Ep done - 22640.
Ep done - 22650.
Ep done - 22660.
Ep done - 22670.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 332         |
|    time_elapsed         | 2404        |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.024859058 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.732      |
|    explained_variance   | 0.213       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0232     |
|    n_updates            | 3310        |
|    policy_gradient_loss | -0.0532     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 6610.
Ep done - 6620.
Ep done - 6630.
Ep done - 6640.
Ep done - 6650.
Ep done - 6660.
Ep done - 6670.
Ep done - 6680.
Ep done - 6690.
Ep done - 6700.
Ep done - 6710.
Ep done - 6720.
Ep done - 6730.
Ep done - 6740.
Ep done - 6750.
Ep done - 6760.
Ep done - 6770.
Ep done - 6780.
Ep done - 6790.
Ep done - 6800.
Eval num_timesteps=680000, episode_reward=0.28 +/- 0.95
Episode length: 29.99 +/- 0.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.285       |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.028031051 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.748      |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0424     |
|    n_updates            | 3320        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 22680.
Ep done - 22690.
Ep done - 22700.
Ep done - 22710.
Ep done - 22720.
Ep done - 22730.
Ep done - 22740.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.37     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 333      |
|    time_elapsed    | 2423     |
|    total_timesteps | 681984   |
---------------------------------
Ep done - 22750.
Ep done - 22760.
Ep done - 22770.
Ep done - 22780.
Ep done - 22790.
Ep done - 22800.
Ep done - 22810.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.35       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 334        |
|    time_elapsed         | 2429       |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.02549539 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.726     |
|    explained_variance   | 0.168      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0284    |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.051     |
|    value_loss           | 0.154      |
----------------------------------------
Ep done - 22820.
Ep done - 22830.
Ep done - 22840.
Ep done - 22850.
Ep done - 22860.
Ep done - 22870.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 335         |
|    time_elapsed         | 2434        |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.021006925 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.728      |
|    explained_variance   | 0.0629      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0464     |
|    n_updates            | 3340        |
|    policy_gradient_loss | -0.0495     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 22880.
Ep done - 22890.
Ep done - 22900.
Ep done - 22910.
Ep done - 22920.
Ep done - 22930.
Ep done - 22940.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.36        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 336         |
|    time_elapsed         | 2440        |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.026017617 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.694      |
|    explained_variance   | 0.242       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0194     |
|    n_updates            | 3350        |
|    policy_gradient_loss | -0.051      |
|    value_loss           | 0.158       |
-----------------------------------------
Ep done - 22950.
Ep done - 22960.
Ep done - 22970.
Ep done - 22980.
Ep done - 22990.
Ep done - 23000.
Ep done - 23010.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 337         |
|    time_elapsed         | 2446        |
|    total_timesteps      | 690176      |
| train/                  |             |
|    approx_kl            | 0.025707705 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.737      |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.027      |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.0517     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 23020.
Ep done - 23030.
Ep done - 23040.
Ep done - 23050.
Ep done - 23060.
Ep done - 23070.
Ep done - 23080.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 338         |
|    time_elapsed         | 2453        |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.024879787 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.718      |
|    explained_variance   | 0.157       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0349     |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.0518     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 23090.
Ep done - 23100.
Ep done - 23110.
Ep done - 23120.
Ep done - 23130.
Ep done - 23140.
Ep done - 23150.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 339         |
|    time_elapsed         | 2459        |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.027677272 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.76       |
|    explained_variance   | 0.267       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0472     |
|    n_updates            | 3380        |
|    policy_gradient_loss | -0.0527     |
|    value_loss           | 0.179       |
-----------------------------------------
Ep done - 23160.
Ep done - 23170.
Ep done - 23180.
Ep done - 23190.
Ep done - 23200.
Ep done - 23210.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.22        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 340         |
|    time_elapsed         | 2465        |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.024484448 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.734      |
|    explained_variance   | 0.153       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0162     |
|    n_updates            | 3390        |
|    policy_gradient_loss | -0.0483     |
|    value_loss           | 0.166       |
-----------------------------------------
Ep done - 23220.
Ep done - 23230.
Ep done - 23240.
Ep done - 23250.
Ep done - 23260.
Ep done - 23270.
Ep done - 23280.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.1        |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 341        |
|    time_elapsed         | 2471       |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.02667423 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.738     |
|    explained_variance   | 0.224      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0229    |
|    n_updates            | 3400       |
|    policy_gradient_loss | -0.0528    |
|    value_loss           | 0.174      |
----------------------------------------
Ep done - 23290.
Ep done - 23300.
Ep done - 23310.
Ep done - 23320.
Ep done - 23330.
Ep done - 23340.
Ep done - 6810.
Ep done - 6820.
Ep done - 6830.
Ep done - 6840.
Ep done - 6850.
Ep done - 6860.
Ep done - 6870.
Ep done - 6880.
Ep done - 6890.
Ep done - 6900.
Ep done - 6910.
Ep done - 6920.
Ep done - 6930.
Ep done - 6940.
Ep done - 6950.
Ep done - 6960.
Ep done - 6970.
Ep done - 6980.
Ep done - 6990.
Ep done - 7000.
Eval num_timesteps=700000, episode_reward=0.09 +/- 0.99
Episode length: 29.90 +/- 0.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.085       |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.027364977 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.741      |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0281     |
|    n_updates            | 3410        |
|    policy_gradient_loss | -0.0531     |
|    value_loss           | 0.178       |
-----------------------------------------
Ep done - 23350.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.33     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 342      |
|    time_elapsed    | 2490     |
|    total_timesteps | 700416   |
---------------------------------
Ep done - 23360.
Ep done - 23370.
Ep done - 23380.
Ep done - 23390.
Ep done - 23400.
Ep done - 23410.
Ep done - 23420.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.22       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 343        |
|    time_elapsed         | 2497       |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.02455983 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.714     |
|    explained_variance   | 0.137      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0359    |
|    n_updates            | 3420       |
|    policy_gradient_loss | -0.0502    |
|    value_loss           | 0.145      |
----------------------------------------
Ep done - 23430.
Ep done - 23440.
Ep done - 23450.
Ep done - 23460.
Ep done - 23470.
Ep done - 23480.
Ep done - 23490.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 344         |
|    time_elapsed         | 2503        |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.027602365 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.727      |
|    explained_variance   | 0.286       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0335     |
|    n_updates            | 3430        |
|    policy_gradient_loss | -0.0545     |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 23500.
Ep done - 23510.
Ep done - 23520.
Ep done - 23530.
Ep done - 23540.
Ep done - 23550.
Ep done - 23560.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.23       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 345        |
|    time_elapsed         | 2510       |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.02597271 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.734     |
|    explained_variance   | 0.0707     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00461    |
|    n_updates            | 3440       |
|    policy_gradient_loss | -0.0521    |
|    value_loss           | 0.183      |
----------------------------------------
Ep done - 23570.
Ep done - 23580.
Ep done - 23590.
Ep done - 23600.
Ep done - 23610.
Ep done - 23620.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.41        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 346         |
|    time_elapsed         | 2517        |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.023222996 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.732      |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00685    |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.0491     |
|    value_loss           | 0.176       |
-----------------------------------------
Ep done - 23630.
Ep done - 23640.
Ep done - 23650.
Ep done - 23660.
Ep done - 23670.
Ep done - 23680.
Ep done - 23690.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 347         |
|    time_elapsed         | 2526        |
|    total_timesteps      | 710656      |
| train/                  |             |
|    approx_kl            | 0.027385704 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.735      |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0575     |
|    n_updates            | 3460        |
|    policy_gradient_loss | -0.0514     |
|    value_loss           | 0.15        |
-----------------------------------------
Ep done - 23700.
Ep done - 23710.
Ep done - 23720.
Ep done - 23730.
Ep done - 23740.
Ep done - 23750.
Ep done - 23760.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.43        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 348         |
|    time_elapsed         | 2532        |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.023845954 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.736      |
|    explained_variance   | 0.208       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00689    |
|    n_updates            | 3470        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.153       |
-----------------------------------------
Ep done - 23770.
Ep done - 23780.
Ep done - 23790.
Ep done - 23800.
Ep done - 23810.
Ep done - 23820.
Ep done - 23830.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.43        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 349         |
|    time_elapsed         | 2538        |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.028580084 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.736      |
|    explained_variance   | 0.261       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00864    |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.136       |
-----------------------------------------
Ep done - 23840.
Ep done - 23850.
Ep done - 23860.
Ep done - 23870.
Ep done - 23880.
Ep done - 23890.
Ep done - 23900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 350         |
|    time_elapsed         | 2543        |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.024781646 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.728      |
|    explained_variance   | 0.043       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0146     |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.0497     |
|    value_loss           | 0.146       |
-----------------------------------------
Ep done - 23910.
Ep done - 23920.
Ep done - 23930.
Ep done - 23940.
Ep done - 23950.
Ep done - 23960.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 351         |
|    time_elapsed         | 2549        |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.030356297 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.716      |
|    explained_variance   | 0.267       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0388     |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.0525     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 23970.
Ep done - 23980.
Ep done - 23990.
Ep done - 24000.
Ep done - 7010.
Ep done - 7020.
Ep done - 7030.
Ep done - 7040.
Ep done - 7050.
Ep done - 7060.
Ep done - 7070.
Ep done - 7080.
Ep done - 7090.
Ep done - 7100.
Ep done - 7110.
Ep done - 7120.
Ep done - 7130.
Ep done - 7140.
Ep done - 7150.
Ep done - 7160.
Ep done - 7170.
Ep done - 7180.
Ep done - 7190.
Ep done - 7200.
Eval num_timesteps=720000, episode_reward=0.32 +/- 0.94
Episode length: 30.07 +/- 0.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.315       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.023668852 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.701      |
|    explained_variance   | 0.0481      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0179     |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.156       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.315
SELFPLAY: new best model, bumping up generation to 10
Ep done - 24010.
Ep done - 24020.
Ep done - 24030.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.11     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 352      |
|    time_elapsed    | 2567     |
|    total_timesteps | 720896   |
---------------------------------
Ep done - 24040.
Ep done - 24050.
Ep done - 24060.
Ep done - 24070.
Ep done - 24080.
Ep done - 24090.
Ep done - 24100.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.07       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 353        |
|    time_elapsed         | 2573       |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.02651381 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.745     |
|    explained_variance   | 0.158      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.035     |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.0516    |
|    value_loss           | 0.172      |
----------------------------------------
Ep done - 24110.
Ep done - 24120.
Ep done - 24130.
Ep done - 24140.
Ep done - 24150.
Ep done - 24160.
Ep done - 24170.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 354         |
|    time_elapsed         | 2579        |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.026785214 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.74       |
|    explained_variance   | 0.212       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0256     |
|    n_updates            | 3530        |
|    policy_gradient_loss | -0.0548     |
|    value_loss           | 0.158       |
-----------------------------------------
Ep done - 24180.
Ep done - 24190.
Ep done - 24200.
Ep done - 24210.
Ep done - 24220.
Ep done - 24230.
Ep done - 24240.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | -0.01      |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 355        |
|    time_elapsed         | 2585       |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.02642811 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.749     |
|    explained_variance   | 0.158      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00428    |
|    n_updates            | 3540       |
|    policy_gradient_loss | -0.0529    |
|    value_loss           | 0.167      |
----------------------------------------
Ep done - 24250.
Ep done - 24260.
Ep done - 24270.
Ep done - 24280.
Ep done - 24290.
Ep done - 24300.
Ep done - 24310.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.16       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 356         |
|    time_elapsed         | 2591        |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.026662275 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.751      |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0302     |
|    n_updates            | 3550        |
|    policy_gradient_loss | -0.0516     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 24320.
Ep done - 24330.
Ep done - 24340.
Ep done - 24350.
Ep done - 24360.
Ep done - 24370.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.07       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 357         |
|    time_elapsed         | 2596        |
|    total_timesteps      | 731136      |
| train/                  |             |
|    approx_kl            | 0.024542304 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.72       |
|    explained_variance   | 0.168       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0364     |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 24380.
Ep done - 24390.
Ep done - 24400.
Ep done - 24410.
Ep done - 24420.
Ep done - 24430.
Ep done - 24440.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.05       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 358         |
|    time_elapsed         | 2602        |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.028935272 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.773      |
|    explained_variance   | 0.182       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0291     |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.0535     |
|    value_loss           | 0.165       |
-----------------------------------------
Ep done - 24450.
Ep done - 24460.
Ep done - 24470.
Ep done - 24480.
Ep done - 24490.
Ep done - 24500.
Ep done - 24510.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 359         |
|    time_elapsed         | 2608        |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.027030844 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.778      |
|    explained_variance   | 0.211       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.026      |
|    n_updates            | 3580        |
|    policy_gradient_loss | -0.0516     |
|    value_loss           | 0.165       |
-----------------------------------------
Ep done - 24520.
Ep done - 24530.
Ep done - 24540.
Ep done - 24550.
Ep done - 24560.
Ep done - 24570.
Ep done - 24580.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 360         |
|    time_elapsed         | 2614        |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.025762793 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.743      |
|    explained_variance   | 0.126       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.044      |
|    n_updates            | 3590        |
|    policy_gradient_loss | -0.051      |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 24590.
Ep done - 24600.
Ep done - 24610.
Ep done - 24620.
Ep done - 24630.
Ep done - 24640.
Ep done - 24650.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 361         |
|    time_elapsed         | 2619        |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.027167317 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.763      |
|    explained_variance   | 0.237       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0335     |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0548     |
|    value_loss           | 0.182       |
-----------------------------------------
Ep done - 24660.
Ep done - 24670.
Ep done - 7210.
Ep done - 7220.
Ep done - 7230.
Ep done - 7240.
Ep done - 7250.
Ep done - 7260.
Ep done - 7270.
Ep done - 7280.
Ep done - 7290.
Ep done - 7300.
Ep done - 7310.
Ep done - 7320.
Ep done - 7330.
Ep done - 7340.
Ep done - 7350.
Ep done - 7360.
Ep done - 7370.
Ep done - 7380.
Ep done - 7390.
Ep done - 7400.
Eval num_timesteps=740000, episode_reward=0.01 +/- 0.99
Episode length: 29.96 +/- 0.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.005       |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.024993174 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.714      |
|    explained_variance   | 0.214       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0178     |
|    n_updates            | 3610        |
|    policy_gradient_loss | -0.0524     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 24680.
Ep done - 24690.
Ep done - 24700.
Ep done - 24710.
Ep done - 24720.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.07     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 362      |
|    time_elapsed    | 2638     |
|    total_timesteps | 741376   |
---------------------------------
Ep done - 24730.
Ep done - 24740.
Ep done - 24750.
Ep done - 24760.
Ep done - 24770.
Ep done - 24780.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30.1      |
|    ep_rew_mean          | 0.08      |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 363       |
|    time_elapsed         | 2643      |
|    total_timesteps      | 743424    |
| train/                  |           |
|    approx_kl            | 0.0292779 |
|    clip_fraction        | 0.213     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.748    |
|    explained_variance   | 0.293     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0258   |
|    n_updates            | 3620      |
|    policy_gradient_loss | -0.0542   |
|    value_loss           | 0.164     |
---------------------------------------
Ep done - 24790.
Ep done - 24800.
Ep done - 24810.
Ep done - 24820.
Ep done - 24830.
Ep done - 24840.
Ep done - 24850.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.06       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 364         |
|    time_elapsed         | 2649        |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.024898924 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.744      |
|    explained_variance   | 0.253       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0212     |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 24860.
Ep done - 24870.
Ep done - 24880.
Ep done - 24890.
Ep done - 24900.
Ep done - 24910.
Ep done - 24920.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.05       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 365         |
|    time_elapsed         | 2655        |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.025575072 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.737      |
|    explained_variance   | 0.125       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00329    |
|    n_updates            | 3640        |
|    policy_gradient_loss | -0.0528     |
|    value_loss           | 0.193       |
-----------------------------------------
Ep done - 24930.
Ep done - 24940.
Ep done - 24950.
Ep done - 24960.
Ep done - 24970.
Ep done - 24980.
Ep done - 24990.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.01        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 366         |
|    time_elapsed         | 2661        |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.026902039 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.732      |
|    explained_variance   | 0.275       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0096     |
|    n_updates            | 3650        |
|    policy_gradient_loss | -0.0508     |
|    value_loss           | 0.178       |
-----------------------------------------
Ep done - 25000.
Ep done - 25010.
Ep done - 25020.
Ep done - 25030.
Ep done - 25040.
Ep done - 25050.
Ep done - 25060.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.08       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 367        |
|    time_elapsed         | 2667       |
|    total_timesteps      | 751616     |
| train/                  |            |
|    approx_kl            | 0.02560645 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.71      |
|    explained_variance   | 0.343      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0313    |
|    n_updates            | 3660       |
|    policy_gradient_loss | -0.0509    |
|    value_loss           | 0.153      |
----------------------------------------
Ep done - 25070.
Ep done - 25080.
Ep done - 25090.
Ep done - 25100.
Ep done - 25110.
Ep done - 25120.
Ep done - 25130.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 368         |
|    time_elapsed         | 2672        |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.024232892 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.743      |
|    explained_variance   | 0.0545      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0268     |
|    n_updates            | 3670        |
|    policy_gradient_loss | -0.0526     |
|    value_loss           | 0.193       |
-----------------------------------------
Ep done - 25140.
Ep done - 25150.
Ep done - 25160.
Ep done - 25170.
Ep done - 25180.
Ep done - 25190.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 369         |
|    time_elapsed         | 2678        |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.025170282 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.705      |
|    explained_variance   | 0.0924      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0318     |
|    n_updates            | 3680        |
|    policy_gradient_loss | -0.0502     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 25200.
Ep done - 25210.
Ep done - 25220.
Ep done - 25230.
Ep done - 25240.
Ep done - 25250.
Ep done - 25260.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 370         |
|    time_elapsed         | 2684        |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.024561776 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.71       |
|    explained_variance   | 0.132       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0254     |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0509     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 25270.
Ep done - 25280.
Ep done - 25290.
Ep done - 25300.
Ep done - 25310.
Ep done - 25320.
Ep done - 25330.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.32       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 371        |
|    time_elapsed         | 2690       |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.02454949 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.704     |
|    explained_variance   | 0.371      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0274    |
|    n_updates            | 3700       |
|    policy_gradient_loss | -0.0512    |
|    value_loss           | 0.147      |
----------------------------------------
Ep done - 25340.
Ep done - 7410.
Ep done - 7420.
Ep done - 7430.
Ep done - 7440.
Ep done - 7450.
Ep done - 7460.
Ep done - 7470.
Ep done - 7480.
Ep done - 7490.
Ep done - 7500.
Ep done - 7510.
Ep done - 7520.
Ep done - 7530.
Ep done - 7540.
Ep done - 7550.
Ep done - 7560.
Ep done - 7570.
Ep done - 7580.
Ep done - 7590.
Ep done - 7600.
Eval num_timesteps=760000, episode_reward=0.18 +/- 0.97
Episode length: 29.95 +/- 0.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.18        |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.024914645 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.696      |
|    explained_variance   | 0.173       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0416     |
|    n_updates            | 3710        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 25350.
Ep done - 25360.
Ep done - 25370.
Ep done - 25380.
Ep done - 25390.
Ep done - 25400.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 372      |
|    time_elapsed    | 2708     |
|    total_timesteps | 761856   |
---------------------------------
Ep done - 25410.
Ep done - 25420.
Ep done - 25430.
Ep done - 25440.
Ep done - 25450.
Ep done - 25460.
Ep done - 25470.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.04       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 373         |
|    time_elapsed         | 2714        |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.025364185 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.717      |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0253     |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.0504     |
|    value_loss           | 0.166       |
-----------------------------------------
Ep done - 25480.
Ep done - 25490.
Ep done - 25500.
Ep done - 25510.
Ep done - 25520.
Ep done - 25530.
Ep done - 25540.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0          |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 374        |
|    time_elapsed         | 2720       |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.02404119 |
|    clip_fraction        | 0.203      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.715     |
|    explained_variance   | 0.263      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0189    |
|    n_updates            | 3730       |
|    policy_gradient_loss | -0.0548    |
|    value_loss           | 0.18       |
----------------------------------------
Ep done - 25550.
Ep done - 25560.
Ep done - 25570.
Ep done - 25580.
Ep done - 25590.
Ep done - 25600.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 375         |
|    time_elapsed         | 2726        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.023928244 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.707      |
|    explained_variance   | 0.0829      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0225     |
|    n_updates            | 3740        |
|    policy_gradient_loss | -0.0491     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 25610.
Ep done - 25620.
Ep done - 25630.
Ep done - 25640.
Ep done - 25650.
Ep done - 25660.
Ep done - 25670.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 376         |
|    time_elapsed         | 2732        |
|    total_timesteps      | 770048      |
| train/                  |             |
|    approx_kl            | 0.024601687 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.736      |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00732    |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.0516     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 25680.
Ep done - 25690.
Ep done - 25700.
Ep done - 25710.
Ep done - 25720.
Ep done - 25730.
Ep done - 25740.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 377         |
|    time_elapsed         | 2737        |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.026525125 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.727      |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0464     |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.0531     |
|    value_loss           | 0.145       |
-----------------------------------------
Ep done - 25750.
Ep done - 25760.
Ep done - 25770.
Ep done - 25780.
Ep done - 25790.
Ep done - 25800.
Ep done - 25810.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 378         |
|    time_elapsed         | 2743        |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.026543988 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.704      |
|    explained_variance   | 0.256       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0094     |
|    n_updates            | 3770        |
|    policy_gradient_loss | -0.0521     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 25820.
Ep done - 25830.
Ep done - 25840.
Ep done - 25850.
Ep done - 25860.
Ep done - 25870.
Ep done - 25880.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.3        |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 379        |
|    time_elapsed         | 2749       |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.02265729 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.697     |
|    explained_variance   | 0.275      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00516   |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.0486    |
|    value_loss           | 0.158      |
----------------------------------------
Ep done - 25890.
Ep done - 25900.
Ep done - 25910.
Ep done - 25920.
Ep done - 25930.
Ep done - 25940.
Ep done - 25950.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.11       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 380        |
|    time_elapsed         | 2755       |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.02484563 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.678     |
|    explained_variance   | 0.289      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0187    |
|    n_updates            | 3790       |
|    policy_gradient_loss | -0.0482    |
|    value_loss           | 0.147      |
----------------------------------------
Ep done - 25960.
Ep done - 25970.
Ep done - 25980.
Ep done - 25990.
Ep done - 26000.
Ep done - 7610.
Ep done - 7620.
Ep done - 7630.
Ep done - 7640.
Ep done - 7650.
Ep done - 7660.
Ep done - 7670.
Ep done - 7680.
Ep done - 7690.
Ep done - 7700.
Ep done - 7710.
Ep done - 7720.
Ep done - 7730.
Ep done - 7740.
Ep done - 7750.
Ep done - 7760.
Ep done - 7770.
Ep done - 7780.
Ep done - 7790.
Ep done - 7800.
Eval num_timesteps=780000, episode_reward=0.16 +/- 0.98
Episode length: 29.97 +/- 0.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.16        |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.025726557 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.695      |
|    explained_variance   | 0.281       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00412     |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.178       |
-----------------------------------------
Ep done - 26010.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.01     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 381      |
|    time_elapsed    | 2774     |
|    total_timesteps | 780288   |
---------------------------------
Ep done - 26020.
Ep done - 26030.
Ep done - 26040.
Ep done - 26050.
Ep done - 26060.
Ep done - 26070.
Ep done - 26080.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 382         |
|    time_elapsed         | 2779        |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.024211492 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.7        |
|    explained_variance   | 0.279       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0312     |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 26090.
Ep done - 26100.
Ep done - 26110.
Ep done - 26120.
Ep done - 26130.
Ep done - 26140.
Ep done - 26150.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 383         |
|    time_elapsed         | 2785        |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.021867257 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0227     |
|    n_updates            | 3820        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 26160.
Ep done - 26170.
Ep done - 26180.
Ep done - 26190.
Ep done - 26200.
Ep done - 26210.
Ep done - 26220.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.12       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 384        |
|    time_elapsed         | 2791       |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.02672518 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.716     |
|    explained_variance   | 0.182      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0445    |
|    n_updates            | 3830       |
|    policy_gradient_loss | -0.051     |
|    value_loss           | 0.168      |
----------------------------------------
Ep done - 26230.
Ep done - 26240.
Ep done - 26250.
Ep done - 26260.
Ep done - 26270.
Ep done - 26280.
Ep done - 26290.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.22        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 385         |
|    time_elapsed         | 2797        |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.026940493 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.7        |
|    explained_variance   | 0.162       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00166     |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.0518     |
|    value_loss           | 0.191       |
-----------------------------------------
Ep done - 26300.
Ep done - 26310.
Ep done - 26320.
Ep done - 26330.
Ep done - 26340.
Ep done - 26350.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.22        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 386         |
|    time_elapsed         | 2803        |
|    total_timesteps      | 790528      |
| train/                  |             |
|    approx_kl            | 0.025165837 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.697      |
|    explained_variance   | 0.259       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0403     |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.0529     |
|    value_loss           | 0.148       |
-----------------------------------------
Ep done - 26360.
Ep done - 26370.
Ep done - 26380.
Ep done - 26390.
Ep done - 26400.
Ep done - 26410.
Ep done - 26420.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 387         |
|    time_elapsed         | 2809        |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.023278793 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.692      |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0137     |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.049      |
|    value_loss           | 0.185       |
-----------------------------------------
Ep done - 26430.
Ep done - 26440.
Ep done - 26450.
Ep done - 26460.
Ep done - 26470.
Ep done - 26480.
Ep done - 26490.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.11        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 388         |
|    time_elapsed         | 2815        |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.023642171 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.66       |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0235     |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 26500.
Ep done - 26510.
Ep done - 26520.
Ep done - 26530.
Ep done - 26540.
Ep done - 26550.
Ep done - 26560.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.28        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 389         |
|    time_elapsed         | 2821        |
|    total_timesteps      | 796672      |
| train/                  |             |
|    approx_kl            | 0.025865741 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.686      |
|    explained_variance   | 0.27        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.036      |
|    n_updates            | 3880        |
|    policy_gradient_loss | -0.0529     |
|    value_loss           | 0.146       |
-----------------------------------------
Ep done - 26570.
Ep done - 26580.
Ep done - 26590.
Ep done - 26600.
Ep done - 26610.
Ep done - 26620.
Ep done - 26630.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 390         |
|    time_elapsed         | 2827        |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.027874108 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.684      |
|    explained_variance   | 0.372       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00665    |
|    n_updates            | 3890        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 26640.
Ep done - 26650.
Ep done - 26660.
Ep done - 26670.
Ep done - 7810.
Ep done - 7820.
Ep done - 7830.
Ep done - 7840.
Ep done - 7850.
Ep done - 7860.
Ep done - 7870.
Ep done - 7880.
Ep done - 7890.
Ep done - 7900.
Ep done - 7910.
Ep done - 7920.
Ep done - 7930.
Ep done - 7940.
Ep done - 7950.
Ep done - 7960.
Ep done - 7970.
Ep done - 7980.
Ep done - 7990.
Ep done - 8000.
Eval num_timesteps=800000, episode_reward=0.30 +/- 0.93
Episode length: 30.06 +/- 0.66
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.305       |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.024245098 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.687      |
|    explained_variance   | 0.0524      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0225     |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.0522     |
|    value_loss           | 0.167       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.305
SELFPLAY: new best model, bumping up generation to 11
Ep done - 26680.
Ep done - 26690.
Ep done - 26700.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | -0.01    |
| time/              |          |
|    fps             | 281      |
|    iterations      | 391      |
|    time_elapsed    | 2846     |
|    total_timesteps | 800768   |
---------------------------------
Ep done - 26710.
Ep done - 26720.
Ep done - 26730.
Ep done - 26740.
Ep done - 26750.
Ep done - 26760.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.14       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 392         |
|    time_elapsed         | 2852        |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.025360499 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.7        |
|    explained_variance   | 0.289       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0259     |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.0531     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 26770.
Ep done - 26780.
Ep done - 26790.
Ep done - 26800.
Ep done - 26810.
Ep done - 26820.
Ep done - 26830.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 393         |
|    time_elapsed         | 2858        |
|    total_timesteps      | 804864      |
| train/                  |             |
|    approx_kl            | 0.024954665 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.744      |
|    explained_variance   | 0.223       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0299     |
|    n_updates            | 3920        |
|    policy_gradient_loss | -0.0516     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 26840.
Ep done - 26850.
Ep done - 26860.
Ep done - 26870.
Ep done - 26880.
Ep done - 26890.
Ep done - 26900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 394         |
|    time_elapsed         | 2864        |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.027630052 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.711      |
|    explained_variance   | 0.269       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0367     |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.0518     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 26910.
Ep done - 26920.
Ep done - 26930.
Ep done - 26940.
Ep done - 26950.
Ep done - 26960.
Ep done - 26970.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30.1      |
|    ep_rew_mean          | 0.11      |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 395       |
|    time_elapsed         | 2870      |
|    total_timesteps      | 808960    |
| train/                  |           |
|    approx_kl            | 0.0236177 |
|    clip_fraction        | 0.194     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.709    |
|    explained_variance   | 0.317     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0122   |
|    n_updates            | 3940      |
|    policy_gradient_loss | -0.049    |
|    value_loss           | 0.174     |
---------------------------------------
Ep done - 26980.
Ep done - 26990.
Ep done - 27000.
Ep done - 27010.
Ep done - 27020.
Ep done - 27030.
Ep done - 27040.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 396         |
|    time_elapsed         | 2876        |
|    total_timesteps      | 811008      |
| train/                  |             |
|    approx_kl            | 0.024640903 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | 0.105       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0432     |
|    n_updates            | 3950        |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.172       |
-----------------------------------------
Ep done - 27050.
Ep done - 27060.
Ep done - 27070.
Ep done - 27080.
Ep done - 27090.
Ep done - 27100.
Ep done - 27110.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 397         |
|    time_elapsed         | 2882        |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.027663965 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.714      |
|    explained_variance   | 0.352       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00778    |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 27120.
Ep done - 27130.
Ep done - 27140.
Ep done - 27150.
Ep done - 27160.
Ep done - 27170.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 398         |
|    time_elapsed         | 2888        |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.026744487 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.694      |
|    explained_variance   | 0.342       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0187     |
|    n_updates            | 3970        |
|    policy_gradient_loss | -0.0511     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 27180.
Ep done - 27190.
Ep done - 27200.
Ep done - 27210.
Ep done - 27220.
Ep done - 27230.
Ep done - 27240.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 399         |
|    time_elapsed         | 2894        |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.022804696 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.699      |
|    explained_variance   | 0.313       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0177     |
|    n_updates            | 3980        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.146       |
-----------------------------------------
Ep done - 27250.
Ep done - 27260.
Ep done - 27270.
Ep done - 27280.
Ep done - 27290.
Ep done - 27300.
Ep done - 27310.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 400         |
|    time_elapsed         | 2901        |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.025034193 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.711      |
|    explained_variance   | 0.262       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.014      |
|    n_updates            | 3990        |
|    policy_gradient_loss | -0.05       |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 27320.
Ep done - 27330.
Ep done - 27340.
Ep done - 8010.
Ep done - 8020.
Ep done - 8030.
Ep done - 8040.
Ep done - 8050.
Ep done - 8060.
Ep done - 8070.
Ep done - 8080.
Ep done - 8090.
Ep done - 8100.
Ep done - 8110.
Ep done - 8120.
Ep done - 8130.
Ep done - 8140.
Ep done - 8150.
Ep done - 8160.
Ep done - 8170.
Ep done - 8180.
Ep done - 8190.
Ep done - 8200.
Eval num_timesteps=820000, episode_reward=-0.14 +/- 0.97
Episode length: 30.00 +/- 0.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | -0.14       |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.025032401 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.703      |
|    explained_variance   | 0.262       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0406     |
|    n_updates            | 4000        |
|    policy_gradient_loss | -0.0497     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 27350.
Ep done - 27360.
Ep done - 27370.
Ep done - 27380.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    fps             | 281      |
|    iterations      | 401      |
|    time_elapsed    | 2921     |
|    total_timesteps | 821248   |
---------------------------------
Ep done - 27390.
Ep done - 27400.
Ep done - 27410.
Ep done - 27420.
Ep done - 27430.
Ep done - 27440.
Ep done - 27450.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 402         |
|    time_elapsed         | 2928        |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.024669003 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.703      |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0342     |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.0518     |
|    value_loss           | 0.185       |
-----------------------------------------
Ep done - 27460.
Ep done - 27470.
Ep done - 27480.
Ep done - 27490.
Ep done - 27500.
Ep done - 27510.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.02        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 403         |
|    time_elapsed         | 2938        |
|    total_timesteps      | 825344      |
| train/                  |             |
|    approx_kl            | 0.024183359 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.717      |
|    explained_variance   | 0.156       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0388     |
|    n_updates            | 4020        |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 27520.
Ep done - 27530.
Ep done - 27540.
Ep done - 27550.
Ep done - 27560.
Ep done - 27570.
Ep done - 27580.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 404         |
|    time_elapsed         | 2943        |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.027588915 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.71       |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00215     |
|    n_updates            | 4030        |
|    policy_gradient_loss | -0.0502     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 27590.
Ep done - 27600.
Ep done - 27610.
Ep done - 27620.
Ep done - 27630.
Ep done - 27640.
Ep done - 27650.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.02        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 405         |
|    time_elapsed         | 2949        |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.028456489 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.721      |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0336     |
|    n_updates            | 4040        |
|    policy_gradient_loss | -0.0503     |
|    value_loss           | 0.141       |
-----------------------------------------
Ep done - 27660.
Ep done - 27670.
Ep done - 27680.
Ep done - 27690.
Ep done - 27700.
Ep done - 27710.
Ep done - 27720.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 406         |
|    time_elapsed         | 2955        |
|    total_timesteps      | 831488      |
| train/                  |             |
|    approx_kl            | 0.023994396 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.71       |
|    explained_variance   | 0.119       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0131     |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.05       |
|    value_loss           | 0.185       |
-----------------------------------------
Ep done - 27730.
Ep done - 27740.
Ep done - 27750.
Ep done - 27760.
Ep done - 27770.
Ep done - 27780.
Ep done - 27790.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 407         |
|    time_elapsed         | 2961        |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.027293175 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.716      |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.017      |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.176       |
-----------------------------------------
Ep done - 27800.
Ep done - 27810.
Ep done - 27820.
Ep done - 27830.
Ep done - 27840.
Ep done - 27850.
Ep done - 27860.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30        |
|    ep_rew_mean          | 0.02      |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 408       |
|    time_elapsed         | 2967      |
|    total_timesteps      | 835584    |
| train/                  |           |
|    approx_kl            | 0.0278573 |
|    clip_fraction        | 0.193     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.692    |
|    explained_variance   | 0.125     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0114   |
|    n_updates            | 4070      |
|    policy_gradient_loss | -0.0506   |
|    value_loss           | 0.18      |
---------------------------------------
Ep done - 27870.
Ep done - 27880.
Ep done - 27890.
Ep done - 27900.
Ep done - 27910.
Ep done - 27920.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.02        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 409         |
|    time_elapsed         | 2972        |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.024068225 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.688      |
|    explained_variance   | 0.331       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0312     |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 27930.
Ep done - 27940.
Ep done - 27950.
Ep done - 27960.
Ep done - 27970.
Ep done - 27980.
Ep done - 27990.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 410         |
|    time_elapsed         | 2978        |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.024830865 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.714      |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0164     |
|    n_updates            | 4090        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 28000.
Ep done - 8210.
Ep done - 8220.
Ep done - 8230.
Ep done - 8240.
Ep done - 8250.
Ep done - 8260.
Ep done - 8270.
Ep done - 8280.
Ep done - 8290.
Ep done - 8300.
Ep done - 8310.
Ep done - 8320.
Ep done - 8330.
Ep done - 8340.
Ep done - 8350.
Ep done - 8360.
Ep done - 8370.
Ep done - 8380.
Ep done - 8390.
Ep done - 8400.
Eval num_timesteps=840000, episode_reward=0.12 +/- 0.98
Episode length: 29.99 +/- 0.59
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.115      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.02722682 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.696     |
|    explained_variance   | 0.263      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0235    |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.0511    |
|    value_loss           | 0.166      |
----------------------------------------
Ep done - 28010.
Ep done - 28020.
Ep done - 28030.
Ep done - 28040.
Ep done - 28050.
Ep done - 28060.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.16     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 411      |
|    time_elapsed    | 2996     |
|    total_timesteps | 841728   |
---------------------------------
Ep done - 28070.
Ep done - 28080.
Ep done - 28090.
Ep done - 28100.
Ep done - 28110.
Ep done - 28120.
Ep done - 28130.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 412         |
|    time_elapsed         | 3002        |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.024379466 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | 0.202       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00262     |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.0519     |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 28140.
Ep done - 28150.
Ep done - 28160.
Ep done - 28170.
Ep done - 28180.
Ep done - 28190.
Ep done - 28200.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 413         |
|    time_elapsed         | 3008        |
|    total_timesteps      | 845824      |
| train/                  |             |
|    approx_kl            | 0.023778558 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.697      |
|    explained_variance   | 0.107       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0308     |
|    n_updates            | 4120        |
|    policy_gradient_loss | -0.0478     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 28210.
Ep done - 28220.
Ep done - 28230.
Ep done - 28240.
Ep done - 28250.
Ep done - 28260.
Ep done - 28270.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 414         |
|    time_elapsed         | 3014        |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.022556622 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.67       |
|    explained_variance   | 0.315       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0108     |
|    n_updates            | 4130        |
|    policy_gradient_loss | -0.0476     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 28280.
Ep done - 28290.
Ep done - 28300.
Ep done - 28310.
Ep done - 28320.
Ep done - 28330.
Ep done - 28340.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.32        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 415         |
|    time_elapsed         | 3019        |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.024552403 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.695      |
|    explained_variance   | 0.301       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0343     |
|    n_updates            | 4140        |
|    policy_gradient_loss | -0.0496     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 28350.
Ep done - 28360.
Ep done - 28370.
Ep done - 28380.
Ep done - 28390.
Ep done - 28400.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 416         |
|    time_elapsed         | 3025        |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.024253491 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.664      |
|    explained_variance   | 0.26        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0287     |
|    n_updates            | 4150        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.166       |
-----------------------------------------
Ep done - 28410.
Ep done - 28420.
Ep done - 28430.
Ep done - 28440.
Ep done - 28450.
Ep done - 28460.
Ep done - 28470.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.19       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 417        |
|    time_elapsed         | 3031       |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.02786235 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.699     |
|    explained_variance   | 0.32       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00141    |
|    n_updates            | 4160       |
|    policy_gradient_loss | -0.0529    |
|    value_loss           | 0.169      |
----------------------------------------
Ep done - 28480.
Ep done - 28490.
Ep done - 28500.
Ep done - 28510.
Ep done - 28520.
Ep done - 28530.
Ep done - 28540.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 418         |
|    time_elapsed         | 3037        |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.023194756 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.666      |
|    explained_variance   | 0.26        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0145     |
|    n_updates            | 4170        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 28550.
Ep done - 28560.
Ep done - 28570.
Ep done - 28580.
Ep done - 28590.
Ep done - 28600.
Ep done - 28610.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.11       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 419        |
|    time_elapsed         | 3043       |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.02557379 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.666     |
|    explained_variance   | 0.182      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00589   |
|    n_updates            | 4180       |
|    policy_gradient_loss | -0.0458    |
|    value_loss           | 0.159      |
----------------------------------------
Ep done - 28620.
Ep done - 28630.
Ep done - 28640.
Ep done - 28650.
Ep done - 28660.
Ep done - 28670.
Ep done - 8410.
Ep done - 8420.
Ep done - 8430.
Ep done - 8440.
Ep done - 8450.
Ep done - 8460.
Ep done - 8470.
Ep done - 8480.
Ep done - 8490.
Ep done - 8500.
Ep done - 8510.
Ep done - 8520.
Ep done - 8530.
Ep done - 8540.
Ep done - 8550.
Ep done - 8560.
Ep done - 8570.
Ep done - 8580.
Ep done - 8590.
Ep done - 8600.
Eval num_timesteps=860000, episode_reward=0.23 +/- 0.95
Episode length: 30.00 +/- 0.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.235       |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.024764694 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.66       |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.029      |
|    n_updates            | 4190        |
|    policy_gradient_loss | -0.0479     |
|    value_loss           | 0.178       |
-----------------------------------------
Ep done - 28680.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 420      |
|    time_elapsed    | 3061     |
|    total_timesteps | 860160   |
---------------------------------
Ep done - 28690.
Ep done - 28700.
Ep done - 28710.
Ep done - 28720.
Ep done - 28730.
Ep done - 28740.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 421         |
|    time_elapsed         | 3067        |
|    total_timesteps      | 862208      |
| train/                  |             |
|    approx_kl            | 0.023308557 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.674      |
|    explained_variance   | 0.349       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0307     |
|    n_updates            | 4200        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.147       |
-----------------------------------------
Ep done - 28750.
Ep done - 28760.
Ep done - 28770.
Ep done - 28780.
Ep done - 28790.
Ep done - 28800.
Ep done - 28810.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 422         |
|    time_elapsed         | 3072        |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.024961278 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.67       |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0232     |
|    n_updates            | 4210        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 28820.
Ep done - 28830.
Ep done - 28840.
Ep done - 28850.
Ep done - 28860.
Ep done - 28870.
Ep done - 28880.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 423         |
|    time_elapsed         | 3078        |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.023435423 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.69       |
|    explained_variance   | 0.218       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0306     |
|    n_updates            | 4220        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 28890.
Ep done - 28900.
Ep done - 28910.
Ep done - 28920.
Ep done - 28930.
Ep done - 28940.
Ep done - 28950.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30        |
|    ep_rew_mean          | 0.34      |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 424       |
|    time_elapsed         | 3084      |
|    total_timesteps      | 868352    |
| train/                  |           |
|    approx_kl            | 0.0221782 |
|    clip_fraction        | 0.191     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.667    |
|    explained_variance   | 0.173     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.00548  |
|    n_updates            | 4230      |
|    policy_gradient_loss | -0.0488   |
|    value_loss           | 0.184     |
---------------------------------------
Ep done - 28960.
Ep done - 28970.
Ep done - 28980.
Ep done - 28990.
Ep done - 29000.
Ep done - 29010.
Ep done - 29020.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.39        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 425         |
|    time_elapsed         | 3090        |
|    total_timesteps      | 870400      |
| train/                  |             |
|    approx_kl            | 0.024031758 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.648      |
|    explained_variance   | 0.297       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0156     |
|    n_updates            | 4240        |
|    policy_gradient_loss | -0.0469     |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 29030.
Ep done - 29040.
Ep done - 29050.
Ep done - 29060.
Ep done - 29070.
Ep done - 29080.
Ep done - 29090.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.36        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 426         |
|    time_elapsed         | 3096        |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.026802812 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.68       |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0202     |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 29100.
Ep done - 29110.
Ep done - 29120.
Ep done - 29130.
Ep done - 29140.
Ep done - 29150.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 427         |
|    time_elapsed         | 3101        |
|    total_timesteps      | 874496      |
| train/                  |             |
|    approx_kl            | 0.024281431 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.63       |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0151      |
|    n_updates            | 4260        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 29160.
Ep done - 29170.
Ep done - 29180.
Ep done - 29190.
Ep done - 29200.
Ep done - 29210.
Ep done - 29220.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.03       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 428        |
|    time_elapsed         | 3107       |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.02462523 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.666     |
|    explained_variance   | 0.424      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0329    |
|    n_updates            | 4270       |
|    policy_gradient_loss | -0.0506    |
|    value_loss           | 0.15       |
----------------------------------------
Ep done - 29230.
Ep done - 29240.
Ep done - 29250.
Ep done - 29260.
Ep done - 29270.
Ep done - 29280.
Ep done - 29290.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 429         |
|    time_elapsed         | 3113        |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.027827362 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.649      |
|    explained_variance   | 0.307       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0178     |
|    n_updates            | 4280        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 29300.
Ep done - 29310.
Ep done - 29320.
Ep done - 29330.
Ep done - 29340.
Ep done - 8610.
Ep done - 8620.
Ep done - 8630.
Ep done - 8640.
Ep done - 8650.
Ep done - 8660.
Ep done - 8670.
Ep done - 8680.
Ep done - 8690.
Ep done - 8700.
Ep done - 8710.
Ep done - 8720.
Ep done - 8730.
Ep done - 8740.
Ep done - 8750.
Ep done - 8760.
Ep done - 8770.
Ep done - 8780.
Ep done - 8790.
Ep done - 8800.
Eval num_timesteps=880000, episode_reward=0.28 +/- 0.95
Episode length: 30.05 +/- 0.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.285       |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.024416707 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.669      |
|    explained_variance   | 0.285       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0198     |
|    n_updates            | 4290        |
|    policy_gradient_loss | -0.0482     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 29350.
Ep done - 29360.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.28     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 430      |
|    time_elapsed    | 3131     |
|    total_timesteps | 880640   |
---------------------------------
Ep done - 29370.
Ep done - 29380.
Ep done - 29390.
Ep done - 29400.
Ep done - 29410.
Ep done - 29420.
Ep done - 29430.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 431         |
|    time_elapsed         | 3137        |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.024722245 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.643      |
|    explained_variance   | 0.256       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.016      |
|    n_updates            | 4300        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.15        |
-----------------------------------------
Ep done - 29440.
Ep done - 29450.
Ep done - 29460.
Ep done - 29470.
Ep done - 29480.
Ep done - 29490.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 432         |
|    time_elapsed         | 3143        |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.024646157 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.67       |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00517     |
|    n_updates            | 4310        |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.188       |
-----------------------------------------
Ep done - 29500.
Ep done - 29510.
Ep done - 29520.
Ep done - 29530.
Ep done - 29540.
Ep done - 29550.
Ep done - 29560.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.25       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 433        |
|    time_elapsed         | 3149       |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.02676207 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.659     |
|    explained_variance   | 0.243      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0241    |
|    n_updates            | 4320       |
|    policy_gradient_loss | -0.0477    |
|    value_loss           | 0.158      |
----------------------------------------
Ep done - 29570.
Ep done - 29580.
Ep done - 29590.
Ep done - 29600.
Ep done - 29610.
Ep done - 29620.
Ep done - 29630.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 434         |
|    time_elapsed         | 3155        |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.024230614 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.666      |
|    explained_variance   | 0.202       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0131      |
|    n_updates            | 4330        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.159       |
-----------------------------------------
Ep done - 29640.
Ep done - 29650.
Ep done - 29660.
Ep done - 29670.
Ep done - 29680.
Ep done - 29690.
Ep done - 29700.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.18       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 435        |
|    time_elapsed         | 3161       |
|    total_timesteps      | 890880     |
| train/                  |            |
|    approx_kl            | 0.02485599 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.676     |
|    explained_variance   | 0.255      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00834   |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.0499    |
|    value_loss           | 0.183      |
----------------------------------------
Ep done - 29710.
Ep done - 29720.
Ep done - 29730.
Ep done - 29740.
Ep done - 29750.
Ep done - 29760.
Ep done - 29770.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.11       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 436        |
|    time_elapsed         | 3167       |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.02350852 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.661     |
|    explained_variance   | 0.123      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0472    |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.047     |
|    value_loss           | 0.173      |
----------------------------------------
Ep done - 29780.
Ep done - 29790.
Ep done - 29800.
Ep done - 29810.
Ep done - 29820.
Ep done - 29830.
Ep done - 29840.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.31        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 437         |
|    time_elapsed         | 3173        |
|    total_timesteps      | 894976      |
| train/                  |             |
|    approx_kl            | 0.024844136 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.665      |
|    explained_variance   | 0.312       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00212    |
|    n_updates            | 4360        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 29850.
Ep done - 29860.
Ep done - 29870.
Ep done - 29880.
Ep done - 29890.
Ep done - 29900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 438         |
|    time_elapsed         | 3178        |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.028930468 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.658      |
|    explained_variance   | 0.136       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.038      |
|    n_updates            | 4370        |
|    policy_gradient_loss | -0.0505     |
|    value_loss           | 0.147       |
-----------------------------------------
Ep done - 29910.
Ep done - 29920.
Ep done - 29930.
Ep done - 29940.
Ep done - 29950.
Ep done - 29960.
Ep done - 29970.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.23       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 439        |
|    time_elapsed         | 3184       |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.02603218 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.664     |
|    explained_variance   | 0.226      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.024      |
|    n_updates            | 4380       |
|    policy_gradient_loss | -0.0495    |
|    value_loss           | 0.167      |
----------------------------------------
Ep done - 29980.
Ep done - 29990.
Ep done - 30000.
Ep done - 8810.
Ep done - 8820.
Ep done - 8830.
Ep done - 8840.
Ep done - 8850.
Ep done - 8860.
Ep done - 8870.
Ep done - 8880.
Ep done - 8890.
Ep done - 8900.
Ep done - 8910.
Ep done - 8920.
Ep done - 8930.
Ep done - 8940.
Ep done - 8950.
Ep done - 8960.
Ep done - 8970.
Ep done - 8980.
Ep done - 8990.
Ep done - 9000.
Eval num_timesteps=900000, episode_reward=0.21 +/- 0.96
Episode length: 30.00 +/- 0.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.215       |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.027750723 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.67       |
|    explained_variance   | 0.22        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0387     |
|    n_updates            | 4390        |
|    policy_gradient_loss | -0.052      |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 30010.
Ep done - 30020.
Ep done - 30030.
Ep done - 30040.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 440      |
|    time_elapsed    | 3203     |
|    total_timesteps | 901120   |
---------------------------------
Ep done - 30050.
Ep done - 30060.
Ep done - 30070.
Ep done - 30080.
Ep done - 30090.
Ep done - 30100.
Ep done - 30110.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 441         |
|    time_elapsed         | 3209        |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.024589341 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.647      |
|    explained_variance   | 0.296       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0114     |
|    n_updates            | 4400        |
|    policy_gradient_loss | -0.0502     |
|    value_loss           | 0.166       |
-----------------------------------------
Ep done - 30120.
Ep done - 30130.
Ep done - 30140.
Ep done - 30150.
Ep done - 30160.
Ep done - 30170.
Ep done - 30180.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 442         |
|    time_elapsed         | 3215        |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.025576489 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.663      |
|    explained_variance   | 0.143       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0171     |
|    n_updates            | 4410        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 30190.
Ep done - 30200.
Ep done - 30210.
Ep done - 30220.
Ep done - 30230.
Ep done - 30240.
Ep done - 30250.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.11        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 443         |
|    time_elapsed         | 3221        |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.025040321 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.657      |
|    explained_variance   | 0.258       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0608     |
|    n_updates            | 4420        |
|    policy_gradient_loss | -0.0505     |
|    value_loss           | 0.151       |
-----------------------------------------
Ep done - 30260.
Ep done - 30270.
Ep done - 30280.
Ep done - 30290.
Ep done - 30300.
Ep done - 30310.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.22        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 444         |
|    time_elapsed         | 3227        |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.027706929 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.626      |
|    explained_variance   | 0.208       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00141    |
|    n_updates            | 4430        |
|    policy_gradient_loss | -0.0505     |
|    value_loss           | 0.182       |
-----------------------------------------
Ep done - 30320.
Ep done - 30330.
Ep done - 30340.
Ep done - 30350.
Ep done - 30360.
Ep done - 30370.
Ep done - 30380.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.35        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 445         |
|    time_elapsed         | 3233        |
|    total_timesteps      | 911360      |
| train/                  |             |
|    approx_kl            | 0.026336592 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.631      |
|    explained_variance   | 0.185       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0277     |
|    n_updates            | 4440        |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 30390.
Ep done - 30400.
Ep done - 30410.
Ep done - 30420.
Ep done - 30430.
Ep done - 30440.
Ep done - 30450.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.35        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 446         |
|    time_elapsed         | 3239        |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.024247909 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.642      |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0271     |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 30460.
Ep done - 30470.
Ep done - 30480.
Ep done - 30490.
Ep done - 30500.
Ep done - 30510.
Ep done - 30520.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.06       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 447        |
|    time_elapsed         | 3245       |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.02774408 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.667     |
|    explained_variance   | 0.209      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.037     |
|    n_updates            | 4460       |
|    policy_gradient_loss | -0.0518    |
|    value_loss           | 0.161      |
----------------------------------------
Ep done - 30530.
Ep done - 30540.
Ep done - 30550.
Ep done - 30560.
Ep done - 30570.
Ep done - 30580.
Ep done - 30590.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.32        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 448         |
|    time_elapsed         | 3251        |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.025873745 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.665      |
|    explained_variance   | 0.232       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0223     |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.19        |
-----------------------------------------
Ep done - 30600.
Ep done - 30610.
Ep done - 30620.
Ep done - 30630.
Ep done - 30640.
Ep done - 30650.
Ep done - 30660.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 449         |
|    time_elapsed         | 3257        |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.025530735 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.631      |
|    explained_variance   | 0.168       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0269     |
|    n_updates            | 4480        |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.156       |
-----------------------------------------
Ep done - 30670.
Ep done - 9010.
Ep done - 9020.
Ep done - 9030.
Ep done - 9040.
Ep done - 9050.
Ep done - 9060.
Ep done - 9070.
Ep done - 9080.
Ep done - 9090.
Ep done - 9100.
Ep done - 9110.
Ep done - 9120.
Ep done - 9130.
Ep done - 9140.
Ep done - 9150.
Ep done - 9160.
Ep done - 9170.
Ep done - 9180.
Ep done - 9190.
Ep done - 9200.
Eval num_timesteps=920000, episode_reward=0.32 +/- 0.93
Episode length: 30.02 +/- 0.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.32        |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.024127588 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.645      |
|    explained_variance   | 0.183       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0207     |
|    n_updates            | 4490        |
|    policy_gradient_loss | -0.0472     |
|    value_loss           | 0.141       |
-----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.32
SELFPLAY: new best model, bumping up generation to 12
Ep done - 30680.
Ep done - 30690.
Ep done - 30700.
Ep done - 30710.
Ep done - 30720.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.25     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 450      |
|    time_elapsed    | 3276     |
|    total_timesteps | 921600   |
---------------------------------
Ep done - 30730.
Ep done - 30740.
Ep done - 30750.
Ep done - 30760.
Ep done - 30770.
Ep done - 30780.
Ep done - 30790.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.02        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 451         |
|    time_elapsed         | 3282        |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.024368642 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.677      |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0376     |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 30800.
Ep done - 30810.
Ep done - 30820.
Ep done - 30830.
Ep done - 30840.
Ep done - 30850.
Ep done - 30860.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.13       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 452         |
|    time_elapsed         | 3289        |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.024527937 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.692      |
|    explained_variance   | 0.335       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0334     |
|    n_updates            | 4510        |
|    policy_gradient_loss | -0.0507     |
|    value_loss           | 0.176       |
-----------------------------------------
Ep done - 30870.
Ep done - 30880.
Ep done - 30890.
Ep done - 30900.
Ep done - 30910.
Ep done - 30920.
Ep done - 30930.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.09       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 453         |
|    time_elapsed         | 3295        |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.027885394 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.675      |
|    explained_variance   | 0.143       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00113     |
|    n_updates            | 4520        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.195       |
-----------------------------------------
Ep done - 30940.
Ep done - 30950.
Ep done - 30960.
Ep done - 30970.
Ep done - 30980.
Ep done - 30990.
Ep done - 31000.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 454         |
|    time_elapsed         | 3301        |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.028608523 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.692      |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0292     |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.0489     |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 31010.
Ep done - 31020.
Ep done - 31030.
Ep done - 31040.
Ep done - 31050.
Ep done - 31060.
Ep done - 31070.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.01       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 455        |
|    time_elapsed         | 3308       |
|    total_timesteps      | 931840     |
| train/                  |            |
|    approx_kl            | 0.02760889 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.67      |
|    explained_variance   | 0.198      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0273    |
|    n_updates            | 4540       |
|    policy_gradient_loss | -0.0526    |
|    value_loss           | 0.188      |
----------------------------------------
Ep done - 31080.
Ep done - 31090.
Ep done - 31100.
Ep done - 31110.
Ep done - 31120.
Ep done - 31130.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.2        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 456         |
|    time_elapsed         | 3314        |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.025265656 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.668      |
|    explained_variance   | 0.135       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.029      |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.186       |
-----------------------------------------
Ep done - 31140.
Ep done - 31150.
Ep done - 31160.
Ep done - 31170.
Ep done - 31180.
Ep done - 31190.
Ep done - 31200.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.05       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 457         |
|    time_elapsed         | 3321        |
|    total_timesteps      | 935936      |
| train/                  |             |
|    approx_kl            | 0.027569462 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.687      |
|    explained_variance   | 0.254       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0116     |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 31210.
Ep done - 31220.
Ep done - 31230.
Ep done - 31240.
Ep done - 31250.
Ep done - 31260.
Ep done - 31270.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | -0.04      |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 458        |
|    time_elapsed         | 3331       |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.02365561 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.666     |
|    explained_variance   | 0.213      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0146     |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.0473    |
|    value_loss           | 0.166      |
----------------------------------------
Ep done - 31280.
Ep done - 31290.
Ep done - 31300.
Ep done - 31310.
Ep done - 31320.
Ep done - 31330.
Ep done - 31340.
Ep done - 9210.
Ep done - 9220.
Ep done - 9230.
Ep done - 9240.
Ep done - 9250.
Ep done - 9260.
Ep done - 9270.
Ep done - 9280.
Ep done - 9290.
Ep done - 9300.
Ep done - 9310.
Ep done - 9320.
Ep done - 9330.
Ep done - 9340.
Ep done - 9350.
Ep done - 9360.
Ep done - 9370.
Ep done - 9380.
Ep done - 9390.
Ep done - 9400.
Eval num_timesteps=940000, episode_reward=0.06 +/- 0.99
Episode length: 30.07 +/- 0.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.1        |
|    mean_reward          | 0.06        |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.026498312 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.67       |
|    explained_variance   | 0.239       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.029      |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.181       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 459      |
|    time_elapsed    | 3349     |
|    total_timesteps | 940032   |
---------------------------------
Ep done - 31350.
Ep done - 31360.
Ep done - 31370.
Ep done - 31380.
Ep done - 31390.
Ep done - 31400.
Ep done - 31410.
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 30.1     |
|    ep_rew_mean          | 0.08     |
| time/                   |          |
|    fps                  | 280      |
|    iterations           | 460      |
|    time_elapsed         | 3355     |
|    total_timesteps      | 942080   |
| train/                  |          |
|    approx_kl            | 0.025725 |
|    clip_fraction        | 0.203    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.685   |
|    explained_variance   | 0.197    |
|    learning_rate        | 0.0003   |
|    loss                 | -0.0262  |
|    n_updates            | 4590     |
|    policy_gradient_loss | -0.0496  |
|    value_loss           | 0.176    |
--------------------------------------
Ep done - 31420.
Ep done - 31430.
Ep done - 31440.
Ep done - 31450.
Ep done - 31460.
Ep done - 31470.
Ep done - 31480.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 461         |
|    time_elapsed         | 3361        |
|    total_timesteps      | 944128      |
| train/                  |             |
|    approx_kl            | 0.023549125 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.671      |
|    explained_variance   | 0.173       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00805    |
|    n_updates            | 4600        |
|    policy_gradient_loss | -0.0497     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 31490.
Ep done - 31500.
Ep done - 31510.
Ep done - 31520.
Ep done - 31530.
Ep done - 31540.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 29.9      |
|    ep_rew_mean          | -0.14     |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 462       |
|    time_elapsed         | 3367      |
|    total_timesteps      | 946176    |
| train/                  |           |
|    approx_kl            | 0.0259708 |
|    clip_fraction        | 0.198     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.643    |
|    explained_variance   | 0.0881    |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0181   |
|    n_updates            | 4610      |
|    policy_gradient_loss | -0.0486   |
|    value_loss           | 0.196     |
---------------------------------------
Ep done - 31550.
Ep done - 31560.
Ep done - 31570.
Ep done - 31580.
Ep done - 31590.
Ep done - 31600.
Ep done - 31610.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 463         |
|    time_elapsed         | 3372        |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.026913587 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.672      |
|    explained_variance   | 0.141       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0308     |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.0513     |
|    value_loss           | 0.186       |
-----------------------------------------
Ep done - 31620.
Ep done - 31630.
Ep done - 31640.
Ep done - 31650.
Ep done - 31660.
Ep done - 31670.
Ep done - 31680.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 464         |
|    time_elapsed         | 3378        |
|    total_timesteps      | 950272      |
| train/                  |             |
|    approx_kl            | 0.027303427 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.635      |
|    explained_variance   | 0.117       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.026      |
|    n_updates            | 4630        |
|    policy_gradient_loss | -0.0467     |
|    value_loss           | 0.193       |
-----------------------------------------
Ep done - 31690.
Ep done - 31700.
Ep done - 31710.
Ep done - 31720.
Ep done - 31730.
Ep done - 31740.
Ep done - 31750.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 465         |
|    time_elapsed         | 3384        |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.028575856 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.654      |
|    explained_variance   | 0.115       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0263     |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.05       |
|    value_loss           | 0.182       |
-----------------------------------------
Ep done - 31760.
Ep done - 31770.
Ep done - 31780.
Ep done - 31790.
Ep done - 31800.
Ep done - 31810.
Ep done - 31820.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 466         |
|    time_elapsed         | 3390        |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.027128486 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.635      |
|    explained_variance   | 0.252       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0125     |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.0513     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 31830.
Ep done - 31840.
Ep done - 31850.
Ep done - 31860.
Ep done - 31870.
Ep done - 31880.
Ep done - 31890.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 467         |
|    time_elapsed         | 3395        |
|    total_timesteps      | 956416      |
| train/                  |             |
|    approx_kl            | 0.027335096 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.646      |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.019      |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.192       |
-----------------------------------------
Ep done - 31900.
Ep done - 31910.
Ep done - 31920.
Ep done - 31930.
Ep done - 31940.
Ep done - 31950.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 468         |
|    time_elapsed         | 3401        |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.024765462 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.627      |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00395    |
|    n_updates            | 4670        |
|    policy_gradient_loss | -0.045      |
|    value_loss           | 0.178       |
-----------------------------------------
Ep done - 31960.
Ep done - 31970.
Ep done - 31980.
Ep done - 31990.
Ep done - 32000.
Ep done - 9410.
Ep done - 9420.
Ep done - 9430.
Ep done - 9440.
Ep done - 9450.
Ep done - 9460.
Ep done - 9470.
Ep done - 9480.
Ep done - 9490.
Ep done - 9500.
Ep done - 9510.
Ep done - 9520.
Ep done - 9530.
Ep done - 9540.
Ep done - 9550.
Ep done - 9560.
Ep done - 9570.
Ep done - 9580.
Ep done - 9590.
Ep done - 9600.
Eval num_timesteps=960000, episode_reward=-0.09 +/- 0.99
Episode length: 29.86 +/- 0.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | -0.09       |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.024277013 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.636      |
|    explained_variance   | 0.128       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00185    |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.191       |
-----------------------------------------
Ep done - 32010.
Ep done - 32020.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.8     |
|    ep_rew_mean     | 0.03     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 469      |
|    time_elapsed    | 3419     |
|    total_timesteps | 960512   |
---------------------------------
Ep done - 32030.
Ep done - 32040.
Ep done - 32050.
Ep done - 32060.
Ep done - 32070.
Ep done - 32080.
Ep done - 32090.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 470         |
|    time_elapsed         | 3425        |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.028589755 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.643      |
|    explained_variance   | 0.267       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0162     |
|    n_updates            | 4690        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 32100.
Ep done - 32110.
Ep done - 32120.
Ep done - 32130.
Ep done - 32140.
Ep done - 32150.
Ep done - 32160.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 471         |
|    time_elapsed         | 3431        |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.029780874 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.642      |
|    explained_variance   | 0.27        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0057     |
|    n_updates            | 4700        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 32170.
Ep done - 32180.
Ep done - 32190.
Ep done - 32200.
Ep done - 32210.
Ep done - 32220.
Ep done - 32230.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 472         |
|    time_elapsed         | 3437        |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.027677998 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.632      |
|    explained_variance   | 0.235       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0106      |
|    n_updates            | 4710        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.188       |
-----------------------------------------
Ep done - 32240.
Ep done - 32250.
Ep done - 32260.
Ep done - 32270.
Ep done - 32280.
Ep done - 32290.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 473         |
|    time_elapsed         | 3442        |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.028242672 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.618      |
|    explained_variance   | 0.311       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0254     |
|    n_updates            | 4720        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 32300.
Ep done - 32310.
Ep done - 32320.
Ep done - 32330.
Ep done - 32340.
Ep done - 32350.
Ep done - 32360.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 474         |
|    time_elapsed         | 3448        |
|    total_timesteps      | 970752      |
| train/                  |             |
|    approx_kl            | 0.026664756 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.601      |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0193     |
|    n_updates            | 4730        |
|    policy_gradient_loss | -0.0465     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 32370.
Ep done - 32380.
Ep done - 32390.
Ep done - 32400.
Ep done - 32410.
Ep done - 32420.
Ep done - 32430.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.15       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 475        |
|    time_elapsed         | 3454       |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.02450955 |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.621     |
|    explained_variance   | 0.211      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0104    |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.0445    |
|    value_loss           | 0.178      |
----------------------------------------
Ep done - 32440.
Ep done - 32450.
Ep done - 32460.
Ep done - 32470.
Ep done - 32480.
Ep done - 32490.
Ep done - 32500.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 476         |
|    time_elapsed         | 3460        |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.023030572 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.598      |
|    explained_variance   | 0.138       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0143     |
|    n_updates            | 4750        |
|    policy_gradient_loss | -0.0454     |
|    value_loss           | 0.182       |
-----------------------------------------
Ep done - 32510.
Ep done - 32520.
Ep done - 32530.
Ep done - 32540.
Ep done - 32550.
Ep done - 32560.
Ep done - 32570.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.03       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 477        |
|    time_elapsed         | 3465       |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.02717704 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.615     |
|    explained_variance   | 0.205      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.016      |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.0503    |
|    value_loss           | 0.194      |
----------------------------------------
Ep done - 32580.
Ep done - 32590.
Ep done - 32600.
Ep done - 32610.
Ep done - 32620.
Ep done - 32630.
Ep done - 32640.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 478         |
|    time_elapsed         | 3471        |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.026526745 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.631      |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0361     |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.0497     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 32650.
Ep done - 32660.
Ep done - 32670.
Ep done - 9610.
Ep done - 9620.
Ep done - 9630.
Ep done - 9640.
Ep done - 9650.
Ep done - 9660.
Ep done - 9670.
Ep done - 9680.
Ep done - 9690.
Ep done - 9700.
Ep done - 9710.
Ep done - 9720.
Ep done - 9730.
Ep done - 9740.
Ep done - 9750.
Ep done - 9760.
Ep done - 9770.
Ep done - 9780.
Ep done - 9790.
Ep done - 9800.
Eval num_timesteps=980000, episode_reward=0.23 +/- 0.97
Episode length: 29.95 +/- 1.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.225       |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.024380993 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.631      |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0166     |
|    n_updates            | 4780        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 32680.
Ep done - 32690.
Ep done - 32700.
Ep done - 32710.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.14     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 479      |
|    time_elapsed    | 3490     |
|    total_timesteps | 980992   |
---------------------------------
Ep done - 32720.
Ep done - 32730.
Ep done - 32740.
Ep done - 32750.
Ep done - 32760.
Ep done - 32770.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 480         |
|    time_elapsed         | 3495        |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.021429172 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.581      |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0244     |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.0446     |
|    value_loss           | 0.183       |
-----------------------------------------
Ep done - 32780.
Ep done - 32790.
Ep done - 32800.
Ep done - 32810.
Ep done - 32820.
Ep done - 32830.
Ep done - 32840.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 481         |
|    time_elapsed         | 3501        |
|    total_timesteps      | 985088      |
| train/                  |             |
|    approx_kl            | 0.027030826 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.582      |
|    explained_variance   | 0.219       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0147     |
|    n_updates            | 4800        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 32850.
Ep done - 32860.
Ep done - 32870.
Ep done - 32880.
Ep done - 32890.
Ep done - 32900.
Ep done - 32910.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.22        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 482         |
|    time_elapsed         | 3507        |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.024484787 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.608      |
|    explained_variance   | 0.231       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0446     |
|    n_updates            | 4810        |
|    policy_gradient_loss | -0.0488     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 32920.
Ep done - 32930.
Ep done - 32940.
Ep done - 32950.
Ep done - 32960.
Ep done - 32970.
Ep done - 32980.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 483         |
|    time_elapsed         | 3513        |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.023829892 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.587      |
|    explained_variance   | 0.225       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0188     |
|    n_updates            | 4820        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.163       |
-----------------------------------------
Ep done - 32990.
Ep done - 33000.
Ep done - 33010.
Ep done - 33020.
Ep done - 33030.
Ep done - 33040.
Ep done - 33050.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 484         |
|    time_elapsed         | 3519        |
|    total_timesteps      | 991232      |
| train/                  |             |
|    approx_kl            | 0.025356593 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.589      |
|    explained_variance   | 0.233       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000468   |
|    n_updates            | 4830        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.194       |
-----------------------------------------
Ep done - 33060.
Ep done - 33070.
Ep done - 33080.
Ep done - 33090.
Ep done - 33100.
Ep done - 33110.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 485         |
|    time_elapsed         | 3524        |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.026105877 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.586      |
|    explained_variance   | 0.323       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0243     |
|    n_updates            | 4840        |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.178       |
-----------------------------------------
Ep done - 33120.
Ep done - 33130.
Ep done - 33140.
Ep done - 33150.
Ep done - 33160.
Ep done - 33170.
Ep done - 33180.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 486         |
|    time_elapsed         | 3530        |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.026490767 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.602      |
|    explained_variance   | 0.201       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0023     |
|    n_updates            | 4850        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 33190.
Ep done - 33200.
Ep done - 33210.
Ep done - 33220.
Ep done - 33230.
Ep done - 33240.
Ep done - 33250.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 487         |
|    time_elapsed         | 3536        |
|    total_timesteps      | 997376      |
| train/                  |             |
|    approx_kl            | 0.028909184 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.595      |
|    explained_variance   | 0.0575      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0276     |
|    n_updates            | 4860        |
|    policy_gradient_loss | -0.0467     |
|    value_loss           | 0.174       |
-----------------------------------------
Ep done - 33260.
Ep done - 33270.
Ep done - 33280.
Ep done - 33290.
Ep done - 33300.
Ep done - 33310.
Ep done - 33320.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 488         |
|    time_elapsed         | 3542        |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.030219974 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.596      |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00906    |
|    n_updates            | 4870        |
|    policy_gradient_loss | -0.0483     |
|    value_loss           | 0.191       |
-----------------------------------------
Ep done - 33330.
Ep done - 33340.
Ep done - 9810.
Ep done - 9820.
Ep done - 9830.
Ep done - 9840.
Ep done - 9850.
Ep done - 9860.
Ep done - 9870.
Ep done - 9880.
Ep done - 9890.
Ep done - 9900.
Ep done - 9910.
Ep done - 9920.
Ep done - 9930.
Ep done - 9940.
Ep done - 9950.
Ep done - 9960.
Ep done - 9970.
Ep done - 9980.
Ep done - 9990.
Ep done - 10000.
Eval num_timesteps=1000000, episode_reward=-0.01 +/- 0.98
Episode length: 29.90 +/- 1.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | -0.015      |
| time/                   |             |
|    total_timesteps      | 1000000     |
| train/                  |             |
|    approx_kl            | 0.026866997 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.578      |
|    explained_variance   | 0.286       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0379     |
|    n_updates            | 4880        |
|    policy_gradient_loss | -0.0457     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 33350.
Ep done - 33360.
Ep done - 33370.
Ep done - 33380.
Ep done - 33390.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 489      |
|    time_elapsed    | 3560     |
|    total_timesteps | 1001472  |
---------------------------------
Ep done - 33400.
Ep done - 33410.
Ep done - 33420.
Ep done - 33430.
Ep done - 33440.
Ep done - 33450.
Ep done - 33460.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.08       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 490        |
|    time_elapsed         | 3566       |
|    total_timesteps      | 1003520    |
| train/                  |            |
|    approx_kl            | 0.02849242 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.644     |
|    explained_variance   | 0.343      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00977   |
|    n_updates            | 4890       |
|    policy_gradient_loss | -0.0537    |
|    value_loss           | 0.167      |
----------------------------------------
Ep done - 33470.
Ep done - 33480.
Ep done - 33490.
Ep done - 33500.
Ep done - 33510.
Ep done - 33520.
Ep done - 33530.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.06        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 491         |
|    time_elapsed         | 3572        |
|    total_timesteps      | 1005568     |
| train/                  |             |
|    approx_kl            | 0.026916582 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.606      |
|    explained_variance   | 0.374       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00205     |
|    n_updates            | 4900        |
|    policy_gradient_loss | -0.0497     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 33540.
Ep done - 33550.
Ep done - 33560.
Ep done - 33570.
Ep done - 33580.
Ep done - 33590.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 492         |
|    time_elapsed         | 3578        |
|    total_timesteps      | 1007616     |
| train/                  |             |
|    approx_kl            | 0.026548743 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.596      |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00218    |
|    n_updates            | 4910        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.189       |
-----------------------------------------
Ep done - 33600.
Ep done - 33610.
Ep done - 33620.
Ep done - 33630.
Ep done - 33640.
Ep done - 33650.
Ep done - 33660.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 493         |
|    time_elapsed         | 3584        |
|    total_timesteps      | 1009664     |
| train/                  |             |
|    approx_kl            | 0.025316237 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.584      |
|    explained_variance   | 0.0268      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0272     |
|    n_updates            | 4920        |
|    policy_gradient_loss | -0.0462     |
|    value_loss           | 0.2         |
-----------------------------------------
Ep done - 33670.
Ep done - 33680.
Ep done - 33690.
Ep done - 33700.
Ep done - 33710.
Ep done - 33720.
Ep done - 33730.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 494         |
|    time_elapsed         | 3590        |
|    total_timesteps      | 1011712     |
| train/                  |             |
|    approx_kl            | 0.028528359 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.597      |
|    explained_variance   | 0.214       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0284     |
|    n_updates            | 4930        |
|    policy_gradient_loss | -0.0517     |
|    value_loss           | 0.185       |
-----------------------------------------
Ep done - 33740.
Ep done - 33750.
Ep done - 33760.
Ep done - 33770.
Ep done - 33780.
Ep done - 33790.
Ep done - 33800.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.04       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 495        |
|    time_elapsed         | 3596       |
|    total_timesteps      | 1013760    |
| train/                  |            |
|    approx_kl            | 0.02521213 |
|    clip_fraction        | 0.19       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.576     |
|    explained_variance   | 0.333      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0285    |
|    n_updates            | 4940       |
|    policy_gradient_loss | -0.0487    |
|    value_loss           | 0.178      |
----------------------------------------
Ep done - 33810.
Ep done - 33820.
Ep done - 33830.
Ep done - 33840.
Ep done - 33850.
Ep done - 33860.
Ep done - 33870.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 496         |
|    time_elapsed         | 3602        |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.023404012 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.567      |
|    explained_variance   | 0.299       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0355     |
|    n_updates            | 4950        |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 33880.
Ep done - 33890.
Ep done - 33900.
Ep done - 33910.
Ep done - 33920.
Ep done - 33930.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 497         |
|    time_elapsed         | 3607        |
|    total_timesteps      | 1017856     |
| train/                  |             |
|    approx_kl            | 0.029646471 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.594      |
|    explained_variance   | 0.252       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.029      |
|    n_updates            | 4960        |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 33940.
Ep done - 33950.
Ep done - 33960.
Ep done - 33970.
Ep done - 33980.
Ep done - 33990.
Ep done - 34000.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.04       |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 498         |
|    time_elapsed         | 3613        |
|    total_timesteps      | 1019904     |
| train/                  |             |
|    approx_kl            | 0.027089607 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.6        |
|    explained_variance   | 0.271       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00623    |
|    n_updates            | 4970        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.185       |
-----------------------------------------
Ep done - 34010.
Ep done - 10010.
Ep done - 10020.
Ep done - 10030.
Ep done - 10040.
Ep done - 10050.
Ep done - 10060.
Ep done - 10070.
Ep done - 10080.
Ep done - 10090.
Ep done - 10100.
Ep done - 10110.
Ep done - 10120.
Ep done - 10130.
Ep done - 10140.
Ep done - 10150.
Ep done - 10160.
Ep done - 10170.
Ep done - 10180.
Ep done - 10190.
Ep done - 10200.
Eval num_timesteps=1020000, episode_reward=0.12 +/- 0.98
Episode length: 30.04 +/- 0.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.125       |
| time/                   |             |
|    total_timesteps      | 1020000     |
| train/                  |             |
|    approx_kl            | 0.023864003 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.607      |
|    explained_variance   | 0.29        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0121      |
|    n_updates            | 4980        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 34020.
Ep done - 34030.
Ep done - 34040.
Ep done - 34050.
Ep done - 34060.
Ep done - 34070.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | -0.1     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 499      |
|    time_elapsed    | 3632     |
|    total_timesteps | 1021952  |
---------------------------------
Ep done - 34080.
Ep done - 34090.
Ep done - 34100.
Ep done - 34110.
Ep done - 34120.
Ep done - 34130.
Ep done - 34140.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 500         |
|    time_elapsed         | 3638        |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.031821813 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.591      |
|    explained_variance   | 0.0984      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0224     |
|    n_updates            | 4990        |
|    policy_gradient_loss | -0.0506     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 34150.
Ep done - 34160.
Ep done - 34170.
Ep done - 34180.
Ep done - 34190.
Ep done - 34200.
Ep done - 34210.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.05       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 501        |
|    time_elapsed         | 3644       |
|    total_timesteps      | 1026048    |
| train/                  |            |
|    approx_kl            | 0.03188567 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.601     |
|    explained_variance   | 0.264      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0304    |
|    n_updates            | 5000       |
|    policy_gradient_loss | -0.0514    |
|    value_loss           | 0.178      |
----------------------------------------
Ep done - 34220.
Ep done - 34230.
Ep done - 34240.
Ep done - 34250.
Ep done - 34260.
Ep done - 34270.
Ep done - 34280.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.07       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 502         |
|    time_elapsed         | 3650        |
|    total_timesteps      | 1028096     |
| train/                  |             |
|    approx_kl            | 0.026380097 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.62       |
|    explained_variance   | 0.105       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00145    |
|    n_updates            | 5010        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.197       |
-----------------------------------------
Ep done - 34290.
Ep done - 34300.
Ep done - 34310.
Ep done - 34320.
Ep done - 34330.
Ep done - 34340.
Ep done - 34350.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 503         |
|    time_elapsed         | 3656        |
|    total_timesteps      | 1030144     |
| train/                  |             |
|    approx_kl            | 0.027627429 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.582      |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00644    |
|    n_updates            | 5020        |
|    policy_gradient_loss | -0.0498     |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 34360.
Ep done - 34370.
Ep done - 34380.
Ep done - 34390.
Ep done - 34400.
Ep done - 34410.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 504         |
|    time_elapsed         | 3662        |
|    total_timesteps      | 1032192     |
| train/                  |             |
|    approx_kl            | 0.028926509 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.583      |
|    explained_variance   | 0.246       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0443     |
|    n_updates            | 5030        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.162       |
-----------------------------------------
Ep done - 34420.
Ep done - 34430.
Ep done - 34440.
Ep done - 34450.
Ep done - 34460.
Ep done - 34470.
Ep done - 34480.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 505         |
|    time_elapsed         | 3669        |
|    total_timesteps      | 1034240     |
| train/                  |             |
|    approx_kl            | 0.025361374 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.568      |
|    explained_variance   | 0.296       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0171     |
|    n_updates            | 5040        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 34490.
Ep done - 34500.
Ep done - 34510.
Ep done - 34520.
Ep done - 34530.
Ep done - 34540.
Ep done - 34550.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.22       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 506        |
|    time_elapsed         | 3675       |
|    total_timesteps      | 1036288    |
| train/                  |            |
|    approx_kl            | 0.02662284 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.586     |
|    explained_variance   | 0.3        |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00215   |
|    n_updates            | 5050       |
|    policy_gradient_loss | -0.048     |
|    value_loss           | 0.197      |
----------------------------------------
Ep done - 34560.
Ep done - 34570.
Ep done - 34580.
Ep done - 34590.
Ep done - 34600.
Ep done - 34610.
Ep done - 34620.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 507         |
|    time_elapsed         | 3681        |
|    total_timesteps      | 1038336     |
| train/                  |             |
|    approx_kl            | 0.025399264 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.567      |
|    explained_variance   | 0.218       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00194    |
|    n_updates            | 5060        |
|    policy_gradient_loss | -0.0456     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 34630.
Ep done - 34640.
Ep done - 34650.
Ep done - 34660.
Ep done - 34670.
Ep done - 10210.
Ep done - 10220.
Ep done - 10230.
Ep done - 10240.
Ep done - 10250.
Ep done - 10260.
Ep done - 10270.
Ep done - 10280.
Ep done - 10290.
Ep done - 10300.
Ep done - 10310.
Ep done - 10320.
Ep done - 10330.
Ep done - 10340.
Ep done - 10350.
Ep done - 10360.
Ep done - 10370.
Ep done - 10380.
Ep done - 10390.
Ep done - 10400.
Eval num_timesteps=1040000, episode_reward=0.06 +/- 0.98
Episode length: 30.02 +/- 0.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.06       |
| time/                   |            |
|    total_timesteps      | 1040000    |
| train/                  |            |
|    approx_kl            | 0.02550928 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.585     |
|    explained_variance   | 0.247      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0129    |
|    n_updates            | 5070       |
|    policy_gradient_loss | -0.0462    |
|    value_loss           | 0.184      |
----------------------------------------
Ep done - 34680.
Ep done - 34690.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 508      |
|    time_elapsed    | 3701     |
|    total_timesteps | 1040384  |
---------------------------------
Ep done - 34700.
Ep done - 34710.
Ep done - 34720.
Ep done - 34730.
Ep done - 34740.
Ep done - 34750.
Ep done - 34760.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 509         |
|    time_elapsed         | 3707        |
|    total_timesteps      | 1042432     |
| train/                  |             |
|    approx_kl            | 0.026146028 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.569      |
|    explained_variance   | 0.274       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00582     |
|    n_updates            | 5080        |
|    policy_gradient_loss | -0.0483     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 34770.
Ep done - 34780.
Ep done - 34790.
Ep done - 34800.
Ep done - 34810.
Ep done - 34820.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 510         |
|    time_elapsed         | 3714        |
|    total_timesteps      | 1044480     |
| train/                  |             |
|    approx_kl            | 0.027175613 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.573      |
|    explained_variance   | 0.198       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0279     |
|    n_updates            | 5090        |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 34830.
Ep done - 34840.
Ep done - 34850.
Ep done - 34860.
Ep done - 34870.
Ep done - 34880.
Ep done - 34890.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 511         |
|    time_elapsed         | 3724        |
|    total_timesteps      | 1046528     |
| train/                  |             |
|    approx_kl            | 0.023768246 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.547      |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00145    |
|    n_updates            | 5100        |
|    policy_gradient_loss | -0.0452     |
|    value_loss           | 0.185       |
-----------------------------------------
Ep done - 34900.
Ep done - 34910.
Ep done - 34920.
Ep done - 34930.
Ep done - 34940.
Ep done - 34950.
Ep done - 34960.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.05       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 512        |
|    time_elapsed         | 3730       |
|    total_timesteps      | 1048576    |
| train/                  |            |
|    approx_kl            | 0.02625433 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.565     |
|    explained_variance   | 0.31       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00353   |
|    n_updates            | 5110       |
|    policy_gradient_loss | -0.048     |
|    value_loss           | 0.162      |
----------------------------------------
Ep done - 34970.
Ep done - 34980.
Ep done - 34990.
Ep done - 35000.
Ep done - 35010.
Ep done - 35020.
Ep done - 35030.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0           |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 513         |
|    time_elapsed         | 3736        |
|    total_timesteps      | 1050624     |
| train/                  |             |
|    approx_kl            | 0.025724938 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.58       |
|    explained_variance   | 0.0989      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0138     |
|    n_updates            | 5120        |
|    policy_gradient_loss | -0.047      |
|    value_loss           | 0.197       |
-----------------------------------------
Ep done - 35040.
Ep done - 35050.
Ep done - 35060.
Ep done - 35070.
Ep done - 35080.
Ep done - 35090.
Ep done - 35100.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.03        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 514         |
|    time_elapsed         | 3742        |
|    total_timesteps      | 1052672     |
| train/                  |             |
|    approx_kl            | 0.026822807 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.58       |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00387    |
|    n_updates            | 5130        |
|    policy_gradient_loss | -0.0454     |
|    value_loss           | 0.194       |
-----------------------------------------
Ep done - 35110.
Ep done - 35120.
Ep done - 35130.
Ep done - 35140.
Ep done - 35150.
Ep done - 35160.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 515         |
|    time_elapsed         | 3747        |
|    total_timesteps      | 1054720     |
| train/                  |             |
|    approx_kl            | 0.027929096 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.562      |
|    explained_variance   | 0.213       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00614    |
|    n_updates            | 5140        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 35170.
Ep done - 35180.
Ep done - 35190.
Ep done - 35200.
Ep done - 35210.
Ep done - 35220.
Ep done - 35230.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.04        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 516         |
|    time_elapsed         | 3753        |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.029356826 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.575      |
|    explained_variance   | 0.297       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0306     |
|    n_updates            | 5150        |
|    policy_gradient_loss | -0.0467     |
|    value_loss           | 0.172       |
-----------------------------------------
Ep done - 35240.
Ep done - 35250.
Ep done - 35260.
Ep done - 35270.
Ep done - 35280.
Ep done - 35290.
Ep done - 35300.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 517         |
|    time_elapsed         | 3759        |
|    total_timesteps      | 1058816     |
| train/                  |             |
|    approx_kl            | 0.027433725 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.596      |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00606     |
|    n_updates            | 5160        |
|    policy_gradient_loss | -0.0482     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 35310.
Ep done - 35320.
Ep done - 35330.
Ep done - 35340.
Ep done - 10410.
Ep done - 10420.
Ep done - 10430.
Ep done - 10440.
Ep done - 10450.
Ep done - 10460.
Ep done - 10470.
Ep done - 10480.
Ep done - 10490.
Ep done - 10500.
Ep done - 10510.
Ep done - 10520.
Ep done - 10530.
Ep done - 10540.
Ep done - 10550.
Ep done - 10560.
Ep done - 10570.
Ep done - 10580.
Ep done - 10590.
Ep done - 10600.
Eval num_timesteps=1060000, episode_reward=0.17 +/- 0.97
Episode length: 30.00 +/- 0.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.175       |
| time/                   |             |
|    total_timesteps      | 1060000     |
| train/                  |             |
|    approx_kl            | 0.026641928 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.579      |
|    explained_variance   | 0.221       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0111     |
|    n_updates            | 5170        |
|    policy_gradient_loss | -0.0471     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 35350.
Ep done - 35360.
Ep done - 35370.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | -0.03    |
| time/              |          |
|    fps             | 280      |
|    iterations      | 518      |
|    time_elapsed    | 3777     |
|    total_timesteps | 1060864  |
---------------------------------
Ep done - 35380.
Ep done - 35390.
Ep done - 35400.
Ep done - 35410.
Ep done - 35420.
Ep done - 35430.
Ep done - 35440.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 519         |
|    time_elapsed         | 3783        |
|    total_timesteps      | 1062912     |
| train/                  |             |
|    approx_kl            | 0.026896965 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.573      |
|    explained_variance   | 0.19        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0124     |
|    n_updates            | 5180        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 35450.
Ep done - 35460.
Ep done - 35470.
Ep done - 35480.
Ep done - 35490.
Ep done - 35500.
Ep done - 35510.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.07       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 520         |
|    time_elapsed         | 3788        |
|    total_timesteps      | 1064960     |
| train/                  |             |
|    approx_kl            | 0.025911283 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.572      |
|    explained_variance   | 0.268       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0363     |
|    n_updates            | 5190        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 35520.
Ep done - 35530.
Ep done - 35540.
Ep done - 35550.
Ep done - 35560.
Ep done - 35570.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 521         |
|    time_elapsed         | 3794        |
|    total_timesteps      | 1067008     |
| train/                  |             |
|    approx_kl            | 0.025647055 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.567      |
|    explained_variance   | 0.276       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00947    |
|    n_updates            | 5200        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 35580.
Ep done - 35590.
Ep done - 35600.
Ep done - 35610.
Ep done - 35620.
Ep done - 35630.
Ep done - 35640.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.22       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 522        |
|    time_elapsed         | 3800       |
|    total_timesteps      | 1069056    |
| train/                  |            |
|    approx_kl            | 0.02913443 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.598     |
|    explained_variance   | 0.229      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0236    |
|    n_updates            | 5210       |
|    policy_gradient_loss | -0.049     |
|    value_loss           | 0.154      |
----------------------------------------
Ep done - 35650.
Ep done - 35660.
Ep done - 35670.
Ep done - 35680.
Ep done - 35690.
Ep done - 35700.
Ep done - 35710.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 523         |
|    time_elapsed         | 3806        |
|    total_timesteps      | 1071104     |
| train/                  |             |
|    approx_kl            | 0.028916035 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.589      |
|    explained_variance   | 0.37        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00964    |
|    n_updates            | 5220        |
|    policy_gradient_loss | -0.0496     |
|    value_loss           | 0.155       |
-----------------------------------------
Ep done - 35720.
Ep done - 35730.
Ep done - 35740.
Ep done - 35750.
Ep done - 35760.
Ep done - 35770.
Ep done - 35780.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.15       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 524        |
|    time_elapsed         | 3811       |
|    total_timesteps      | 1073152    |
| train/                  |            |
|    approx_kl            | 0.03167568 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.563     |
|    explained_variance   | 0.367      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0336    |
|    n_updates            | 5230       |
|    policy_gradient_loss | -0.0466    |
|    value_loss           | 0.161      |
----------------------------------------
Ep done - 35790.
Ep done - 35800.
Ep done - 35810.
Ep done - 35820.
Ep done - 35830.
Ep done - 35840.
Ep done - 35850.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 525         |
|    time_elapsed         | 3817        |
|    total_timesteps      | 1075200     |
| train/                  |             |
|    approx_kl            | 0.028381355 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.577      |
|    explained_variance   | 0.272       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.012      |
|    n_updates            | 5240        |
|    policy_gradient_loss | -0.0465     |
|    value_loss           | 0.172       |
-----------------------------------------
Ep done - 35860.
Ep done - 35870.
Ep done - 35880.
Ep done - 35890.
Ep done - 35900.
Ep done - 35910.
Ep done - 35920.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 526         |
|    time_elapsed         | 3823        |
|    total_timesteps      | 1077248     |
| train/                  |             |
|    approx_kl            | 0.025819339 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.564      |
|    explained_variance   | 0.139       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0397      |
|    n_updates            | 5250        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.203       |
-----------------------------------------
Ep done - 35930.
Ep done - 35940.
Ep done - 35950.
Ep done - 35960.
Ep done - 35970.
Ep done - 35980.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.11       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 527        |
|    time_elapsed         | 3829       |
|    total_timesteps      | 1079296    |
| train/                  |            |
|    approx_kl            | 0.02915848 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.594     |
|    explained_variance   | 0.291      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00483   |
|    n_updates            | 5260       |
|    policy_gradient_loss | -0.0498    |
|    value_loss           | 0.181      |
----------------------------------------
Ep done - 35990.
Ep done - 36000.
Ep done - 36010.
Ep done - 10610.
Ep done - 10620.
Ep done - 10630.
Ep done - 10640.
Ep done - 10650.
Ep done - 10660.
Ep done - 10670.
Ep done - 10680.
Ep done - 10690.
Ep done - 10700.
Ep done - 10710.
Ep done - 10720.
Ep done - 10730.
Ep done - 10740.
Ep done - 10750.
Ep done - 10760.
Ep done - 10770.
Ep done - 10780.
Ep done - 10790.
Ep done - 10800.
Eval num_timesteps=1080000, episode_reward=0.11 +/- 0.97
Episode length: 29.97 +/- 0.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.11        |
| time/                   |             |
|    total_timesteps      | 1080000     |
| train/                  |             |
|    approx_kl            | 0.026472282 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.588      |
|    explained_variance   | 0.133       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00284     |
|    n_updates            | 5270        |
|    policy_gradient_loss | -0.0478     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 36020.
Ep done - 36030.
Ep done - 36040.
Ep done - 36050.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.17     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 528      |
|    time_elapsed    | 3847     |
|    total_timesteps | 1081344  |
---------------------------------
Ep done - 36060.
Ep done - 36070.
Ep done - 36080.
Ep done - 36090.
Ep done - 36100.
Ep done - 36110.
Ep done - 36120.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30.1      |
|    ep_rew_mean          | 0.31      |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 529       |
|    time_elapsed         | 3852      |
|    total_timesteps      | 1083392   |
| train/                  |           |
|    approx_kl            | 0.0261134 |
|    clip_fraction        | 0.182     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.579    |
|    explained_variance   | 0.266     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0241    |
|    n_updates            | 5280      |
|    policy_gradient_loss | -0.0471   |
|    value_loss           | 0.177     |
---------------------------------------
Ep done - 36130.
Ep done - 36140.
Ep done - 36150.
Ep done - 36160.
Ep done - 36170.
Ep done - 36180.
Ep done - 36190.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 530         |
|    time_elapsed         | 3858        |
|    total_timesteps      | 1085440     |
| train/                  |             |
|    approx_kl            | 0.026997842 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.587      |
|    explained_variance   | 0.256       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0239     |
|    n_updates            | 5290        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.149       |
-----------------------------------------
Ep done - 36200.
Ep done - 36210.
Ep done - 36220.
Ep done - 36230.
Ep done - 36240.
Ep done - 36250.
Ep done - 36260.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 531         |
|    time_elapsed         | 3864        |
|    total_timesteps      | 1087488     |
| train/                  |             |
|    approx_kl            | 0.031240392 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.602      |
|    explained_variance   | 0.232       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0486     |
|    n_updates            | 5300        |
|    policy_gradient_loss | -0.0502     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 36270.
Ep done - 36280.
Ep done - 36290.
Ep done - 36300.
Ep done - 36310.
Ep done - 36320.
Ep done - 36330.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 532         |
|    time_elapsed         | 3870        |
|    total_timesteps      | 1089536     |
| train/                  |             |
|    approx_kl            | 0.024942383 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.576      |
|    explained_variance   | 0.274       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00431     |
|    n_updates            | 5310        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 36340.
Ep done - 36350.
Ep done - 36360.
Ep done - 36370.
Ep done - 36380.
Ep done - 36390.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 533         |
|    time_elapsed         | 3876        |
|    total_timesteps      | 1091584     |
| train/                  |             |
|    approx_kl            | 0.028525583 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.554      |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0172     |
|    n_updates            | 5320        |
|    policy_gradient_loss | -0.0456     |
|    value_loss           | 0.191       |
-----------------------------------------
Ep done - 36400.
Ep done - 36410.
Ep done - 36420.
Ep done - 36430.
Ep done - 36440.
Ep done - 36450.
Ep done - 36460.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 534         |
|    time_elapsed         | 3881        |
|    total_timesteps      | 1093632     |
| train/                  |             |
|    approx_kl            | 0.029505882 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.56       |
|    explained_variance   | 0.0968      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00347     |
|    n_updates            | 5330        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.192       |
-----------------------------------------
Ep done - 36470.
Ep done - 36480.
Ep done - 36490.
Ep done - 36500.
Ep done - 36510.
Ep done - 36520.
Ep done - 36530.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.06       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 535        |
|    time_elapsed         | 3887       |
|    total_timesteps      | 1095680    |
| train/                  |            |
|    approx_kl            | 0.03230448 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.588     |
|    explained_variance   | 0.18       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0278    |
|    n_updates            | 5340       |
|    policy_gradient_loss | -0.0515    |
|    value_loss           | 0.162      |
----------------------------------------
Ep done - 36540.
Ep done - 36550.
Ep done - 36560.
Ep done - 36570.
Ep done - 36580.
Ep done - 36590.
Ep done - 36600.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.11        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 536         |
|    time_elapsed         | 3893        |
|    total_timesteps      | 1097728     |
| train/                  |             |
|    approx_kl            | 0.026814286 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.594      |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0363     |
|    n_updates            | 5350        |
|    policy_gradient_loss | -0.047      |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 36610.
Ep done - 36620.
Ep done - 36630.
Ep done - 36640.
Ep done - 36650.
Ep done - 36660.
Ep done - 36670.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.01        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 537         |
|    time_elapsed         | 3899        |
|    total_timesteps      | 1099776     |
| train/                  |             |
|    approx_kl            | 0.024818137 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.55       |
|    explained_variance   | 0.213       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0229     |
|    n_updates            | 5360        |
|    policy_gradient_loss | -0.044      |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 10810.
Ep done - 10820.
Ep done - 10830.
Ep done - 10840.
Ep done - 10850.
Ep done - 10860.
Ep done - 10870.
Ep done - 10880.
Ep done - 10890.
Ep done - 10900.
Ep done - 10910.
Ep done - 10920.
Ep done - 10930.
Ep done - 10940.
Ep done - 10950.
Ep done - 10960.
Ep done - 10970.
Ep done - 10980.
Ep done - 10990.
Ep done - 11000.
Eval num_timesteps=1100000, episode_reward=0.22 +/- 0.97
Episode length: 30.02 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.22       |
| time/                   |            |
|    total_timesteps      | 1100000    |
| train/                  |            |
|    approx_kl            | 0.02901395 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.586     |
|    explained_variance   | 0.235      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0223    |
|    n_updates            | 5370       |
|    policy_gradient_loss | -0.05      |
|    value_loss           | 0.193      |
----------------------------------------
Ep done - 36680.
Ep done - 36690.
Ep done - 36700.
Ep done - 36710.
Ep done - 36720.
Ep done - 36730.
Ep done - 36740.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.9     |
|    ep_rew_mean     | 0.1      |
| time/              |          |
|    fps             | 281      |
|    iterations      | 538      |
|    time_elapsed    | 3917     |
|    total_timesteps | 1101824  |
---------------------------------
Ep done - 36750.
Ep done - 36760.
Ep done - 36770.
Ep done - 36780.
Ep done - 36790.
Ep done - 36800.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 539         |
|    time_elapsed         | 3923        |
|    total_timesteps      | 1103872     |
| train/                  |             |
|    approx_kl            | 0.034219615 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.58       |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00387    |
|    n_updates            | 5380        |
|    policy_gradient_loss | -0.0497     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 36810.
Ep done - 36820.
Ep done - 36830.
Ep done - 36840.
Ep done - 36850.
Ep done - 36860.
Ep done - 36870.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 540         |
|    time_elapsed         | 3929        |
|    total_timesteps      | 1105920     |
| train/                  |             |
|    approx_kl            | 0.024331324 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.581      |
|    explained_variance   | 0.248       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00451    |
|    n_updates            | 5390        |
|    policy_gradient_loss | -0.0457     |
|    value_loss           | 0.187       |
-----------------------------------------
Ep done - 36880.
Ep done - 36890.
Ep done - 36900.
Ep done - 36910.
Ep done - 36920.
Ep done - 36930.
Ep done - 36940.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 541         |
|    time_elapsed         | 3935        |
|    total_timesteps      | 1107968     |
| train/                  |             |
|    approx_kl            | 0.025897883 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.573      |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0163     |
|    n_updates            | 5400        |
|    policy_gradient_loss | -0.0493     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 36950.
Ep done - 36960.
Ep done - 36970.
Ep done - 36980.
Ep done - 36990.
Ep done - 37000.
Ep done - 37010.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 542         |
|    time_elapsed         | 3940        |
|    total_timesteps      | 1110016     |
| train/                  |             |
|    approx_kl            | 0.030793617 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.576      |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.012      |
|    n_updates            | 5410        |
|    policy_gradient_loss | -0.0488     |
|    value_loss           | 0.191       |
-----------------------------------------
Ep done - 37020.
Ep done - 37030.
Ep done - 37040.
Ep done - 37050.
Ep done - 37060.
Ep done - 37070.
Ep done - 37080.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 543         |
|    time_elapsed         | 3946        |
|    total_timesteps      | 1112064     |
| train/                  |             |
|    approx_kl            | 0.029994639 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.573      |
|    explained_variance   | 0.256       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0262     |
|    n_updates            | 5420        |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 37090.
Ep done - 37100.
Ep done - 37110.
Ep done - 37120.
Ep done - 37130.
Ep done - 37140.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 544         |
|    time_elapsed         | 3952        |
|    total_timesteps      | 1114112     |
| train/                  |             |
|    approx_kl            | 0.027075242 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.594      |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0068     |
|    n_updates            | 5430        |
|    policy_gradient_loss | -0.0485     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 37150.
Ep done - 37160.
Ep done - 37170.
Ep done - 37180.
Ep done - 37190.
Ep done - 37200.
Ep done - 37210.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.09        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 545         |
|    time_elapsed         | 3958        |
|    total_timesteps      | 1116160     |
| train/                  |             |
|    approx_kl            | 0.028990414 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.569      |
|    explained_variance   | 0.395       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00515     |
|    n_updates            | 5440        |
|    policy_gradient_loss | -0.0505     |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 37220.
Ep done - 37230.
Ep done - 37240.
Ep done - 37250.
Ep done - 37260.
Ep done - 37270.
Ep done - 37280.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.11        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 546         |
|    time_elapsed         | 3964        |
|    total_timesteps      | 1118208     |
| train/                  |             |
|    approx_kl            | 0.026758898 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.565      |
|    explained_variance   | 0.279       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0114     |
|    n_updates            | 5450        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.183       |
-----------------------------------------
Ep done - 37290.
Ep done - 37300.
Ep done - 37310.
Ep done - 37320.
Ep done - 37330.
Ep done - 37340.
Ep done - 11010.
Ep done - 11020.
Ep done - 11030.
Ep done - 11040.
Ep done - 11050.
Ep done - 11060.
Ep done - 11070.
Ep done - 11080.
Ep done - 11090.
Ep done - 11100.
Ep done - 11110.
Ep done - 11120.
Ep done - 11130.
Ep done - 11140.
Ep done - 11150.
Ep done - 11160.
Ep done - 11170.
Ep done - 11180.
Ep done - 11190.
Ep done - 11200.
Eval num_timesteps=1120000, episode_reward=0.10 +/- 0.98
Episode length: 30.02 +/- 0.63
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.095       |
| time/                   |             |
|    total_timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.029538069 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.605      |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0364     |
|    n_updates            | 5460        |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 37350.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.06     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 547      |
|    time_elapsed    | 3982     |
|    total_timesteps | 1120256  |
---------------------------------
Ep done - 37360.
Ep done - 37370.
Ep done - 37380.
Ep done - 37390.
Ep done - 37400.
Ep done - 37410.
Ep done - 37420.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 548         |
|    time_elapsed         | 3988        |
|    total_timesteps      | 1122304     |
| train/                  |             |
|    approx_kl            | 0.028959777 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.59       |
|    explained_variance   | 0.197       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0487     |
|    n_updates            | 5470        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.189       |
-----------------------------------------
Ep done - 37430.
Ep done - 37440.
Ep done - 37450.
Ep done - 37460.
Ep done - 37470.
Ep done - 37480.
Ep done - 37490.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 0.22       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 549        |
|    time_elapsed         | 3994       |
|    total_timesteps      | 1124352    |
| train/                  |            |
|    approx_kl            | 0.02778568 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.587     |
|    explained_variance   | 0.272      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0362    |
|    n_updates            | 5480       |
|    policy_gradient_loss | -0.049     |
|    value_loss           | 0.185      |
----------------------------------------
Ep done - 37500.
Ep done - 37510.
Ep done - 37520.
Ep done - 37530.
Ep done - 37540.
Ep done - 37550.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 550         |
|    time_elapsed         | 4000        |
|    total_timesteps      | 1126400     |
| train/                  |             |
|    approx_kl            | 0.027335301 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.561      |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.012       |
|    n_updates            | 5490        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.189       |
-----------------------------------------
Ep done - 37560.
Ep done - 37570.
Ep done - 37580.
Ep done - 37590.
Ep done - 37600.
Ep done - 37610.
Ep done - 37620.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 551         |
|    time_elapsed         | 4006        |
|    total_timesteps      | 1128448     |
| train/                  |             |
|    approx_kl            | 0.030623032 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.567      |
|    explained_variance   | 0.0945      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0161      |
|    n_updates            | 5500        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.196       |
-----------------------------------------
Ep done - 37630.
Ep done - 37640.
Ep done - 37650.
Ep done - 37660.
Ep done - 37670.
Ep done - 37680.
Ep done - 37690.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 552         |
|    time_elapsed         | 4012        |
|    total_timesteps      | 1130496     |
| train/                  |             |
|    approx_kl            | 0.026411686 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.575      |
|    explained_variance   | 0.176       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0322     |
|    n_updates            | 5510        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.183       |
-----------------------------------------
Ep done - 37700.
Ep done - 37710.
Ep done - 37720.
Ep done - 37730.
Ep done - 37740.
Ep done - 37750.
Ep done - 37760.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 553         |
|    time_elapsed         | 4018        |
|    total_timesteps      | 1132544     |
| train/                  |             |
|    approx_kl            | 0.027640793 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.576      |
|    explained_variance   | 0.332       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0238     |
|    n_updates            | 5520        |
|    policy_gradient_loss | -0.0471     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 37770.
Ep done - 37780.
Ep done - 37790.
Ep done - 37800.
Ep done - 37810.
Ep done - 37820.
Ep done - 37830.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 554         |
|    time_elapsed         | 4024        |
|    total_timesteps      | 1134592     |
| train/                  |             |
|    approx_kl            | 0.027683832 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.573      |
|    explained_variance   | 0.302       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0157     |
|    n_updates            | 5530        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 37840.
Ep done - 37850.
Ep done - 37860.
Ep done - 37870.
Ep done - 37880.
Ep done - 37890.
Ep done - 37900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 555         |
|    time_elapsed         | 4030        |
|    total_timesteps      | 1136640     |
| train/                  |             |
|    approx_kl            | 0.030256888 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.574      |
|    explained_variance   | 0.211       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00997    |
|    n_updates            | 5540        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 37910.
Ep done - 37920.
Ep done - 37930.
Ep done - 37940.
Ep done - 37950.
Ep done - 37960.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.14       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 556        |
|    time_elapsed         | 4036       |
|    total_timesteps      | 1138688    |
| train/                  |            |
|    approx_kl            | 0.02931164 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.541     |
|    explained_variance   | 0.257      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0435    |
|    n_updates            | 5550       |
|    policy_gradient_loss | -0.0467    |
|    value_loss           | 0.159      |
----------------------------------------
Ep done - 37970.
Ep done - 37980.
Ep done - 37990.
Ep done - 38000.
Ep done - 38010.
Ep done - 11210.
Ep done - 11220.
Ep done - 11230.
Ep done - 11240.
Ep done - 11250.
Ep done - 11260.
Ep done - 11270.
Ep done - 11280.
Ep done - 11290.
Ep done - 11300.
Ep done - 11310.
Ep done - 11320.
Ep done - 11330.
Ep done - 11340.
Ep done - 11350.
Ep done - 11360.
Ep done - 11370.
Ep done - 11380.
Ep done - 11390.
Ep done - 11400.
Eval num_timesteps=1140000, episode_reward=0.14 +/- 0.98
Episode length: 29.93 +/- 0.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | 0.135       |
| time/                   |             |
|    total_timesteps      | 1140000     |
| train/                  |             |
|    approx_kl            | 0.030173201 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.589      |
|    explained_variance   | 0.29        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0193     |
|    n_updates            | 5560        |
|    policy_gradient_loss | -0.046      |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 38020.
Ep done - 38030.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.15     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 557      |
|    time_elapsed    | 4055     |
|    total_timesteps | 1140736  |
---------------------------------
Ep done - 38040.
Ep done - 38050.
Ep done - 38060.
Ep done - 38070.
Ep done - 38080.
Ep done - 38090.
Ep done - 38100.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 558         |
|    time_elapsed         | 4061        |
|    total_timesteps      | 1142784     |
| train/                  |             |
|    approx_kl            | 0.024520043 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.589      |
|    explained_variance   | 0.364       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0327     |
|    n_updates            | 5570        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.168       |
-----------------------------------------
Ep done - 38110.
Ep done - 38120.
Ep done - 38130.
Ep done - 38140.
Ep done - 38150.
Ep done - 38160.
Ep done - 38170.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 559         |
|    time_elapsed         | 4067        |
|    total_timesteps      | 1144832     |
| train/                  |             |
|    approx_kl            | 0.026724555 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.571      |
|    explained_variance   | 0.267       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00809     |
|    n_updates            | 5580        |
|    policy_gradient_loss | -0.0458     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 38180.
Ep done - 38190.
Ep done - 38200.
Ep done - 38210.
Ep done - 38220.
Ep done - 38230.
Ep done - 38240.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 560         |
|    time_elapsed         | 4073        |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.029701931 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.578      |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0286     |
|    n_updates            | 5590        |
|    policy_gradient_loss | -0.048      |
|    value_loss           | 0.153       |
-----------------------------------------
Ep done - 38250.
Ep done - 38260.
Ep done - 38270.
Ep done - 38280.
Ep done - 38290.
Ep done - 38300.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.28       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 561        |
|    time_elapsed         | 4079       |
|    total_timesteps      | 1148928    |
| train/                  |            |
|    approx_kl            | 0.02826906 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.564     |
|    explained_variance   | 0.13       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0168    |
|    n_updates            | 5600       |
|    policy_gradient_loss | -0.0452    |
|    value_loss           | 0.185      |
----------------------------------------
Ep done - 38310.
Ep done - 38320.
Ep done - 38330.
Ep done - 38340.
Ep done - 38350.
Ep done - 38360.
Ep done - 38370.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 562         |
|    time_elapsed         | 4086        |
|    total_timesteps      | 1150976     |
| train/                  |             |
|    approx_kl            | 0.028691527 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.568      |
|    explained_variance   | 0.264       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.025      |
|    n_updates            | 5610        |
|    policy_gradient_loss | -0.0495     |
|    value_loss           | 0.147       |
-----------------------------------------
Ep done - 38380.
Ep done - 38390.
Ep done - 38400.
Ep done - 38410.
Ep done - 38420.
Ep done - 38430.
Ep done - 38440.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.35       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 563        |
|    time_elapsed         | 4092       |
|    total_timesteps      | 1153024    |
| train/                  |            |
|    approx_kl            | 0.02656088 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.533     |
|    explained_variance   | 0.314      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0315    |
|    n_updates            | 5620       |
|    policy_gradient_loss | -0.0445    |
|    value_loss           | 0.164      |
----------------------------------------
Ep done - 38450.
Ep done - 38460.
Ep done - 38470.
Ep done - 38480.
Ep done - 38490.
Ep done - 38500.
Ep done - 38510.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.17        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 564         |
|    time_elapsed         | 4098        |
|    total_timesteps      | 1155072     |
| train/                  |             |
|    approx_kl            | 0.029759582 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.551      |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0116     |
|    n_updates            | 5630        |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.189       |
-----------------------------------------
Ep done - 38520.
Ep done - 38530.
Ep done - 38540.
Ep done - 38550.
Ep done - 38560.
Ep done - 38570.
Ep done - 38580.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.8       |
|    ep_rew_mean          | 0.19       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 565        |
|    time_elapsed         | 4105       |
|    total_timesteps      | 1157120    |
| train/                  |            |
|    approx_kl            | 0.02746657 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.542     |
|    explained_variance   | 0.235      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0309    |
|    n_updates            | 5640       |
|    policy_gradient_loss | -0.0447    |
|    value_loss           | 0.169      |
----------------------------------------
Ep done - 38590.
Ep done - 38600.
Ep done - 38610.
Ep done - 38620.
Ep done - 38630.
Ep done - 38640.
Ep done - 38650.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 566         |
|    time_elapsed         | 4112        |
|    total_timesteps      | 1159168     |
| train/                  |             |
|    approx_kl            | 0.027576279 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.56       |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0119      |
|    n_updates            | 5650        |
|    policy_gradient_loss | -0.0467     |
|    value_loss           | 0.186       |
-----------------------------------------
Ep done - 38660.
Ep done - 38670.
Ep done - 11410.
Ep done - 11420.
Ep done - 11430.
Ep done - 11440.
Ep done - 11450.
Ep done - 11460.
Ep done - 11470.
Ep done - 11480.
Ep done - 11490.
Ep done - 11500.
Ep done - 11510.
Ep done - 11520.
Ep done - 11530.
Ep done - 11540.
Ep done - 11550.
Ep done - 11560.
Ep done - 11570.
Ep done - 11580.
Ep done - 11590.
Ep done - 11600.
Eval num_timesteps=1160000, episode_reward=0.12 +/- 0.97
Episode length: 29.98 +/- 0.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.12        |
| time/                   |             |
|    total_timesteps      | 1160000     |
| train/                  |             |
|    approx_kl            | 0.023773635 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.559      |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.011      |
|    n_updates            | 5660        |
|    policy_gradient_loss | -0.0455     |
|    value_loss           | 0.195       |
-----------------------------------------
Ep done - 38680.
Ep done - 38690.
Ep done - 38700.
Ep done - 38710.
Ep done - 38720.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.8     |
|    ep_rew_mean     | -0.02    |
| time/              |          |
|    fps             | 280      |
|    iterations      | 567      |
|    time_elapsed    | 4134     |
|    total_timesteps | 1161216  |
---------------------------------
Ep done - 38730.
Ep done - 38740.
Ep done - 38750.
Ep done - 38760.
Ep done - 38770.
Ep done - 38780.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 568         |
|    time_elapsed         | 4140        |
|    total_timesteps      | 1163264     |
| train/                  |             |
|    approx_kl            | 0.028621612 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.571      |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.012      |
|    n_updates            | 5670        |
|    policy_gradient_loss | -0.0494     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 38790.
Ep done - 38800.
Ep done - 38810.
Ep done - 38820.
Ep done - 38830.
Ep done - 38840.
Ep done - 38850.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.12        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 569         |
|    time_elapsed         | 4146        |
|    total_timesteps      | 1165312     |
| train/                  |             |
|    approx_kl            | 0.027639596 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.57       |
|    explained_variance   | 0.239       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00238     |
|    n_updates            | 5680        |
|    policy_gradient_loss | -0.0462     |
|    value_loss           | 0.172       |
-----------------------------------------
Ep done - 38860.
Ep done - 38870.
Ep done - 38880.
Ep done - 38890.
Ep done - 38900.
Ep done - 38910.
Ep done - 38920.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 570         |
|    time_elapsed         | 4152        |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.027011678 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.55       |
|    explained_variance   | 0.228       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0169     |
|    n_updates            | 5690        |
|    policy_gradient_loss | -0.0458     |
|    value_loss           | 0.195       |
-----------------------------------------
Ep done - 38930.
Ep done - 38940.
Ep done - 38950.
Ep done - 38960.
Ep done - 38970.
Ep done - 38980.
Ep done - 38990.
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30        |
|    ep_rew_mean          | 0.29      |
| time/                   |           |
|    fps                  | 281       |
|    iterations           | 571       |
|    time_elapsed         | 4157      |
|    total_timesteps      | 1169408   |
| train/                  |           |
|    approx_kl            | 0.0291804 |
|    clip_fraction        | 0.193     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.565    |
|    explained_variance   | 0.179     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0221   |
|    n_updates            | 5700      |
|    policy_gradient_loss | -0.048    |
|    value_loss           | 0.18      |
---------------------------------------
Ep done - 39000.
Ep done - 39010.
Ep done - 39020.
Ep done - 39030.
Ep done - 39040.
Ep done - 39050.
Ep done - 39060.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.45        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 572         |
|    time_elapsed         | 4163        |
|    total_timesteps      | 1171456     |
| train/                  |             |
|    approx_kl            | 0.028761595 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.545      |
|    explained_variance   | 0.079       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0313     |
|    n_updates            | 5710        |
|    policy_gradient_loss | -0.0486     |
|    value_loss           | 0.167       |
-----------------------------------------
Ep done - 39070.
Ep done - 39080.
Ep done - 39090.
Ep done - 39100.
Ep done - 39110.
Ep done - 39120.
Ep done - 39130.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.37        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 573         |
|    time_elapsed         | 4169        |
|    total_timesteps      | 1173504     |
| train/                  |             |
|    approx_kl            | 0.027691904 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.537      |
|    explained_variance   | 0.0781      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0159      |
|    n_updates            | 5720        |
|    policy_gradient_loss | -0.0471     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 39140.
Ep done - 39150.
Ep done - 39160.
Ep done - 39170.
Ep done - 39180.
Ep done - 39190.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 574         |
|    time_elapsed         | 4174        |
|    total_timesteps      | 1175552     |
| train/                  |             |
|    approx_kl            | 0.028707996 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.528      |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000923   |
|    n_updates            | 5730        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 39200.
Ep done - 39210.
Ep done - 39220.
Ep done - 39230.
Ep done - 39240.
Ep done - 39250.
Ep done - 39260.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 575         |
|    time_elapsed         | 4180        |
|    total_timesteps      | 1177600     |
| train/                  |             |
|    approx_kl            | 0.029333873 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.523      |
|    explained_variance   | 0.223       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00495    |
|    n_updates            | 5740        |
|    policy_gradient_loss | -0.0444     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 39270.
Ep done - 39280.
Ep done - 39290.
Ep done - 39300.
Ep done - 39310.
Ep done - 39320.
Ep done - 39330.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.3         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 576         |
|    time_elapsed         | 4186        |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.029127758 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.543      |
|    explained_variance   | 0.236       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0119     |
|    n_updates            | 5750        |
|    policy_gradient_loss | -0.0488     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 39340.
Ep done - 11610.
Ep done - 11620.
Ep done - 11630.
Ep done - 11640.
Ep done - 11650.
Ep done - 11660.
Ep done - 11670.
Ep done - 11680.
Ep done - 11690.
Ep done - 11700.
Ep done - 11710.
Ep done - 11720.
Ep done - 11730.
Ep done - 11740.
Ep done - 11750.
Ep done - 11760.
Ep done - 11770.
Ep done - 11780.
Ep done - 11790.
Ep done - 11800.
Eval num_timesteps=1180000, episode_reward=0.24 +/- 0.97
Episode length: 30.02 +/- 0.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.245      |
| time/                   |            |
|    total_timesteps      | 1180000    |
| train/                  |            |
|    approx_kl            | 0.02925193 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.532     |
|    explained_variance   | 0.257      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0268    |
|    n_updates            | 5760       |
|    policy_gradient_loss | -0.045     |
|    value_loss           | 0.155      |
----------------------------------------
Ep done - 39350.
Ep done - 39360.
Ep done - 39370.
Ep done - 39380.
Ep done - 39390.
Ep done - 39400.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.33     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 577      |
|    time_elapsed    | 4204     |
|    total_timesteps | 1181696  |
---------------------------------
Ep done - 39410.
Ep done - 39420.
Ep done - 39430.
Ep done - 39440.
Ep done - 39450.
Ep done - 39460.
Ep done - 39470.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.38        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 578         |
|    time_elapsed         | 4210        |
|    total_timesteps      | 1183744     |
| train/                  |             |
|    approx_kl            | 0.027631342 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.541      |
|    explained_variance   | 0.188       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.013       |
|    n_updates            | 5770        |
|    policy_gradient_loss | -0.0457     |
|    value_loss           | 0.154       |
-----------------------------------------
Ep done - 39480.
Ep done - 39490.
Ep done - 39500.
Ep done - 39510.
Ep done - 39520.
Ep done - 39530.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 579         |
|    time_elapsed         | 4216        |
|    total_timesteps      | 1185792     |
| train/                  |             |
|    approx_kl            | 0.026849411 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.519      |
|    explained_variance   | 0.279       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0303      |
|    n_updates            | 5780        |
|    policy_gradient_loss | -0.0459     |
|    value_loss           | 0.17        |
-----------------------------------------
Ep done - 39540.
Ep done - 39550.
Ep done - 39560.
Ep done - 39570.
Ep done - 39580.
Ep done - 39590.
Ep done - 39600.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.33        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 580         |
|    time_elapsed         | 4221        |
|    total_timesteps      | 1187840     |
| train/                  |             |
|    approx_kl            | 0.029896608 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.52       |
|    explained_variance   | 0.209       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0293     |
|    n_updates            | 5790        |
|    policy_gradient_loss | -0.0423     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 39610.
Ep done - 39620.
Ep done - 39630.
Ep done - 39640.
Ep done - 39650.
Ep done - 39660.
Ep done - 39670.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 0.21       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 581        |
|    time_elapsed         | 4227       |
|    total_timesteps      | 1189888    |
| train/                  |            |
|    approx_kl            | 0.02600096 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.537     |
|    explained_variance   | 0.32       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0136    |
|    n_updates            | 5800       |
|    policy_gradient_loss | -0.0471    |
|    value_loss           | 0.138      |
----------------------------------------
Ep done - 39680.
Ep done - 39690.
Ep done - 39700.
Ep done - 39710.
Ep done - 39720.
Ep done - 39730.
Ep done - 39740.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 582         |
|    time_elapsed         | 4233        |
|    total_timesteps      | 1191936     |
| train/                  |             |
|    approx_kl            | 0.029014654 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.514      |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.028      |
|    n_updates            | 5810        |
|    policy_gradient_loss | -0.0467     |
|    value_loss           | 0.181       |
-----------------------------------------
Ep done - 39750.
Ep done - 39760.
Ep done - 39770.
Ep done - 39780.
Ep done - 39790.
Ep done - 39800.
Ep done - 39810.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.25       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 583        |
|    time_elapsed         | 4239       |
|    total_timesteps      | 1193984    |
| train/                  |            |
|    approx_kl            | 0.02565179 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.525     |
|    explained_variance   | 0.206      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00163    |
|    n_updates            | 5820       |
|    policy_gradient_loss | -0.0451    |
|    value_loss           | 0.184      |
----------------------------------------
Ep done - 39820.
Ep done - 39830.
Ep done - 39840.
Ep done - 39850.
Ep done - 39860.
Ep done - 39870.
Ep done - 39880.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.14       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 584        |
|    time_elapsed         | 4245       |
|    total_timesteps      | 1196032    |
| train/                  |            |
|    approx_kl            | 0.03212636 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.521     |
|    explained_variance   | 0.208      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0294    |
|    n_updates            | 5830       |
|    policy_gradient_loss | -0.0498    |
|    value_loss           | 0.162      |
----------------------------------------
Ep done - 39890.
Ep done - 39900.
Ep done - 39910.
Ep done - 39920.
Ep done - 39930.
Ep done - 39940.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.2         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 585         |
|    time_elapsed         | 4250        |
|    total_timesteps      | 1198080     |
| train/                  |             |
|    approx_kl            | 0.029612288 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.544      |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0114     |
|    n_updates            | 5840        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.188       |
-----------------------------------------
Ep done - 39950.
Ep done - 39960.
Ep done - 39970.
Ep done - 39980.
Ep done - 39990.
Ep done - 40000.
Ep done - 40010.
Ep done - 11810.
Ep done - 11820.
Ep done - 11830.
Ep done - 11840.
Ep done - 11850.
Ep done - 11860.
Ep done - 11870.
Ep done - 11880.
Ep done - 11890.
Ep done - 11900.
Ep done - 11910.
Ep done - 11920.
Ep done - 11930.
Ep done - 11940.
Ep done - 11950.
Ep done - 11960.
Ep done - 11970.
Ep done - 11980.
Ep done - 11990.
Ep done - 12000.
Eval num_timesteps=1200000, episode_reward=0.18 +/- 0.97
Episode length: 29.98 +/- 0.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.18        |
| time/                   |             |
|    total_timesteps      | 1200000     |
| train/                  |             |
|    approx_kl            | 0.030654412 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.545      |
|    explained_variance   | 0.224       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00565    |
|    n_updates            | 5850        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.173       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.24     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 586      |
|    time_elapsed    | 4269     |
|    total_timesteps | 1200128  |
---------------------------------
Ep done - 40020.
Ep done - 40030.
Ep done - 40040.
Ep done - 40050.
Ep done - 40060.
Ep done - 40070.
Ep done - 40080.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.11       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 587        |
|    time_elapsed         | 4274       |
|    total_timesteps      | 1202176    |
| train/                  |            |
|    approx_kl            | 0.02648024 |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.519     |
|    explained_variance   | 0.191      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00117   |
|    n_updates            | 5860       |
|    policy_gradient_loss | -0.0441    |
|    value_loss           | 0.189      |
----------------------------------------
Ep done - 40090.
Ep done - 40100.
Ep done - 40110.
Ep done - 40120.
Ep done - 40130.
Ep done - 40140.
Ep done - 40150.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.13        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 588         |
|    time_elapsed         | 4280        |
|    total_timesteps      | 1204224     |
| train/                  |             |
|    approx_kl            | 0.029933369 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.56       |
|    explained_variance   | 0.183       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00918    |
|    n_updates            | 5870        |
|    policy_gradient_loss | -0.0489     |
|    value_loss           | 0.195       |
-----------------------------------------
Ep done - 40160.
Ep done - 40170.
Ep done - 40180.
Ep done - 40190.
Ep done - 40200.
Ep done - 40210.
Ep done - 40220.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 589         |
|    time_elapsed         | 4286        |
|    total_timesteps      | 1206272     |
| train/                  |             |
|    approx_kl            | 0.026581435 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.53       |
|    explained_variance   | 0.143       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0297     |
|    n_updates            | 5880        |
|    policy_gradient_loss | -0.0443     |
|    value_loss           | 0.182       |
-----------------------------------------
Ep done - 40230.
Ep done - 40240.
Ep done - 40250.
Ep done - 40260.
Ep done - 40270.
Ep done - 40280.
Ep done - 40290.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 590         |
|    time_elapsed         | 4292        |
|    total_timesteps      | 1208320     |
| train/                  |             |
|    approx_kl            | 0.028538093 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.528      |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00299    |
|    n_updates            | 5890        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.158       |
-----------------------------------------
Ep done - 40300.
Ep done - 40310.
Ep done - 40320.
Ep done - 40330.
Ep done - 40340.
Ep done - 40350.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.05        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 591         |
|    time_elapsed         | 4298        |
|    total_timesteps      | 1210368     |
| train/                  |             |
|    approx_kl            | 0.032508392 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.531      |
|    explained_variance   | 0.199       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0138      |
|    n_updates            | 5900        |
|    policy_gradient_loss | -0.0475     |
|    value_loss           | 0.187       |
-----------------------------------------
Ep done - 40360.
Ep done - 40370.
Ep done - 40380.
Ep done - 40390.
Ep done - 40400.
Ep done - 40410.
Ep done - 40420.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 592         |
|    time_elapsed         | 4303        |
|    total_timesteps      | 1212416     |
| train/                  |             |
|    approx_kl            | 0.027994756 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.527      |
|    explained_variance   | 0.335       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00448     |
|    n_updates            | 5910        |
|    policy_gradient_loss | -0.0472     |
|    value_loss           | 0.169       |
-----------------------------------------
Ep done - 40430.
Ep done - 40440.
Ep done - 40450.
Ep done - 40460.
Ep done - 40470.
Ep done - 40480.
Ep done - 40490.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 593         |
|    time_elapsed         | 4309        |
|    total_timesteps      | 1214464     |
| train/                  |             |
|    approx_kl            | 0.025979564 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.553      |
|    explained_variance   | 0.0997      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0133     |
|    n_updates            | 5920        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.196       |
-----------------------------------------
Ep done - 40500.
Ep done - 40510.
Ep done - 40520.
Ep done - 40530.
Ep done - 40540.
Ep done - 40550.
Ep done - 40560.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.25        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 594         |
|    time_elapsed         | 4315        |
|    total_timesteps      | 1216512     |
| train/                  |             |
|    approx_kl            | 0.029552398 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.529      |
|    explained_variance   | 0.283       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00377    |
|    n_updates            | 5930        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.152       |
-----------------------------------------
Ep done - 40570.
Ep done - 40580.
Ep done - 40590.
Ep done - 40600.
Ep done - 40610.
Ep done - 40620.
Ep done - 40630.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 595         |
|    time_elapsed         | 4321        |
|    total_timesteps      | 1218560     |
| train/                  |             |
|    approx_kl            | 0.031055685 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.533      |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00342    |
|    n_updates            | 5940        |
|    policy_gradient_loss | -0.0478     |
|    value_loss           | 0.175       |
-----------------------------------------
Ep done - 40640.
Ep done - 40650.
Ep done - 40660.
Ep done - 40670.
Ep done - 40680.
Ep done - 12010.
Ep done - 12020.
Ep done - 12030.
Ep done - 12040.
Ep done - 12050.
Ep done - 12060.
Ep done - 12070.
Ep done - 12080.
Ep done - 12090.
Ep done - 12100.
Ep done - 12110.
Ep done - 12120.
Ep done - 12130.
Ep done - 12140.
Ep done - 12150.
Ep done - 12160.
Ep done - 12170.
Ep done - 12180.
Ep done - 12190.
Ep done - 12200.
Eval num_timesteps=1220000, episode_reward=0.28 +/- 0.94
Episode length: 30.00 +/- 0.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.275       |
| time/                   |             |
|    total_timesteps      | 1220000     |
| train/                  |             |
|    approx_kl            | 0.025340725 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.513      |
|    explained_variance   | 0.172       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00762     |
|    n_updates            | 5950        |
|    policy_gradient_loss | -0.045      |
|    value_loss           | 0.207       |
-----------------------------------------
Ep done - 40690.
Ep done - 40700.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.09     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 596      |
|    time_elapsed    | 4339     |
|    total_timesteps | 1220608  |
---------------------------------
Ep done - 40710.
Ep done - 40720.
Ep done - 40730.
Ep done - 40740.
Ep done - 40750.
Ep done - 40760.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 597         |
|    time_elapsed         | 4345        |
|    total_timesteps      | 1222656     |
| train/                  |             |
|    approx_kl            | 0.027545616 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.539      |
|    explained_variance   | 0.231       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0106     |
|    n_updates            | 5960        |
|    policy_gradient_loss | -0.0488     |
|    value_loss           | 0.179       |
-----------------------------------------
Ep done - 40770.
Ep done - 40780.
Ep done - 40790.
Ep done - 40800.
Ep done - 40810.
Ep done - 40820.
Ep done - 40830.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 598         |
|    time_elapsed         | 4351        |
|    total_timesteps      | 1224704     |
| train/                  |             |
|    approx_kl            | 0.032940164 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.534      |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00918     |
|    n_updates            | 5970        |
|    policy_gradient_loss | -0.0459     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 40840.
Ep done - 40850.
Ep done - 40860.
Ep done - 40870.
Ep done - 40880.
Ep done - 40890.
Ep done - 40900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.16        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 599         |
|    time_elapsed         | 4357        |
|    total_timesteps      | 1226752     |
| train/                  |             |
|    approx_kl            | 0.027630426 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.532      |
|    explained_variance   | 0.262       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00229    |
|    n_updates            | 5980        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.185       |
-----------------------------------------
Ep done - 40910.
Ep done - 40920.
Ep done - 40930.
Ep done - 40940.
Ep done - 40950.
Ep done - 40960.
Ep done - 40970.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.29        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 600         |
|    time_elapsed         | 4363        |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.029554721 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.557      |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0395     |
|    n_updates            | 5990        |
|    policy_gradient_loss | -0.0497     |
|    value_loss           | 0.173       |
-----------------------------------------
Ep done - 40980.
Ep done - 40990.
Ep done - 41000.
Ep done - 41010.
Ep done - 41020.
Ep done - 41030.
Ep done - 41040.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.19        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 601         |
|    time_elapsed         | 4368        |
|    total_timesteps      | 1230848     |
| train/                  |             |
|    approx_kl            | 0.030193977 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.505      |
|    explained_variance   | 0.312       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00457     |
|    n_updates            | 6000        |
|    policy_gradient_loss | -0.0452     |
|    value_loss           | 0.171       |
-----------------------------------------
Ep done - 41050.
Ep done - 41060.
Ep done - 41070.
Ep done - 41080.
Ep done - 41090.
Ep done - 41100.
Ep done - 41110.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.07       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 602        |
|    time_elapsed         | 4374       |
|    total_timesteps      | 1232896    |
| train/                  |            |
|    approx_kl            | 0.03111786 |
|    clip_fraction        | 0.195      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.544     |
|    explained_variance   | 0.244      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0112    |
|    n_updates            | 6010       |
|    policy_gradient_loss | -0.0489    |
|    value_loss           | 0.192      |
----------------------------------------
Ep done - 41120.
Ep done - 41130.
Ep done - 41140.
Ep done - 41150.
Ep done - 41160.
Ep done - 41170.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.15        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 603         |
|    time_elapsed         | 4380        |
|    total_timesteps      | 1234944     |
| train/                  |             |
|    approx_kl            | 0.031364407 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.544      |
|    explained_variance   | 0.228       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.011      |
|    n_updates            | 6020        |
|    policy_gradient_loss | -0.0487     |
|    value_loss           | 0.186       |
-----------------------------------------
Ep done - 41180.
Ep done - 41190.
Ep done - 41200.
Ep done - 41210.
Ep done - 41220.
Ep done - 41230.
Ep done - 41240.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.24        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 604         |
|    time_elapsed         | 4386        |
|    total_timesteps      | 1236992     |
| train/                  |             |
|    approx_kl            | 0.029250601 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.509      |
|    explained_variance   | 0.225       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0286     |
|    n_updates            | 6030        |
|    policy_gradient_loss | -0.0439     |
|    value_loss           | 0.186       |
-----------------------------------------
Ep done - 41250.
Ep done - 41260.
Ep done - 41270.
Ep done - 41280.
Ep done - 41290.
Ep done - 41300.
Ep done - 41310.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 605         |
|    time_elapsed         | 4392        |
|    total_timesteps      | 1239040     |
| train/                  |             |
|    approx_kl            | 0.028948672 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.53       |
|    explained_variance   | 0.241       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0178      |
|    n_updates            | 6040        |
|    policy_gradient_loss | -0.0469     |
|    value_loss           | 0.161       |
-----------------------------------------
Ep done - 41320.
Ep done - 41330.
Ep done - 41340.
Ep done - 12210.
Ep done - 12220.
Ep done - 12230.
Ep done - 12240.
Ep done - 12250.
Ep done - 12260.
Ep done - 12270.
Ep done - 12280.
Ep done - 12290.
Ep done - 12300.
Ep done - 12310.
Ep done - 12320.
Ep done - 12330.
Ep done - 12340.
Ep done - 12350.
Ep done - 12360.
Ep done - 12370.
Ep done - 12380.
Ep done - 12390.
Ep done - 12400.
Eval num_timesteps=1240000, episode_reward=0.12 +/- 0.96
Episode length: 29.98 +/- 0.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 0.125       |
| time/                   |             |
|    total_timesteps      | 1240000     |
| train/                  |             |
|    approx_kl            | 0.027200744 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.523      |
|    explained_variance   | 0.365       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0263     |
|    n_updates            | 6050        |
|    policy_gradient_loss | -0.0473     |
|    value_loss           | 0.16        |
-----------------------------------------
Ep done - 41350.
Ep done - 41360.
Ep done - 41370.
Ep done - 41380.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.29     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 606      |
|    time_elapsed    | 4411     |
|    total_timesteps | 1241088  |
---------------------------------
Ep done - 41390.
Ep done - 41400.
Ep done - 41410.
Ep done - 41420.
Ep done - 41430.
Ep done - 41440.
Ep done - 41450.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.36        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 607         |
|    time_elapsed         | 4417        |
|    total_timesteps      | 1243136     |
| train/                  |             |
|    approx_kl            | 0.029442634 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.508      |
|    explained_variance   | 0.227       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0157     |
|    n_updates            | 6060        |
|    policy_gradient_loss | -0.0438     |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 41460.
Ep done - 41470.
Ep done - 41480.
Ep done - 41490.
Ep done - 41500.
Ep done - 41510.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.13       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 608        |
|    time_elapsed         | 4422       |
|    total_timesteps      | 1245184    |
| train/                  |            |
|    approx_kl            | 0.02891732 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.499     |
|    explained_variance   | 0.113      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0146    |
|    n_updates            | 6070       |
|    policy_gradient_loss | -0.0455    |
|    value_loss           | 0.189      |
----------------------------------------
Ep done - 41520.
Ep done - 41530.
Ep done - 41540.
Ep done - 41550.
Ep done - 41560.
Ep done - 41570.
Ep done - 41580.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 609         |
|    time_elapsed         | 4428        |
|    total_timesteps      | 1247232     |
| train/                  |             |
|    approx_kl            | 0.028047552 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.523      |
|    explained_variance   | 0.119       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0195     |
|    n_updates            | 6080        |
|    policy_gradient_loss | -0.0478     |
|    value_loss           | 0.2         |
-----------------------------------------
Ep done - 41590.
Ep done - 41600.
Ep done - 41610.
Ep done - 41620.
Ep done - 41630.
Ep done - 41640.
Ep done - 41650.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.39        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 610         |
|    time_elapsed         | 4434        |
|    total_timesteps      | 1249280     |
| train/                  |             |
|    approx_kl            | 0.029232133 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.553      |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0185     |
|    n_updates            | 6090        |
|    policy_gradient_loss | -0.0489     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 41660.
Ep done - 41670.
Ep done - 41680.
Ep done - 41690.
Ep done - 41700.
Ep done - 41710.
Ep done - 41720.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 611         |
|    time_elapsed         | 4440        |
|    total_timesteps      | 1251328     |
| train/                  |             |
|    approx_kl            | 0.029770399 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.505      |
|    explained_variance   | 0.105       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0259     |
|    n_updates            | 6100        |
|    policy_gradient_loss | -0.043      |
|    value_loss           | 0.157       |
-----------------------------------------
Ep done - 41730.
Ep done - 41740.
Ep done - 41750.
Ep done - 41760.
Ep done - 41770.
Ep done - 41780.
Ep done - 41790.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 612         |
|    time_elapsed         | 4446        |
|    total_timesteps      | 1253376     |
| train/                  |             |
|    approx_kl            | 0.029388603 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.533      |
|    explained_variance   | 0.154       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00654    |
|    n_updates            | 6110        |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.202       |
-----------------------------------------
Ep done - 41800.
Ep done - 41810.
Ep done - 41820.
Ep done - 41830.
Ep done - 41840.
Ep done - 41850.
Ep done - 41860.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.23        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 613         |
|    time_elapsed         | 4452        |
|    total_timesteps      | 1255424     |
| train/                  |             |
|    approx_kl            | 0.030018408 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.51       |
|    explained_variance   | 0.221       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000516   |
|    n_updates            | 6120        |
|    policy_gradient_loss | -0.0465     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 41870.
Ep done - 41880.
Ep done - 41890.
Ep done - 41900.
Ep done - 41910.
Ep done - 41920.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.27        |
| time/                   |             |
|    fps                  | 282         |
|    iterations           | 614         |
|    time_elapsed         | 4458        |
|    total_timesteps      | 1257472     |
| train/                  |             |
|    approx_kl            | 0.028554983 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.531      |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00239     |
|    n_updates            | 6130        |
|    policy_gradient_loss | -0.0496     |
|    value_loss           | 0.177       |
-----------------------------------------
Ep done - 41930.
Ep done - 41940.
Ep done - 41950.
Ep done - 41960.
Ep done - 41970.
Ep done - 41980.
Ep done - 41990.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.27       |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 615        |
|    time_elapsed         | 4464       |
|    total_timesteps      | 1259520    |
| train/                  |            |
|    approx_kl            | 0.02796075 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.488     |
|    explained_variance   | 0.149      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0462     |
|    n_updates            | 6140       |
|    policy_gradient_loss | -0.0441    |
|    value_loss           | 0.201      |
----------------------------------------
Ep done - 42000.
Ep done - 42010.
Ep done - 12410.
Ep done - 12420.
Ep done - 12430.
Ep done - 12440.
Ep done - 12450.
Ep done - 12460.
Ep done - 12470.
Ep done - 12480.
Ep done - 12490.
Ep done - 12500.
Ep done - 12510.
Ep done - 12520.
Ep done - 12530.
Ep done - 12540.
Ep done - 12550.
Ep done - 12560.
Ep done - 12570.
Ep done - 12580.
Ep done - 12590.
Ep done - 12600.
Eval num_timesteps=1260000, episode_reward=0.34 +/- 0.93
Episode length: 30.04 +/- 0.54
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.345      |
| time/                   |            |
|    total_timesteps      | 1260000    |
| train/                  |            |
|    approx_kl            | 0.02776324 |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.503     |
|    explained_variance   | 0.174      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0216    |
|    n_updates            | 6150       |
|    policy_gradient_loss | -0.0445    |
|    value_loss           | 0.151      |
----------------------------------------
New best mean reward!
SELFPLAY: mean_reward achieved: 0.345
SELFPLAY: new best model, bumping up generation to 13
Ep done - 42020.
Ep done - 42030.
Ep done - 42040.
Ep done - 42050.
Ep done - 42060.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.1     |
|    ep_rew_mean     | 0.18     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 616      |
|    time_elapsed    | 4484     |
|    total_timesteps | 1261568  |
---------------------------------
Ep done - 42070.
Ep done - 42080.
Ep done - 42090.
Ep done - 42100.
Ep done - 42110.
Ep done - 42120.
Ep done - 42130.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.01       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 617        |
|    time_elapsed         | 4490       |
|    total_timesteps      | 1263616    |
| train/                  |            |
|    approx_kl            | 0.03104126 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.566     |
|    explained_variance   | 0.0903     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0234    |
|    n_updates            | 6160       |
|    policy_gradient_loss | -0.0483    |
|    value_loss           | 0.217      |
----------------------------------------
Ep done - 42140.
Ep done - 42150.
Ep done - 42160.
Ep done - 42170.
Ep done - 42180.
Ep done - 42190.
Ep done - 42200.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | -0.05      |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 618        |
|    time_elapsed         | 4496       |
|    total_timesteps      | 1265664    |
| train/                  |            |
|    approx_kl            | 0.03193061 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.572     |
|    explained_variance   | 0.145      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0272    |
|    n_updates            | 6170       |
|    policy_gradient_loss | -0.0515    |
|    value_loss           | 0.191      |
----------------------------------------
Ep done - 42210.
Ep done - 42220.
Ep done - 42230.
Ep done - 42240.
Ep done - 42250.
Ep done - 42260.
Ep done - 42270.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.21        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 619         |
|    time_elapsed         | 4502        |
|    total_timesteps      | 1267712     |
| train/                  |             |
|    approx_kl            | 0.027899783 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.556      |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00149     |
|    n_updates            | 6180        |
|    policy_gradient_loss | -0.0465     |
|    value_loss           | 0.164       |
-----------------------------------------
Ep done - 42280.
Ep done - 42290.
Ep done - 42300.
Ep done - 42310.
Ep done - 42320.
Ep done - 42330.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.02        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 620         |
|    time_elapsed         | 4509        |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.028588172 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.555      |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0149     |
|    n_updates            | 6190        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.182       |
-----------------------------------------
Ep done - 42340.
Ep done - 42350.
Ep done - 42360.
Ep done - 42370.
Ep done - 42380.
Ep done - 42390.
Ep done - 42400.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.06       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 621         |
|    time_elapsed         | 4516        |
|    total_timesteps      | 1271808     |
| train/                  |             |
|    approx_kl            | 0.022961274 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.558      |
|    explained_variance   | 0.186       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0299     |
|    n_updates            | 6200        |
|    policy_gradient_loss | -0.0468     |
|    value_loss           | 0.183       |
-----------------------------------------
Ep done - 42410.
Ep done - 42420.
Ep done - 42430.
Ep done - 42440.
Ep done - 42450.
Ep done - 42460.
Ep done - 42470.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.13       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 622         |
|    time_elapsed         | 4522        |
|    total_timesteps      | 1273856     |
| train/                  |             |
|    approx_kl            | 0.028382808 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.576      |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0312     |
|    n_updates            | 6210        |
|    policy_gradient_loss | -0.0476     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 42480.
Ep done - 42490.
Ep done - 42500.
Ep done - 42510.
Ep done - 42520.
Ep done - 42530.
Ep done - 42540.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.1         |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 623         |
|    time_elapsed         | 4532        |
|    total_timesteps      | 1275904     |
| train/                  |             |
|    approx_kl            | 0.025751563 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.555      |
|    explained_variance   | 0.275       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000746   |
|    n_updates            | 6220        |
|    policy_gradient_loss | -0.0451     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 42550.
Ep done - 42560.
Ep done - 42570.
Ep done - 42580.
Ep done - 42590.
Ep done - 42600.
Ep done - 42610.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.12       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 624         |
|    time_elapsed         | 4538        |
|    total_timesteps      | 1277952     |
| train/                  |             |
|    approx_kl            | 0.030375853 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.517      |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0155     |
|    n_updates            | 6230        |
|    policy_gradient_loss | -0.0442     |
|    value_loss           | 0.194       |
-----------------------------------------
Ep done - 42620.
Ep done - 42630.
Ep done - 42640.
Ep done - 42650.
Ep done - 42660.
Ep done - 42670.
Ep done - 42680.
Ep done - 12610.
Ep done - 12620.
Ep done - 12630.
Ep done - 12640.
Ep done - 12650.
Ep done - 12660.
Ep done - 12670.
Ep done - 12680.
Ep done - 12690.
Ep done - 12700.
Ep done - 12710.
Ep done - 12720.
Ep done - 12730.
Ep done - 12740.
Ep done - 12750.
Ep done - 12760.
Ep done - 12770.
Ep done - 12780.
Ep done - 12790.
Ep done - 12800.
Eval num_timesteps=1280000, episode_reward=0.04 +/- 0.99
Episode length: 29.96 +/- 0.54
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 0.04       |
| time/                   |            |
|    total_timesteps      | 1280000    |
| train/                  |            |
|    approx_kl            | 0.03238165 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.573     |
|    explained_variance   | 0.22       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0373    |
|    n_updates            | 6240       |
|    policy_gradient_loss | -0.0498    |
|    value_loss           | 0.182      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | -0.1     |
| time/              |          |
|    fps             | 280      |
|    iterations      | 625      |
|    time_elapsed    | 4556     |
|    total_timesteps | 1280000  |
---------------------------------
Ep done - 42690.
Ep done - 42700.
Ep done - 42710.
Ep done - 42720.
Ep done - 42730.
Ep done - 42740.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.03        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 626         |
|    time_elapsed         | 4562        |
|    total_timesteps      | 1282048     |
| train/                  |             |
|    approx_kl            | 0.028237728 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.556      |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00248     |
|    n_updates            | 6250        |
|    policy_gradient_loss | -0.0448     |
|    value_loss           | 0.184       |
-----------------------------------------
Ep done - 42750.
Ep done - 42760.
Ep done - 42770.
Ep done - 42780.
Ep done - 42790.
Ep done - 42800.
Ep done - 42810.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.07       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 627         |
|    time_elapsed         | 4568        |
|    total_timesteps      | 1284096     |
| train/                  |             |
|    approx_kl            | 0.031132046 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.579      |
|    explained_variance   | 0.136       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00284    |
|    n_updates            | 6260        |
|    policy_gradient_loss | -0.0484     |
|    value_loss           | 0.201       |
-----------------------------------------
Ep done - 42820.
Ep done - 42830.
Ep done - 42840.
Ep done - 42850.
Ep done - 42860.
Ep done - 42870.
Ep done - 42880.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 628         |
|    time_elapsed         | 4573        |
|    total_timesteps      | 1286144     |
| train/                  |             |
|    approx_kl            | 0.034514997 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.572      |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0132     |
|    n_updates            | 6270        |
|    policy_gradient_loss | -0.0476     |
|    value_loss           | 0.193       |
-----------------------------------------
Ep done - 42890.
Ep done - 42900.
Ep done - 42910.
Ep done - 42920.
Ep done - 42930.
Ep done - 42940.
Ep done - 42950.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.05       |
| time/                   |            |
|    fps                  | 281        |
|    iterations           | 629        |
|    time_elapsed         | 4579       |
|    total_timesteps      | 1288192    |
| train/                  |            |
|    approx_kl            | 0.02653654 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.549     |
|    explained_variance   | 0.2        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00386    |
|    n_updates            | 6280       |
|    policy_gradient_loss | -0.0462    |
|    value_loss           | 0.178      |
----------------------------------------
Ep done - 42960.
Ep done - 42970.
Ep done - 42980.
Ep done - 42990.
Ep done - 43000.
Ep done - 43010.
Ep done - 43020.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.02       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 630         |
|    time_elapsed         | 4585        |
|    total_timesteps      | 1290240     |
| train/                  |             |
|    approx_kl            | 0.031482376 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.548      |
|    explained_variance   | 0.301       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00879     |
|    n_updates            | 6290        |
|    policy_gradient_loss | -0.0499     |
|    value_loss           | 0.18        |
-----------------------------------------
Ep done - 43030.
Ep done - 43040.
Ep done - 43050.
Ep done - 43060.
Ep done - 43070.
Ep done - 43080.
Ep done - 43090.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.1        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 631         |
|    time_elapsed         | 4591        |
|    total_timesteps      | 1292288     |
| train/                  |             |
|    approx_kl            | 0.030462759 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.563      |
|    explained_variance   | 0.0241      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00831    |
|    n_updates            | 6300        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.204       |
-----------------------------------------
Ep done - 43100.
Ep done - 43110.
Ep done - 43120.
Ep done - 43130.
Ep done - 43140.
Ep done - 43150.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.07       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 632         |
|    time_elapsed         | 4596        |
|    total_timesteps      | 1294336     |
| train/                  |             |
|    approx_kl            | 0.029940693 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.558      |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00395    |
|    n_updates            | 6310        |
|    policy_gradient_loss | -0.0474     |
|    value_loss           | 0.185       |
-----------------------------------------
Ep done - 43160.
Ep done - 43170.
Ep done - 43180.
Ep done - 43190.
Ep done - 43200.
Ep done - 43210.
Ep done - 43220.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.09       |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 633         |
|    time_elapsed         | 4602        |
|    total_timesteps      | 1296384     |
| train/                  |             |
|    approx_kl            | 0.031651467 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.549      |
|    explained_variance   | 0.157       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0113     |
|    n_updates            | 6320        |
|    policy_gradient_loss | -0.0462     |
|    value_loss           | 0.19        |
-----------------------------------------
Ep done - 43230.
Ep done - 43240.
Ep done - 43250.
Ep done - 43260.
Ep done - 43270.
Ep done - 43280.
Ep done - 43290.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.8        |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 634         |
|    time_elapsed         | 4608        |
|    total_timesteps      | 1298432     |
| train/                  |             |
|    approx_kl            | 0.026331231 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.559      |
|    explained_variance   | 0.199       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0197     |
|    n_updates            | 6330        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.198       |
-----------------------------------------
Ep done - 43300.
Ep done - 43310.
Ep done - 43320.
Ep done - 43330.
Ep done - 43340.
Ep done - 12810.
Ep done - 12820.
Ep done - 12830.
Ep done - 12840.
Ep done - 12850.
Ep done - 12860.
Ep done - 12870.
Ep done - 12880.
Ep done - 12890.
Ep done - 12900.
Ep done - 12910.
Ep done - 12920.
Ep done - 12930.
Ep done - 12940.
Ep done - 12950.
Ep done - 12960.
Ep done - 12970.
Ep done - 12980.
Ep done - 12990.
Ep done - 13000.
Eval num_timesteps=1300000, episode_reward=-0.06 +/- 0.98
Episode length: 29.93 +/- 0.53
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.9        |
|    mean_reward          | -0.06       |
| time/                   |             |
|    total_timesteps      | 1300000     |
| train/                  |             |
|    approx_kl            | 0.025408188 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.518      |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00706    |
|    n_updates            | 6340        |
|    policy_gradient_loss | -0.0461     |
|    value_loss           | 0.186       |
-----------------------------------------
Ep done - 43350.
Ep done - 43360.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.22     |
| time/              |          |
|    fps             | 281      |
|    iterations      | 635      |
|    time_elapsed    | 4626     |
|    total_timesteps | 1300480  |
---------------------------------
Ep done - 43370.
Ep done - 43380.
Ep done - 43390.
Ep done - 43400.
Ep done - 43410.
Ep done - 43420.
Ep done - 43430.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 281         |
|    iterations           | 636         |
|    time_elapsed         | 4634        |
|    total_timesteps      | 1302528     |
| train/                  |             |
|    approx_kl            | 0.030345514 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.507      |
|    explained_variance   | 0.227       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00653    |
|    n_updates            | 6350        |
|    policy_gradient_loss | -0.045      |
|    value_loss           | 0.191       |
-----------------------------------------
Ep done - 43440.
Ep done - 43450.
Ep done - 43460.
Ep done - 43470.
Ep done - 43480.
Ep done - 43490.
Ep done - 43500.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.18        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 637         |
|    time_elapsed         | 4644        |
|    total_timesteps      | 1304576     |
| train/                  |             |
|    approx_kl            | 0.029032245 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.532      |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0141     |
|    n_updates            | 6360        |
|    policy_gradient_loss | -0.0466     |
|    value_loss           | 0.191       |
-----------------------------------------
Ep done - 43510.
Ep done - 43520.
Ep done - 43530.
Ep done - 43540.
Ep done - 43550.
Ep done - 43560.
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 0.15       |
| time/                   |            |
|    fps                  | 280        |
|    iterations           | 638        |
|    time_elapsed         | 4653       |
|    total_timesteps      | 1306624    |
| train/                  |            |
|    approx_kl            | 0.02865433 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.526     |
|    explained_variance   | 0.282      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00888    |
|    n_updates            | 6370       |
|    policy_gradient_loss | -0.0467    |
|    value_loss           | 0.181      |
----------------------------------------
Ep done - 43570.
Ep done - 43580.
Ep done - 43590.
Ep done - 43600.
Ep done - 43610.
Ep done - 43620.
Ep done - 43630.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.04       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 639         |
|    time_elapsed         | 4663        |
|    total_timesteps      | 1308672     |
| train/                  |             |
|    approx_kl            | 0.030314427 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.543      |
|    explained_variance   | 0.17        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0231     |
|    n_updates            | 6380        |
|    policy_gradient_loss | -0.0477     |
|    value_loss           | 0.193       |
-----------------------------------------
Ep done - 43640.
Ep done - 43650.
Ep done - 43660.
Ep done - 43670.
Ep done - 43680.
Ep done - 43690.
Ep done - 43700.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.1        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 640         |
|    time_elapsed         | 4673        |
|    total_timesteps      | 1310720     |
| train/                  |             |
|    approx_kl            | 0.032994937 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.537      |
|    explained_variance   | 0.221       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0195      |
|    n_updates            | 6390        |
|    policy_gradient_loss | -0.0492     |
|    value_loss           | 0.195       |
-----------------------------------------
Ep done - 43710.
Ep done - 43720.
Ep done - 43730.
Ep done - 43740.
Ep done - 43750.
Ep done - 43760.
Ep done - 43770.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | -0.03       |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 641         |
|    time_elapsed         | 4682        |
|    total_timesteps      | 1312768     |
| train/                  |             |
|    approx_kl            | 0.028796153 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.531      |
|    explained_variance   | 0.215       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00803     |
|    n_updates            | 6400        |
|    policy_gradient_loss | -0.0457     |
|    value_loss           | 0.198       |
-----------------------------------------
Ep done - 43780.
Ep done - 43790.
Ep done - 43800.
Ep done - 43810.
Ep done - 43820.
Ep done - 43830.
Ep done - 43840.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 0.14        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 642         |
|    time_elapsed         | 4692        |
|    total_timesteps      | 1314816     |
| train/                  |             |
|    approx_kl            | 0.028369807 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.526      |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0153      |
|    n_updates            | 6410        |
|    policy_gradient_loss | -0.0481     |
|    value_loss           | 0.186       |
-----------------------------------------
Ep done - 43850.
Ep done - 43860.
Ep done - 43870.
Ep done - 43880.
Ep done - 43890.
Ep done - 43900.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | 0.08        |
| time/                   |             |
|    fps                  | 280         |
|    iterations           | 643         |
|    time_elapsed         | 4701        |
|    total_timesteps      | 1316864     |
| train/                  |             |
|    approx_kl            | 0.028640838 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.507      |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0217     |
|    n_updates            | 6420        |
|    policy_gradient_loss | -0.0443     |
|    value_loss           | 0.189       |
-----------------------------------------
Ep done - 43910.
Ep done - 43920.
Ep done - 43930.
Ep done - 43940.
Ep done - 43950.
Ep done - 43960.
Ep done - 43970.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 0.07        |
| time/                   |             |
|    fps                  | 279         |
|    iterations           | 644         |
|    time_elapsed         | 4711        |
|    total_timesteps      | 1318912     |
| train/                  |             |
|    approx_kl            | 0.028458625 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.504      |
|    explained_variance   | 0.225       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00275    |
|    n_updates            | 6430        |
|    policy_gradient_loss | -0.0442     |
|    value_loss           | 0.191       |
-----------------------------------------
Ep done - 43980.
Ep done - 43990.
Ep done - 44000.
Ep done - 44010.
Ep done - 13010.
Ep done - 13020.
Ep done - 13030.
Ep done - 13040.
Ep done - 13050.
Ep done - 13060.
Ep done - 13070.
Ep done - 13080.
Ep done - 13090.
Ep done - 13100.
Ep done - 13110.
Ep done - 13120.
Ep done - 13130.
Ep done - 13140.
Ep done - 13150.
Ep done - 13160.
Ep done - 13170.
Ep done - 13180.
Ep done - 13190.
Ep done - 13200.
Eval num_timesteps=1320000, episode_reward=-0.13 +/- 0.98
Episode length: 29.96 +/- 0.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | -0.13       |
| time/                   |             |
|    total_timesteps      | 1320000     |
| train/                  |             |
|    approx_kl            | 0.029562378 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.487      |
|    explained_variance   | 0.106       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00247     |
|    n_updates            | 6440        |
|    policy_gradient_loss | -0.0428     |
|    value_loss           | 0.206       |
-----------------------------------------
Ep done - 44020.
Ep done - 44030.
Ep done - 44040.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 0.02     |
| time/              |          |
|    fps             | 278      |
|    iterations      | 645      |
|    time_elapsed    | 4742     |
|    total_timesteps | 1320960  |
---------------------------------
Ep done - 44050.
Ep done - 44060.
Ep done - 44070.
Ep done - 44080.
Ep done - 44090.
Ep done - 44100.
Ep done - 44110.
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.9        |
|    ep_rew_mean          | -0.01       |
| time/                   |             |
|    fps                  | 278         |
|    iterations           | 646         |
|    time_elapsed         | 4751        |
|    total_timesteps      | 1323008     |
| train/                  |             |
|    approx_kl            | 0.029914357 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.507      |
|    explained_variance   | 0.239       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0139      |
|    n_updates            | 6450        |
|    policy_gradient_loss | -0.0495     |
|    value_loss           | 0.188       |
-----------------------------------------
slurmstepd-n16: error: *** JOB 532 ON n16 CANCELLED AT 2024-06-06T02:14:27 ***
